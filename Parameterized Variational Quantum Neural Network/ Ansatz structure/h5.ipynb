{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586edb7a-4b3b-475e-8736-e85f04cf1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as npp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# set the random seed\n",
    "npp.random.seed(42)\n",
    "\n",
    "# create a device to execute the circuit on\n",
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "@qml.qnode(dev, diff_method=\"parameter-shift\", interface=\"autograd\")\n",
    "def circuit(params,inputs):\n",
    "    qml.RY(inputs[0], wires=0)\n",
    "    qml.RY(inputs[1], wires=1)\n",
    "    qml.RY(inputs[2], wires=2)\n",
    "    qml.RY(inputs[3], wires=3)\n",
    "    \n",
    "\n",
    "    qml.U3(params[0],params[1],params[2], wires=0)\n",
    "    qml.U3(params[3],params[4],params[5], wires=1)\n",
    "    qml.U3(params[6],params[7],params[8], wires=2)\n",
    "    qml.U3(params[9],params[10],params[11], wires=3)\n",
    "    \n",
    "\n",
    "    qml.broadcast(qml.CNOT, wires=[0, 1, 2,3], pattern=\"pyramid\")\n",
    "    '''\n",
    "    qml.RY(inputs[0]*1.5, wires=0)\n",
    "    qml.RY(inputs[1]*1.5, wires=1)\n",
    "    qml.RY(inputs[2]*1.5, wires=2)\n",
    "    qml.RY(inputs[3]*1.5, wires=3)\n",
    "'''\n",
    "    qml.U3(params[12],params[13],params[14], wires=0)\n",
    "    qml.U3(params[15],params[16],params[17], wires=1)\n",
    "    qml.U3(params[18],params[19],params[20], wires=2)\n",
    "    qml.U3(params[21],params[22],params[23], wires=3)\n",
    "\n",
    "    qml.broadcast(qml.CNOT, wires=[0, 1, 2,3], pattern=\"pyramid\")\n",
    "    \n",
    "    '''\n",
    "    qml.RY(inputs[0]*2, wires=0)\n",
    "    qml.RY(inputs[1]*2, wires=1)\n",
    "    qml.RY(inputs[2]*2, wires=2)\n",
    "    qml.RY(inputs[3]*2, wires=3)\n",
    "\n",
    "    qml.U3(params[24],params[25],params[26], wires=0)\n",
    "    qml.U3(params[27],params[28],params[29], wires=1)\n",
    "    qml.U3(params[30],params[31],params[32], wires=2)\n",
    "    qml.U3(params[33],params[34],params[35], wires=3)\n",
    "\n",
    "    qml.broadcast(qml.CNOT, wires=[0, 1, 2, 3], pattern=\"ring\")\n",
    "    '''\n",
    "    #return qml.expval(qml.PauliX(0) @ qml.PauliI(1)@ qml.PauliY(2)@ qml.PauliI(3))\n",
    "    return qml.expval(qml.PauliX(0) @  qml.PauliY(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21f8a3e-a4ab-4c9d-bcf5-73c1b9429ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "def norminv(x):\n",
    "    return ((1.0/math.sqrt(2.0*math.pi)) * math.exp(-x*x*0.5))\n",
    "\n",
    "def d1(S0, K, r, T, sigma, q):\n",
    "    deno = (sigma * math.sqrt(T))\n",
    "    if (deno==0):\n",
    "        return 0\n",
    "    logReturns = math.log(S0/float(K)) if ((S0/float(K)) > 0.0) else 0.0\n",
    "    return (float(logReturns) + (float(r) - float(q) + float(sigma)*float(sigma)*0.5)*float(T)) / float(deno)\n",
    "    \n",
    "def d2(S0, K, r, T, sigma, q):\n",
    "        return d1(S0, K, r, T, sigma, q)-sigma*math.sqrt(T)\n",
    "        \n",
    "def bsformula(callput, S0, K, r, T, sigma, q=0):\n",
    "    N = stats.norm.cdf\n",
    "                \n",
    "    def optionValueOfCall(S0, K, r, T, sigma, q):       \n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        _d2 = d2(S0, K, r, T, sigma, q)\n",
    "        return S0*math.exp(-q*T)*N(_d1)- K*math.exp(-r*T)*N(_d2)\n",
    "      \n",
    "    def optionValueOfPut(S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        _d2 = d2(S0, K, r, T, sigma, q)\n",
    "        return float(K)*math.exp(-float(r)*float(T))*N(-_d2) - float(S0)*math.exp(-float(q)*float(T))*N(-_d1)\n",
    "        \n",
    "    def delta(callput, S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)        \n",
    "        if callput.lower() == \"call\":            \n",
    "            return N(_d1) * math.exp(-q*T)\n",
    "        else:\n",
    "            return (N(_d1)-1)* math.exp(-q*T)\n",
    "    \n",
    "    def vega(S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        return S0  * math.sqrt(T) * norminv(_d1)  * math.exp(-q*T)\n",
    "    \n",
    "    if callput.lower()==\"call\":\n",
    "        optionValue = optionValueOfCall(S0, K, r, T, sigma, q)\n",
    "    else:\n",
    "        optionValue = optionValueOfPut(S0, K, r, T, sigma, q)\n",
    "        \n",
    "    _delta = delta(callput, S0, K, r, T, sigma, q)\n",
    "    _vega = vega(S0, K, r, T, sigma, q)\n",
    "    \n",
    "    return (optionValue, _delta, _vega)\n",
    "\n",
    "def bsm_iv_generator(num_sample = 100,tao_bound=[0.01,2.0],  sigma_bound=[0.01,2.0], \n",
    "                     money_bound=[0.3,3.0], rr_bound=[0.01,0.2], callput='call', seed=42):\n",
    "    \n",
    "    # input parameters: when callput is not in 'call' or 'put', randomly generate the option price followed by root-finding methods to\n",
    "    # compute the corresponding implied vol\n",
    "    # return: X_input = [time,stock,rr, dividen, option_price]. Y_outpu  = volatility \n",
    "    np.random.seed(seed)\n",
    "    tao_min,tao_max = tao_bound[0],tao_bound[1]\n",
    "    \n",
    "    sigma_min, sigma_max = sigma_bound[0],sigma_bound[1]\n",
    "    moneyness_min,moneyness_max = money_bound[0],money_bound[1]\n",
    "    rr_min,rr_max = rr_bound[0],rr_bound[1]\n",
    "   \n",
    "    \n",
    "\n",
    "    num_sample = int(num_sample)\n",
    "    xx = np.zeros([num_sample,4],dtype='float')\n",
    "    \n",
    "   \n",
    "    xx[:,0] = np.random.uniform(sigma_min, sigma_max,xx.shape[0])\n",
    "    xx[:,1] = np.random.uniform(tao_min,tao_max,xx.shape[0])\n",
    "    xx[:,2] = np.random.uniform(moneyness_min,moneyness_max,xx.shape[0])\n",
    "    xx[:,3] = np.random.uniform(rr_min,rr_max,xx.shape[0])\n",
    "   \n",
    "    \n",
    "   \n",
    "    strike=1.0 #fixed strike\n",
    "    #callput = 'call' # call option\n",
    "    v = np.zeros(xx.shape[0]) # option value\n",
    "    k = np.ones(xx.shape[0]) # strike price, just in order to match the shape of v\n",
    "    \n",
    "    if callput in ['call','put']:        \n",
    "        for i in range(0,xx.shape[0]):        \n",
    "            sigma, T, S0, interest = xx[i,0],xx[i,1],xx[i,2],xx[i,3]\n",
    "            ## use the Black-Schole function in compfin.py\n",
    "            v[i] = bsformula(callput, S0, strike, interest, T, sigma)[0]              \n",
    "            \n",
    "  \n",
    "    v= v.reshape(xx.shape[0],1)     \n",
    "    xx_sample = np.concatenate((xx,v),axis=1) #sigma, time, s, r, v\n",
    "    \n",
    "    \n",
    "    X_input   = xx_sample[:,1:]   # time,stock,rr, option_price\n",
    "    Y_output  =  xx_sample[:,0] # sigma -implied volatility is the predictive variable.\n",
    "  \n",
    "    return X_input,Y_output\n",
    "#  log-transformation of the option value\n",
    "def logscale_vol(x_train_dat,y_train_dat,otm_lower=0.0000001):\n",
    "   # input data: x_train_dat = [time,stock,rr, option_price], y_train_dat = sigma  \n",
    "   \n",
    "    xtv_train_log=x_train_dat.copy()    \n",
    "    ytv_train_log =y_train_dat.copy()\n",
    "    \n",
    "    \n",
    "    #v_lower[v_lower<0.0]=0.0 # V=max(S-E*exp(-rt),0)  \n",
    "    xintrinsic_train=xtv_train_log[:,1]-1.0*np.exp(-1.0*xtv_train_log[:,2]*xtv_train_log[:,0])\n",
    "    xintrinsic_train[xintrinsic_train<0.0]=0.0 ## \\tilde{V} = max(S-E*exp(-rt),0)\n",
    "    xtv_train_log[:,-1] = xtv_train_log[:,-1] -xintrinsic_train\n",
    "    \n",
    "    ## remove intrisinc values below the threshold (otm_lower \\approx machine pricision)  \n",
    "   \n",
    "    ytv_train_log = ytv_train_log[~np.less(xtv_train_log[:,-1],otm_lower)]\n",
    "    xtv_train_log = xtv_train_log[~np.less(xtv_train_log[:,-1],otm_lower),:]\n",
    "    xtv_train_log[:,-1]=np.log(xtv_train_log[:,-1])\n",
    "\n",
    "    return xtv_train_log,ytv_train_log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce82ab6f-af86-47ed-9c2c-ddf97780cd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maturity time  range:\n",
      "0.5005522117123602 0.5986886936600517\n",
      "Stock price  range:\n",
      "0.9802780852212476 1.0188712833088385\n",
      "interest rate  range:\n",
      "0.030829391446392806 0.07928252270553005\n",
      "option value  range:\n",
      "0.09746900812834913 0.21773104905666268\n",
      "sigma range:\n",
      "0.308233797718321 0.6879639408647977\n",
      "(50, 4)\n",
      "maturity time  range:\n",
      "0.5005522117123602 0.5986886936600517\n",
      "Stock price  range:\n",
      "0.9802780852212476 1.0188712833088385\n",
      "interest rate  range:\n",
      "0.030829391446392806 0.07928252270553005\n",
      "time option-value  range:\n",
      "-2.614763769983766 -1.672877716398405\n",
      "sigma range:\n",
      "0.308233797718321 0.6879639408647977\n",
      "(40, 4)\n",
      "Parameters: [0.64203165 0.08413996 0.16162871 0.89855419 0.60642906 0.00919705\n",
      " 0.10147154 0.66350177 0.00506158 0.16080805 0.54873379 0.6918952\n",
      " 0.65196126 0.22426931 0.71217922 0.23724909 0.3253997  0.74649141\n",
      " 0.6496329  0.84922341 0.65761289 0.5683086  0.09367477 0.3677158 ]\n",
      "inputs: [0.26520237 0.24398964 0.97301055 0.39309772]\n",
      "Expectation value: -0.3177230950242893\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xin_input,Yin_output=bsm_iv_generator(num_sample = 50,tao_bound=[0.5,0.6],  sigma_bound=[0.3,0.7], \n",
    "                                      money_bound=[0.98,1.02], rr_bound=[0.03,0.08],callput='call')\n",
    "\n",
    "#check the data value range on each dimension\n",
    "## xin = [maturity time, Stock price, interest rate, dividend, option value]\n",
    "\n",
    "xlabel =  ['maturity time', 'Stock price', 'interest rate','option value']\n",
    "for i in range(0, len(xlabel)):\n",
    "    print(xlabel[i]+'  range:')\n",
    "    print(np.min(Xin_input[:,i]),np.max(Xin_input[:,i]))\n",
    "    \n",
    "print('sigma range:')\n",
    "print(np.min(Yin_output),np.max(Yin_output))\n",
    "print(np.shape(Xin_input))\n",
    "\n",
    "# generate and shuffle the data set into training and test part\n",
    "xtv_train_log_all,ytv_train_log_all=logscale_vol(Xin_input,Yin_output,otm_lower=1e-4)\n",
    "'''\n",
    "for i in range(4):\n",
    "    xtv_train_log_all[:,i]= min_max_normalization(xtv_train_log_all[:,i])\n",
    "'''\n",
    "#ytv_train_log_all=ytv_train_log_all/2\n",
    "xtv_train_log,xtv_test_log, ytv_train_log, ytv_test_log   = train_test_split(xtv_train_log_all,ytv_train_log_all,test_size=0.2,random_state=42)\n",
    "\n",
    "xlabel =  ['maturity time', 'Stock price', 'interest rate','time option-value']\n",
    "for i in range(0, len(xlabel)):\n",
    "    print(xlabel[i]+'  range:')\n",
    "    print(np.min(xtv_train_log_all[:,i]),np.max(xtv_train_log_all[:,i]))\n",
    "    \n",
    "print('sigma range:')\n",
    "print(np.min(ytv_train_log),np.max(ytv_train_log))\n",
    "## how many samples after cleaning\n",
    "print(np.shape(xtv_train_log))\n",
    "\n",
    "\n",
    "params = npp.random.random([24], requires_grad=True)\n",
    "inputs = npp.random.random([4], requires_grad=True)\n",
    "print(\"Parameters:\", params)\n",
    "print(\"inputs:\", inputs)\n",
    "print(\"Expectation value:\", circuit(params,inputs))\n",
    "\n",
    "\n",
    "qnode = qml.QNode(circuit, dev)\n",
    "qml.draw_mpl(circuit, decimals=1, style=\"sketch\")(params,inputs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5c5020-7fea-46b3-85c1-c67a90814673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.19603752255519513\n",
      "[-1.96037523e-01 -1.25598342e-01 -3.50789266e-02  3.45149683e-02\n",
      "  3.37177398e-02  8.88773595e-03  3.39784618e-02 -2.84225530e-02\n",
      " -2.67335802e-02 -2.01225577e-01  1.63174468e-01  1.27555138e-01\n",
      "  9.44929434e-05 -1.57689939e-01 -1.25598342e-01 -6.58429621e-02\n",
      "  9.03700216e-03  5.46504132e-02 -1.13037884e-01 -2.59400207e-01\n",
      " -1.46401020e-01 -6.30796563e-02  9.21567104e-02  7.44812408e-02]\n",
      "[-1.96037523e-01 -1.25598342e-01 -3.50789266e-02  3.45149683e-02\n",
      "  3.37177398e-02  8.88773595e-03  3.39784618e-02 -2.84225530e-02\n",
      " -2.67335802e-02 -2.01225577e-01  1.63174468e-01  1.27555138e-01\n",
      "  9.44929434e-05 -1.57689939e-01 -1.25598342e-01 -6.58429621e-02\n",
      "  9.03700216e-03  5.46504132e-02 -1.13037884e-01 -2.59400207e-01\n",
      " -1.46401020e-01 -6.30796563e-02  9.21567104e-02  7.44812408e-02]\n",
      "[-1.96037523e-01 -1.25598342e-01 -3.50789266e-02  3.45149683e-02\n",
      "  3.37177398e-02  8.88773595e-03  3.39784618e-02 -2.84225530e-02\n",
      " -2.67335802e-02 -2.01225577e-01  1.63174468e-01  1.27555138e-01\n",
      "  9.44929434e-05 -1.57689939e-01 -1.25598342e-01 -6.58429621e-02\n",
      "  9.03700216e-03  5.46504132e-02 -1.13037884e-01 -2.59400207e-01\n",
      " -1.46401020e-01 -6.30796563e-02  9.21567104e-02  7.44812408e-02]\n"
     ]
    }
   ],
   "source": [
    "def parameter_shift_term(qnode,params,inputs, i):\n",
    "    shifted = params.copy()\n",
    "    shifted[i] += np.pi/2\n",
    "    forward = qnode(shifted,inputs)  # forward evaluation\n",
    "\n",
    "    shifted[i] -= np.pi\n",
    "    backward = qnode(shifted,inputs) # backward evaluation\n",
    "\n",
    "    return 0.5 * (forward - backward)\n",
    "\n",
    "# gradient with respect to the first parameter\n",
    "print(parameter_shift_term(circuit,params,inputs, 0))\n",
    "\n",
    "\n",
    "def parameter_shift(qnode, params,inputs):\n",
    "    gradients = np.zeros([len(params)])\n",
    "\n",
    "    for i in range(len(params)):\n",
    "        gradients[i] = parameter_shift_term(qnode,params,inputs, i)\n",
    "\n",
    "    return gradients\n",
    "\n",
    "print(parameter_shift(circuit, params,inputs))\n",
    "\n",
    "grad_function = qml.grad(circuit)\n",
    "print(grad_function(params,inputs)[0])\n",
    "\n",
    "\n",
    "print(qml.gradients.param_shift(circuit)(params,inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9715830-fa60-4d48-bbc4-27dc40dbdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from itertools import chain\n",
    "import time\n",
    "def QNN(weights, angles):\n",
    "    return circuit(weights, angles)\n",
    "\n",
    "def cost(weights, features, labels):\n",
    "    predictions = [QNN(weights, f) for f in features]\n",
    "    \n",
    "    return square_loss(labels, predictions)\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def R2(labels, predictions):\n",
    "\n",
    "    r2 = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        r2 = r2 + metrics.r2_score(labels, predictions)\n",
    "    r2 = r2 / len(labels)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48fdbeb0-8d5d-419e-be05-d99d3936b2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=xtv_train_log\n",
    "Y=ytv_train_log\n",
    "weights_init = npp.random.random([24], requires_grad=True)\n",
    "opt = qml.AdamOptimizer(0.01)\n",
    "batch_size = 20\n",
    "batches = len (X) // batch_size\n",
    "X_batches = npp.array_split(npp.arange(len(X)) , batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2218b3c-8997-4af9-84d6-318bffadf9d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.15842303476819658 R2: -11.378371760415444 time: 1703257560.6394541\n",
      "batch_idx: 1 loss: 0.17724478713529807 R2: -9.963558352884508 time: 1703257570.137254\n",
      "Training [0%] Loss: 0.16783391095174732 time: 1703257570.137254\n",
      "weight: [ 0.66171386  0.10385605  0.18129672  0.91809118  0.58645566 -0.01079985\n",
      "  0.12127441  0.6435112  -0.01488222  0.14080857  0.52872678  0.67188547\n",
      "  0.67159476  0.24395345  0.7318953   0.2172414   0.34457035  0.76596678\n",
      "  0.63009235  0.8683607   0.67697015  0.58801571  0.07366752  0.34770849]\n",
      "epoch 2\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.11996821060445073 R2: -8.63566669713003 time: 1703257579.657267\n",
      "batch_idx: 1 loss: 0.13919929279213758 R2: -7.409914859214384 time: 1703257589.18225\n",
      "Training [1%] Loss: 0.12958375169829417 time: 1703257589.18225\n",
      "weight: [ 0.68099578  0.12343244  0.20084286  0.93746148  0.56956244 -0.02701151\n",
      "  0.14090963  0.62369699 -0.03446649  0.12092712  0.50885663  0.65199095\n",
      "  0.69101319  0.26347705  0.75147169  0.20271318  0.36324834  0.78519819\n",
      "  0.61095538  0.88717391  0.69601368  0.60699593  0.05378685  0.32783832]\n",
      "epoch 3\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.08797818931208053 R2: -6.311688334753136 time: 1703257598.136818\n",
      "batch_idx: 1 loss: 0.10781659780306789 R2: -5.345977824612221 time: 1703257607.4923317\n",
      "Training [1%] Loss: 0.09789739355757421 time: 1703257607.4923317\n",
      "weight: [ 0.70056442  0.14317851  0.22053709  0.9565774   0.55641941 -0.03810071\n",
      "  0.16053006  0.60435111 -0.05327337  0.10119347  0.48932038  0.63238341\n",
      "  0.71048711  0.28313615  0.77121777  0.19939368  0.38241423  0.80456684\n",
      "  0.59142181  0.90595855  0.71532617  0.62420728  0.03422014  0.30830199]\n",
      "epoch 4\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.06412296077814238 R2: -4.528805315108619 time: 1703257617.682261\n",
      "batch_idx: 1 loss: 0.08431555262672061 R2: -3.8492796593667533 time: 1703257627.526245\n",
      "Training [1%] Loss: 0.07421925670243149 time: 1703257627.526245\n",
      "weight: [ 0.71981659  0.16260219  0.239853    0.97434744  0.54486778 -0.04696613\n",
      "  0.18012321  0.58592765 -0.07078795  0.08171057  0.47042967  0.61335292\n",
      "  0.72906217  0.30231631  0.79064144  0.2046679   0.40121258  0.82315818\n",
      "  0.57188266  0.92308275  0.73405866  0.63787079  0.01526978  0.28941105]\n",
      "epoch 5\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.04862744021735352 R2: -3.311147353906204 time: 1703257637.099415\n",
      "batch_idx: 1 loss: 0.06839032198005153 R2: -2.8886186693956253 time: 1703257646.1631434\n",
      "Training [2%] Loss: 0.058508881098702524 time: 1703257646.1631434\n",
      "weight: [ 0.73735952  0.18073018  0.25785761  0.98974461  0.5326073  -0.05679901\n",
      "  0.19980439  0.56897671 -0.08651092  0.0626004   0.4525984   0.59530152\n",
      "  0.74515204  0.31989582  0.80876944  0.21347473  0.41809928  0.83948768\n",
      "  0.55347782  0.93677012  0.75078207  0.64598838 -0.00265466  0.27157883]\n",
      "epoch 6\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.04013621229593027 R2: -2.575650366823699 time: 1703257655.273562\n",
      "batch_idx: 1 loss: 0.05844371312436254 R2: -2.3414662691482993 time: 1703257664.4818587\n",
      "Training [2%] Loss: 0.04928996271014641 time: 1703257664.4818587\n",
      "weight: [ 0.75127841  0.1963347   0.27348799  1.00262761  0.51952024 -0.0679505\n",
      "  0.2197779   0.55400923 -0.10008347  0.04397698  0.43629459  0.57870541\n",
      "  0.75743075  0.33461752  0.82437395  0.22037545  0.43134255  0.85230044\n",
      "  0.53840527  0.94718419  0.76419254  0.64757645 -0.01908309  0.25527103]\n",
      "epoch 7\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.03636328847306056 R2: -2.1750640946429525 time: 1703257674.118645\n",
      "batch_idx: 1 loss: 0.05235337227707151 R2: -2.04976276005784 time: 1703257684.2907372\n",
      "Training [2%] Loss: 0.044358330375066035 time: 1703257684.2907372\n",
      "weight: [ 0.76012899  0.20856863  0.28611947  1.01372799  0.50725967 -0.07837493\n",
      "  0.24020711  0.54139691 -0.11133059  0.02591115  0.42195612  0.56403653\n",
      "  0.76558968  0.34575786  0.83660788  0.21907478  0.43982316  0.86126076\n",
      "  0.52942061  0.95646769  0.77383563  0.64318675 -0.03357485  0.24091985]\n",
      "epoch 8\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0349404523412998 R2: -1.95415195173628 time: 1703257694.258323\n",
      "batch_idx: 1 loss: 0.04816443418312482 R2: -1.8705629627709466 time: 1703257704.1003606\n",
      "Training [3%] Loss: 0.04155244326221231 time: 1703257704.1003606\n",
      "weight: [ 0.76360647  0.21742924  0.29590566  1.02405645  0.4983434  -0.0847878\n",
      "  0.26115949  0.53136961 -0.12021961  0.00840627  0.40989762  0.55166354\n",
      "  0.76996526  0.35339295  0.8454685   0.20927604  0.44333599  0.86675777\n",
      "  0.52803686  0.96715151  0.78003976  0.63412698 -0.04582073  0.22883015]\n",
      "epoch 9\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.03403357817218698 R2: -1.7904624619386893 time: 1703257713.3009307\n",
      "batch_idx: 1 loss: 0.044491367447038424 R2: -1.7049254700985177 time: 1703257722.1083317\n",
      "Training [3%] Loss: 0.0392624728096127 time: 1703257722.1083317\n",
      "weight: [ 0.76217635  0.22358812  0.30360054  1.03445638  0.49488545 -0.08467758\n",
      "  0.28263202  0.52406353 -0.12680078 -0.00859921  0.40024855  0.54177363\n",
      "  0.77087382  0.35809184  0.85162738  0.19437015  0.44235171  0.86942424\n",
      "  0.53360792  0.98071565  0.78348082  0.62166628 -0.05570796  0.21911879]\n",
      "epoch 10\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.03255255174512283 R2: -1.6091906863658214 time: 1703257731.413669\n",
      "batch_idx: 1 loss: 0.04058012739460552 R2: -1.5010442155110848 time: 1703257740.429864\n",
      "Training [3%] Loss: 0.03656633956986417 time: 1703257740.429864\n",
      "weight: [ 0.75649504  0.22798662  0.31021355  1.04544152  0.49755991 -0.07799274\n",
      "  0.3045783   0.51954907 -0.13117674 -0.02520524  0.39294297  0.53434545\n",
      "  0.76835367  0.36053189  0.85602587  0.17645978  0.43766715  0.86987668\n",
      "  0.5444466   0.99717819  0.78489979  0.60679043 -0.063325    0.21170726]\n",
      "epoch 11\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.03007276173650032 R2: -1.3792411486774812 time: 1703257749.7185955\n",
      "batch_idx: 1 loss: 0.03621147658879983 R2: -1.2460560910432412 time: 1703257759.498831\n",
      "Training [4%] Loss: 0.03314211916265007 time: 1703257759.498831\n",
      "weight: [ 0.74719735  0.23159542  0.31678311  1.05719757  0.50563085 -0.06625734\n",
      "  0.32691092  0.51781704 -0.13350156 -0.04151409  0.38774805  0.52916828\n",
      "  0.76227779  0.3613194   0.85963468  0.15660718  0.43015167  0.86861113\n",
      "  0.55895701  1.01588065  0.78495983  0.59023465 -0.06892423  0.20635299]\n",
      "epoch 12\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.02666787966064762 R2: -1.1028895410736348 time: 1703257769.37502\n",
      "batch_idx: 1 loss: 0.03155027678470442 R2: -0.9545473849032188 time: 1703257779.1419964\n",
      "Training [4%] Loss: 0.02910907822267602 time: 1703257779.1419964\n",
      "weight: [ 0.73492774  0.2353172   0.3242253   1.06964823  0.51772059 -0.05112557\n",
      "  0.34948986  0.51874016 -0.13399278 -0.05759721  0.38430816  0.52588489\n",
      "  0.75265119  0.36097353  0.86335646  0.13548378  0.42061253  0.86595566\n",
      "  0.57591837  1.03613529  0.78414845  0.57256945 -0.07287046  0.20269547]\n",
      "epoch 13\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.02272930240528483 R2: -0.8040254221342489 time: 1703257788.1154408\n",
      "batch_idx: 1 loss: 0.02698708876774548 R2: -0.6569978008201282 time: 1703257797.344868\n",
      "Training [4%] Loss: 0.024858195586515155 time: 1703257797.344868\n",
      "weight: [ 0.7204065   0.2398836   0.33315118  1.08252375  0.53239817 -0.03398704\n",
      "  0.37210642  0.52202206 -0.13294931 -0.07347135  0.38218814  0.52403783\n",
      "  0.73985227  0.35996402  0.86792285  0.11367979  0.40976008  0.86209247\n",
      "  0.5943695   1.05728276  0.78273013  0.55427549 -0.07559282  0.20030091]\n",
      "epoch 14\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.01880077811677757 R2: -0.5170328387620878 time: 1703257806.3058164\n",
      "batch_idx: 1 loss: 0.02298784247314873 R2: -0.38913999930030135 time: 1703257815.5951335\n",
      "Training [5%] Loss: 0.02089431029496315 time: 1703257815.5951335\n",
      "weight: [ 0.70448873  0.2456691   0.34366051  1.09540166  0.54826928 -0.01613853\n",
      "  0.39446498  0.52713176 -0.13077646 -0.0890856   0.38091038  0.52311037\n",
      "  0.72465983  0.35871977  0.87370836  0.09187324  0.39824423  0.85717283\n",
      "  0.6134161   1.07851481  0.78077858  0.53580028 -0.07754466  0.19870094]\n",
      "epoch 15\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.015428844641701179 R2: -0.27647290310280864 time: 1703257825.3285236\n",
      "batch_idx: 1 loss: 0.01994529222559313 R2: -0.18169006883577232 time: 1703257835.4861524\n",
      "Training [5%] Loss: 0.017687068433647153 time: 1703257835.4861524\n",
      "weight: [ 6.88281194e-01  2.52466215e-01  3.55183383e-01  1.10771526e+00\n",
      "  5.63853042e-01  1.01647876e-03  4.16163838e-01  5.33210006e-01\n",
      " -1.28017360e-01 -1.04319224e-01  3.79988927e-01  5.22564460e-01\n",
      "  7.08248688e-01  3.57570657e-01  8.80505471e-01  7.09510753e-02\n",
      "  3.86745939e-01  8.51509677e-01  6.32037140e-01  1.09867469e+00\n",
      "  7.78296132e-01  5.17597846e-01 -7.91680079e-02  1.97428574e-01]\n",
      "epoch 16\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.013012042233947632 R2: -0.10647712838992351 time: 1703257845.5316975\n",
      "batch_idx: 1 loss: 0.01801479309294455 R2: -0.04913492406795661 time: 1703257854.9951835\n",
      "Training [5%] Loss: 0.015513417663446091 time: 1703257854.9951835\n",
      "weight: [ 0.67333173  0.25931935  0.3663374   1.11874876  0.57759907  0.0160286\n",
      "  0.43668374  0.53894998 -0.12537337 -0.11899199  0.37896704  0.52188369\n",
      "  0.69246393  0.35664715  0.88735861  0.05207379  0.3760987   0.84578423\n",
      "  0.64892438  1.11619492  0.77538212  0.5001463  -0.08085764  0.19605696]\n",
      "epoch 17\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.011635200292776636 R2: -0.009046535937736522 time: 1703257864.1329844\n",
      "batch_idx: 1 loss: 0.016956586805487485 R2: 0.021149694537764607 time: 1703257873.0539362\n",
      "Training [6%] Loss: 0.01429589354913206 time: 1703257873.0539362\n",
      "weight: [ 0.66166674  0.26453521  0.37484867  1.12767797  0.58825197  0.02783671\n",
      "  0.45541463  0.54258879 -0.1236597  -0.1328909   0.37746299  0.52062813\n",
      "  0.68023392  0.35582595  0.89257447  0.03657461  0.36734854  0.84114072\n",
      "  0.66249647  1.1294155   0.77235247  0.48392711 -0.08292297  0.19424318]\n",
      "epoch 18\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.010959277161625284 R2: 0.043389868671046175 time: 1703257882.017023\n",
      "batch_idx: 1 loss: 0.01615579359284013 R2: 0.0682066661892442 time: 1703257891.98288\n",
      "Training [6%] Loss: 0.013557535377232706 time: 1703257891.98288\n",
      "weight: [ 0.65518542  0.266216    0.37824108  1.13375757  0.59531108  0.03620015\n",
      "  0.47177269  0.54239121 -0.12362109 -0.14581744  0.37522043  0.51849741\n",
      "  0.67476351  0.35482227  0.89425525  0.02557218  0.36155995  0.83893652\n",
      "  0.67132593  1.13724007  0.76967674  0.4693475  -0.08555355  0.19177081]\n",
      "epoch 19\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.010390777113969431 R2: 0.09493207841111762 time: 1703257902.108098\n",
      "batch_idx: 1 loss: 0.01501858210638515 R2: 0.13158370223168112 time: 1703257912.3120368\n",
      "Training [6%] Loss: 0.01270467961017729 time: 1703257912.3120368\n",
      "weight: [ 0.65458407  0.26340556  0.37553554  1.13665167  0.59903104  0.04157358\n",
      "  0.48541176  0.53761722 -0.12563928 -0.15764683  0.37214557  0.51537936\n",
      "  0.67703552  0.35342454  0.89144482  0.0194686   0.35931427  0.84004854\n",
      "  0.67483743  1.13951748  0.76769596  0.45662301 -0.08880184  0.18857442]\n",
      "epoch 20\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00954261631691912 R2: 0.17274962013389047 time: 1703257922.272451\n",
      "batch_idx: 1 loss: 0.013403445551205068 R2: 0.2220877635440317 time: 1703257931.6988816\n",
      "Training [7%] Loss: 0.011473030934062094 time: 1703257931.6988816\n",
      "weight: [ 0.65911101  0.25664551  0.36776524  1.13663411  0.59999685  0.04458869\n",
      "  0.4963945   0.52887927 -0.12956523 -0.16837251  0.36830827  0.51135461\n",
      "  0.68543202  0.35168229  0.88468477  0.01779989  0.36035451  0.84433605\n",
      "  0.67355087  1.13685635  0.76636287  0.44569805 -0.09259532  0.18473054]\n",
      "epoch 21\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.008455612682663465 R2: 0.2720197526552332 time: 1703257941.1482913\n",
      "batch_idx: 1 loss: 0.01157248061967335 R2: 0.3241054470877249 time: 1703257951.0296016\n",
      "Training [7%] Loss: 0.010014046651168408 time: 1703257951.0296016\n",
      "weight: [ 0.66728604  0.247378    0.35683252  1.1344467   0.59878505  0.04571701\n",
      "  0.50517922  0.5175521  -0.13482884 -0.17811258  0.36390516  0.5066542\n",
      "  0.69760271  0.34987339  0.87541725  0.01952664  0.36376238  0.85083169\n",
      "  0.66867272  1.13028356  0.76529069  0.43626815 -0.09677205  0.18041974]\n",
      "epoch 22\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.007388013838786868 R2: 0.3719591386145198 time: 1703257960.9954789\n",
      "batch_idx: 1 loss: 0.009861584492431118 R2: 0.41714608702943334 time: 1703257971.2001243\n",
      "Training [7%] Loss: 0.008624799165608992 time: 1703257971.2001243\n",
      "weight: [ 0.67753203  0.2372158   0.34464045  1.13098771  0.59589486  0.04527202\n",
      "  0.51245828  0.50515573 -0.14069301 -0.18708062  0.35920412  0.50159428\n",
      "  0.71141218  0.34831519  0.86525505  0.02340584  0.36838519  0.85826836\n",
      "  0.66160291  1.12102223  0.76403838  0.42788079 -0.10112364  0.17587841]\n",
      "epoch 23\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.006541550664873294 R2: 0.4559390198967468 time: 1703257980.6109607\n",
      "batch_idx: 1 loss: 0.008459468101167515 R2: 0.4903906510146535 time: 1703257990.2291188\n",
      "Training [8%] Loss: 0.007500509383020404 time: 1703257990.2291188\n",
      "weight: [ 0.68843915  0.22751     0.33276003  1.12706127  0.59178658  0.0435315\n",
      "  0.51897131  0.49302776 -0.14647818 -0.19553718  0.35448863  0.49651055\n",
      "  0.72510124  0.34719109  0.85554926  0.02823566  0.3731731   0.86548975\n",
      "  0.65365557  1.11036564  0.76236377  0.420053   -0.1054353   0.17135287]\n",
      "epoch 24\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.005958195805246645 R2: 0.5191577026025517 time: 1703258000.1110797\n",
      "batch_idx: 1 loss: 0.00738078628823092 R2: 0.5442997150343666 time: 1703258009.3799996\n",
      "Training [8%] Loss: 0.006669491046738783 time: 1703258009.3799996\n",
      "weight: [ 0.69888214  0.21911617  0.32224448  1.12325258  0.58687156  0.0407794\n",
      "  0.52536395  0.48214223 -0.15168941 -0.20373862  0.35001184  0.49170377\n",
      "  0.73738753  0.34649294  0.84715543  0.03299662  0.37735216  0.87166749\n",
      "  0.64592133  1.09957011  0.76028921  0.41236416 -0.10951839  0.16706146]\n",
      "epoch 25\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.005560314332965804 R2: 0.565916226590827 time: 1703258019.1356964\n",
      "batch_idx: 1 loss: 0.006540794104821025 R2: 0.5855013765735901 time: 1703258029.2294304\n",
      "Training [8%] Loss: 0.006050554218893414 time: 1703258029.2294304\n",
      "weight: [ 0.70809634  0.21236729  0.31358292  1.1199047   0.58144158  0.0372486\n",
      "  0.53210519  0.4730449  -0.15604738 -0.21189473  0.34596466  0.48740163\n",
      "  0.74753914  0.34607457  0.84040655  0.03693964  0.38045714  0.87634354\n",
      "  0.63918716  1.0897128   0.75800548  0.4045107  -0.11323299  0.16316786]\n",
      "epoch 26\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.005233420948020463 R2: 0.603727412578284 time: 1703258038.9771786\n",
      "batch_idx: 1 loss: 0.005837683152016675 R2: 0.62123950562842 time: 1703258048.3351948\n",
      "Training [9%] Loss: 0.005535552050018569 time: 1703258048.3351948\n",
      "weight: [ 0.71570118  0.20722356  0.30682421  1.11715369  0.57561174  0.03305374\n",
      "  0.53945434  0.46590588 -0.15945761 -0.22014052  0.34245909  0.48373809\n",
      "  0.7553223   0.3457521   0.83526282  0.03963166  0.38228172  0.87935792\n",
      "  0.63389864  1.0815274   0.7557273   0.39632693 -0.11649946  0.15976692]\n",
      "epoch 27\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.004890174026496793 R2: 0.638713558156894 time: 1703258057.5191574\n",
      "batch_idx: 1 loss: 0.005203199760098494 R2: 0.6559973334569447 time: 1703258066.557928\n",
      "Training [9%] Loss: 0.005046686893297644 time: 1703258066.557928\n",
      "weight: [ 0.72165812  0.2034699   0.30177073  1.11498619  0.56934016  0.02819103\n",
      "  0.54746514  0.46063092 -0.16195864 -0.22852313  0.33952525  0.48074909\n",
      "  0.76085687  0.34539054  0.83150916  0.04095288  0.38281168  0.88075256\n",
      "  0.63017067  1.07529664  0.75359063  0.38778154 -0.11929958  0.15688246]\n",
      "epoch 28\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.004498733446262503 R2: 0.6735138098270036 time: 1703258076.19703\n",
      "batch_idx: 1 loss: 0.004616994158658846 R2: 0.6906167974024972 time: 1703258086.3077486\n",
      "Training [9%] Loss: 0.004557863802460675 time: 1703258086.3077486\n",
      "weight: [ 0.72618466  0.20085879  0.2981347   1.11329828  0.56252995  0.02261725\n",
      "  0.55601537  0.45696598 -0.16367525 -0.23700279  0.33711984  0.47838222\n",
      "  0.76447109  0.34494879  0.82889804  0.04105015  0.3821772   0.88070729\n",
      "  0.62784051  1.07086276  0.7516208   0.37895885 -0.12166886  0.15447533]\n",
      "epoch 29\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.004078581065511478 R2: 0.7074598544140719 time: 1703258096.3218036\n",
      "batch_idx: 1 loss: 0.004093683025307561 R2: 0.7233141002221021 time: 1703258106.0875509\n",
      "Training [10%] Loss: 0.004086132045409519 time: 1703258106.0875509\n",
      "weight: [ 0.72965675  0.19917235  0.2956204   1.11194588  0.55517049  0.01637045\n",
      "  0.56485129  0.45456668 -0.16478494 -0.24546543  0.33514318  0.47651681\n",
      "  0.76660328  0.34448163  0.8272116   0.04026343  0.38062725  0.8795144\n",
      "  0.62654508  1.06774041  0.74975864  0.3700311  -0.12368264  0.15245908]\n",
      "epoch 30\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0036759179411823702 R2: 0.7381663310461547 time: 1703258115.1314292\n",
      "batch_idx: 1 loss: 0.003657262886338866 R2: 0.7515734416108055 time: 1703258124.079741\n",
      "Training [10%] Loss: 0.003666590413760618 time: 1703258124.079741\n",
      "weight: [ 0.73251904  0.19822372  0.29394732  1.11078293  0.54746033  0.00967889\n",
      "  0.57363861  0.45303698 -0.16549496 -0.25374419  0.33346133  0.47499043\n",
      "  0.76774742  0.34411096  0.82626297  0.03904299  0.37851332  0.8775716\n",
      "  0.62580561  1.06527491  0.74791732  0.36122588 -0.12543879  0.15071985]\n",
      "epoch 31\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0033343082420183717 R2: 0.7634573694215974 time: 1703258133.906662\n",
      "batch_idx: 1 loss: 0.0033177193187636303 R2: 0.7738760541892911 time: 1703258143.824408\n",
      "Training [10%] Loss: 0.003326013780391001 time: 1703258143.824408\n",
      "weight: [ 0.73520802  0.1978321   0.29284513  1.10968657  0.53986418  0.00301232\n",
      "  0.5820159   0.45195639 -0.16602297 -0.26164724  0.33193011  0.47362774\n",
      "  0.76841701  0.34398134  0.82587136  0.03786736  0.37626611  0.87536799\n",
      "  0.62511182  1.06280144  0.74604157  0.35279078 -0.12703981  0.14913736]\n",
      "epoch 32\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.003073942586599023 R2: 0.7827106560225863 time: 1703258153.929152\n",
      "batch_idx: 1 loss: 0.003060298420214701 R2: 0.7905323409418522 time: 1703258163.6387668\n",
      "Training [11%] Loss: 0.0030671205034068618 time: 1703258163.6387668\n",
      "weight: [ 0.73808813  0.1978038   0.29205074  1.1085701   0.53307277 -0.00295584\n",
      "  0.58964892  0.45091586 -0.16657497 -0.26898926  0.33041823  0.47226863\n",
      "  0.76910233  0.34421507  0.82584305  0.03716597  0.37434962  0.87343955\n",
      "  0.62400317  1.05977885  0.74414439  0.34495646 -0.12857668  0.14760422]\n",
      "epoch 33\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0028868288142710097 R2: 0.7971122933320549 time: 1703258172.4784198\n",
      "batch_idx: 1 loss: 0.002851137355301884 R2: 0.8033629554562791 time: 1703258181.5241961\n",
      "Training [11%] Loss: 0.002868983084786447 time: 1703258181.5241961\n",
      "weight: [ 0.74140387  0.1979395   0.29132509  1.10738563  0.52784843 -0.00749264\n",
      "  0.59628291  0.44957249 -0.16731801 -0.27562307  0.32882684  0.47079208\n",
      "  0.77021012  0.34488017  0.82597876  0.03725148  0.37318495  0.87228262\n",
      "  0.62214276  1.05587695  0.74230479  0.33790083 -0.13011635  0.14604116]\n",
      "epoch 34\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0027476657289280545 R2: 0.8088364464503359 time: 1703258190.6673183\n",
      "batch_idx: 1 loss: 0.0026549829151335373 R2: 0.8145248028994159 time: 1703258201.196816\n",
      "Training [11%] Loss: 0.002701324322030796 time: 1703258201.196816\n",
      "weight: [ 0.74525507  0.19806783  0.2904886   1.10612005  0.52477894 -0.01003366\n",
      "  0.6017851   0.44771299 -0.16835268 -0.28146645  0.32710297  0.4691328\n",
      "  0.77199692  0.34597883  0.82610709  0.03827224  0.37305614  0.87224033\n",
      "  0.61937147  1.0510029   0.74062822  0.33171974 -0.13169434  0.14440641]\n",
      "epoch 35\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0026323265157981277 R2: 0.8197178173694717 time: 1703258211.38111\n",
      "batch_idx: 1 loss: 0.0024533463643605477 R2: 0.8252754821549504 time: 1703258222.0591319\n",
      "Training [12%] Loss: 0.0025428364400793377 time: 1703258222.0591319\n",
      "weight: [ 0.74960079  0.19808483  0.28945565  1.10478737  0.52404569 -0.01039703\n",
      "  0.60616584  0.44529685 -0.16969639 -0.28651766  0.32524452  0.46728746\n",
      "  0.77452493  0.34745491  0.82612409  0.04019671  0.37403462  0.87340927\n",
      "  0.61572677  1.04527299  0.73919311  0.3264116  -0.13331308  0.14269807]\n",
      "epoch 36\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0025311290908424313 R2: 0.8303293569309647 time: 1703258232.8690286\n",
      "batch_idx: 1 loss: 0.002250419370988196 R2: 0.8355343230789041 time: 1703258243.1199636\n",
      "Training [12%] Loss: 0.002390774230915314 time: 1703258243.1199636\n",
      "weight: [ 0.75429089  0.19797244  0.2882436   1.10341974  0.52534506 -0.00885707\n",
      "  0.60956972  0.44245113 -0.17128762 -0.29085441  0.32329545  0.46530899\n",
      "  0.7776665   0.34921202  0.82601169  0.04283522  0.37596242  0.87561833\n",
      "  0.61141846  1.03895356  0.73801553  0.32188215 -0.13494622  0.1409493 ]\n",
      "epoch 37\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0024482452843012535 R2: 0.8400808735292596 time: 1703258253.0892687\n",
      "batch_idx: 1 loss: 0.002063699681355036 R2: 0.8444504955761476 time: 1703258263.2365525\n",
      "Training [12%] Loss: 0.002255972482828145 time: 1703258263.2365525\n",
      "weight: [ 0.75911566  0.19778336  0.28694718  1.10205802  0.52799875 -0.00604321\n",
      "  0.6122374   0.43941398 -0.17301181 -0.29461564  0.32133219  0.46329009\n",
      "  0.78115999  0.3511334   0.82582261  0.04589259  0.37850538  0.8784928\n",
      "  0.60676905  1.03239417  0.73705024  0.31796907 -0.13654767  0.13921736]\n",
      "epoch 38\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002390590597955311 R2: 0.8480916193177958 time: 1703258273.2548018\n",
      "batch_idx: 1 loss: 0.0019087548907979822 R2: 0.8513517565612743 time: 1703258283.5169413\n",
      "Training [13%] Loss: 0.0021496727443766463 time: 1703258283.5169413\n",
      "weight: [ 0.7638594   0.1976028   0.28569134  1.1007431   0.5311663  -0.00274144\n",
      "  0.61444991  0.43645292 -0.17473832 -0.29797075  0.31944466  0.46134008\n",
      "  0.7846941   0.35310016  0.82564206  0.04903639  0.38125093  0.88157038\n",
      "  0.60213707  1.02596382  0.73621974  0.31447962 -0.13806352  0.13756929]\n",
      "epoch 39\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002357562119638585 R2: 0.8540111979925766 time: 1703258293.325893\n",
      "batch_idx: 1 loss: 0.0017900958121717966 R2: 0.8562791576989259 time: 1703258302.525597\n",
      "Training [13%] Loss: 0.0020738289659051907 time: 1703258302.525597\n",
      "weight: [ 7.68344794e-01  1.97509652e-01  2.84586131e-01  1.09950886e+00\n",
      "  5.34057463e-01  3.06428207e-04  6.16470968e-01  4.33792581e-01\n",
      " -1.76354039e-01 -3.01084761e-01  3.17716466e-01  4.59560804e-01\n",
      "  7.87989510e-01  3.55007844e-01  8.25548909e-01  5.19637506e-02\n",
      "  3.83810732e-01  8.84419897e-01  5.97844221e-01  1.01999206e+00\n",
      "  7.35447668e-01  3.11230552e-01 -1.39444146e-01  1.36067031e-01]\n",
      "epoch 40\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002339499383450007 R2: 0.8582105988479942 time: 1703258311.4341326\n",
      "batch_idx: 1 loss: 0.0017021832084415662 R2: 0.8598510751570277 time: 1703258320.649759\n",
      "Training [13%] Loss: 0.0020208412959457868 time: 1703258320.649759\n",
      "weight: [ 0.77245969  0.19755317  0.28369987  1.09837777  0.53608672  0.00254952\n",
      "  0.618501    0.43157383 -0.17778425 -0.30408792  0.31620882  0.45802701\n",
      "  0.79085481  0.35678053  0.82559243  0.05445292  0.385898    0.88672768\n",
      "  0.59412145  1.01471903  0.73467879  0.3080808  -0.14065403  0.13475539]\n",
      "epoch 41\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0023237355119186238 R2: 0.8614087293739565 time: 1703258329.7850893\n",
      "batch_idx: 1 loss: 0.0016361619081188181 R2: 0.8627676292900182 time: 1703258339.8304164\n",
      "Training [14%] Loss: 0.001979948710018721 time: 1703258339.8304164\n",
      "weight: [ 0.77616469  0.1977469   0.28305235  1.0973593   0.53695055  0.0037018\n",
      "  0.62065058  0.42984543 -0.17899913 -0.30705599  0.31495097  0.45677464\n",
      "  0.79320967  0.3583795   0.82578616  0.05639141  0.38736728  0.88833938\n",
      "  0.59108179  1.01026319  0.73388344  0.30495098 -0.14167766  0.13365473]\n",
      "epoch 42\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0023019089541556166 R2: 0.8641751840118841 time: 1703258349.935104\n",
      "batch_idx: 1 loss: 0.0015857289739116716 R2: 0.8654081163742904 time: 1703258359.2551153\n",
      "Training [14%] Loss: 0.001943818964033644 time: 1703258359.2551153\n",
      "weight: [ 0.77948457  0.19807234  0.28262036  1.09645075  0.53663453  0.00374985\n",
      "  0.62293542  0.42857689 -0.18000998 -0.31000404  0.31393817  0.45579834\n",
      "  0.79508086  0.35980379  0.82611159  0.05777902  0.38821931  0.88926236\n",
      "  0.58871984  1.00661537  0.73305437  0.30182797 -0.14252069  0.13275949]\n",
      "epoch 43\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0022732651965452254 R2: 0.8666827558362412 time: 1703258368.3929787\n",
      "batch_idx: 1 loss: 0.0015485699176321281 R2: 0.8677605909937638 time: 1703258377.3163204\n",
      "Training [14%] Loss: 0.0019109175570886767 time: 1703258377.3163204\n",
      "weight: [ 0.7824895   0.19848512  0.28234769  1.09563995  0.53537109  0.00291424\n",
      "  0.62529034  0.42767995 -0.18085964 -0.31289312  0.31313653  0.45505739\n",
      "  0.79658095  0.36108225  0.82652437  0.05870932  0.3885797   0.88964038\n",
      "  0.58693305  1.00366077  0.73220361  0.29875592 -0.14320676  0.13204199]\n",
      "epoch 44\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002242804855753629 R2: 0.8687978056899108 time: 1703258386.5547552\n",
      "batch_idx: 1 loss: 0.001523978895170266 R2: 0.869632256914208 time: 1703258395.8767562\n",
      "Training [15%] Loss: 0.0018833918754619476 time: 1703258395.8767562\n",
      "weight: [ 0.78527187  0.19892171  0.28215637  1.09490914  0.53356645  0.00158106\n",
      "  0.6275972   0.42703201 -0.18161028 -0.31564746  0.31249309  0.45448784\n",
      "  0.79787697  0.36226008  0.82696096  0.05933611  0.38865956  0.88971011\n",
      "  0.58555722  1.00122103  0.73136059  0.2958172  -0.14377107  0.13146026]\n",
      "epoch 45\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0022166703757385948 R2: 0.8703506627923371 time: 1703258405.054195\n",
      "batch_idx: 1 loss: 0.0015097284236488605 R2: 0.8709196303531614 time: 1703258414.9008904\n",
      "Training [15%] Loss: 0.0018631993996937276 time: 1703258414.9008904\n",
      "weight: [ 7.87924056e-01  1.99308872e-01  2.81960055e-01  1.09423911e+00\n",
      "  5.31705044e-01  2.11165619e-04  6.29720033e-01  4.26500478e-01\n",
      " -1.82329783e-01 -3.18177655e-01  3.11948449e-01  4.54018047e-01\n",
      "  7.99153406e-01  3.63384350e-01  8.27348128e-01  5.98327498e-02\n",
      "  3.88704306e-01  8.89745332e-01  5.84408513e-01  9.99103101e-01\n",
      "  7.30567603e-01  2.93107418e-01 -1.44252358e-01  1.30967800e-01]\n",
      "epoch 46\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021983038997622963 R2: 0.8713489238216114 time: 1703258424.5971007\n",
      "batch_idx: 1 loss: 0.0015010698206037432 R2: 0.8717298614255855 time: 1703258433.949965\n",
      "Training [15%] Loss: 0.0018496868601830198 time: 1703258433.949965\n",
      "weight: [ 7.90521016e-01  1.99577697e-01  2.81680244e-01  1.09361306e+00\n",
      "  5.30238253e-01 -7.65823185e-04  6.31540306e-01  4.25967914e-01\n",
      " -1.83077875e-01 -3.20404983e-01  3.11449516e-01  4.53584104e-01\n",
      "  8.00573541e-01  3.64492836e-01  8.27616953e-01  6.03522809e-02\n",
      "  3.88937258e-01  8.89995230e-01  5.83324490e-01  9.97141953e-01\n",
      "  7.29869292e-01  2.90710005e-01 -1.44685119e-01  1.30523250e-01]\n",
      "epoch 47\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002187582794431755 R2: 0.8719895448416326 time: 1703258442.949851\n",
      "batch_idx: 1 loss: 0.0014925371194781927 R2: 0.8722967241504523 time: 1703258452.003976\n",
      "Training [16%] Loss: 0.0018400599569549738 time: 1703258452.003976\n",
      "weight: [ 7.93110260e-01  1.99679805e-01  2.81262786e-01  1.09301945e+00\n",
      "  5.29476296e-01 -1.05457348e-03  6.32984963e-01  4.25354515e-01\n",
      " -1.83894326e-01 -3.22281386e-01  3.10959518e-01  4.53142086e-01\n",
      "  8.02246455e-01  3.65608483e-01  8.27719061e-01  6.09962719e-02\n",
      "  3.89509287e-01  8.90628440e-01  5.82196133e-01  9.95228378e-01\n",
      "  7.29297648e-01  2.88675469e-01 -1.45093568e-01  1.30097771e-01]\n",
      "epoch 48\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021825508043757467 R2: 0.872506436770817 time: 1703258461.4126208\n",
      "batch_idx: 1 loss: 0.001480756048976592 R2: 0.8728063877521872 time: 1703258471.301273\n",
      "Training [16%] Loss: 0.0018316534266761694 time: 1703258471.301273\n",
      "weight: [ 7.95710201e-01  1.99599357e-01  2.80688686e-01  1.09245326e+00\n",
      "  5.29516272e-01 -5.62427481e-04  6.34041084e-01  4.24631422e-01\n",
      " -1.84792293e-01 -3.23800572e-01  3.10463243e-01  4.52674430e-01\n",
      "  8.04208832e-01  3.66739189e-01  8.27638613e-01  6.17988035e-02\n",
      "  3.90468441e-01  8.91698975e-01  5.80984235e-01  9.93319251e-01\n",
      "  7.28859477e-01  2.87010175e-01 -1.45488646e-01  1.29678803e-01]\n",
      "epoch 49\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021815177670512177 R2: 0.873016538954901 time: 1703258480.594952\n",
      "batch_idx: 1 loss: 0.0014657722075292437 R2: 0.8733001488326904 time: 1703258489.4077733\n",
      "Training [16%] Loss: 0.0018236449872902306 time: 1703258489.4077733\n",
      "weight: [ 7.98315749e-01  1.99354630e-01  2.79974119e-01  1.09191536e+00\n",
      "  5.30234784e-01  5.93491231e-04  6.34754302e-01  4.23819275e-01\n",
      " -1.85759107e-01 -3.24997858e-01  3.09966572e-01  4.52189370e-01\n",
      "  8.06427583e-01  3.67880889e-01  8.27393886e-01  6.27285164e-02\n",
      "  3.91759495e-01  8.93145743e-01  5.79716859e-01  9.91432292e-01\n",
      "  7.28533491e-01  2.85676960e-01 -1.45868437e-01  1.29269591e-01]\n",
      "epoch 50\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021836647041366133 R2: 0.8734952512280317 time: 1703258498.8728647\n",
      "batch_idx: 1 loss: 0.0014500226050999856 R2: 0.8737179843897213 time: 1703258508.1609719\n",
      "Training [17%] Loss: 0.0018168436546182995 time: 1703258508.1609719\n",
      "weight: [ 0.80090835  0.19898813  0.27915938  1.09141032  0.53134638  0.00214156\n",
      "  0.6352127   0.42297257 -0.18676403 -0.32593961  0.30949093  0.45171415\n",
      "  0.80882157  0.36902195  0.82702739  0.06370661  0.39325242  0.8948247\n",
      "  0.57847013  0.98962949  0.72827878  0.28460656 -0.14622156  0.12888502]\n",
      "epoch 51\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021882247669915986 R2: 0.8738688981918228 time: 1703258517.79061\n",
      "batch_idx: 1 loss: 0.001436194193538984 R2: 0.8740073544695722 time: 1703258527.7122595\n",
      "Training [17%] Loss: 0.0018122094802652913 time: 1703258527.7122595\n",
      "weight: [ 0.80346691  0.19855034  0.27829213  1.09094352  0.53250059  0.00374768\n",
      "  0.63552212  0.42215679 -0.18776974 -0.32670606  0.30906464  0.45128445\n",
      "  0.81129323  0.37014787  0.82658959  0.06463427  0.39478764  0.89655965\n",
      "  0.57733958  0.98799372  0.72804959  0.28371573 -0.14653234  0.1285452 ]\n",
      "epoch 52\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002193657587650482 R2: 0.8741130134162569 time: 1703258537.1245823\n",
      "batch_idx: 1 loss: 0.001425757782460311 R2: 0.8741861376116628 time: 1703258546.1063507\n",
      "Training [17%] Loss: 0.0018097076850553966 time: 1703258546.1063507\n",
      "weight: [ 0.80597642  0.19808439  0.27741207  1.09051866  0.5333807   0.00510915\n",
      "  0.63578046  0.42142752 -0.18874331 -0.32737288  0.30871378  0.45093322\n",
      "  0.81375838  0.37124575  0.82612365  0.06542104  0.39622172  0.89819298\n",
      "  0.57641104  0.98660336  0.72780874  0.28292642 -0.14678632  0.12826873]\n",
      "epoch 53\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021978417379107814 R2: 0.8742732991022699 time: 1703258555.2128098\n",
      "batch_idx: 1 loss: 0.0014188602760252806 R2: 0.8743221594204978 time: 1703258564.319099\n",
      "Training [18%] Loss: 0.001808351006968031 time: 1703258564.319099\n",
      "weight: [ 0.80843257  0.19761696  0.27654203  1.09013628  0.53377564  0.00602336\n",
      "  0.63605775  0.42081755 -0.1896636  -0.3279963   0.30845495  0.45068186\n",
      "  0.81616577  0.37230809  0.82565622  0.0660069   0.3974603   0.89962167\n",
      "  0.57573891  0.98551042  0.72753477  0.2821809  -0.14697462  0.12806728]\n",
      "epoch 54\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021990547442316006 R2: 0.8744180340914223 time: 1703258573.4221048\n",
      "batch_idx: 1 loss: 0.001414996696393428 R2: 0.8744740061909513 time: 1703258582.8054101\n",
      "Training [18%] Loss: 0.0018070257203125144 time: 1703258582.8054101\n",
      "weight: [ 0.81084205  0.19715616  0.2756862   1.08979359  0.5336126   0.00641923\n",
      "  0.636386    0.42033346 -0.19052402 -0.32860514  0.30829153  0.45053561\n",
      "  0.81850339  0.37333475  0.82519542  0.06637344  0.39847263  0.90081258\n",
      "  0.57533563  0.9847272   0.72722238  0.28144979 -0.14709628  0.12794268]\n",
      "epoch 55\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002196810247272696 R2: 0.8745845748101889 time: 1703258593.1959434\n",
      "batch_idx: 1 loss: 0.0014135672730346512 R2: 0.8746550497201762 time: 1703258603.4693038\n",
      "Training [18%] Loss: 0.0018051887601536736 time: 1703258603.4693038\n",
      "weight: [ 0.81321958  0.19669469  0.27483365  1.08948523  0.53295139  0.00635242\n",
      "  0.63675974  0.41995932 -0.19133117 -0.32920056  0.30821366  0.4504835\n",
      "  0.82079344  0.37433277  0.82473395  0.06654339  0.39928815  0.90179813\n",
      "  0.57517312  0.98422459  0.72687864  0.28073202 -0.14715827  0.12788692]\n",
      "epoch 56\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021919099489881104 R2: 0.8747665403600321 time: 1703258612.6493468\n",
      "batch_idx: 1 loss: 0.001413942521489812 R2: 0.8748434989181918 time: 1703258622.0774634\n",
      "Training [19%] Loss: 0.0018029262352389612 time: 1703258622.0774634\n",
      "weight: [ 0.81558327  0.19621574  0.27396456  1.08920467  0.53195007  0.00597277\n",
      "  0.63714541  0.41966459 -0.19210086 -0.3297626   0.30820157  0.45050244\n",
      "  0.82307998  0.37531407  0.82425499  0.06657029  0.39997969  0.9026576\n",
      "  0.57519357  0.98394112  0.72651771  0.28004802 -0.14717355  0.12788459]\n",
      "epoch 57\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021858008353405427 R2: 0.8749398120526879 time: 1703258631.5376947\n",
      "batch_idx: 1 loss: 0.001415279274135241 R2: 0.8750164397408178 time: 1703258641.151381\n",
      "Training [19%] Loss: 0.001800540054737892 time: 1703258641.151381\n",
      "weight: [ 0.81795013  0.19569955  0.27305698  1.08894552  0.53081355  0.00547541\n",
      "  0.63749608  0.41941356 -0.19285256 -0.33026084  0.30823088  0.45056368\n",
      "  0.82541384  0.37629218  0.8237388   0.06652218  0.40063921  0.90349075\n",
      "  0.57532579  0.98379952  0.72615567  0.27942875 -0.14715782  0.12791682]\n",
      "epoch 58\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002179800064927245 R2: 0.8750939373328747 time: 1703258651.129609\n",
      "batch_idx: 1 loss: 0.0014165106823182598 R2: 0.8751726244918853 time: 1703258661.1091933\n",
      "Training [19%] Loss: 0.0017981553736227524 time: 1703258661.1091933\n",
      "weight: [ 0.82033298  0.19512943  0.27209263  1.08870254  0.52973813  0.00504765\n",
      "  0.63776723  0.41917429 -0.19360407 -0.33066616  0.30827834  0.45063979\n",
      "  0.82783875  0.37727909  0.82316869  0.06646406  0.4013527   0.90439046\n",
      "  0.57550242  0.98372505  0.72580612  0.27890374 -0.14712603  0.12796565]\n",
      "epoch 59\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021746757742461334 R2: 0.8752408398981005 time: 1703258670.1960366\n",
      "batch_idx: 1 loss: 0.0014166547574424447 R2: 0.8753285130325251 time: 1703258679.4348965\n",
      "Training [20%] Loss: 0.001795665265844289 time: 1703258679.4348965\n",
      "weight: [ 0.82273941  0.19449594  0.27106073  1.08847201  0.52886452  0.00482384\n",
      "  0.63792942  0.41892539 -0.19436717 -0.33096037  0.30832656  0.45071048\n",
      "  0.83038181  0.37828315  0.8225352   0.06644346  0.40218008  0.90542112\n",
      "  0.5756738   0.98366093  0.72547718  0.27849129 -0.1470895   0.12801755]\n",
      "epoch 60\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021706625483200828 R2: 0.8754001805060438 time: 1703258688.4684467\n",
      "batch_idx: 1 loss: 0.0014152149612044072 R2: 0.8754994307518773 time: 1703258697.4904218\n",
      "Training [20%] Loss: 0.0017929387547622449 time: 1703258697.4904218\n",
      "weight: [ 0.82517262  0.19379837  0.26995902  1.08825151  0.5282508   0.00485934\n",
      "  0.63797523  0.41865907 -0.19514559 -0.33114159  0.30836661  0.45076574\n",
      "  0.83305024  0.3793084   0.82183763  0.06648238  0.40314476  0.90660731\n",
      "  0.57581542  0.98357721  0.72517066  0.27819309 -0.14705437  0.12806538]\n",
      "epoch 61\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002167663932472635 R2: 0.8755812310039781 time: 1703258706.6476915\n",
      "batch_idx: 1 loss: 0.0014123471371053184 R2: 0.8756871782412408 time: 1703258715.4533741\n",
      "Training [20%] Loss: 0.0017900055347889767 time: 1703258715.4533741\n",
      "weight: [ 0.82763336  0.19304336  0.26879207  1.08803926  0.527871    0.005129\n",
      "  0.63791913  0.41838002 -0.19593529 -0.33122441  0.30839809  0.45080592\n",
      "  0.83583421  0.38035502  0.82108262  0.06657705  0.40423453  0.90793499\n",
      "  0.57592779  0.98347187  0.72488332  0.27799407 -0.14702149  0.12810847]\n",
      "epoch 62\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021653914502961875 R2: 0.8757784906195598 time: 1703258724.878502\n",
      "batch_idx: 1 loss: 0.0014086833151337646 R2: 0.875883251597801 time: 1703258734.9882705\n",
      "Training [21%] Loss: 0.001787037382714976 time: 1703258734.9882705\n",
      "weight: [ 0.83012198  0.19224155  0.2675679   1.08783351  0.52763716  0.00554812\n",
      "  0.63779159  0.41810101 -0.19672691 -0.33123554  0.30842697  0.45083917\n",
      "  0.83871387  0.38142062  0.8202808   0.06670438  0.40541193  0.90936294\n",
      "  0.57602985  0.98336476  0.72460969  0.27786693 -0.14698772  0.12815106]\n",
      "epoch 63\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002163402123845008 R2: 0.8759809182085976 time: 1703258744.639741\n",
      "batch_idx: 1 loss: 0.001404976657813786 R2: 0.8760799324313769 time: 1703258753.8073819\n",
      "Training [21%] Loss: 0.0017841893908293969 time: 1703258753.8073819\n",
      "weight: [ 0.83263976  0.19140372  0.26629437  1.08763211  0.52743519  0.00600679\n",
      "  0.63762962  0.41783716 -0.19750915 -0.33120671  0.3084622   0.45087717\n",
      "  0.84166744  0.38250169  0.81944297  0.06683264  0.40662974  0.91083962\n",
      "  0.57614854  0.98328679  0.72434505  0.27777931 -0.14694805  0.12819964]\n",
      "epoch 64\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002161150648241509 R2: 0.8761824976226176 time: 1703258762.850076\n",
      "batch_idx: 1 loss: 0.0014018103651539985 R2: 0.8762767624109772 time: 1703258772.1816504\n",
      "Training [21%] Loss: 0.0017814805066977536 time: 1703258772.1816504\n",
      "weight: [ 0.83518913  0.19053813  0.26497687  1.08743253  0.52716212  0.00640558\n",
      "  0.63746701  0.41760089 -0.19827194 -0.33116713  0.30851194  0.45093063\n",
      "  0.84467757  0.38359516  0.81857738  0.06693275  0.40784618  0.91231963\n",
      "  0.57630816  0.98326755  0.7240871   0.27770147 -0.14689787  0.12826022]\n",
      "epoch 65\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002158134237048572 R2: 0.8763845340109448 time: 1703258781.1981592\n",
      "batch_idx: 1 loss: 0.0013994864137947037 R2: 0.8764780479302559 time: 1703258790.208607\n",
      "Training [22%] Loss: 0.001778810325421638 time: 1703258790.208607\n",
      "weight: [ 0.83777287  0.18964959  0.26361778  1.08723219  0.526754    0.0066824\n",
      "  0.63732677  0.41739917 -0.19900863 -0.33113764  0.30858073  0.45100578\n",
      "  0.84773433  0.38469943  0.81768885  0.06698711  0.40903561  0.91377511\n",
      "  0.5765222   0.98332471  0.72383595  0.2776122  -0.1468347   0.12833611]\n",
      "epoch 66\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002154074258572366 R2: 0.8765905878287559 time: 1703258800.7048256\n",
      "batch_idx: 1 loss: 0.0013980498547725418 R2: 0.8766865892485258 time: 1703258810.8518567\n",
      "Training [22%] Loss: 0.0017760620566724537 time: 1703258810.8518567\n",
      "weight: [ 0.84039286  0.18874027  0.26221751  1.08702894  0.52619844  0.00682466\n",
      "  0.63721767  0.41723312 -0.1997166  -0.33112782  0.30866811  0.45110267\n",
      "  0.85083473  0.38581483  0.81677953  0.06699392  0.41019277  0.91519999\n",
      "  0.5767896   0.98345804  0.72359283  0.27750165 -0.14675914  0.12842683]\n",
      "epoch 67\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021490136360542466 R2: 0.8768012543096193 time: 1703258820.04032\n",
      "batch_idx: 1 loss: 0.0013973518091091313 R2: 0.8769006464506862 time: 1703258829.095823\n",
      "Training [22%] Loss: 0.0017731827225816888 time: 1703258829.095823\n",
      "weight: [ 0.8430489   0.18781137  0.26077625  1.08682152  0.52553119  0.00686611\n",
      "  0.63713507  0.41709956 -0.20039669 -0.33113651  0.30876876  0.45121536\n",
      "  0.85397984  0.3869434   0.81585063  0.06696651  0.41133044  0.9166074\n",
      "  0.57709576  0.98364909  0.7233583   0.2773708  -0.14667474  0.12852821]\n",
      "epoch 68\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002143266857758878 R2: 0.8770137388167246 time: 1703258838.2010972\n",
      "batch_idx: 1 loss: 0.0013971052770136814 R2: 0.8771160271476577 time: 1703258847.7141647\n",
      "Training [23%] Loss: 0.0017701860673862797 time: 1703258847.7141647\n",
      "weight: [ 0.84573817  0.1868648   0.25929549  1.08660978  0.52482021  0.00687162\n",
      "  0.6370651   0.41699344 -0.2010517  -0.33115499  0.30887414  0.45133392\n",
      "  0.85717122  0.38808818  0.81490406  0.0669286   0.41247268  0.91802223\n",
      "  0.5774171   0.98386606  0.723131    0.27722822 -0.14658706  0.1286336 ]\n",
      "epoch 69\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00213726567566281 R2: 0.8772251288539182 time: 1703258857.5880835\n",
      "batch_idx: 1 loss: 0.001396949365512894 R2: 0.8773299022289553 time: 1703258867.4731438\n",
      "Training [23%] Loss: 0.001767107520587852 time: 1703258867.4731438\n",
      "weight: [ 0.84845565  0.18590412  0.25777874  1.08639445  0.52414338  0.00691579\n",
      "  0.63699072  0.4169102  -0.20168471 -0.33117166  0.30897468  0.45144712\n",
      "  0.86040811  0.38925236  0.81394337  0.06690728  0.41364609  0.91947184\n",
      "  0.57772755  0.98407203  0.72290736  0.27708533 -0.14650227  0.12873559]\n",
      "epoch 70\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021313984540952107 R2: 0.8774351001807024 time: 1703258877.2583182\n",
      "batch_idx: 1 loss: 0.0013965421295167196 R2: 0.8775423666923181 time: 1703258886.7236738\n",
      "Training [23%] Loss: 0.0017639702918059651 time: 1703258886.7236738\n",
      "weight: [ 0.85119531  0.18493452  0.25623121  1.08617671  0.52356662  0.00706183\n",
      "  0.63689758  0.41684746 -0.20229755 -0.33117668  0.30906213  0.45154527\n",
      "  0.86368623  0.39043843  0.81297377  0.066926    0.41487184  0.92097769\n",
      "  0.57800491  0.98423376  0.7226823   0.27695177 -0.14642574  0.12882772]\n",
      "epoch 71\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002125914372321315 R2: 0.877645550839605 time: 1703258896.008327\n",
      "batch_idx: 1 loss: 0.0013956618236865277 R2: 0.8777550125867931 time: 1703258904.8103454\n",
      "Training [24%] Loss: 0.0017607880980039213 time: 1703258904.8103454\n",
      "weight: [ 0.85395167  0.18396203  0.25465868  1.08595759  0.52312834  0.00734656\n",
      "  0.63677817  0.41680562 -0.20289002 -0.33116531  0.30913113  0.45162218\n",
      "  0.86699839  0.39164779  0.81200128  0.06699948  0.41616068  0.92255013\n",
      "  0.5782352   0.98432864  0.72245064  0.27683201 -0.14636098  0.12890581]\n",
      "epoch 72\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021209010433431313 R2: 0.8778582699334292 time: 1703258914.355504\n",
      "batch_idx: 1 loss: 0.0013942674225595583 R2: 0.8779687497981781 time: 1703258923.9144666\n",
      "Training [24%] Loss: 0.0017575842329513448 time: 1703258923.9144666\n",
      "weight: [ 0.85672112  0.18299225  0.25306611  1.08573741  0.52283375  0.00777485\n",
      "  0.63663332  0.4167874  -0.20345979 -0.33113928  0.30917991  0.45167601\n",
      "  0.87033619  0.39288067  0.81103151  0.06713166  0.41751165  0.92418727\n",
      "  0.5784143   0.98434803  0.72220849  0.2767241  -0.14630926  0.12896841]\n",
      "epoch 73\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021163058504161947 R2: 0.8780733057255852 time: 1703258933.897749\n",
      "batch_idx: 1 loss: 0.0013924857903974187 R2: 0.8781831123864092 time: 1703258942.8316777\n",
      "Training [24%] Loss: 0.0017543958204068067 time: 1703258942.8316777\n",
      "weight: [ 0.85950253  0.18202937  0.25145667  1.08551563  0.52265933  0.00832385\n",
      "  0.63647109  0.41679678 -0.20400294 -0.33110591  0.30920985  0.45170871\n",
      "  0.87369195  0.39413636  0.81006863  0.06731691  0.41891431  0.92587742\n",
      "  0.57854662  0.98429637  0.72195429  0.27662046 -0.14626981  0.12901657]\n",
      "epoch 74\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002111975257488056 R2: 0.8782893102107681 time: 1703258951.921668\n",
      "batch_idx: 1 loss: 0.0013905374944031194 R2: 0.8783971875896451 time: 1703258960.8914287\n",
      "Training [25%] Loss: 0.0017512563759455877 time: 1703258960.8914287\n",
      "weight: [ 0.86229694  0.18107577  0.2498315   1.08529093  0.52256466  0.0089544\n",
      "  0.63630368  0.4168378  -0.20451484 -0.33107577  0.30922432  0.45172464\n",
      "  0.87705991  0.39541368  0.80911502  0.06754373  0.42035322  0.92760389\n",
      "  0.57864171  0.98418677  0.72168871  0.27651034 -0.14624061  0.12905287]\n",
      "epoch 75\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002107706073465671 R2: 0.8785049506564488 time: 1703258970.3218431\n",
      "batch_idx: 1 loss: 0.0013886446715222094 R2: 0.8786107156927908 time: 1703258980.0693674\n",
      "Training [25%] Loss: 0.0017481753724939402 time: 1703258980.0693674\n",
      "weight: [ 0.86510633  0.18013251  0.24819042  1.08506173  0.52250708  0.00962513\n",
      "  0.6361436   0.41691384 -0.20499105 -0.33105959  0.30922712  0.45172862\n",
      "  0.88043622  0.39671139  0.80817177  0.06779946  0.42181284  0.92935011\n",
      "  0.57871015  0.98403477  0.72141378  0.27638286 -0.14621929  0.12908029]\n",
      "epoch 76\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021033076058043308 R2: 0.8787197937858122 time: 1703258989.7136366\n",
      "batch_idx: 1 loss: 0.0013869613401739868 R2: 0.8788242040988667 time: 1703258999.67579\n",
      "Training [25%] Loss: 0.0017451344729891589 time: 1703258999.67579\n",
      "weight: [ 0.86793219  0.1792004   0.24653321  1.08482677  0.52245443  0.0103048\n",
      "  0.63600032  0.41702739 -0.20542787 -0.33106553  0.30922109  0.45172431\n",
      "  0.88381792  0.39802861  0.80723966  0.06807456  0.42328151  0.9311036\n",
      "  0.57875983  0.98385222  0.72113128  0.27622973 -0.14620406  0.12910108]\n",
      "epoch 77\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002098661220056986 R2: 0.878934090396414 time: 1703259009.565546\n",
      "batch_idx: 1 loss: 0.0013855419032926526 R2: 0.8790382344701368 time: 1703259018.4849603\n",
      "Training [26%] Loss: 0.0017421015616748193 time: 1703259018.4849603\n",
      "weight: [ 0.87077406  0.17828122  0.24486104  1.08458562  0.52239253  0.01097953\n",
      "  0.63587824  0.41718049 -0.20582251 -0.3310975   0.30920731  0.45171311\n",
      "  0.88720127  0.39936491  0.80632048  0.06836525  0.42475333  0.93285788\n",
      "  0.57879386  0.98364318  0.72084115  0.27604694 -0.14619426  0.12911609]\n",
      "epoch 78\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002093754016049757 R2: 0.8791481219920921 time: 1703259027.628358\n",
      "batch_idx: 1 loss: 0.0013843428148551796 R2: 0.8792529032810064 time: 1703259036.6659086\n",
      "Training [26%] Loss: 0.0017390484154524684 time: 1703259036.6659086\n",
      "weight: [ 0.87362892  0.17737851  0.24317728  1.08433891  0.52232592  0.01165357\n",
      "  0.6357765   0.41737529 -0.206173   -0.33115491  0.30918489  0.45169401\n",
      "  0.89058056  0.40072028  0.80541777  0.06867395  0.426228    0.93461208\n",
      "  0.57881029  0.98340281  0.72054061  0.27583493 -0.14619046  0.12912465]\n",
      "epoch 79\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020886715487857437 R2: 0.8793619536628798 time: 1703259045.9451616\n",
      "batch_idx: 1 loss: 0.001383247114414251 R2: 0.8794679320104415 time: 1703259055.564741\n",
      "Training [26%] Loss: 0.0017359593315999975 time: 1703259055.564741\n",
      "weight: [ 0.8764914   0.1764976   0.24148746  1.08408826  0.5222727   0.01234431\n",
      "  0.63569032  0.41761455 -0.20647774 -0.33123373  0.30915153  0.45166424\n",
      "  0.89394769  0.40209494  0.80453686  0.06900766  0.42770895  0.93636907\n",
      "  0.57880363  0.98311937  0.72022422  0.27559754 -0.14619413  0.12912496]\n",
      "epoch 80\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002083555530463304 R2: 0.879575706959417 time: 1703259065.362366\n",
      "batch_idx: 1 loss: 0.001382104406136161 R2: 0.8796831460630271 time: 1703259074.7921462\n",
      "Training [27%] Loss: 0.0017328299682997325 time: 1703259074.7921462\n",
      "weight: [ 0.87935488  0.17564482  0.23979831  1.08383579  0.52225596  0.01307403\n",
      "  0.63561335  0.41790167 -0.20673524 -0.33132846  0.30910441  0.45162037\n",
      "  0.89729308  0.40348908  0.80368408  0.06937507  0.42920082  0.93813278\n",
      "  0.57876724  0.98277845  0.71988507  0.27534011 -0.14620708  0.12911481]\n",
      "epoch 81\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002078548751561838 R2: 0.879789837197262 time: 1703259084.0867891\n",
      "batch_idx: 1 loss: 0.0013807783009503558 R2: 0.8798987227702684 time: 1703259092.6790648\n",
      "Training [27%] Loss: 0.0017296635262560969 time: 1703259092.6790648\n",
      "weight: [ 0.88221305  0.17482608  0.23811621  1.08358365  0.5222948   0.01386123\n",
      "  0.63554005  0.41824035 -0.20694378 -0.33143407  0.30904124  0.45155957\n",
      "  0.90060744  0.40490269  0.80286534  0.06978344  0.43070701  0.93990597\n",
      "  0.5786959   0.98236774  0.71951648  0.27506746 -0.14623077  0.12909238]\n",
      "epoch 82\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020737501254624716 R2: 0.8800050069526657 time: 1703259103.4022155\n",
      "batch_idx: 1 loss: 0.0013791879908109654 R2: 0.88011501443853 time: 1703259113.2421362\n",
      "Training [27%] Loss: 0.0017264690581367185 time: 1703259113.2421362\n",
      "weight: [ 0.88506141  0.1740455   0.23644561  1.08333334  0.52239786  0.01471436\n",
      "  0.63546747  0.41863394 -0.20710145 -0.3315476   0.30896098  0.4514805\n",
      "  0.90388374  0.40633547  0.80208476  0.07023625  0.43222829  0.94168883\n",
      "  0.57858758  0.98188091  0.71911387  0.27478242 -0.14626587  0.12905686]\n",
      "epoch 83\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002069191868356099 R2: 0.8802216926167217 time: 1703259122.2923086\n",
      "batch_idx: 1 loss: 0.0013773286791788823 R2: 0.880332253802256 time: 1703259131.0322258\n",
      "Training [28%] Loss: 0.0017232602737674908 time: 1703259131.0322258\n",
      "weight: [ 0.88789819  0.17330444  0.23478802  1.08308551  0.52256111  0.01562962\n",
      "  0.63539592  0.4190849  -0.20720621 -0.33166876  0.30886412  0.4513837\n",
      "  0.90711872  0.4077869   0.80134369  0.07073236  0.43376256  0.94347893\n",
      "  0.5784441   0.98131926  0.71867574  0.27448523 -0.14631204  0.12900864]\n",
      "epoch 84\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002064839668869739 R2: 0.8804399490088481 time: 1703259140.1922023\n",
      "batch_idx: 1 loss: 0.0013752631915245588 R2: 0.8805504876958983 time: 1703259149.3374848\n",
      "Training [28%] Loss: 0.001720051430197149 time: 1703259149.3374848\n",
      "weight: [ 0.89072429  0.17260142  0.23314199  1.08283989  0.52277003  0.01659312\n",
      "  0.63532838  0.41959448 -0.20725609 -0.33179948  0.30875247  0.45127129\n",
      "  0.91031319  0.40925634  0.80064068  0.07126667  0.43530564  0.94527208\n",
      "  0.5782704   0.98069092  0.71820382  0.27417396 -0.14636805  0.12894917]\n",
      "epoch 85\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002060611393882111 R2: 0.880659527895026 time: 1703259158.7623017\n",
      "batch_idx: 1 loss: 0.0013730904977179918 R2: 0.8807697354905466 time: 1703259168.366302\n",
      "Training [28%] Loss: 0.0017168509458000514 time: 1703259168.366302\n",
      "weight: [ 0.89354246  0.17193298  0.23150397  1.08259567  0.52300501  0.01758606\n",
      "  0.63526914  0.42016292 -0.20724933 -0.33194281  0.30862855  0.45114621\n",
      "  0.91347098  0.41074319  0.79997224  0.07183198  0.43685273  0.94706373\n",
      "  0.57807308  0.98000791  0.71770201  0.27384564 -0.14643224  0.12888047]\n",
      "epoch 86\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020564079930650405 R2: 0.8808801586120858 time: 1703259177.105798\n",
      "batch_idx: 1 loss: 0.0013709065189577894 R2: 0.8809901140749767 time: 1703259187.0132217\n",
      "Training [29%] Loss: 0.001713657256011415 time: 1703259187.0132217\n",
      "weight: [ 0.89635583  0.17129498  0.22986982  1.08235199  0.5232477   0.01859086\n",
      "  0.63522214  0.42078999 -0.20718442 -0.33210151  0.30849484  0.45101137\n",
      "  0.91659703  0.41224696  0.79933424  0.07242131  0.43839982  0.94885027\n",
      "  0.57785846  0.97928236  0.71717472  0.27349763 -0.14650294  0.12880453]\n",
      "epoch 87\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020521476235351665 R2: 0.8811017040685588 time: 1703259197.9358807\n",
      "batch_idx: 1 loss: 0.0013687728386753957 R2: 0.8812117752935119 time: 1703259206.822003\n",
      "Training [29%] Loss: 0.0017104602311052812 time: 1703259206.822003\n",
      "weight: [ 0.89916648  0.17068407  0.22823635  1.08210843  0.52348623  0.01959621\n",
      "  0.63518959  0.42147578 -0.20706005 -0.33227683  0.30835313  0.45086882\n",
      "  0.91969527  0.41376727  0.79872332  0.07302982  0.4399447   0.95062987\n",
      "  0.57763124  0.97852322  0.71662518  0.27312875 -0.14657892  0.1287228 ]\n",
      "epoch 88\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020477914071241644 R2: 0.8813241292302335 time: 1703259215.4677267\n",
      "batch_idx: 1 loss: 0.0013667023106807878 R2: 0.8814347616767089 time: 1703259224.1723864\n",
      "Training [29%] Loss: 0.001707246858902476 time: 1703259224.1723864\n",
      "weight: [ 0.90197458  0.17009857  0.22660231  1.08186532  0.5237175   0.02059932\n",
      "  0.63517143  0.42222129 -0.20687498 -0.33246802  0.30820425  0.45071944\n",
      "  0.92276721  0.4153038   0.79813782  0.07365566  0.44148718  0.95240259\n",
      "  0.57739375  0.97773446  0.71605436  0.2727398  -0.14665961  0.12863594]\n",
      "epoch 89\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020433510336946513 R2: 0.881547430005558 time: 1703259232.9322987\n",
      "batch_idx: 1 loss: 0.0013646630930027452 R2: 0.8816589650621587 time: 1703259242.0535686\n",
      "Training [30%] Loss: 0.0017040070633486983 time: 1703259242.0535686\n",
      "weight: [ 0.90477825  0.16953862  0.22496846  1.08162372  0.52394628  0.021605\n",
      "  0.63516554  0.42302857 -0.20662793 -0.33267251  0.30804813  0.45056297\n",
      "  0.92581157  0.41685621  0.79757788  0.07429981  0.44302871  0.95416993\n",
      "  0.57714627  0.97691543  0.71546091  0.27233334 -0.14674504  0.12854389]\n",
      "epoch 90\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020388760977630405 R2: 0.8817716377972709 time: 1703259251.1241415\n",
      "batch_idx: 1 loss: 0.0013625974392666791 R2: 0.8818842190313388 time: 1703259260.6370268\n",
      "Training [30%] Loss: 0.0017007367685148598 time: 1703259260.6370268\n",
      "weight: [ 0.90757437  0.16900549  0.22333683  1.08138517  0.52418171  0.02262231\n",
      "  0.63516871  0.42390046 -0.20631751 -0.33288674  0.30788417  0.45039855\n",
      "  0.92882535  0.41842409  0.79704475  0.07496475  0.44457159  0.9559341\n",
      "  0.57688791  0.97606278  0.714842    0.2719129  -0.14683555  0.12844613]\n",
      "epoch 91\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002034428311542988 R2: 0.8819968525831496 time: 1703259269.70753\n",
      "batch_idx: 1 loss: 0.0013604479900874696 R2: 0.8821104032207077 time: 1703259278.7668552\n",
      "Training [30%] Loss: 0.0016974381508152287 time: 1703259278.7668552\n",
      "weight: [ 0.91035976  0.16850042  0.22170946  1.08115123  0.52443287  0.02366026\n",
      "  0.63517785  0.4248399  -0.20594233 -0.33310722  0.30771181  0.45022533\n",
      "  0.93180549  0.42000697  0.79653968  0.07565293  0.44611805  0.95769729\n",
      "  0.57661788  0.97517324  0.71419478  0.27148192 -0.14693152  0.12834218]\n",
      "epoch 92\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020300546100974473 R2: 0.8822232069094372 time: 1703259288.0720856\n",
      "batch_idx: 1 loss: 0.0013581817966437652 R2: 0.8823374639398116 time: 1703259297.1721404\n",
      "Training [31%] Loss: 0.0016941182033706063 time: 1703259297.1721404\n",
      "weight: [ 0.9131324   0.16802347  0.22008714  1.08092306  0.524705    0.02472419\n",
      "  0.63519093  0.42584918 -0.20550106 -0.33333143  0.3075309   0.45004301\n",
      "  0.9347507   0.42160443  0.79606273  0.07636539  0.44766974  0.95946116\n",
      "  0.57633639  0.97424607  0.7135178   0.27104291 -0.14703303  0.12823189]\n",
      "epoch 93\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020257696091384287 R2: 0.8824507686045026 time: 1703259305.942424\n",
      "batch_idx: 1 loss: 0.0013558026673018725 R2: 0.8825653815038024 time: 1703259315.1820242\n",
      "Training [31%] Loss: 0.0016907861382201507 time: 1703259315.1820242\n",
      "weight: [ 0.91589211  0.16757297  0.21846877  1.08070118  0.52499794  0.02581417\n",
      "  0.63520743  0.42692949 -0.20499253 -0.33355826  0.30734198  0.4498521\n",
      "  0.93766245  0.42321614  0.79561222  0.07710114  0.44922745  0.96122681\n",
      "  0.57604508  0.97328413  0.71281173  0.27059702 -0.14713971  0.12811568]\n",
      "epoch 94\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002021552498438714 R2: 0.8826794827691448 time: 1703259324.0673022\n",
      "batch_idx: 1 loss: 0.0013533472750451052 R2: 0.882794158945198 time: 1703259333.137332\n",
      "Training [31%] Loss: 0.0016874498867419097 time: 1703259333.137332\n",
      "weight: [ 0.91864043  0.1671456   0.21685151  1.08048554  0.52530677  0.02692572\n",
      "  0.63522818  0.42808088 -0.2044158  -0.33378782  0.30714611  0.44965377\n",
      "  0.9405448   0.4248419   0.79518486  0.07785748  0.45079137  0.96299493\n",
      "  0.57574679  0.97229344  0.71207927  0.27014422 -0.14725084  0.12799438]\n",
      "epoch 95\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020173577386738027 R2: 0.8829092101143978 time: 1703259342.1822276\n",
      "batch_idx: 1 loss: 0.0013508679903409895 R2: 0.8830238379851666 time: 1703259351.6422074\n",
      "Training [32%] Loss: 0.001684112864507396 time: 1703259351.6422074\n",
      "weight: [ 0.92137979  0.16673729  0.21523168  1.08027574  0.52562454  0.02805232\n",
      "  0.63525461  0.42930269 -0.20377004 -0.33402091  0.3069446   0.44944952\n",
      "  0.94340312  0.42648168  0.79477655  0.07863092  0.45236147  0.9647661\n",
      "  0.57544475  0.97128142  0.71132418  0.26968383 -0.14736553  0.12786904]\n",
      "epoch 96\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002013134396259701 R2: 0.8831398130318137 time: 1703259361.1674736\n",
      "batch_idx: 1 loss: 0.0013484111618923926 R2: 0.8832544914899645 time: 1703259371.9823422\n",
      "Training [32%] Loss: 0.0016807727790760468 time: 1703259371.9823422\n",
      "weight: [ 0.92411236  0.16634428  0.21360595  1.08007143  0.52594534  0.02918849\n",
      "  0.63528801  0.43059434 -0.20305443 -0.33425822  0.30673858  0.44924064\n",
      "  0.94624228  0.42813544  0.79438354  0.07941845  0.45393789  0.96654103\n",
      "  0.57514183  0.97025468  0.7105499   0.26921526 -0.14748301  0.12774058]\n",
      "epoch 97\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020088460254511853 R2: 0.8833712121754909 time: 1703259381.2121415\n",
      "batch_idx: 1 loss: 0.001346000450086165 R2: 0.8834861772817526 time: 1703259390.145455\n",
      "Training [32%] Loss: 0.0016774232377686751 time: 1703259390.145455\n",
      "weight: [ 0.92683906  0.16596412  0.21197234  1.07987264  0.52626675  0.0303321\n",
      "  0.6353289   0.43195596 -0.20226797 -0.3344998   0.30652874  0.44902788\n",
      "  0.94906506  0.42980307  0.79400337  0.08021835  0.45552118  0.96832067\n",
      "  0.57483985  0.96921734  0.70975847  0.26873852 -0.14760281  0.12760953]\n",
      "epoch 98\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020044827871715893 R2: 0.883603396410199 time: 1703259399.3156948\n",
      "batch_idx: 1 loss: 0.0013436313455156457 R2: 0.8837188998294039 time: 1703259408.1842382\n",
      "Training [33%] Loss: 0.0016740570663436175 time: 1703259408.1842382\n",
      "weight: [ 0.92955914  0.16559599  0.21033068  1.07967992  0.52659049  0.03148499\n",
      "  0.63537685  0.43338871 -0.20140941 -0.33474487  0.30631521  0.44881134\n",
      "  0.95187152  0.43148427  0.79363525  0.08103051  0.45711226  0.97010607\n",
      "  0.5745395   0.96817046  0.70895005  0.26825438 -0.14772485  0.12747601]\n",
      "epoch 99\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020000610055123714 R2: 0.8838364161823081 time: 1703259417.387584\n",
      "batch_idx: 1 loss: 0.001341277781704587 R2: 0.8839526206812642 time: 1703259426.662333\n",
      "Training [33%] Loss: 0.0016706693936084792 time: 1703259426.662333\n",
      "weight: [ 0.93227047  0.16524047  0.20868221  1.0794942   0.52692128  0.03265188\n",
      "  0.63543084  0.43489462 -0.20047725 -0.33499212  0.30609772  0.44859063\n",
      "  0.95465946  0.43317857  0.79327973  0.08185599  0.45871222  0.97189826\n",
      "  0.57424058  0.96711281  0.70812334  0.26776412 -0.1478493   0.12733974]\n",
      "epoch 100\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019956114224486546 R2: 0.8840703725995605 time: 1703259435.8275516\n",
      "batch_idx: 1 loss: 0.0013389069432948218 R2: 0.8841873010931327 time: 1703259445.0861077\n",
      "Training [33%] Loss: 0.001667259182871738 time: 1703259445.0861077\n",
      "weight: [ 0.93497045  0.16489864  0.20702873  1.07931653  0.52726454  0.03383817\n",
      "  0.63548974  0.43647599 -0.19946987 -0.33524018  0.30587583  0.44836521\n",
      "  0.95742578  0.43488538  0.79293789  0.08269618  0.46032204  0.97369803\n",
      "  0.57394266  0.96604241  0.7072765   0.26726902 -0.14797646  0.12720038]\n",
      "epoch 101\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019911626491288755 R2: 0.8843053868676298 time: 1703259454.403517\n",
      "batch_idx: 1 loss: 0.0013364952506053937 R2: 0.8844229344366455 time: 1703259464.1687536\n",
      "Training [34%] Loss: 0.0016638289498671346 time: 1703259464.1687536\n",
      "weight: [ 0.93765694  0.16457123  0.20537164  1.07914775  0.52762408  0.03504769\n",
      "  0.63555294  0.43813477 -0.1983857  -0.33548819  0.30564929  0.44813472\n",
      "  0.96016794  0.43660414  0.79261048  0.08355197  0.46194239  0.97550589\n",
      "  0.57364561  0.96495815  0.70640828  0.26676987 -0.14810652  0.12705769]\n",
      "epoch 102\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019867278434151643 R2: 0.8845415522073727 time: 1703259473.0472283\n",
      "batch_idx: 1 loss: 0.0013340382161497553 R2: 0.8846595540534464 time: 1703259482.2721353\n",
      "Training [34%] Loss: 0.0016603830297824598 time: 1703259482.2721353\n",
      "weight: [ 0.94032889  0.16425803  0.20371128  1.0789883   0.52800084  0.03628148\n",
      "  0.6356206   0.43987201 -0.19722332 -0.3357361   0.30541815  0.44789923\n",
      "  0.96288501  0.43833443  0.79229729  0.08442322  0.46357354  0.9773221\n",
      "  0.57334993  0.96386078  0.70551873  0.26626669 -0.14823943  0.1269117 ]\n",
      "epoch 103\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001982300217499059 R2: 0.8847789026696479 time: 1703259491.362579\n",
      "batch_idx: 1 loss: 0.00133155001756349 R2: 0.8848972295886266 time: 1703259500.2728574\n",
      "Training [34%] Loss: 0.0016569251175312745 time: 1703259500.2728574\n",
      "weight: [ 0.94298639  0.16395788  0.20204697  1.07883818  0.52839301  0.03753791\n",
      "  0.63569363  0.44168787 -0.1959815  -0.33598458  0.30518275  0.44765916\n",
      "  0.96557766  0.44007598  0.79199713  0.08530886  0.46521546  0.97914676\n",
      "  0.57305666  0.96275278  0.70460917  0.2657588  -0.14837495  0.12676273]\n",
      "epoch 104\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019778584364331334 R2: 0.8850174246264292 time: 1703259509.5974677\n",
      "batch_idx: 1 loss: 0.0013290539348041358 R2: 0.8851360572907572 time: 1703259518.6473458\n",
      "Training [35%] Loss: 0.0016534561856186346 time: 1703259518.6473458\n",
      "weight: [ 0.94563011  0.16366916  0.20037755  1.07869718  0.52879746  0.03881408\n",
      "  0.63577329  0.44358197 -0.19465914 -0.33623473  0.30494359  0.44741512\n",
      "  0.96824734  0.44182864  0.79170841  0.08620737  0.46686797  0.98097989\n",
      "  0.57276711  0.96163747  0.70368159  0.26524512 -0.14851276  0.12661117]\n",
      "epoch 105\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001973378464506895 R2: 0.8852570967233031 time: 1703259527.7257514\n",
      "batch_idx: 1 loss: 0.001326569288800268 R2: 0.8853761376438098 time: 1703259536.7173316\n",
      "Training [35%] Loss: 0.0016499738766535816 time: 1703259536.7173316\n",
      "weight: [ 0.94826046  0.16339054  0.19870215  1.07856512  0.52921162  0.04010757\n",
      "  0.63586075  0.44555402 -0.1932551  -0.3364876   0.30470107  0.44716761\n",
      "  0.97089507  0.44359221  0.7914298   0.08711745  0.4685309   0.98282144\n",
      "  0.57248236  0.96051767  0.70273773  0.2647246  -0.14865256  0.12645738]\n",
      "epoch 106\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019688456458003094 R2: 0.8854979257485784 time: 1703259545.93725\n",
      "batch_idx: 1 loss: 0.0013241017060569705 R2: 0.8856175466117729 time: 1703259555.2072444\n",
      "Training [35%] Loss: 0.00164647367592864 time: 1703259555.2072444\n",
      "weight: [ 0.95087695  0.16312154  0.19702078  1.07844211  0.52963472  0.04141774\n",
      "  0.63595679  0.44760428 -0.19176807 -0.33674385  0.30445535  0.44691686\n",
      "  0.9735204   0.44536634  0.79116079  0.08803852  0.47020411  0.98467129\n",
      "  0.57220306  0.95939483  0.70177838  0.26419655 -0.14879424  0.1263015 ]\n",
      "epoch 107\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019642609860424836 R2: 0.8857399624040889 time: 1703259564.0524838\n",
      "batch_idx: 1 loss: 0.0013216411735298384 R2: 0.8858603227448887 time: 1703259572.817307\n",
      "Training [36%] Loss: 0.0016429510797861609 time: 1703259572.817307\n",
      "weight: [ 0.95347811  0.1628626   0.19533449  1.07832857  0.5300681   0.04274594\n",
      "  0.63606171  0.44973371 -0.19019655 -0.3370037   0.30420632  0.44666277\n",
      "  0.97612133  0.44715048  0.79090185  0.08897074  0.47188756  0.98652922\n",
      "  0.57192936  0.9582689   0.7008032   0.26366069 -0.14893787  0.12614347]\n",
      "epoch 108\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019596388743255435 R2: 0.8859832985022917 time: 1703259581.6392443\n",
      "batch_idx: 1 loss: 0.001319168090593856 R2: 0.8861044812653164 time: 1703259590.3965347\n",
      "Training [36%] Loss: 0.0016394034824596998 time: 1703259590.3965347\n",
      "weight: [ 0.95606177  0.16261474  0.19364491  1.07822513  0.53051433  0.04409471\n",
      "  0.63617558  0.45194371 -0.18853892 -0.33726709  0.30395372  0.44640505\n",
      "  0.9786949   0.44894394  0.79065399  0.08991472  0.47358119  0.98839492\n",
      "  0.57166112  0.9571389   0.69981118  0.26311698 -0.14908362  0.12598308]\n",
      "epoch 109\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001954998179950353 R2: 0.8862280481894722 time: 1703259598.9925373\n",
      "batch_idx: 1 loss: 0.0013166635312257913 R2: 0.8863500417361438 time: 1703259607.6320996\n",
      "Training [36%] Loss: 0.0016358308555880722 time: 1703259607.6320996\n",
      "weight: [ 0.95862588  0.16237891  0.19195363  1.07813243  0.5309758   0.04546641\n",
      "  0.63629849  0.45423561 -0.18679356 -0.33753401  0.30369732  0.44614343\n",
      "  0.98123829  0.45074601  0.79041817  0.09087103  0.47528492  0.99026806\n",
      "  0.57139828  0.956004    0.69880137  0.26256535 -0.14923165  0.12582014]\n",
      "epoch 110\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001950352040222273 R2: 0.8864743181157355 time: 1703259616.462517\n",
      "batch_idx: 1 loss: 0.001314118015043951 R2: 0.8865970494496157 time: 1703259625.1793633\n",
      "Training [37%] Loss: 0.001632235027633112 time: 1703259625.1793633\n",
      "weight: [ 0.96116901  0.16215547  0.19026157  1.07805086  0.53145365  0.0468622\n",
      "  0.63643081  0.4566102  -0.18495899 -0.33780474  0.30343703  0.44587785\n",
      "  0.98374978  0.45255611  0.79019473  0.09183973  0.47699866  0.99214838\n",
      "  0.57114107  0.9548643   0.69777357  0.26200545 -0.149382    0.1256546 ]\n",
      "epoch 111\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019457018561864427 R2: 0.8867221829088722 time: 1703259634.4471438\n",
      "batch_idx: 1 loss: 0.001311534228385045 R2: 0.8868455821357124 time: 1703259643.8072395\n",
      "Training [37%] Loss: 0.001628618042285744 time: 1703259643.8072395\n",
      "weight: [ 0.96369063  0.16194398  0.18856886  1.07798057  0.53194746  0.04828171\n",
      "  0.63657329  0.45906755 -0.18303396 -0.33807992  0.30317297  0.44560848\n",
      "  0.98622904  0.45437383  0.78998323  0.09282033  0.47872232  0.99403577\n",
      "  0.57089006  0.95372111  0.69672848  0.26143661 -0.1495346   0.12548658]\n",
      "epoch 112\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019410382388173216 R2: 0.8869716834814338 time: 1703259653.1334987\n",
      "batch_idx: 1 loss: 0.0013089227899882772 R2: 0.887095742131742 time: 1703259662.527235\n",
      "Training [37%] Loss: 0.0016249805144027993 time: 1703259662.527235\n",
      "weight: [ 0.96619081  0.16174346  0.18687504  1.0779215   0.53245587  0.04972368\n",
      "  0.63672683  0.46160725 -0.18101735 -0.33836037  0.30290538  0.44533563\n",
      "  0.9886767   0.45619894  0.78978272  0.09381195  0.48045587  0.99593028\n",
      "  0.57064604  0.95257645  0.69566748  0.26085799 -0.14968925  0.1253163 ]\n",
      "epoch 113\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019363476688295366 R2: 0.8872228478519242 time: 1703259671.4196982\n",
      "batch_idx: 1 loss: 0.001306294161972556 R2: 0.8873476367604095 time: 1703259680.1476912\n",
      "Training [38%] Loss: 0.0016213209154010463 time: 1703259680.1476912\n",
      "weight: [ 0.96866966  0.16155292  0.18517963  1.0778736   0.53297769  0.05118697\n",
      "  0.6368923   0.46422882 -0.17890809 -0.33864686  0.3026345   0.44505962\n",
      "  0.99109351  0.45803118  0.78959217  0.09481376  0.48219935  0.99783205\n",
      "  0.57040981  0.95143234  0.69459192  0.26026882 -0.14984578  0.12514399]\n",
      "epoch 114\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019316205994677552 R2: 0.8874757173770158 time: 1703259688.787114\n",
      "batch_idx: 1 loss: 0.0013036517232273633 R2: 0.8876013562078391 time: 1703259697.7971454\n",
      "Training [38%] Loss: 0.0016176361613475592 time: 1703259697.7971454\n",
      "weight: [ 0.97112681  0.1613717   0.18348256  1.07783702  0.53351271  0.05267143\n",
      "  0.63707032  0.46693214 -0.17670502 -0.33893991  0.30236046  0.44478063\n",
      "  0.99347962  0.45987024  0.78941095  0.09582526  0.48395288  0.99974124\n",
      "  0.57018197  0.95029016  0.69350266  0.25966857 -0.15000408  0.12496978]\n",
      "epoch 115\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019268562313184256 R2: 0.8877303621290842 time: 1703259706.5625737\n",
      "batch_idx: 1 loss: 0.0013009898604165768 R2: 0.887856963621867 time: 1703259715.2074833\n",
      "Training [38%] Loss: 0.0016139230458675012 time: 1703259715.2074833\n",
      "weight: [ 0.97356132  0.16119966  0.18178428  1.0778121   0.534062    0.0541781\n",
      "  0.63726125  0.46971754 -0.17440683 -0.3392397   0.30208325  0.44449864\n",
      "  0.99583435  0.46171566  0.78923891  0.09684633  0.48571665  1.00165796\n",
      "  0.56996293  0.94915045  0.69239987  0.25905699 -0.15016417  0.12479366]\n",
      "epoch 116\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019220614873727826 R2: 0.8879868794485585 time: 1703259724.2023885\n",
      "batch_idx: 1 loss: 0.001298297654939271 R2: 0.8881145043282604 time: 1703259733.3222625\n",
      "Training [39%] Loss: 0.0016101795711560268 time: 1703259733.3222625\n",
      "weight: [ 0.9759719   0.16103693  0.18008556  1.07779936  0.53462736  0.05570873\n",
      "  0.63746526  0.47258567 -0.17201216 -0.33954622  0.30180277  0.44421357\n",
      "  0.9981566   0.46356687  0.78907619  0.09787712  0.48749087  1.00358234\n",
      "  0.56975298  0.9480133   0.69128332  0.25843405 -0.15032609  0.12461556]\n",
      "epoch 117\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001917245389503186 R2: 0.8882453778379581 time: 1703259742.242318\n",
      "batch_idx: 1 loss: 0.0012955654032339383 R2: 0.8883740259104582 time: 1703259750.8322926\n",
      "Training [39%] Loss: 0.001606405396368562 time: 1703259750.8322926\n",
      "weight: [ 0.97835738  0.16088353  0.17838702  1.07779928  0.53521046  0.05726495\n",
      "  0.63768254  0.47553705 -0.16951967 -0.33985945  0.30151895  0.44392534\n",
      "  1.00044552  0.46542335  0.78892279  0.09891772  0.48927582  1.00551456\n",
      "  0.56955248  0.94687894  0.69015287  0.25779971 -0.15048988  0.12443545]\n",
      "epoch 118\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00191241272757354 R2: 0.8885059551863701 time: 1703259759.3423295\n",
      "batch_idx: 1 loss: 0.0012927897318229953 R2: 0.8886355946621327 time: 1703259768.532104\n",
      "Training [39%] Loss: 0.0016026012296982677 time: 1703259768.532104\n",
      "weight: [ 0.98071707  0.16073907  0.17668887  1.0778122   0.53581223  0.05884764\n",
      "  0.63791344  0.4785718  -0.16692815 -0.34017954  0.30123182  0.44363397\n",
      "  1.00270105  0.4672847   0.78877832  0.09996791  0.4910718   1.00745491\n",
      "  0.56936194  0.94574817  0.68900888  0.2571538  -0.15065553  0.12425336]\n",
      "epoch 119\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019075609791143016 R2: 0.8887686852087449 time: 1703259777.2422092\n",
      "batch_idx: 1 loss: 0.0012899742767189908 R2: 0.8888992991909961 time: 1703259786.1722827\n",
      "Training [40%] Loss: 0.0015987676279166463 time: 1703259786.1722827\n",
      "weight: [ 0.98305084  0.16060269  0.17499082  1.07783828  0.53643275  0.06045689\n",
      "  0.63815845  0.48168959 -0.16423655 -0.3405068   0.3009415   0.44333964\n",
      "  1.00492391  0.46915068  0.78864195  0.1010272   0.49287917  1.00940384\n",
      "  0.56918207  0.9446224   0.68785226  0.25649601 -0.15082292  0.1240694 ]\n",
      "epoch 120\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019026820515664108 R2: 0.8890336211839973 time: 1703259795.8724725\n",
      "batch_idx: 1 loss: 0.0012871259490838632 R2: 0.8891652402275627 time: 1703259805.392225\n",
      "Training [40%] Loss: 0.001594904000325137 time: 1703259805.392225\n",
      "weight: [ 0.98535883  0.16047337  0.17329237  1.07787761  0.53707173  0.0620924\n",
      "  0.63841814  0.48488982 -0.1614439  -0.3408416   0.30064817  0.44304257\n",
      "  1.00711524  0.47102112  0.78851262  0.10209494  0.49469834  1.01136186\n",
      "  0.56901361  0.94350332  0.68668416  0.25582593 -0.15099191  0.12388374]\n",
      "epoch 121\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018977672599693473 R2: 0.8893008127891875 time: 1703259814.6574035\n",
      "batch_idx: 1 loss: 0.0012842496322634357 R2: 0.8894335131250493 time: 1703259823.3472204\n",
      "Training [40%] Loss: 0.0015910084461163915 time: 1703259823.3472204\n",
      "weight: [ 0.98764102  0.16035019  0.17159318  1.07793031  0.53772914  0.06375412\n",
      "  0.63869303  0.48817198 -0.15854923 -0.34118427  0.30035198  0.44274293\n",
      "  1.00927596  0.47289582  0.78838945  0.10317059  0.49652969  1.01332946\n",
      "  0.5688573   0.94239238  0.68550556  0.25514326 -0.15116241  0.12369652]\n",
      "epoch 122\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018928120389215546 R2: 0.8895703229254035 time: 1703259831.9822173\n",
      "batch_idx: 1 loss: 0.0012813448893439971 R2: 0.8897041946762176 time: 1703259840.7732298\n",
      "Training [41%] Loss: 0.0015870784641327758 time: 1703259840.7732298\n",
      "weight: [ 0.98989704  0.16023261  0.16989323  1.07799663  0.53840558  0.06544259\n",
      "  0.6389835   0.49153585 -0.15555148 -0.34153497  0.30005298  0.4424408\n",
      "  1.01140643  0.47477447  0.78827186  0.10425383  0.49837356  1.01530701\n",
      "  0.56871375  0.94129057  0.684317    0.25444781 -0.15133436  0.12350781]\n",
      "epoch 123\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001887817372801269 R2: 0.8898422336515777 time: 1703259849.4540484\n",
      "batch_idx: 1 loss: 0.0012784065841216139 R2: 0.8899773434130391 time: 1703259858.167444\n",
      "Training [41%] Loss: 0.0015831119784614415 time: 1703259858.167444\n",
      "weight: [ 0.99212618  0.16012037  0.16819284  1.07807695  0.53910217  0.06715884\n",
      "  0.63928983  0.49498142 -0.1524495  -0.34189374  0.29975116  0.44213616\n",
      "  1.01350653  0.47665667  0.78815963  0.10534454  0.50023021  1.01729471\n",
      "  0.56858348  0.94019844  0.68311865  0.25373949 -0.15150774  0.12331759]\n",
      "epoch 124\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018827873807398371 R2: 0.8901166386179018 time: 1703259866.752409\n",
      "batch_idx: 1 loss: 0.0012754285411365044 R2: 0.8902530121142174 time: 1703259875.6425164\n",
      "Training [41%] Loss: 0.0015791079609381708 time: 1703259875.6425164\n",
      "weight: [ 0.99432768  0.16001334  0.16649242  1.07817165  0.5398201   0.06890396\n",
      "  0.6396123   0.49850871 -0.14924218 -0.3422606   0.29944649  0.44182899\n",
      "  1.01557601  0.47854197  0.7880526   0.10644261  0.50209987  1.01929273\n",
      "  0.56846702  0.93911642  0.68191057  0.25301826 -0.15168259  0.12312587]\n",
      "epoch 125\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018777251377754232 R2: 0.8903936277691459 time: 1703259884.482638\n",
      "batch_idx: 1 loss: 0.0012724074167262775 R2: 0.8905312622422658 time: 1703259893.0525413\n",
      "Training [42%] Loss: 0.0015750662772508503 time: 1703259893.0525413\n",
      "weight: [ 0.99650098  0.15991124  0.16479218  1.07828103  0.54056009  0.07067859\n",
      "  0.63995128  0.50211751 -0.14592846 -0.34263568  0.29913897  0.4415193\n",
      "  1.0176149   0.48042999  0.7879505   0.10754785  0.5039827   1.02130119\n",
      "  0.56836495  0.93804519  0.68069302  0.25228395 -0.15185886  0.12293265]\n",
      "epoch 126\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001872629803506088 R2: 0.8906732751422692 time: 1703259902.0142515\n",
      "batch_idx: 1 loss: 0.0012693440866811813 R2: 0.8908121699843251 time: 1703259911.4725788\n",
      "Training [42%] Loss: 0.0015709869450936348 time: 1703259911.4725788\n",
      "weight: [ 0.99864587  0.15981357  0.16309213  1.07840525  0.54132231  0.0724828\n",
      "  0.64030724  0.50580722 -0.14250744 -0.34301925  0.29882868  0.4412072\n",
      "  1.01962367  0.48232044  0.78785283  0.10865985  0.50587885  1.02332023\n",
      "  0.56827794  0.93698575  0.6794666   0.25153627 -0.15203651  0.12273803]\n",
      "epoch 127\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018674969041503574 R2: 0.8909556383012294 time: 1703259920.626602\n",
      "batch_idx: 1 loss: 0.0012662418592507248 R2: 0.891095820445521 time: 1703259929.4021993\n",
      "Training [42%] Loss: 0.0015668693817005412 time: 1703259929.4021993\n",
      "weight: [ 1.00076235  0.15971973  0.16139214  1.07854439  0.54210653  0.0743163\n",
      "  0.64068072  0.50957705 -0.1389783  -0.34341165  0.2985157   0.44089281\n",
      "  1.02160297  0.48421307  0.78775898  0.10977811  0.50778843  1.02534997\n",
      "  0.5682067   0.93593927  0.67823211  0.25077487 -0.15221544  0.12254212]\n",
      "epoch 128\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001862321214546364 R2: 0.891240768686065 time: 1703259938.1372056\n",
      "batch_idx: 1 loss: 0.001263103148261028 R2: 0.8913822947544074 time: 1703259946.7474222\n",
      "Training [43%] Loss: 0.001562712181403696 time: 1703259946.7474222\n",
      "weight: [ 1.00285034  0.15962921  0.15969214  1.07869851  0.54291256  0.0761788\n",
      "  0.64107226  0.51342613 -0.13534026 -0.34381324  0.29820013  0.44057624\n",
      "  1.02355334  0.48610762  0.78766847  0.11090218  0.50971148  1.02739044\n",
      "  0.56815192  0.9349068   0.67699024  0.24999937 -0.15239557  0.122345  ]\n",
      "epoch 129\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018570998944334592 R2: 0.8915287239018188 time: 1703259955.6724627\n",
      "batch_idx: 1 loss: 0.0012599271782954605 R2: 0.8916716597363952 time: 1703259964.4073484\n",
      "Training [43%] Loss: 0.0015585135363644599 time: 1703259964.4073484\n",
      "weight: [ 1.00490956  0.15954176  0.15799232  1.07886775  0.5437405   0.07807031\n",
      "  0.64148234  0.51735378 -0.13159252 -0.3442243   0.297882    0.44025756\n",
      "  1.02547496  0.48800373  0.78758102  0.1120317   0.51164792  1.02944151\n",
      "  0.56811424  0.93388914  0.67574142  0.24920948 -0.15257686  0.12214673]\n",
      "epoch 130\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001851833584053112 R2: 0.8918195726198566 time: 1703259973.0694642\n",
      "batch_idx: 1 loss: 0.0012567102714339984 R2: 0.8919639676311493 time: 1703259982.092576\n",
      "Training [43%] Loss: 0.0015542719277435552 time: 1703259982.092576\n",
      "weight: [ 1.00693952  0.15945731  0.15629305  1.0790523   0.54459071  0.07999105\n",
      "  0.64191139  0.52135939 -0.12773428 -0.34464505  0.2975613   0.43993678\n",
      "  1.02736767  0.48990096  0.78749657  0.11316645  0.51359761  1.0315029\n",
      "  0.56809427  0.93288678  0.67448583  0.24840492 -0.15275929  0.12194734]\n",
      "epoch 131\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018465248925882186 R2: 0.8921133891456232 time: 1703259991.2426078\n",
      "batch_idx: 1 loss: 0.001253448204669595 R2: 0.8922592650494969 time: 1703260001.125728\n",
      "Training [44%] Loss: 0.0015499865486289068 time: 1703260001.125728\n",
      "weight: [ 1.00893972  0.15937588  0.15459477  1.07925235  0.54546351  0.08194123\n",
      "  0.64235986  0.52544234 -0.12376476 -0.3450757   0.29723802  0.43961389\n",
      "  1.02923128  0.49179884  0.78741514  0.11430619  0.5155603   1.03357425\n",
      "  0.56809263  0.93190018  0.67322359  0.24758546 -0.15294285  0.12174684]\n",
      "epoch 132\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018411757081982477 R2: 0.8924102424076595 time: 1703260010.2965157\n",
      "batch_idx: 1 loss: 0.0012501386426267652 R2: 0.892557603164853 time: 1703260019.3422923\n",
      "Training [44%] Loss: 0.0015456571754125063 time: 1703260019.3422923\n",
      "weight: [ 1.01090981  0.15929738  0.15289778  1.07946802  0.54635896  0.08392078\n",
      "  0.64282821  0.52960177 -0.11968333 -0.34551654  0.29691218  0.43928893\n",
      "  1.03106577  0.49369696  0.78733664  0.11545062  0.51753574  1.03565518\n",
      "  0.56810995  0.93092995  0.67195498  0.24675078 -0.15312751  0.12154528]\n",
      "epoch 133\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018357854868703643 R2: 0.8927101880330417 time: 1703260028.1652725\n",
      "batch_idx: 1 loss: 0.0012467818103287563 R2: 0.8928590410171895 time: 1703260036.732237\n",
      "Training [44%] Loss: 0.0015412836485995604 time: 1703260036.732237\n",
      "weight: [ 1.01284969  0.1592216   0.15120225  1.07969932  0.54727675  0.0859293\n",
      "  0.64331698  0.53383658 -0.11548948 -0.34596791  0.2965838   0.43896198\n",
      "  1.03287138  0.49559494  0.78726085  0.11659934  0.51952365  1.03774532\n",
      "  0.56814694  0.92997685  0.67068046  0.24590051 -0.1533132   0.12134272]\n",
      "epoch 134\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018303516909424617 R2: 0.8930132692756747 time: 1703260045.5025434\n",
      "batch_idx: 1 loss: 0.0012433791234791377 R2: 0.8931636398813507 time: 1703260054.4572055\n",
      "Training [45%] Loss: 0.0015368654072107997 time: 1703260054.4572055\n",
      "weight: [ 1.01475937  0.15914826  0.14950827  1.07994619  0.5482164   0.08796619\n",
      "  0.64382671  0.53814549 -0.11118283 -0.34643019  0.29625297  0.43863314\n",
      "  1.03464848  0.49749244  0.78718751  0.11775189  0.52152372  1.03984429\n",
      "  0.5682043   0.92904175  0.6694006   0.24503426 -0.15349986  0.12113926]\n",
      "epoch 135\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018248717605541538 R2: 0.8933195249898237 time: 1703260063.1323736\n",
      "batch_idx: 1 loss: 0.0012399311140907634 R2: 0.8934714537122017 time: 1703260072.2026143\n",
      "Training [45%] Loss: 0.0015324014373224587 time: 1703260072.2026143\n",
      "weight: [ 1.0166388   0.15907716  0.14781598  1.08020861  0.54917749  0.09003094\n",
      "  0.64435794  0.54252722 -0.10676303 -0.34690373  0.29591972  0.43830247\n",
      "  1.03639735  0.49938911  0.78711641  0.11890784  0.5235356   1.04195163\n",
      "  0.56828275  0.9281254   0.66811587  0.24415166 -0.15368743  0.12093497]\n",
      "epoch 136\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018193448741285142 R2: 0.8936289973077679 time: 1703260081.3524485\n",
      "batch_idx: 1 loss: 0.0012364363892291468 R2: 0.893782523476642 time: 1703260090.123443\n",
      "Training [45%] Loss: 0.0015278906316788304 time: 1703260090.123443\n",
      "weight: [ 1.01848784  0.15900822  0.14612565  1.08048657  0.55015979  0.09212321\n",
      "  0.64491114  0.54698055 -0.10222983 -0.34738881  0.29558408  0.43797003\n",
      "  1.03811809  0.50128451  0.78704747  0.12006684  0.52555889  1.0440668\n",
      "  0.568383    0.9272284   0.66682659  0.24325242 -0.15387585  0.12072991]\n",
      "epoch 137\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018137721192885616 R2: 0.8939417327153343 time: 1703260098.8947296\n",
      "batch_idx: 1 loss: 0.001232892333836336 R2: 0.8940968794711732 time: 1703260107.4826353\n",
      "Training [46%] Loss: 0.0015233322265624488 time: 1703260107.4826353\n",
      "weight: [ 1.02030627  0.15894143  0.1444376   1.08078007  0.5511632   0.09424279\n",
      "  0.64548678  0.55150425 -0.09758299 -0.34788568  0.29524606  0.43763584\n",
      "  1.0398107   0.50317817  0.78698069  0.12122857  0.52759311  1.0461892\n",
      "  0.56850573  0.92635124  0.66553294  0.24233626 -0.1540651   0.12052412]\n",
      "epoch 138\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018081551316029743 R2: 0.8942577761616762 time: 1703260116.3076336\n",
      "batch_idx: 1 loss: 0.0012292967776368134 R2: 0.8944145487133669 time: 1703260125.1871572\n",
      "Training [46%] Loss: 0.0015187259546198938 time: 1703260125.1871572\n",
      "weight: [ 1.02209395  0.15887679  0.14275213  1.08108911  0.55218752  0.09638939\n",
      "  0.6460853   0.55609702 -0.09282242 -0.34839457  0.29490567  0.43729994\n",
      "  1.04147524  0.50506963  0.78691604  0.1223927   0.5296378   1.04831821\n",
      "  0.56865168  0.92549441  0.66423514  0.24140292 -0.15425513  0.12031764]\n",
      "epoch 139\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018024944999151973 R2: 0.8945771635310369 time: 1703260134.186037\n",
      "batch_idx: 1 loss: 0.001225649147909479 R2: 0.8947355605257574 time: 1703260142.9923167\n",
      "Training [46%] Loss: 0.0015140718239123382 time: 1703260142.9923167\n",
      "weight: [ 1.02385087  0.15881416  0.14106943  1.08141359  0.55323237  0.09856252\n",
      "  0.64670717  0.56075735 -0.08794816 -0.34891574  0.29456295  0.43696238\n",
      "  1.04311195  0.50695848  0.78685341  0.12355883  0.53169245  1.05045322\n",
      "  0.56882159  0.92465855  0.66293353  0.24045214 -0.15444589  0.12011056]\n",
      "epoch 140\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017967892781402951 R2: 0.8948999187462483 time: 1703260151.6072059\n",
      "batch_idx: 1 loss: 0.0012219502261735851 R2: 0.895059945661546 time: 1703260160.3944063\n",
      "Training [47%] Loss: 0.00150936975215694 time: 1703260160.3944063\n",
      "weight: [ 1.02557718  0.15875335  0.13938959  1.08175335  0.55429719  0.10076158\n",
      "  0.64735289  0.56548356 -0.08296042 -0.34944948  0.29421793  0.43662325\n",
      "  1.04472121  0.50884433  0.7867926   0.12472652  0.5337566   1.05259364\n",
      "  0.56901623  0.92384433  0.66162855  0.23948362 -0.15463731  0.11990293]\n",
      "epoch 141\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017910378668709432 R2: 0.8952260573078975 time: 1703260169.722325\n",
      "batch_idx: 1 loss: 0.0012182008970530165 R2: 0.8953877302206804 time: 1703260178.7544081\n",
      "Training [47%] Loss: 0.0015046193819619798 time: 1703260178.7544081\n",
      "weight: [ 1.02727305  0.15869416  0.1377127   1.08210821  0.55538141  0.10298589\n",
      "  0.64802292  0.57027391 -0.0778595  -0.34999607  0.29387069  0.43628262\n",
      "  1.04630341  0.51072679  0.78673342  0.12589532  0.53582972  1.05473887\n",
      "  0.56923637  0.92305244  0.66032065  0.23849708 -0.15482933  0.11969487]\n",
      "epoch 142\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001785239348515778 R2: 0.8955555923589593 time: 1703260187.502518\n",
      "batch_idx: 1 loss: 0.0012144010795587944 R2: 0.8957189299528819 time: 1703260196.5122783\n",
      "Training [47%] Loss: 0.0014998202140372862 time: 1703260196.5122783\n",
      "weight: [ 1.02893858  0.15863646  0.13603888  1.08247799  0.55648452  0.10523492\n",
      "  0.64871772  0.57512664 -0.07264584 -0.35055573  0.29352126  0.43594056\n",
      "  1.04785886  0.51260543  0.78667572  0.12706481  0.53791126  1.05688822\n",
      "  0.5694828   0.92228346  0.65901016  0.23749229 -0.15502187  0.11948642]\n",
      "epoch 143\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017793940879521901 R2: 0.8958885376135056 time: 1703260205.3223531\n",
      "batch_idx: 1 loss: 0.0012105497252672417 R2: 0.896053549734742 time: 1703260214.2626572\n",
      "Training [48%] Loss: 0.001494971906609716 time: 1703260214.2626572\n",
      "weight: [ 1.03057387  0.15858018  0.13436834  1.08286251  0.55760611  0.10750818\n",
      "  0.6494377   0.58004001 -0.06731994 -0.35112867  0.29316967  0.43559711\n",
      "  1.04938779  0.5144798   0.78661944  0.12823461  0.54000061  1.05904097\n",
      "  0.56975629  0.92153791  0.65769734  0.23646904 -0.15521488  0.11927767]\n",
      "epoch 144\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017735031896991406 R2: 0.8962249048479448 time: 1703260222.9323537\n",
      "batch_idx: 1 loss: 0.0012066457343730234 R2: 0.8963915880039082 time: 1703260231.74246\n",
      "Training [48%] Loss: 0.001490074462036082 time: 1703260231.74246\n",
      "weight: [ 1.032179    0.15852524  0.13270126  1.08326157  0.55874573  0.10980517\n",
      "  0.65018328  0.5850122  -0.06188244 -0.35171508  0.29281595  0.43525233\n",
      "  1.05089041  0.51634941  0.7865645   0.12940433  0.54209713  1.06119634\n",
      "  0.57005763  0.92081624  0.65638241  0.23542715 -0.15540831  0.11906868]\n",
      "epoch 145\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017675674481216427 R2: 0.8965646986718697 time: 1703260241.0773597\n",
      "batch_idx: 1 loss: 0.0012026888576965966 R2: 0.8967330415531082 time: 1703260250.1472154\n",
      "Training [48%] Loss: 0.0014851281529091197 time: 1703260250.1472154\n",
      "weight: [ 1.03375417  0.15847155  0.13103776  1.08367492  0.55990281  0.11212531\n",
      "  0.65095489  0.59004126 -0.05633416 -0.35231516  0.29246013  0.43490628\n",
      "  1.05236703  0.51821382  0.7865108   0.13057355  0.54420015  1.06335356\n",
      "  0.5703876   0.92011896  0.65506569  0.23436641 -0.1556021   0.11885951]\n",
      "epoch 146\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017615867913886648 R2: 0.8969079134629142 time: 1703260258.777656\n",
      "batch_idx: 1 loss: 0.001198679783807481 R2: 0.8970779062858197 time: 1703260267.7639098\n",
      "Training [49%] Loss: 0.0014801332875980728 time: 1703260267.7639098\n",
      "weight: [ 1.03529965  0.15841893  0.12937792  1.08410223  0.56107664  0.11446785\n",
      "  0.65175295  0.5951251  -0.05067606 -0.35292913  0.29210227  0.43455903\n",
      "  1.05381802  0.52007258  0.78645818  0.13174183  0.54630897  1.06551184\n",
      "  0.57074702  0.91944664  0.65374752  0.23328661 -0.15579617  0.11865026]\n",
      "epoch 147\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017555606525810577 R2: 0.897254534931726 time: 1703260276.3523552\n",
      "batch_idx: 1 loss: 0.0011946194407566647 R2: 0.8974261736767748 time: 1703260285.312572\n",
      "Training [49%] Loss: 0.0014750900466688611 time: 1703260285.312572\n",
      "weight: [ 1.03681576  0.15836722  0.12772179  1.08454314  0.56226643  0.11683201\n",
      "  0.65257788  0.60026156 -0.04490925 -0.35355722  0.29174243  0.43421066\n",
      "  1.05524379  0.52192525  0.78640648  0.13290869  0.5484229   1.06767038\n",
      "  0.57113667  0.91879983  0.65242828  0.23218755 -0.15599044  0.11844102]\n",
      "epoch 148\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017494888131513464 R2: 0.8976045443173961 time: 1703260294.2824464\n",
      "batch_idx: 1 loss: 0.0011905082464502836 R2: 0.8977778266427512 time: 1703260303.1724293\n",
      "Training [49%] Loss: 0.001469998529800815 time: 1703260303.1724293\n",
      "weight: [ 1.0383028   0.15831631  0.12606945  1.08499726  0.56347142  0.11921704\n",
      "  0.65343008  0.60544842 -0.03903501 -0.35419964  0.29138065  0.43386126\n",
      "  1.05664468  0.52377136  0.78635557  0.1340737   0.55054114  1.06982832\n",
      "  0.57155735  0.91817899  0.6511083   0.23106902 -0.15618483  0.11823188]\n",
      "epoch 149\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017433718937633715 R2: 0.8979579210457261 time: 1703260311.9773338\n",
      "batch_idx: 1 loss: 0.0011863459928945412 R2: 0.898132838712357 time: 1703260320.7728994\n",
      "Training [50%] Loss: 0.0014648589433289565 time: 1703260320.7728994\n",
      "weight: [ 1.03976105  0.15826609  0.12442103  1.08546419  0.56469089  0.12162223\n",
      "  0.65430994  0.61068348 -0.03305469 -0.35485656  0.29101699  0.43351087\n",
      "  1.05802096  0.52561041  0.78630535  0.13523642  0.55266289  1.07198472\n",
      "  0.57200985  0.91758457  0.64978783  0.22993087 -0.15637928  0.11802292]\n",
      "epoch 150\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017372110958033943 R2: 0.8983146416118546 time: 1703260329.7026668\n",
      "batch_idx: 1 loss: 0.0011821323783422102 R2: 0.8984911769124959 time: 1703260338.645834\n",
      "Training [50%] Loss: 0.0014596717370728022 time: 1703260338.645834\n",
      "weight: [ 1.0411908   0.1582165   0.12277662  1.0859435   0.56592405  0.12404682\n",
      "  0.65521784  0.61596446 -0.02696984 -0.35552819  0.29065147  0.43315956\n",
      "  1.05937291  0.52744188  0.78625576  0.13639643  0.55478727  1.07413865\n",
      "  0.57249495  0.91701693  0.64846711  0.22877291 -0.15657371  0.11781422]\n",
      "epoch 151\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017310075381220588 R2: 0.8986746762456234 time: 1703260347.2435703\n",
      "batch_idx: 1 loss: 0.0011778676014340252 R2: 0.8988528052677124 time: 1703260356.0774953\n",
      "Training [50%] Loss: 0.0014544375697780419 time: 1703260356.0774953\n",
      "weight: [ 1.0425924   0.15816743  0.12113632  1.08643472  0.56717004  0.12648999\n",
      "  0.65615413  0.621289   -0.02078215 -0.35621471  0.29028416  0.43280742\n",
      "  1.06070084  0.52926526  0.78620669  0.13755329  0.5569134   1.07628914\n",
      "  0.57301343  0.91647647  0.64714642  0.22759499 -0.15676805  0.11760587]\n",
      "epoch 152\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017247618612168318 R2: 0.8990379868502958 time: 1703260364.8876772\n",
      "batch_idx: 1 loss: 0.0011735524545922632 R2: 0.8992176856159659 time: 1703260374.6573496\n",
      "Training [51%] Loss: 0.0014491571579045475 time: 1703260374.6573496\n",
      "weight: [ 1.04396625  0.15811874  0.11950015  1.08693729  0.56842791  0.12895086\n",
      "  0.6571192   0.62665466 -0.01449348 -0.35691632  0.28991511  0.43245452\n",
      "  1.0620051   0.53108005  0.786158    0.13870652  0.55904039  1.07843522\n",
      "  0.57356605  0.91596361  0.64582607  0.22639693 -0.15696221  0.11739798]\n",
      "epoch 153\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017184744262760507 R2: 0.8994045281165863 time: 1703260383.9624476\n",
      "batch_idx: 1 loss: 0.0011691879041900674 R2: 0.899585775416423 time: 1703260393.6773508\n",
      "Training [51%] Loss: 0.001443831165233059 time: 1703260393.6773508\n",
      "weight: [ 1.04531281  0.15807029  0.11786815  1.08745065  0.56969665  0.13142849\n",
      "  0.65811338  0.63205891 -0.00810585 -0.35763323  0.28954438  0.43210095\n",
      "  1.06328606  0.53288573  0.78610955  0.13985567  0.56116731  1.08057595\n",
      "  0.57415358  0.91547873  0.6445064   0.22517857 -0.15715609  0.11719064]\n",
      "epoch 154\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017121458268947423 R2: 0.899774250459633 time: 1703260403.4194522\n",
      "batch_idx: 1 loss: 0.001164774635067294 R2: 0.8999570251764227 time: 1703260412.6126232\n",
      "Training [51%] Loss: 0.001438460230981018 time: 1703260412.6126232\n",
      "weight: [ 1.04663252  0.15802194  0.11624034  1.08797419  0.57097525  0.13392194\n",
      "  0.65913701  0.63749922 -0.00162143 -0.35836563  0.28917203  0.43174679\n",
      "  1.06454407  0.5346818   0.7860612   0.14100026  0.56329321  1.08271031\n",
      "  0.57477676  0.9150222   0.64318768  0.22393974 -0.15734961  0.11698397]\n",
      "epoch 155\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017057771712176181 R2: 0.9001471018488486 time: 1703260421.3925016\n",
      "batch_idx: 1 loss: 0.001160313003951752 R2: 0.9003313782037801 time: 1703260430.2972684\n",
      "Training [52%] Loss: 0.0014330450875846851 time: 1703260430.2972684\n",
      "weight: [ 1.04792579  0.15797358  0.11461676  1.08850727  0.57226271  0.13643033\n",
      "  0.6601904   0.64297305  0.00495749 -0.3591137   0.28879813  0.43139213\n",
      "  1.06577946  0.5364677   0.78601284  0.14213985  0.56541711  1.08483732\n",
      "  0.57543632  0.91459432  0.64187017  0.22268032 -0.15754269  0.11677806]\n",
      "epoch 156\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016993698890740226 R2: 0.9005230270632432 time: 1703260439.3775187\n",
      "batch_idx: 1 loss: 0.0011558033877799505 R2: 0.9007087728043832 time: 1703260448.2524796\n",
      "Training [52%] Loss: 0.0014275866384269864 time: 1703260448.2524796\n",
      "weight: [ 1.0491931   0.15792508  0.11299743  1.08904924  0.573558    0.13895274\n",
      "  0.66127386  0.64847784  0.01162846 -0.35987759  0.28842272  0.43103705\n",
      "  1.06699254  0.53824289  0.78596434  0.14327398  0.56753802  1.08695597\n",
      "  0.57613298  0.91419536  0.64055412  0.22140019 -0.15773522  0.11657301]\n",
      "epoch 157\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016929253145688394 R2: 0.9009019656285993 time: 1703260457.242221\n",
      "batch_idx: 1 loss: 0.0011512465295881872 R2: 0.9010891446331757 time: 1703260466.1122375\n",
      "Training [52%] Loss: 0.0014220859220785134 time: 1703260466.1122375\n",
      "weight: [ 1.05043493  0.15787629  0.11138235  1.08959939  0.57486004  0.1414882\n",
      "  0.66238765  0.65401097  0.01838887 -0.36065748  0.28804589  0.43068163\n",
      "  1.06818368  0.54000683  0.78591555  0.14440219  0.56965496  1.08906526\n",
      "  0.57686744  0.91382559  0.6392398   0.22009922 -0.15792712  0.11636894]\n",
      "epoch 158\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016864444788976594 R2: 0.901283850852167 time: 1703260475.0123315\n",
      "batch_idx: 1 loss: 0.0011466435431423175 R2: 0.9014724270597471 time: 1703260484.0863307\n",
      "Training [53%] Loss: 0.0014165440110199884 time: 1703260484.0863307\n",
      "weight: [ 1.05165181  0.15782703  0.10977148  1.09015699  0.57616771  0.14403573\n",
      "  0.66353205  0.65956977  0.02523597 -0.36145353  0.28766769  0.43032598\n",
      "  1.06935326  0.54175899  0.78586629  0.14552401  0.57176694  1.09116425\n",
      "  0.57764037  0.91348531  0.63792751  0.2187773  -0.15811829  0.11616597]\n",
      "epoch 159\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016799282792988091 R2: 0.9016686109831651 time: 1703260493.5112233\n",
      "batch_idx: 1 loss: 0.0011419956225867548 R2: 0.9018585496794318 time: 1703260503.082336\n",
      "Training [53%] Loss: 0.001410961950942782 time: 1703260503.082336\n",
      "weight: [ 1.05284431  0.15777712  0.10816477  1.09072123  0.57747982  0.14659431\n",
      "  0.66470731  0.66515156  0.03216686 -0.36226591  0.2872882   0.42997018\n",
      "  1.07050169  0.54349883  0.78581637  0.14663897  0.57387298  1.09325199\n",
      "  0.57845244  0.91317475  0.63661753  0.21743434 -0.15830861  0.1159642 ]\n",
      "epoch 160\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016733777941382287 R2: 0.9020561712718662 time: 1703260512.122187\n",
      "batch_idx: 1 loss: 0.0011373037885404334 R2: 0.9022474369579594 time: 1703260521.222218\n",
      "Training [53%] Loss: 0.001405340791339331 time: 1703260521.222218\n",
      "weight: [ 1.05401297  0.15772636  0.10656217  1.09129133  0.57879524  0.14916294\n",
      "  0.66591364  0.67075368  0.03917853 -0.36309478  0.2869075   0.42961435\n",
      "  1.07162937  0.54522582  0.78576561  0.14774659  0.57597208  1.09532755\n",
      "  0.57930426  0.91289414  0.63531013  0.21607024 -0.15849799  0.11576377]\n",
      "epoch 161\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001666794403449807 R2: 0.9024464549665507 time: 1703260530.452614\n",
      "batch_idx: 1 loss: 0.0011325689148477145 R2: 0.9026390086098812 time: 1703260539.2573466\n",
      "Training [54%] Loss: 0.0013996816591487608 time: 1703260539.2573466\n",
      "weight: [ 1.05515835  0.15767457  0.10496361  1.09186645  0.58011279  0.15174063\n",
      "  0.66715124  0.67637346  0.04626783 -0.36394026  0.28652565  0.42925857\n",
      "  1.07273666  0.54693941  0.78571383  0.14884643  0.57806326  1.09739\n",
      "  0.58019646  0.91264365  0.63400556  0.21468494 -0.15868632  0.11556478]\n",
      "epoch 162\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016601796216715939 R2: 0.9028393826390986 time: 1703260548.5574396\n",
      "batch_idx: 1 loss: 0.0011277919594855925 R2: 0.9030331813351365 time: 1703260557.3172135\n",
      "Training [54%] Loss: 0.0013939857905785932 time: 1703260557.3172135\n",
      "weight: [ 1.05628101  0.15762156  0.10336904  1.09244574  0.58143129  0.15432638\n",
      "  0.66842031  0.68200825  0.0534315  -0.36480249  0.28614274  0.42890294\n",
      "  1.07382397  0.54863904  0.78566082  0.14993801  0.58014552  1.09943845\n",
      "  0.58112961  0.91242344  0.63270406  0.21327836 -0.15887349  0.11536737]\n",
      "epoch 163\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016535348553495446 R2: 0.9032348710250979 time: 1703260566.3025093\n",
      "batch_idx: 1 loss: 0.001122974126901605 R2: 0.9034298701990402 time: 1703260575.1624508\n",
      "Training [54%] Loss: 0.001388254491125575 time: 1703260575.1624508\n",
      "weight: [ 1.05738156  0.15756712  0.10177836  1.09302832  0.58274953  0.15691915\n",
      "  0.66972099  0.68765536  0.06066614 -0.36568162  0.28575885  0.42854757\n",
      "  1.07489168  0.55032419  0.78560638  0.15102088  0.5822179   1.10147203\n",
      "  0.58210424  0.91223365  0.6314059   0.21185045 -0.1590594   0.11517166]\n",
      "epoch 164\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016468613431375304 R2: 0.9036328329028438 time: 1703260585.2644296\n",
      "batch_idx: 1 loss: 0.001118116800455698 R2: 0.9038289885463898 time: 1703260595.2225502\n",
      "Training [55%] Loss: 0.0013824890717966142 time: 1703260595.2225502\n",
      "weight: [ 1.0584606   0.15751102  0.10019146  1.09361325  0.58406626  0.15951789\n",
      "  0.67105341  0.69331214  0.06796826 -0.36657778  0.28537406  0.42819257\n",
      "  1.07594022  0.55199431  0.78555027  0.15209457  0.58427943  1.1034899\n",
      "  0.58312086  0.91207441  0.63011132  0.21040116 -0.15924392  0.11497778]\n",
      "epoch 165\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016401603094496633 R2: 0.9040331782488552 time: 1703260604.1575365\n",
      "batch_idx: 1 loss: 0.0011132213446900226 R2: 0.9042304470132834 time: 1703260613.1523871\n",
      "Training [55%] Loss: 0.001376690827069843 time: 1703260613.1523871\n",
      "weight: [ 1.05951876  0.15745302  0.09860824  1.09419959  0.58538019  0.16212154\n",
      "  0.6724177   0.69897591  0.07533424 -0.3674911   0.28498845  0.42783804\n",
      "  1.07697001  0.55364886  0.78549228  0.15315862  0.58632917  1.10549125\n",
      "  0.58417994  0.9119458   0.6288206   0.20893044 -0.15942693  0.11478587]\n",
      "epoch 166\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016334331380261809 R2: 0.9044358155439485 time: 1703260622.1647506\n",
      "batch_idx: 1 loss: 0.0011082889964924409 R2: 0.9046341530576539 time: 1703260631.382189\n",
      "Training [55%] Loss: 0.0013708610672593109 time: 1703260631.382189\n",
      "weight: [ 1.06055664  0.15739292  0.09702859  1.09478638  0.58669008  0.16472903\n",
      "  0.67381393  0.70464407  0.08276039 -0.3684217   0.28460211  0.42748411\n",
      "  1.07798143  0.55528733  0.78543217  0.15421258  0.58836616  1.10747529\n",
      "  0.58528191  0.9118479   0.62753396  0.20743825 -0.15960833  0.11459606]\n",
      "epoch 167\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016266813807474857 R2: 0.9048406521041061 time: 1703260640.5372088\n",
      "batch_idx: 1 loss: 0.001103320938268241 R2: 0.9050400116775768 time: 1703260650.0224805\n",
      "Training [56%] Loss: 0.0013650011595078633 time: 1703260650.0224805\n",
      "weight: [ 1.06157487  0.15733048  0.0954524   1.09537265  0.58799464  0.16733932\n",
      "  0.67524216  0.71031403  0.09024294 -0.36936972  0.28421513  0.42713086\n",
      "  1.07897488  0.55690915  0.78536974  0.15525601  0.59038948  1.10944125\n",
      "  0.58642716  0.91178072  0.62625162  0.20592456 -0.15978798  0.11440849]\n",
      "epoch 168\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016199066169058987 R2: 0.9052475934908066 time: 1703260659.8056152\n",
      "batch_idx: 1 loss: 0.0010983184424798475 R2: 0.9054479266303052 time: 1703260669.474682\n",
      "Training [56%] Loss: 0.001359112529692873 time: 1703260669.474682\n",
      "weight: [ 1.06257405  0.15726548  0.09387955  1.09595739  0.58929261  0.16995132\n",
      "  0.67670242  0.71598321  0.09777802 -0.37033526  0.28382759  0.42677843\n",
      "  1.07995075  0.5585138   0.78530474  0.15628846  0.59239821  1.1113884\n",
      "  0.58761602  0.91174426  0.62497381  0.20438937 -0.15996577  0.1142233 ]\n",
      "epoch 169\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016131103314843734 R2: 0.9056565430082374 time: 1703260678.3775864\n",
      "batch_idx: 1 loss: 0.0010932829206972924 R2: 0.9058578010258393 time: 1703260687.1623363\n",
      "Training [56%] Loss: 0.001353196626090833 time: 1703260687.1623363\n",
      "weight: [ 1.06355482  0.15719769  0.0923099   1.09653958  0.59058267  0.17256395\n",
      "  0.6781947   0.72164909  0.10536169 -0.37131845  0.2834396   0.42642693\n",
      "  1.08090944  0.56010075  0.78523695  0.15730949  0.59439146  1.11331603\n",
      "  0.58884878  0.9117385   0.62370074  0.20283264 -0.16014157  0.11404063]\n",
      "epoch 170\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016062939334034055 R2: 0.9060674020404844 time: 1703260695.922429\n",
      "batch_idx: 1 loss: 0.0010882158386686855 R2: 0.9062695369885032 time: 1703260704.7374449\n",
      "Training [57%] Loss: 0.0013472548860360455 time: 1703260704.7374449\n",
      "weight: [ 1.0645178   0.15712687  0.09074335  1.09711819  0.59186352  0.17517612\n",
      "  0.67971898  0.72730915  0.11298997 -0.37231942  0.28305123  0.42607647\n",
      "  1.08185133  0.56166949  0.78516612  0.15831868  0.59636837  1.11522349\n",
      "  0.59012568  0.91176339  0.62243263  0.20125436 -0.16031525  0.11386062]\n",
      "epoch 171\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015994588668781524 R2: 0.9064800709597124 time: 1703260713.5774632\n",
      "batch_idx: 1 loss: 0.001083118607722393 R2: 0.9066830351063897 time: 1703260722.8923478\n",
      "Training [57%] Loss: 0.0013412887373002726 time: 1703260722.8923478\n",
      "weight: [ 1.06546364  0.15705277  0.08917974  1.09769218  0.59313385  0.17778674\n",
      "  0.68127518  0.73296095  0.1206588  -0.37333826  0.2826626   0.42572718\n",
      "  1.08277681  0.5632195   0.78509203  0.1593156   0.59832808  1.11711015\n",
      "  0.59144692  0.91181885  0.62116968  0.19965454 -0.16048668  0.11368343]\n",
      "epoch 172\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001592606677629262 R2: 0.9068944497513989 time: 1703260732.157127\n",
      "batch_idx: 1 loss: 0.0010779925704580942 R2: 0.9070981944910382 time: 1703260741.0168085\n",
      "Training [57%] Loss: 0.0013352996240436781 time: 1703260741.0168085\n",
      "weight: [ 1.06639293  0.15697519  0.08761896  1.0982605   0.59439237  0.18039473\n",
      "  0.68286322  0.7386021   0.1283641  -0.3743751   0.28227378  0.42537917\n",
      "  1.08368626  0.56475026  0.78501444  0.16029984  0.60026979  1.11897541\n",
      "  0.59281264  0.91190476  0.61991208  0.19803318 -0.16065573  0.11350921]\n",
      "epoch 173\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015857389664954453 R2: 0.9073104379217607 time: 1703260750.082597\n",
      "batch_idx: 1 loss: 0.0010728390788817192 R2: 0.9075149134703123 time: 1703260758.8658106\n",
      "Training [58%] Loss: 0.0013292890226885823 time: 1703260758.8658106\n",
      "weight: [ 1.0673063   0.15689388  0.08606087  1.09882211  0.59563782  0.18299902\n",
      "  0.68448296  0.74423024  0.13610176 -0.37543003  0.28188489  0.42503257\n",
      "  1.08458003  0.56626128  0.78493314  0.161271    0.6021927   1.12081871\n",
      "  0.59422291  0.91202097  0.61866     0.1963903  -0.16082227  0.11333809]\n",
      "epoch 174\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015788572949387719 R2: 0.9077279340762274 time: 1703260767.7982905\n",
      "batch_idx: 1 loss: 0.0010676595644321602 R2: 0.9079330902326108 time: 1703260776.6385458\n",
      "Training [58%] Loss: 0.001323258429685466 time: 1703260776.6385458\n",
      "weight: [ 1.06820436  0.15680862  0.08450536  1.09937594  0.59686891  0.18559855\n",
      "  0.68613423  0.7498431   0.14386764 -0.37650315  0.28149601  0.42468749\n",
      "  1.0854585   0.56775205  0.78484788  0.16222868  0.60409605  1.12263954\n",
      "  0.59567777  0.91216732  0.6174136   0.19472592 -0.16098616  0.11317024]\n",
      "epoch 175\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015719631484766236 R2: 0.9081468358346136 time: 1703260785.272304\n",
      "batch_idx: 1 loss: 0.0010624555247500808 R2: 0.9083526228826093 time: 1703260793.7974124\n",
      "Training [58%] Loss: 0.0013172093366133522 time: 1703260793.7974124\n",
      "weight: [ 1.0690877   0.15671919  0.0829523   1.09992096  0.5980844   0.18819224\n",
      "  0.68781685  0.75543844  0.15165757 -0.37759455  0.28110724  0.42434405\n",
      "  1.08632202  0.56922209  0.78475844  0.16317251  0.60597913  1.12443742\n",
      "  0.59717719  0.9123436   0.61617304  0.19304007 -0.16114728  0.11300581]\n",
      "epoch 176\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001565057984648324 R2: 0.9085670402601524 time: 1703260802.9274912\n",
      "batch_idx: 1 loss: 0.0010572284543290211 R2: 0.9087734090763602 time: 1703260812.1735902\n",
      "Training [59%] Loss: 0.0013111432194886725 time: 1703260812.1735902\n",
      "weight: [ 1.06995694  0.15662535  0.08140154  1.1004561   0.59928305  0.19077905\n",
      "  0.68953057  0.76101409  0.15946742 -0.37870433  0.28071868  0.42400239\n",
      "  1.08717094  0.57067094  0.7846646   0.16410209  0.60784126  1.12621191\n",
      "  0.59872109  0.91254959  0.61493848  0.19133279 -0.16130548  0.11284494]\n",
      "epoch 177\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001558143297037542 R2: 0.9089884443751977 time: 1703260821.452272\n",
      "batch_idx: 1 loss: 0.0010519798020953521 R2: 0.9091953458184558 time: 1703260830.5626504\n",
      "Training [59%] Loss: 0.0013050615495664472 time: 1703260830.5626504\n",
      "weight: [ 1.07081265  0.15652689  0.07985299  1.10098034  0.60046364  0.19335795\n",
      "  0.69127511  0.76656797  0.16729301 -0.37983256  0.28033043  0.42366261\n",
      "  1.08800561  0.57209812  0.78456614  0.16501709  0.60968177  1.12796263\n",
      "  0.60030932  0.91278503  0.61371003  0.18960414 -0.16146063  0.1126878 ]\n",
      "epoch 178\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015512206218726962 R2: 0.9094109452955731 time: 1703260839.5625846\n",
      "batch_idx: 1 loss: 0.001046710995287966 R2: 0.9096183297167217 time: 1703260848.2474551\n",
      "Training [59%] Loss: 0.0012989658085803312 time: 1703260848.2474551\n",
      "weight: [ 1.0716554   0.1564236   0.07830652  1.10149264  0.60162502  0.19592793\n",
      "  0.69305017  0.77209805  0.17513022 -0.38097932  0.2799426   0.42332485\n",
      "  1.08882636  0.57350319  0.78446286  0.16591714  0.61150007  1.12968921\n",
      "  0.60194168  0.91304964  0.61248782  0.18785418 -0.16161259  0.11253454]\n",
      "epoch 179\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001544291489475757 R2: 0.9098344399952621 time: 1703260856.8874424\n",
      "batch_idx: 1 loss: 0.001041423489843199 R2: 0.9100422574254943 time: 1703260865.7325819\n",
      "Training [60%] Loss: 0.001292857489659478 time: 1703260865.7325819\n",
      "weight: [ 1.07248576  0.15631528  0.07676202  1.10199201  0.60276603  0.19848801\n",
      "  0.6948554   0.77760238  0.18297495 -0.38214467  0.27955527  0.42298922\n",
      "  1.08963351  0.5748857   0.78435454  0.16680192  0.61329558  1.13139133\n",
      "  0.60361792  0.91334309  0.61127193  0.18608298 -0.16176123  0.1123853 ]\n",
      "epoch 180\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015373573831622186 R2: 0.9102588251037791 time: 1703260874.7024784\n",
      "batch_idx: 1 loss: 0.0010361187853968933 R2: 0.9104670258326102 time: 1703260883.5027037\n",
      "Training [60%] Loss: 0.001286738084279556 time: 1703260883.5027037\n",
      "weight: [ 1.07330427  0.15620174  0.07521939  1.10247744  0.60388555  0.2010372\n",
      "  0.69669041  0.78307909  0.1908231  -0.38332866  0.27916854  0.42265584\n",
      "  1.09042738  0.57624522  0.78424099  0.1676711   0.61506776  1.13306872\n",
      "  0.60533771  0.91366505  0.61006246  0.18429063 -0.16190641  0.11224025]\n",
      "epoch 181\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015304197494995884 R2: 0.9106839970238905 time: 1703260892.4925377\n",
      "batch_idx: 1 loss: 0.0010307983927138006 R2: 0.9108925318907138 time: 1703260902.3174834\n",
      "Training [60%] Loss: 0.0012806090711066946 time: 1703260902.3174834\n",
      "weight: [ 1.07411147  0.15608277  0.07367854  1.10294797  0.60498252  0.20357456\n",
      "  0.69855478  0.78852637  0.19867065 -0.38453134  0.27878252  0.42232483\n",
      "  1.09120826  0.57758134  0.78412203  0.16852439  0.61681611  1.13472113\n",
      "  0.60710068  0.91401516  0.60885947  0.18247722 -0.162048    0.11209953]\n",
      "epoch 182\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015234800398910462 R2: 0.9111098522456655 time: 1703260912.0177615\n",
      "batch_idx: 1 loss: 0.0010254637960584857 R2: 0.9113186723939537 time: 1703260920.9766314\n",
      "Training [61%] Loss: 0.001274471917974766 time: 1703260920.9766314\n",
      "weight: [ 1.07490787  0.15595821  0.07213938  1.10340264  0.6060559   0.20609916\n",
      "  0.70044803  0.7939425   0.2065136  -0.38575277  0.2783973   0.42199632\n",
      "  1.09197646  0.57889366  0.78399746  0.16936148  0.61854019  1.13634835\n",
      "  0.60890639  0.91439301  0.60766302  0.18064286 -0.16218586  0.11196331]\n",
      "epoch 183\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001516539732379187 R2: 0.9115362875285656 time: 1703260929.327518\n",
      "batch_idx: 1 loss: 0.0010201164515089046 R2: 0.9117453440037433 time: 1703260937.7434852\n",
      "Training [61%] Loss: 0.0012683280919440457 time: 1703260937.7434852\n",
      "weight: [ 1.07569398  0.15582788  0.07060184  1.10384052  0.60710471  0.20861012\n",
      "  0.70236967  0.79932584  0.21434803 -0.38699295  0.27801297  0.4216704\n",
      "  1.09273225  0.58018179  0.78386714  0.17018211  0.62023956  1.13795021\n",
      "  0.61075436  0.91479819  0.60647315  0.17878766 -0.16231985  0.11183172]\n",
      "epoch 184\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015096003131391893 R2: 0.9119631998189816 time: 1703260946.5526505\n",
      "batch_idx: 1 loss: 0.0010147578157126533 R2: 0.9121724434940368 time: 1703260955.230634\n",
      "Training [61%] Loss: 0.0012621790644259212 time: 1703260955.230634\n",
      "weight: [ 1.07647027  0.15569163  0.06906584  1.10426074  0.60812801  0.21110658\n",
      "  0.70431915  0.80467484  0.22217008 -0.38825192  0.27762964  0.42134721\n",
      "  1.09347589  0.58144534  0.78373089  0.17098602  0.62191386  1.13952657\n",
      "  0.61264403  0.91523024  0.60528986  0.17691176 -0.16244985  0.11170492]\n",
      "epoch 185\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015026632450221686 R2: 0.9123904860822687 time: 1703260964.858414\n",
      "batch_idx: 1 loss: 0.0010093893672858379 R2: 0.9125998679443155 time: 1703260974.1373298\n",
      "Training [62%] Loss: 0.0012560263061540031 time: 1703260974.1373298\n",
      "weight: [ 1.07723721  0.15554932  0.06753134  1.10466242  0.60912491  0.21358771\n",
      "  0.70629589  0.80998802  0.22997594 -0.38952968  0.27724739  0.42102684\n",
      "  1.09420765  0.58268396  0.78358858  0.17177296  0.62356273  1.14107732\n",
      "  0.6145748   0.91568869  0.60411316  0.17501529 -0.16257572  0.11158306]\n",
      "epoch 186\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014957299596883335 R2: 0.9128180432892845 time: 1703260983.6426961\n",
      "batch_idx: 1 loss: 0.001004012598282886 R2: 0.9130275147120581 time: 1703260993.3877065\n",
      "Training [62%] Loss: 0.0012498712789856098 time: 1703260993.3877065\n",
      "weight: [ 1.07799524  0.15540081  0.06599828  1.10504473  0.61009459  0.21605271\n",
      "  0.70829927  0.81526399  0.23776191 -0.39082623  0.27686631  0.42070941\n",
      "  1.09492777  0.5838973   0.78344007  0.17254271  0.62518589  1.1426024\n",
      "  0.61654602  0.91617305  0.60294302  0.17309842 -0.16269733  0.11146627]\n",
      "epoch 187\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014888018769212124 R2: 0.91324576858218 time: 1703261002.097765\n",
      "batch_idx: 1 loss: 0.0009986289906530714 R2: 0.913455281291799 time: 1703261010.5323963\n",
      "Training [62%] Loss: 0.001243715433787142 time: 1703261010.5323963\n",
      "weight: [ 1.07874479  0.15524598  0.06446664  1.1054069   0.61103626  0.21850083\n",
      "  0.71032865  0.82050144  0.24552435 -0.39214154  0.2764865   0.42039502\n",
      "  1.09563649  0.58508503  0.78328524  0.17329506  0.62678306  1.14410175\n",
      "  0.61855698  0.91668281  0.60177942  0.17116132 -0.16281456  0.1113547 ]\n",
      "epoch 188\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014818804237174009 R2: 0.91367355944029 time: 1703261019.5022817\n",
      "batch_idx: 1 loss: 0.0009932400066597481 R2: 0.913883065277456 time: 1703261029.3927004\n",
      "Training [63%] Loss: 0.0012375602151885744 time: 1703261029.3927004\n",
      "weight: [ 1.07948626  0.15508472  0.06293639  1.10574816  0.61194921  0.22093137\n",
      "  0.71238331  0.82569915  0.25325973 -0.39347559  0.27610803  0.42008378\n",
      "  1.09633402  0.58624684  0.78312397  0.17402981  0.62835403  1.14557538\n",
      "  0.62060693  0.91721742  0.60062228  0.16920417 -0.16292728  0.1112485 ]\n",
      "epoch 189\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001474967030931302 R2: 0.9141013137006364 time: 1703261038.8830638\n",
      "batch_idx: 1 loss: 0.000987847101325021 R2: 0.9143107644940228 time: 1703261047.3025239\n",
      "Training [63%] Loss: 0.0012314070661281614 time: 1703261047.3025239\n",
      "weight: [ 1.08022004  0.15491692  0.06140752  1.10606781  0.6128328   0.22334366\n",
      "  0.71446255  0.83085597  0.26096459 -0.39482833  0.275731    0.41977578\n",
      "  1.09702058  0.58738242  0.78295618  0.17474678  0.6298986   1.14702331\n",
      "  0.62269506  0.91777632  0.59947154  0.16722717 -0.16303537  0.11114778]\n",
      "epoch 190\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014680631144146467 R2: 0.914528929479904 time: 1703261055.687732\n",
      "batch_idx: 1 loss: 0.0009824517386823202 R2: 0.9147382771676813 time: 1703261064.022629\n",
      "Training [63%] Loss: 0.0012252574265484836 time: 1703261064.022629\n",
      "weight: [ 1.08094648  0.15474251  0.05988002  1.10636518  0.61368643  0.22573708\n",
      "  0.7165656   0.83597086  0.26863559 -0.3961997   0.27535549  0.41947111\n",
      "  1.09769636  0.58849149  0.78278177  0.17544582  0.63141665  1.14844559\n",
      "  0.62482054  0.91835893  0.5983271   0.16523053 -0.16313871  0.11105269]\n",
      "epoch 191\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014611700638111082 R2: 0.9149563051520146 time: 1703261072.4927597\n",
      "batch_idx: 1 loss: 0.000977055392381988 R2: 0.9151655019892833 time: 1703261081.072521\n",
      "Training [64%] Loss: 0.001219112728096548 time: 1703261081.072521\n",
      "weight: [ 1.08166593  0.15456141  0.05835392  1.10663967  0.6145096   0.22811104\n",
      "  0.71869166  0.84104284  0.27626948 -0.39758963  0.27498157  0.41916988\n",
      "  1.09836156  0.58957379  0.78260067  0.17612679  0.63290806  1.14984229\n",
      "  0.62698247  0.91896467  0.59718883  0.16321449 -0.16323719  0.11096335]\n",
      "epoch 192\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014542892495452613 R2: 0.9153833394520412 time: 1703261089.4475822\n",
      "batch_idx: 1 loss: 0.0009716595319465814 R2: 0.9155923380786744 time: 1703261098.0135694\n",
      "Training [64%] Loss: 0.0012129743907459214 time: 1703261098.0135694\n",
      "weight: [ 1.08237872  0.15437356  0.05682922  1.10689069  0.61530183  0.23046502\n",
      "  0.72083991  0.84607104  0.28386314 -0.39899802  0.27460933  0.41887215\n",
      "  1.09901636  0.59062906  0.78241281  0.17678954  0.63437276  1.15121353\n",
      "  0.62917995  0.91959291  0.59605661  0.1611793  -0.16333069  0.11087989]\n",
      "epoch 193\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014474220363702018 R2: 0.9158099316301429 time: 1703261106.4473274\n",
      "batch_idx: 1 loss: 0.000966265611514878 R2: 0.9160186849752041 time: 1703261114.658848\n",
      "Training [64%] Loss: 0.00120684382394254 time: 1703261114.658848\n",
      "weight: [ 1.08308513  0.1541789   0.05530597  1.10711773  0.61606276  0.23279854\n",
      "  0.72300949  0.85105463  0.29141353 -0.40042477  0.27423882  0.41857803\n",
      "  1.09966092  0.59165708  0.78221816  0.17743398  0.63581071  1.15255945\n",
      "  0.63141199  0.92024304  0.59493029  0.1591252  -0.16341911  0.11080242]\n",
      "epoch 194\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014405697866923493 R2: 0.9162359815451986 time: 1703261122.8314545\n",
      "batch_idx: 1 loss: 0.000960875071767674 R2: 0.9164444427360647 time: 1703261130.8642676\n",
      "Training [65%] Loss: 0.0012007224292300118 time: 1703261130.8642676\n",
      "weight: [ 1.08378546  0.15397741  0.05378421  1.10732032  0.61679206  0.23511116\n",
      "  0.72519953  0.85599291  0.29891774 -0.40186976  0.27387013  0.41828757\n",
      "  1.10029542  0.59265762  0.78201667  0.17805999  0.63722193  1.1538802\n",
      "  0.63367763  0.9209144   0.59380968  0.15705249 -0.16350233  0.11073105]\n",
      "epoch 195\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001433733851445659 R2: 0.9166613896846391 time: 1703261139.0226789\n",
      "batch_idx: 1 loss: 0.0009554893487707713 R2: 0.9168695120966321 time: 1703261147.2127357\n",
      "Training [65%] Loss: 0.0011946116001082152 time: 1703261147.2127357\n",
      "weight: [ 1.08447994  0.15376906  0.05226399  1.10749804  0.61748948  0.23740251\n",
      "  0.72740912  0.86088523  0.30637296 -0.40333284  0.27350332  0.41800086\n",
      "  1.10091998  0.59363049  0.78180832  0.17866751  0.63860643  1.15517598\n",
      "  0.63597584  0.92160636  0.59269459  0.15496145 -0.16358027  0.1106659 ]\n",
      "epoch 196\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014269155605675825 R2: 0.9170860571917631 time: 1703261156.0281746\n",
      "batch_idx: 1 loss: 0.0009501098767720165 R2: 0.9172937945945232 time: 1703261164.4057095\n",
      "Training [65%] Loss: 0.0011885127186697995 time: 1703261164.4057095\n",
      "weight: [ 1.08516882  0.15355384  0.05074538  1.10765052  0.61815484  0.23967224\n",
      "  0.72963732  0.86573102  0.31377653 -0.40481386  0.27313844  0.41771796\n",
      "  1.10153476  0.5945755   0.78159309  0.17925645  0.6399643   1.15644698\n",
      "  0.63830558  0.92231824  0.59158482  0.15285239 -0.16365283  0.11060706]\n",
      "epoch 197\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014201162231107243 R2: 0.9175098859674626 time: 1703261172.9423344\n",
      "batch_idx: 1 loss: 0.0009447380812075438 R2: 0.9177171926270635 time: 1703261181.2577503\n",
      "Training [66%] Loss: 0.001182427152159134 time: 1703261181.2577503\n",
      "weight: [ 1.08585232  0.15333174  0.04922845  1.10777744  0.61878804  0.24192008\n",
      "  0.73188319  0.8705298   0.32112586 -0.40631265  0.27277557  0.41743893\n",
      "  1.10213989  0.59549248  0.78137099  0.17982677  0.64129563  1.15769344\n",
      "  0.64066579  0.92304937  0.59048013  0.15072562 -0.16371992  0.11055464]\n",
      "epoch 198\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014133371340068212 R2: 0.9179327788256206 time: 1703261189.5977514\n",
      "batch_idx: 1 loss: 0.0009393753699531561 R2: 0.9181396095014172 time: 1703261197.9147124\n",
      "Training [66%] Loss: 0.0011763562519799887 time: 1703261197.9147124\n",
      "weight: [ 1.08653062  0.15310278  0.0477133   1.10787855  0.61938902  0.2441458\n",
      "  0.73414574  0.87528115  0.3284185  -0.40782902  0.27241474  0.41716383\n",
      "  1.10273548  0.59638128  0.78114203  0.18037842  0.64260054  1.15891561\n",
      "  0.64305538  0.92379907  0.58938027  0.1485815  -0.16378145  0.11050872]\n",
      "epoch 199\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014065795772519529 R2: 0.9183546396324835 time: 1703261206.2475693\n",
      "batch_idx: 1 loss: 0.0009340231313831025 R2: 0.9185609495420548 time: 1703261214.7048156\n",
      "Training [66%] Loss: 0.0011703013543175277 time: 1703261214.7048156\n",
      "weight: [ 1.08720391  0.15286698  0.04620002  1.10795365  0.61995781  0.24634919\n",
      "  0.736424    0.87998474  0.33565213 -0.40936276  0.27205602  0.41689271\n",
      "  1.10332166  0.59724178  0.78090624  0.18091137  0.6438792   1.16011376\n",
      "  0.64547326  0.92456666  0.58828499  0.14642036 -0.16383734  0.11046938]\n",
      "epoch 200\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013998448209775224 R2: 0.9187753733984956 time: 1703261223.1935673\n",
      "batch_idx: 1 loss: 0.0009286827385185041 R2: 0.9189811182504639 time: 1703261231.527306\n",
      "Training [67%] Loss: 0.0011642637797480131 time: 1703261231.527306\n",
      "weight: [ 1.08787232  0.15262438  0.04468871  1.10800257  0.62049448  0.24853013\n",
      "  0.73871695  0.88464029  0.34282453 -0.41091366  0.27169944  0.4166256\n",
      "  1.10389851  0.59807384  0.78066363  0.18142561  0.64513179  1.16128818\n",
      "  0.64791832  0.92535143  0.587194    0.14424258 -0.16388751  0.1104367 ]\n",
      "epoch 201\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013931341097098795 R2: 0.9191948863569401 time: 1703261240.056837\n",
      "batch_idx: 1 loss: 0.0009233555517591614 R2: 0.9194000224597187 time: 1703261248.5423012\n",
      "Training [67%] Loss: 0.0011582448307345204 time: 1703261248.5423012\n",
      "weight: [ 1.08853601  0.15237502  0.0431795   1.10802522  0.62099919  0.25068853\n",
      "  0.74102357  0.88924762  0.3499336  -0.41248147  0.27134504  0.41636256\n",
      "  1.10446615  0.59887736  0.78041428  0.18192113  0.64635852  1.16243918\n",
      "  0.65038945  0.92615269  0.58610701  0.14204852 -0.16393191  0.11041076]\n",
      "epoch 202\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001386448661209316 R2: 0.9196130860776007 time: 1703261256.9224353\n",
      "batch_idx: 1 loss: 0.000918042915621942 R2: 0.9198175704476979 time: 1703261265.9476933\n",
      "Training [67%] Loss: 0.0011522457884156289 time: 1703261265.9476933\n",
      "weight: [ 1.08919508  0.15211896  0.04167251  1.10802156  0.62147214  0.25282434\n",
      "  0.74334285  0.89380658  0.35697736 -0.41406596  0.27099287  0.41610361\n",
      "  1.10502467  0.59965227  0.78015821  0.18239792  0.64755964  1.16356708\n",
      "  0.65288553  0.92696975  0.58502369  0.13983859 -0.16397046  0.11039162]\n",
      "epoch 203\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001379789668686309 R2: 0.9200298816189656 time: 1703261273.9124997\n",
      "batch_idx: 1 loss: 0.0009127461524428384 R2: 0.9202336720298379 time: 1703261281.712582\n",
      "Training [68%] Loss: 0.0011462679105645737 time: 1703261281.712582\n",
      "weight: [ 1.08984963  0.15185626  0.04016787  1.10799159  0.62191361  0.25493756\n",
      "  0.74567374  0.8983171   0.36395393 -0.41566684  0.27064295  0.41584877\n",
      "  1.10557414  0.60039847  0.77989552  0.18285601  0.6487354   1.16467224\n",
      "  0.65540543  0.92780189  0.58394373  0.13761318 -0.16400311  0.11037934]\n",
      "epoch 204\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013731583029988478 R2: 0.9204451836808293 time: 1703261290.1327562\n",
      "batch_idx: 1 loss: 0.0009074665587497077 R2: 0.9206482386736521 time: 1703261298.322727\n",
      "Training [68%] Loss: 0.0011403124308742778 time: 1703261298.322727\n",
      "weight: [ 1.09049975  0.151587    0.03866572  1.10793537  0.62232391  0.25702824\n",
      "  0.74801521  0.90277919  0.37086155 -0.41728385  0.27029531  0.41559808\n",
      "  1.10611464  0.60111593  0.77962626  0.1832954   0.6498861   1.165755\n",
      "  0.65794805  0.92864842  0.58286678  0.1353727  -0.1640298   0.11037397]\n",
      "epoch 205\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013665557105748559 R2: 0.9208589047272285 time: 1703261306.322772\n",
      "batch_idx: 1 loss: 0.0009022054057711195 R2: 0.9210611836451463 time: 1703261314.4414551\n",
      "Training [68%] Loss: 0.0011343805581729878 time: 1703261314.4414551\n",
      "weight: [ 1.09114549  0.15131127  0.03716621  1.10785301  0.62270342  0.25909647\n",
      "  0.7503662   0.90719289  0.37769859 -0.41891668  0.26994998  0.41535153\n",
      "  1.10664625  0.60180459  0.77935053  0.18371614  0.65101204  1.16681575\n",
      "  0.66051226  0.92950865  0.58179249  0.13311758 -0.16405049  0.11037555]\n",
      "epoch 206\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013599830085820183 R2: 0.921270959089086 time: 1703261322.7023559\n",
      "batch_idx: 1 loss: 0.0008969639404725223 R2: 0.9214724221581203 time: 1703261331.2616858\n",
      "Training [69%] Loss: 0.0011284734745272704 time: 1703261331.2616858\n",
      "weight: [ 1.09178691  0.15102916  0.03566949  1.10774469  0.62305258  0.26114235\n",
      "  0.75272568  0.9115583   0.38446348 -0.42056503  0.26960696  0.41510915\n",
      "  1.10716902  0.60246442  0.77906842  0.18411825  0.65211354  1.16785486\n",
      "  0.66309697  0.93038187  0.58072049  0.13084826 -0.16406513  0.11038412]\n",
      "epoch 207\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013534412818075174 R2: 0.9216812630761122 time: 1703261339.512429\n",
      "batch_idx: 1 loss: 0.0008917433835660411 R2: 0.9218818714972123 time: 1703261348.5023594\n",
      "Training [69%] Loss: 0.0011225923326867791 time: 1703261348.5023594\n",
      "weight: [ 1.09242404  0.15074077  0.03417572  1.1076106   0.62337185  0.26316607\n",
      "  0.7550926   0.9158756   0.39115481 -0.42222857  0.26926629  0.41487094\n",
      "  1.10768302  0.60309541  0.77878003  0.18450176  0.65319097  1.16887274\n",
      "  0.66570109  0.93126739  0.57965041  0.12856518 -0.1640737   0.11039971]\n",
      "epoch 208\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013469315829690947 R2: 0.9220897351087084 time: 1703261357.622532\n",
      "batch_idx: 1 loss: 0.0008865449251182529 R2: 0.9222894511174504 time: 1703261366.497631\n",
      "Training [69%] Loss: 0.0011167382540436738 time: 1703261366.497631\n",
      "weight: [ 1.0930569   0.15044622  0.03268508  1.10745102  0.62366175  0.26516782\n",
      "  0.75746592  0.92014499  0.39777124 -0.42390698  0.26892795  0.41463688\n",
      "  1.1081883   0.60369756  0.77848547  0.18486674  0.65424468  1.16986981\n",
      "  0.66832354  0.93216453  0.57858186  0.12626878 -0.16407616  0.11042234]\n",
      "epoch 209\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013404549339433778 R2: 0.9224962958515881 time: 1703261374.6939578\n",
      "batch_idx: 1 loss: 0.0008813697211331005 R2: 0.9226950827446749 time: 1703261382.7423258\n",
      "Training [70%] Loss: 0.001110912327538239 time: 1703261382.7423258\n",
      "weight: [ 1.0936855   0.15014562  0.03119773  1.10726624  0.62392285  0.26714783\n",
      "  0.75984461  0.92436673  0.40431153 -0.42559992  0.26859196  0.41440698\n",
      "  1.10868491  0.60427088  0.77818488  0.18521321  0.65527506  1.17084649\n",
      "  0.67096324  0.9330726   0.57751444  0.12395952 -0.16407249  0.11045204]\n",
      "epoch 210\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013340123248056241 R2: 0.9229008683266222 time: 1703261391.1523294\n",
      "batch_idx: 1 loss: 0.0008762188929058309 R2: 0.9230986904896146 time: 1703261399.9065096\n",
      "Training [70%] Loss: 0.0011051156088557274 time: 1703261399.9065096\n",
      "weight: [ 1.09430982  0.14983911  0.02971385  1.10705663  0.62415575  0.26910635\n",
      "  0.76222764  0.92854113  0.41077453 -0.42730702  0.26825833  0.41418122\n",
      "  1.10917289  0.60481539  0.77787836  0.18554124  0.65628251  1.1718032\n",
      "  0.67361917  0.93399092  0.57644775  0.12163788 -0.16406267  0.11048881]\n",
      "epoch 211\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013276047106542332 R2: 0.9233033780035054 time: 1703261408.6020503\n",
      "batch_idx: 1 loss: 0.0008710935276169752 R2: 0.9235002009631146 time: 1703261416.99941\n",
      "Training [70%] Loss: 0.001099349119135604 time: 1703261416.99941\n",
      "weight: [ 1.09492985  0.14952681  0.02823364  1.10682258  0.62436109  0.27104369\n",
      "  0.764614    0.93266853  0.41715922 -0.42902794  0.26792703  0.41395958\n",
      "  1.10965228  0.60533112  0.77756607  0.18585087  0.65726744  1.17274041\n",
      "  0.67629029  0.93491883  0.57538137  0.11930431 -0.16404668  0.11053265]\n",
      "epoch 212\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013212330087556965 R2: 0.9237037528845635 time: 1703261425.2899003\n",
      "batch_idx: 1 loss: 0.0008659946776814678 R2: 0.9238995433726058 time: 1703261433.5709946\n",
      "Training [71%] Loss: 0.0010936138432185822 time: 1703261433.5709946\n",
      "weight: [ 1.09554555  0.14920889  0.02675727  1.10656452  0.62453953  0.27296015\n",
      "  0.76700268  0.93674932  0.42346462 -0.43076229  0.26759807  0.41374203\n",
      "  1.1101231   0.60581813  0.77724814  0.18614216  0.65823027  1.17365856\n",
      "  0.67897561  0.93585568  0.57431488  0.1169593  -0.16402454  0.11058357]\n",
      "epoch 213\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013148980977624196 R2: 0.9241019235946949 time: 1703261442.293939\n",
      "batch_idx: 1 loss: 0.0008609233584292049 R2: 0.9242966495957738 time: 1703261450.857582\n",
      "Training [71%] Loss: 0.0010879107280958122 time: 1703261450.857582\n",
      "weight: [ 1.0961569   0.14888547  0.02528494  1.10628295  0.62469176  0.27485608\n",
      "  0.7693927   0.94078393  0.42968987 -0.4325097   0.26727142  0.41352854\n",
      "  1.1105854   0.60627646  0.77692473  0.18641516  0.65917145  1.17455811\n",
      "  0.68167415  0.9368008   0.57324785  0.11460331 -0.16399622  0.11064155]\n",
      "epoch 214\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001308600818156915 R2: 0.9244978234695054 time: 1703261459.8654528\n",
      "batch_idx: 1 loss: 0.0008558805458318455 R2: 0.9246914542441503 time: 1703261468.873776\n",
      "Training [71%] Loss: 0.0010822406819943802 time: 1703261468.873776\n",
      "weight: [ 1.09676383  0.14855673  0.02381686  1.10597838  0.62481852  0.27673184\n",
      "  0.77178307  0.9447728   0.43583418 -0.4342698   0.26694709  0.41331908\n",
      "  1.1110392   0.60670619  0.77659599  0.18666992  0.66009144  1.17543953\n",
      "  0.68438495  0.93775356  0.57217986  0.11223683 -0.16396174  0.11070657]\n",
      "epoch 215\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013023419719917606 R2: 0.924891388627341 time: 1703261478.569248\n",
      "batch_idx: 1 loss: 0.0008508671757253746 R2: 0.9250838947275474 time: 1703261488.03239\n",
      "Training [72%] Loss: 0.0010766045738585675 time: 1703261488.03239\n",
      "weight: [ 1.09736629  0.14822283  0.02235321  1.10565137  0.62492053  0.2785878\n",
      "  0.77417285  0.94871643  0.44189683 -0.43604217  0.26662503  0.41311361\n",
      "  1.11148451  0.60710739  0.77626209  0.1869065   0.66099068  1.17630332\n",
      "  0.68710709  0.93871333  0.57111046  0.10986033 -0.1639211   0.11077863]\n",
      "epoch 216\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012961223213844653 R2: 0.9252825580208681 time: 1703261496.9824517\n",
      "batch_idx: 1 loss: 0.0008458841440712286 R2: 0.9254739113155417 time: 1703261506.0627465\n",
      "Training [72%] Loss: 0.001071003232727847 time: 1703261506.0627465\n",
      "weight: [ 1.09796422  0.14788394  0.02089422  1.1053025   0.62499857  0.28042437\n",
      "  0.77656109  0.95261534  0.4478772  -0.43782645  0.26630523  0.41291209\n",
      "  1.11192135  0.60748015  0.7759232   0.18712495  0.66186965  1.17714994\n",
      "  0.68983967  0.93967949  0.57003923  0.1074743  -0.16387433  0.11085768]\n",
      "epoch 217\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001289942586999872 R2: 0.9256712734767454 time: 1703261514.969816\n",
      "batch_idx: 1 loss: 0.0008409323067839781 R2: 0.9258614471841872 time: 1703261524.0376396\n",
      "Training [72%] Loss: 0.001065437446891925 time: 1703261524.0376396\n",
      "weight: [ 1.09855754  0.14754024  0.01944008  1.10493241  0.62505342  0.28224195\n",
      "  0.77894687  0.95647007  0.45377471 -0.43962221  0.26598765  0.41271445\n",
      "  1.11234974  0.60782457  0.77557949  0.1873253   0.66272883  1.17797989\n",
      "  0.69258182  0.94065143  0.56896571  0.10507921 -0.16382144  0.11094369]\n",
      "epoch 218\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001283803447752245 R2: 0.9260574797322411 time: 1703261533.6273549\n",
      "batch_idx: 1 loss: 0.000836012478568015 R2: 0.9262464484431945 time: 1703261543.3727462\n",
      "Training [73%] Loss: 0.00105990796316013 time: 1703261543.3727462\n",
      "weight: [ 1.09914617  0.1471919   0.01799102  1.10454175  0.62508586  0.28404096\n",
      "  0.78132929  0.96028118  0.45958886 -0.44142907  0.26567227  0.41252066\n",
      "  1.11276968  0.60814076  0.77523116  0.18750762  0.66356871  1.17879368\n",
      "  0.69533271  0.94162857  0.56788947  0.10267555 -0.16376245  0.11103663]\n",
      "epoch 219\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012777055414886225 R2: 0.9264411244674238 time: 1703261553.0176\n",
      "batch_idx: 1 loss: 0.0008311254316416214 R2: 0.9266288641501179 time: 1703261562.1925795\n",
      "Training [73%] Loss: 0.001054415486565122 time: 1703261562.1925795\n",
      "weight: [ 1.09973003  0.14683913  0.01654724  1.10413121  0.62509669  0.28582184\n",
      "  0.78370749  0.96404927  0.46531923 -0.44324661  0.26535904  0.41233064\n",
      "  1.11318117  0.60842882  0.77487838  0.18767193  0.66438979  1.17959179\n",
      "  0.69809151  0.94261031  0.56681005  0.1002638  -0.1636974   0.11113646]\n",
      "epoch 220\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001271649465455442 R2: 0.9268221583246307 time: 1703261571.0526662\n",
      "batch_idx: 1 loss: 0.0008262718954026085 R2: 0.9270086463199398 time: 1703261579.3427312\n",
      "Training [73%] Loss: 0.0010489606804290252 time: 1703261579.3427312\n",
      "weight: [ 1.10030903  0.14648211  0.01510898  1.10370149  0.62508673  0.28758503\n",
      "  0.7860806   0.96777493  0.47096544 -0.44507444  0.26504793  0.41214435\n",
      "  1.11358423  0.60868889  0.77452136  0.18781828  0.66519256  1.18037475\n",
      "  0.70085747  0.94359608  0.56572702  0.09784442 -0.16362632  0.11124311]\n",
      "epoch 221\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001265635775943478 R2: 0.9272005349110441 time: 1703261587.7274525\n",
      "batch_idx: 1 loss: 0.000821452557009366 R2: 0.9273857499301805 time: 1703261596.2067595\n",
      "Training [74%] Loss: 0.001043544166476422 time: 1703261596.2067595\n",
      "weight: [ 1.10088307  0.14612104  0.01367644  1.10325333  0.62505678  0.28933096\n",
      "  0.7884478   0.97145879  0.47652718 -0.44691215  0.26473889  0.41196171\n",
      "  1.11397884  0.60892108  0.7741603   0.18794669  0.66597753  1.18114306\n",
      "  0.70362981  0.94458533  0.56463993  0.09541789 -0.16354924  0.11135654]\n",
      "epoch 222\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012596649876920368 R2: 0.9275762107887437 time: 1703261604.9301326\n",
      "batch_idx: 1 loss: 0.0008166680619922229 R2: 0.9277601329150971 time: 1703261613.3777308\n",
      "Training [74%] Loss: 0.00103816652484213 time: 1703261613.3777308\n",
      "weight: [ 1.10145207  0.14575615  0.01224988  1.1027875   0.62500767  0.2910601\n",
      "  0.79080828  0.97510149  0.48200417 -0.44875932  0.26443188  0.41178265\n",
      "  1.114365    0.60912553  0.7737954   0.18805719  0.66674521  1.18189724\n",
      "  0.70640782  0.94557751  0.56354834  0.09298468 -0.16346622  0.11147669]\n",
      "epoch 223\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012537375739238136 R2: 0.9279491454588757 time: 1703261622.2312574\n",
      "batch_idx: 1 loss: 0.0008119190143333077 R2: 0.9281317561450428 time: 1703261630.2227948\n",
      "Training [74%] Loss: 0.0010328282941285607 time: 1703261630.2227948\n",
      "weight: [ 1.10201591  0.14538763  0.0108295   1.10230476  0.6249402   0.29277288\n",
      "  0.79316126  0.97870368  0.48739621 -0.45061556  0.26412684  0.4116071\n",
      "  1.11474269  0.6093024   0.77342688  0.1881498   0.66749612  1.1826378\n",
      "  0.70919082  0.94657208  0.5624518   0.09054525 -0.1633773   0.11160348]\n",
      "epoch 224\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012478539671029675 R2: 0.9283193013409419 time: 1703261638.3925602\n",
      "batch_idx: 1 loss: 0.0008072059763558918 R2: 0.9285005833943025 time: 1703261646.4825528\n",
      "Training [75%] Loss: 0.0010275299717294297 time: 1703261646.4825528\n",
      "weight: [ 1.10257451  0.1450157   0.00941555  1.10180593  0.62485519  0.29446975\n",
      "  0.79550599  0.98226601  0.49270313 -0.45248046  0.26382373  0.41143499\n",
      "  1.11511191  0.60945182  0.77305496  0.18822454  0.66823077  1.18336528\n",
      "  0.71197814  0.94756853  0.56134989  0.08810005 -0.16328252  0.11173687]\n",
      "epoch 225\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012420145597814647 R2: 0.9286866437429595 time: 1703261654.615659\n",
      "batch_idx: 1 loss: 0.0008025294690655575 R2: 0.9288665813032513 time: 1703261662.8176112\n",
      "Training [75%] Loss: 0.001022272014423511 time: 1703261662.8176112\n",
      "weight: [ 1.10312775  0.1446406   0.00800826  1.10129181  0.62475345  0.29615118\n",
      "  0.79784175  0.98578915  0.49792481 -0.45435363  0.26352248  0.41126624\n",
      "  1.11547263  0.60957395  0.77267985  0.1882814   0.66894968  1.18408019\n",
      "  0.71476915  0.94856635  0.56024215  0.08564954 -0.16318195  0.11187676]\n",
      "epoch 226\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001236219705077556 R2: 0.929051140819545 time: 1703261670.98283\n",
      "batch_idx: 1 loss: 0.0007978899730354969 R2: 0.929229719336363 time: 1703261679.1304815\n",
      "Training [75%] Loss: 0.0010170548390565264 time: 1703261679.1304815\n",
      "weight: [ 1.10367554  0.14426254  0.00660789  1.10076323  0.62463577  0.29781759\n",
      "  0.80016783  0.98927378  0.50306116 -0.45623465  0.26322304  0.41110076\n",
      "  1.11582484  0.60966897  0.7723018   0.1883204   0.66965339  1.18478306\n",
      "  0.71756326  0.94956504  0.55912816  0.08319417 -0.16307564  0.11202309]\n",
      "epoch 227\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012304697170291458 R2: 0.929412763520401 time: 1703261687.1937895\n",
      "batch_idx: 1 loss: 0.0007932879293493792 R2: 0.9295899697328018 time: 1703261695.161484\n",
      "Training [76%] Loss: 0.0010118788231892625 time: 1703261695.161484\n",
      "weight: [ 1.10421778  0.14388177  0.00521466  1.10022103  0.62450295  0.29946943\n",
      "  0.80248355  0.99272057  0.50811213 -0.45812314  0.26292535  0.41093848\n",
      "  1.1161685   0.60973702  0.77192102  0.18834153  0.67034242  1.18547443\n",
      "  0.72035988  0.95056412  0.55800748  0.08073436 -0.16296365  0.11217577]\n",
      "epoch 228\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012247648713325223 R2: 0.9297714855339573 time: 1703261703.4474254\n",
      "batch_idx: 1 loss: 0.0007887237402289012 R2: 0.9299473074471253 time: 1703261711.819721\n",
      "Training [76%] Loss: 0.001006744305780712 time: 1703261711.819721\n",
      "weight: [ 1.10475435  0.14349851  0.00382884  1.09966607  0.62435578  0.30110714\n",
      "  0.80478828  0.9961302   0.51307773 -0.4600187   0.26262934  0.4107793\n",
      "  1.1165036   0.60977829  0.77153777  0.18834478  0.67101729  1.18615482\n",
      "  0.72315848  0.95156312  0.5568797   0.07827057 -0.16284605  0.11233473]\n",
      "epoch 229\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012191054065469067 R2: 0.9301272832277505 time: 1703261720.0123699\n",
      "batch_idx: 1 loss: 0.0007841977695326286 R2: 0.9303017100821785 time: 1703261728.3427722\n",
      "Training [76%] Loss: 0.0010016515880397676 time: 1703261728.3427722\n",
      "weight: [ 1.10528516  0.14311303  0.00245066  1.0990992   0.62419501  0.30273114\n",
      "  0.80708139  0.99950336  0.51795795 -0.46192094  0.26233496  0.41062315\n",
      "  1.11683009  0.60979295  0.77115228  0.18833012  0.67167853  1.18682478\n",
      "  0.72595853  0.95256157  0.55574439  0.07580319 -0.1627229   0.11249986]\n",
      "epoch 230\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012134915253563007 R2: 0.9304801355833495 time: 1703261736.4823925\n",
      "batch_idx: 1 loss: 0.000779710343557617 R2: 0.9306531578183119 time: 1703261744.5374026\n",
      "Training [77%] Loss: 0.000996600934456959 time: 1703261744.5374026\n",
      "weight: [ 1.10581011e+00  1.42725556e-01  1.08040085e-03  1.09852129e+00\n",
      "  6.24021410e-01  3.04341858e-01  8.09362285e-01  1.00284072e+00\n",
      "  5.22752868e-01 -4.63829490e-01  2.62042126e-01  4.10469916e-01\n",
      "  1.11714794e+00  6.09781194e-01  7.70764812e-01  1.88297536e-01\n",
      "  6.72326679e-01  1.18748483e+00  7.28759544e-01  9.53559035e-01\n",
      "  5.54601143e-01  7.33326689e-02 -1.62594283e-01  1.12671084e-01]\n",
      "epoch 231\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001207923395547765 R2: 0.9308300241238617 time: 1703261752.9235775\n",
      "batch_idx: 1 loss: 0.0007752617522466828 R2: 0.9310016333406311 time: 1703261760.9327896\n",
      "Training [77%] Loss: 0.000991592573897224 time: 1703261760.9327896\n",
      "weight: [ 1.10632910e+00  1.42336354e-01 -2.81691043e-04  1.09793320e+00\n",
      "  6.23835725e-01  3.05939698e-01  8.11630405e-01  1.00614297e+00\n",
      "  5.27462545e-01 -4.65743960e-01  2.61750778e-01  4.10319523e-01\n",
      "  1.11745711e+00  6.09743202e-01  7.70375610e-01  1.88246993e-01\n",
      "  6.72962263e-01  1.18813552e+00  7.31561055e-01  9.54555069e-01\n",
      "  5.53449541e-01  7.08593964e-02 -1.62460264e-01  1.12848306e-01]\n",
      "epoch 232\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012024011508263166 R2: 0.9311769328355759 time: 1703261768.9824152\n",
      "batch_idx: 1 loss: 0.0007708522504912295 R2: 0.9313471217625657 time: 1703261776.9927223\n",
      "Training [77%] Loss: 0.000986626700658773 time: 1703261776.9927223\n",
      "weight: [ 1.10684203  0.14194568 -0.00163535  1.09733581  0.62363868  0.30752506\n",
      "  0.81388521  1.00941078  0.53208708 -0.46766398  0.26146084  0.41017187\n",
      "  1.11775755  0.60967917  0.76998494  0.18817845  0.67358581  1.18877737\n",
      "  0.73436262  0.95554925  0.55228918  0.06838378 -0.16232092  0.11303143]\n",
      "epoch 233\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011969248918161505 R2: 0.9315208480871082 time: 1703261785.1066794\n",
      "batch_idx: 1 loss: 0.0007664820592413693 R2: 0.9316896105441053 time: 1703261793.3324003\n",
      "Training [78%] Loss: 0.0009817034755287598 time: 1703261793.3324003\n",
      "weight: [ 1.10734881  0.1415538  -0.0029803   1.09672998  0.62343099  0.30909835\n",
      "  0.81612618  1.01264483  0.53662661 -0.46958919  0.26117225  0.41002687\n",
      "  1.11804922  0.60958929  0.76959306  0.18809187  0.67419786  1.18941093\n",
      "  0.73716382  0.95654115  0.55111967  0.06590621 -0.16217633  0.11322035]\n",
      "epoch 234\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001191494687355026 R2: 0.9318617585475805 time: 1703261801.5683599\n",
      "batch_idx: 1 loss: 0.0007621513664891639 R2: 0.932029089406029 time: 1703261809.5728312\n",
      "Training [78%] Loss: 0.000976823026922095 time: 1703261809.5728312\n",
      "weight: [ 1.10784934  0.14116098 -0.00431627  1.09611659  0.62321335  0.31065993\n",
      "  0.81835283  1.01584579  0.54108126 -0.47151922  0.26088492  0.40988443\n",
      "  1.11833207  0.60947378  0.76920024  0.18798719  0.67479893  1.19003675\n",
      "  0.73996425  0.95753038  0.54994061  0.06342707 -0.16202658  0.11341497]\n",
      "epoch 235\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011861105758584627 R2: 0.9321996551025885 time: 1703261817.482502\n",
      "batch_idx: 1 loss: 0.0007578603283775933 R2: 0.9323655502429304 time: 1703261825.5227833\n",
      "Training [78%] Loss: 0.000971985452118028 time: 1703261825.5227833\n",
      "weight: [ 1.10834354  0.1407675  -0.00564299  1.0954965   0.62298643  0.31221018\n",
      "  0.82056471  1.01901431  0.5454512  -0.47345371  0.26059879  0.40974444\n",
      "  1.11860604  0.60933283  0.76880676  0.18786437  0.67538957  1.19065535\n",
      "  0.74276355  0.95851653  0.54875161  0.06094673 -0.16187174  0.11361518]\n",
      "epoch 236\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011807725665418868 R2: 0.9325345307668413 time: 1703261833.6226027\n",
      "batch_idx: 1 loss: 0.0007536090705020864 R2: 0.9326989870363389 time: 1703261841.8876467\n",
      "Training [79%] Loss: 0.0009671908185219867 time: 1703261841.8876467\n",
      "weight: [ 1.10883132  0.14037363 -0.00696016  1.09487058  0.6227509   0.31374945\n",
      "  0.82276136  1.02215107  0.5497366  -0.47539233  0.26031377  0.40960681\n",
      "  1.11887107  0.60916667  0.76841288  0.18772333  0.67597029  1.19126728\n",
      "  0.74556136  0.95949922  0.54755231  0.05846557 -0.16171191  0.11382089]\n",
      "epoch 237\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011754806405644108 R2: 0.9328663805945793 time: 1703261849.9328067\n",
      "batch_idx: 1 loss: 0.0007493976892209419 R2: 0.9330293957668878 time: 1703261857.697674\n",
      "Training [79%] Loss: 0.0009624391648926764 time: 1703261857.697674\n",
      "weight: [ 1.1093126   0.13997965 -0.0082675   1.09423966  0.62250739  0.31527809\n",
      "  0.82494239  1.0252567   0.55393766 -0.47733472  0.26002978  0.40947143\n",
      "  1.1191271   0.6089755   0.76801891  0.18756401  0.67654163  1.19187308\n",
      "  0.74835733  0.96047806  0.54634232  0.05598394 -0.16154717  0.11403197]\n",
      "epoch 238\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011702347522904708 R2: 0.9331952015901208 time: 1703261865.4127405\n",
      "batch_idx: 1 loss: 0.0007452262528202646 R2: 0.9333567743246507 time: 1703261873.4036272\n",
      "Training [79%] Loss: 0.0009577305025553677 time: 1703261873.4036272\n",
      "weight: [ 1.1097873   0.13958586 -0.00956472  1.09360461  0.62225653  0.31679643\n",
      "  0.8271074   1.02833184  0.55805457 -0.47928055  0.25974676  0.40933822\n",
      "  1.11937407  0.60875955  0.76762511  0.18738633  0.67710412  1.19247328\n",
      "  0.75115116  0.96145268  0.54512128  0.0535022  -0.1613776   0.11424832]\n",
      "epoch 239\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011650348306978622 R2: 0.9335209926194968 time: 1703261881.3678052\n",
      "batch_idx: 1 loss: 0.0007410948026116998 R2: 0.9336811224186927 time: 1703261889.5224402\n",
      "Training [80%] Loss: 0.000953064816654781 time: 1703261889.5224402\n",
      "weight: [ 1.11025536  0.13919253 -0.01085152  1.09296625  0.62199891  0.31830479\n",
      "  0.82925602  1.03137712  0.56208756 -0.4812295   0.25946461  0.40920708\n",
      "  1.11961191  0.60851905  0.76723179  0.18719023  0.67765828  1.19306844\n",
      "  0.75394255  0.96242272  0.54388883  0.05102068 -0.16120331  0.11446982]\n",
      "epoch 240\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011598807807599529 R2: 0.9338437543222369 time: 1703261897.7725646\n",
      "batch_idx: 1 loss: 0.0007370033541366477 R2: 0.9340024414878634 time: 1703261905.703771\n",
      "Training [80%] Loss: 0.0009484420674483003 time: 1703261905.703771\n",
      "weight: [ 1.1107167   0.13879997 -0.01212759  1.09232541  0.62173513  0.31980348\n",
      "  0.83138792  1.03439317  0.56603684 -0.48318124  0.25918327  0.40907789\n",
      "  1.11984054  0.60825423  0.76683923  0.18697561  0.67820465  1.19365909\n",
      "  0.7567312   0.96338783  0.54264463  0.04853972 -0.16102438  0.11469637]\n",
      "epoch 241\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011547724846750972 R2: 0.9341634890225776 time: 1703261914.054573\n",
      "batch_idx: 1 loss: 0.0007329518984945567 R2: 0.9343207346134761 time: 1703261922.212548\n",
      "Training [80%] Loss: 0.000943862191584827 time: 1703261922.212548\n",
      "weight: [ 1.11117125  0.13840848 -0.01339263  1.0916829   0.62146573  0.32129278\n",
      "  0.83350278  1.0373806   0.56990265 -0.48513545  0.25890264  0.40895057\n",
      "  1.12005989  0.60796532  0.76644774  0.18674239  0.67874374  1.19424576\n",
      "  0.75951685  0.96434764  0.54138832  0.04605965 -0.1608409   0.11492784]\n",
      "epoch 242\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011497098030200065 R2: 0.9344802006410516 time: 1703261930.3397686\n",
      "batch_idx: 1 loss: 0.0007289404036446193 R2: 0.9346360064329986 time: 1703261938.8278975\n",
      "Training [81%] Loss: 0.0009393251033323129 time: 1703261938.8278975\n",
      "weight: [ 1.11161896  0.13801835 -0.01464631  1.09103952  0.62119127  0.32277299\n",
      "  0.83560029  1.04034     0.57368523 -0.48709184  0.25862264  0.40882501\n",
      "  1.12026988  0.60765258  0.76605761  0.18649049  0.67927608  1.194829\n",
      "  0.76229925  0.96530182  0.54011957  0.04358079 -0.16065298  0.11516413]\n",
      "epoch 243\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011446925759756581 R2: 0.934793894608075 time: 1703261946.887748\n",
      "batch_idx: 1 loss: 0.0007249688155774206 R2: 0.9349482630541885 time: 1703261955.1854048\n",
      "Training [81%] Loss: 0.0009348306957765393 time: 1703261955.1854048\n",
      "weight: [ 1.11205978  0.1376299  -0.01588832  1.09039604  0.62091226  0.32424436\n",
      "  0.83768018  1.04327197  0.57738482 -0.48905009  0.2583432   0.40870111\n",
      "  1.12047042  0.60731626  0.76566915  0.18621982  0.6798022   1.19540935\n",
      "  0.76507815  0.96625003  0.53883806  0.04110343 -0.1604607   0.1154051 ]\n",
      "epoch 244\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011397206246370132 R2: 0.9351045777799788 time: 1703261963.2912004\n",
      "batch_idx: 1 loss: 0.0007210370594210072 R2: 0.9352575119705404 time: 1703261971.3926315\n",
      "Training [81%] Loss: 0.0009303788420290103 time: 1703261971.3926315\n",
      "weight: [ 1.11249365  0.13724342 -0.01711834  1.08975323  0.62062921  0.32570714\n",
      "  0.8397422   1.04617707  0.58100167 -0.49100992  0.25806423  0.40857878\n",
      "  1.12066145  0.6069566   0.76528268  0.18593028  0.68032261  1.19598733\n",
      "  0.76785333  0.96719193  0.53754346  0.0386279  -0.16026416  0.11565065]\n",
      "epoch 245\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011347937522894873 R2: 0.9354122583566353 time: 1703261979.5238543\n",
      "batch_idx: 1 loss: 0.0007171450405893568 R2: 0.9355637619793484 time: 1703261987.6978123\n",
      "Training [82%] Loss: 0.0009259693964394221 time: 1703261987.6978123\n",
      "weight: [ 1.11292053  0.13685924 -0.01833602  1.08911183  0.62034259  0.32716159\n",
      "  0.8417861   1.04905588  0.58453604 -0.49297103  0.25778565  0.4084579\n",
      "  1.12084286  0.60657387  0.76489849  0.18562178  0.68083785  1.19656349\n",
      "  0.77062456  0.96812719  0.53623545  0.03615448 -0.16006347  0.11590064]\n",
      "epoch 246\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011299117455883614 R2: 0.93571694580033 time: 1703261995.5526333\n",
      "batch_idx: 1 loss: 0.000713292645962712 R2: 0.9358670231025144 time: 1703262003.5673933\n",
      "Training [82%] Loss: 0.0009216021957755367 time: 1703262003.5673933\n",
      "weight: [ 1.11334038  0.13647766 -0.01954103  1.08847259  0.62005287  0.32860794\n",
      "  0.84381166  1.05190895  0.58798819 -0.49493315  0.25750737  0.40833839\n",
      "  1.12101457  0.60616834  0.76451692  0.18529423  0.68134841  1.19713835\n",
      "  0.77339165  0.96905548  0.53491373  0.03368346 -0.15985872  0.11615497]\n",
      "epoch 247\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011250743757066967 R2: 0.9360186507567126 time: 1703262011.3958142\n",
      "batch_idx: 1 loss: 0.0007094797450052298 R2: 0.936167306509336 time: 1703262019.2626815\n",
      "Training [82%] Loss: 0.0009172770603559633 time: 1703262019.2626815\n",
      "weight: [ 1.11375317  0.13609901 -0.02073302  1.08783619  0.6197605   0.33004639\n",
      "  0.8458187   1.05473682  0.59135838 -0.496896    0.25722931  0.40822015\n",
      "  1.12117648  0.60574029  0.76413826  0.18494754  0.68185483  1.19771245\n",
      "  0.77615438  0.9699765   0.533578    0.03121512 -0.15965001  0.1164135 ]\n",
      "epoch 248\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011202813995238646 R2: 0.9363173849788181 time: 1703262027.1229143\n",
      "batch_idx: 1 loss: 0.0007057061907952003 R2: 0.9364646244410941 time: 1703262035.0028486\n",
      "Training [83%] Loss: 0.0009129937951595325 time: 1703262035.0028486\n",
      "weight: [ 1.11415888  0.1357236  -0.02191165  1.08720334  0.61946589  0.33147715\n",
      "  0.84780701  1.05754001  0.59464687 -0.49885932  0.25695139  0.40810307\n",
      "  1.12132851  0.60529001  0.76376285  0.18458161  0.68235762  1.19828632\n",
      "  0.77891259  0.97088991  0.53222797  0.02874974 -0.15943745  0.11667611]\n",
      "epoch 249\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001115532560818094 R2: 0.9366131612539936 time: 1703262042.862618\n",
      "batch_idx: 1 loss: 0.0007019718210437478 R2: 0.9367589901382878 time: 1703262050.7875865\n",
      "Training [83%] Loss: 0.0009087521909309209 time: 1703262050.7875865\n",
      "weight: [ 1.11455747  0.13535175 -0.02307656  1.08657469  0.61916946  0.33290041\n",
      "  0.84977644  1.06031905  0.59785393 -0.50082284  0.25667353  0.40798707\n",
      "  1.12147055  0.60481778  0.76339101  0.18419636  0.68285728  1.19886046\n",
      "  0.78166608  0.97179541  0.53086336  0.02628758 -0.15922114  0.11694267]\n",
      "epoch 250\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011108275913812242 R2: 0.9369059933329755 time: 1703262058.6724288\n",
      "batch_idx: 1 loss: 0.000698276459152873 R2: 0.9370504177711743 time: 1703262066.5677724\n",
      "Training [83%] Loss: 0.0009045520252670485 time: 1703262066.5677724\n",
      "weight: [ 1.11494893  0.13498379 -0.02422738  1.08595089  0.61887158  0.33431636\n",
      "  0.85172684  1.06307442  0.60097983 -0.50278631  0.25639563  0.40787203\n",
      "  1.12160251  0.60432391  0.76302305  0.1837917   0.68335434  1.19943542\n",
      "  0.78441468  0.97269269  0.52948388  0.02382892 -0.15900117  0.11721307]\n",
      "epoch 251\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011061662120568506 R2: 0.9371958958611366 time: 1703262074.3275006\n",
      "batch_idx: 1 loss: 0.0006946199152620899 R2: 0.9373389223732431 time: 1703262082.3048143\n",
      "Training [84%] Loss: 0.0009003930636594703 time: 1703262082.3048143\n",
      "weight: [ 1.11533326  0.13462004 -0.02536375  1.08533257  0.61857263  0.33572516\n",
      "  0.85365807  1.06580663  0.60402483 -0.50474948  0.25611762  0.40775787\n",
      "  1.12172429  0.60380872  0.7626593   0.18336754  0.6838493   1.2000117\n",
      "  0.78715823  0.97358143  0.52808928  0.021374   -0.15877766  0.11748717]\n",
      "epoch 252\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011015481337778945 R2: 0.9374828843126657 time: 1703262090.0675144\n",
      "batch_idx: 1 loss: 0.0006910019872162846 R2: 0.9376245197769892 time: 1703262097.8195465\n",
      "Training [84%] Loss: 0.0008962750604970895 time: 1703262097.8195465\n",
      "weight: [ 1.11571044  0.13426083 -0.0264853   1.08472031  0.61827297  0.33712698\n",
      "  0.85557     1.06851615  0.60698919 -0.50671212  0.25583942  0.40764449\n",
      "  1.12183579  0.60327251  0.76230008  0.18292382  0.68434267  1.20058981\n",
      "  0.78989657  0.97446134  0.52667928  0.01892307 -0.15855072  0.11776485]\n",
      "epoch 253\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010969730586343836 R2: 0.9377669749281049 time: 1703262105.7429016\n",
      "batch_idx: 1 loss: 0.0006874224614716012 R2: 0.9379072265521373 time: 1703262113.653745\n",
      "Training [84%] Loss: 0.0008921977600529924 time: 1703262113.653745\n",
      "weight: [ 1.11608047  0.13390648 -0.02759165  1.08411471  0.61797291  0.33852196\n",
      "  0.85746254  1.07120345  0.60987319 -0.50867397  0.25556094  0.40753179\n",
      "  1.12193691  0.60271563  0.76194573  0.18246045  0.68483495  1.20117026\n",
      "  0.79262955  0.97533211  0.52525365  0.01647639 -0.15832043  0.11804597]\n",
      "epoch 254\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010924406809200162 R2: 0.9380481846546613 time: 1703262121.5227158\n",
      "batch_idx: 1 loss: 0.0006838811140018327 R2: 0.9381870599470219 time: 1703262129.6011875\n",
      "Training [85%] Loss: 0.0008881608974609244 time: 1703262129.6011875\n",
      "weight: [ 1.11644337  0.13355731 -0.02868241  1.08351631  0.61767278  0.33991023\n",
      "  0.85933559  1.07386896  0.6126771  -0.51063482  0.25528209  0.40741969\n",
      "  1.12202754  0.60213841  0.76159657  0.18197737  0.68532664  1.20175355\n",
      "  0.79535701  0.97619344  0.52381212  0.01403418 -0.15808692  0.11833042]\n",
      "epoch 255\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010879506881162546 R2: 0.9383265310888762 time: 1703262137.3427792\n",
      "batch_idx: 1 loss: 0.0006803777112110887 R2: 0.9384640378331712 time: 1703262145.2724502\n",
      "Training [85%] Loss: 0.0008841641996636717 time: 1703262145.2724502\n",
      "weight: [ 1.11679915  0.13321366 -0.02975719  1.08292563  0.61737288  0.34129194\n",
      "  0.86118907  1.07651315  0.61540118 -0.51259443  0.2550028   0.40730808\n",
      "  1.12210759  0.60154121  0.76125292  0.18147451  0.68581824  1.20234016\n",
      "  0.79807882  0.97704504  0.52235447  0.0115967  -0.15785029  0.11861806]\n",
      "epoch 256\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010835027618448637 R2: 0.9386020324219567 time: 1703262152.941486\n",
      "batch_idx: 1 loss: 0.0006769120108050053 R2: 0.9387381786525116 time: 1703262160.7599432\n",
      "Training [85%] Loss: 0.0008802073863249345 time: 1703262160.7599432\n",
      "weight: [ 1.11714781  0.13287585 -0.0308156   1.08234318  0.6170735   0.34266719\n",
      "  0.8630229   1.07913641  0.6180457  -0.51455259  0.25472298  0.40719688\n",
      "  1.12217696  0.6009244   0.76091511  0.18095183  0.68631024  1.20293059\n",
      "  0.80079484  0.97788662  0.52088046  0.00916417 -0.15761065  0.11890875]\n",
      "epoch 257\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001079096578829343 R2: 0.938874707388282 time: 1703262168.6326547\n",
      "batch_idx: 1 loss: 0.0006734837626094256 R2: 0.9390095013669757 time: 1703262176.5628226\n",
      "Training [86%] Loss: 0.0008762901707193843 time: 1703262176.5628226\n",
      "weight: [ 1.11748939  0.1325442  -0.03185725  1.08176944  0.6167749   0.3440361\n",
      "  0.86483704  1.08173919  0.62061093 -0.51650909  0.25444256  0.407086\n",
      "  1.12223553  0.60028835  0.76058345  0.18040928  0.68680314  1.2035253\n",
      "  0.80350493  0.97871789  0.51938987  0.00673681 -0.1573681   0.11920238]\n",
      "epoch 258\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001074731811844387 R2: 0.9391445752168603 time: 1703262184.3948233\n",
      "batch_idx: 1 loss: 0.0006700927093802378 R2: 0.9392780254109535 time: 1703262192.759795\n",
      "Training [86%] Loss: 0.0008724122606123125 time: 1703262192.759795\n",
      "weight: [ 1.11782391  0.13221903 -0.03288173  1.08120487  0.61647733  0.34539877\n",
      "  0.86663144  1.08432186  0.62309713 -0.51846371  0.25416145  0.40697534\n",
      "  1.12228322  0.59963345  0.76025829  0.17984682  0.68729741  1.20412476\n",
      "  0.80620896  0.97953855  0.5178825   0.00431485 -0.15712276  0.11949881]\n",
      "epoch 259\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001070408130612327 R2: 0.9394116555851475 time: 1703262200.9328625\n",
      "batch_idx: 1 loss: 0.0006667385876253103 R2: 0.9395437706468186 time: 1703262208.9225132\n",
      "Training [86%] Loss: 0.0008685733591188188 time: 1703262208.9225132\n",
      "weight: [ 1.11815141  0.13190066 -0.03388863  1.08064988  0.61618105  0.34675528\n",
      "  0.86840605  1.08688483  0.62550458 -0.52041624  0.25387956  0.40686482\n",
      "  1.12231993  0.59896012  0.75993992  0.17926443  0.68779354  1.20472942\n",
      "  0.8089068   0.98034834  0.51635812  0.00189851 -0.15687473  0.1197979 ]\n",
      "epoch 260\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00106612520265745 R2: 0.9396759685752734 time: 1703262216.982923\n",
      "batch_idx: 1 loss: 0.0006634211284036644 R2: 0.9398067573231087 time: 1703262225.0977478\n",
      "Training [87%] Loss: 0.0008647731655305572 time: 1703262225.0977478\n",
      "weight: [ 1.11847193e+00  1.31589417e-01 -3.48775367e-02  1.08010489e+00\n",
      "  6.15886261e-01  3.48105739e-01  8.70160859e-01  1.08942846e+00\n",
      "  6.27833531e-01 -5.22366496e-01  2.53596830e-01  4.06754357e-01\n",
      "  1.12234554e+00  5.98268767e-01  7.59628673e-01  1.78662099e-01\n",
      "  6.88292003e-01  1.20533973e+00  8.11598321e-01  9.81146974e-01\n",
      "  5.14816558e-01 -5.11991623e-04 -1.56624122e-01  1.20099534e-01]\n",
      "epoch 261\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010618826941583537 R2: 0.9399375346331122 time: 1703262233.3827484\n",
      "batch_idx: 1 loss: 0.0006601400580765226 R2: 0.9400670060349157 time: 1703262241.57119\n",
      "Training [87%] Loss: 0.0008610113761174382 time: 1703262241.57119\n",
      "weight: [ 1.11878551  0.1312856  -0.03584805  1.07957028  0.61559319  0.34945021\n",
      "  0.87189584  1.09195313  0.63008426 -0.52431427  0.25331317  0.40664385\n",
      "  1.12235999  0.59755983  0.75932486  0.17803981  0.68879326  1.2059561\n",
      "  0.81428341  0.98193418  0.51325761 -0.00291644 -0.15637105  0.12040357]\n",
      "epoch 262\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010576802707961794 R2: 0.9401963745301428 time: 1703262249.707603\n",
      "batch_idx: 1 loss: 0.0006568950990359268 R2: 0.9403245376867678 time: 1703262257.5775285\n",
      "Training [87%] Loss: 0.0008572876849160531 time: 1703262257.5775285\n",
      "weight: [ 1.11909221  0.13098953 -0.03679974  1.0790464   0.61530204  0.35078877\n",
      "  0.87361099  1.09445919  0.63225704 -0.52625938  0.2530285   0.40653323\n",
      "  1.12236316  0.59683375  0.75902878  0.17739759  0.68929778  1.20657894\n",
      "  0.81696193  0.98270969  0.5116811  -0.00531464 -0.15611563  0.12070987]\n",
      "epoch 263\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001053517598562613 R2: 0.9404525093275755 time: 1703262265.4524896\n",
      "batch_idx: 1 loss: 0.0006536859704365611 R2: 0.9405793734582228 time: 1703262273.2026958\n",
      "Training [88%] Loss: 0.0008536017844995871 time: 1703262273.2026958\n",
      "weight: [ 1.11939208  0.1307015  -0.0377322   1.07853358  0.61501298  0.35212148\n",
      "  0.8753063   1.09694698  0.63435212 -0.52820164  0.25274275  0.40642241\n",
      "  1.12235497  0.596091    0.75874076  0.17673545  0.68980601  1.20720865\n",
      "  0.81963378  0.98347326  0.51008685 -0.00770636 -0.15585796  0.12101831]\n",
      "epoch 264\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001049394344522011 R2: 0.940705960342593 time: 1703262280.879926\n",
      "batch_idx: 1 loss: 0.0006505123889114742 R2: 0.9408315347718528 time: 1703262288.7129116\n",
      "Training [88%] Loss: 0.0008499533667167426 time: 1703262288.7129116\n",
      "weight: [ 1.11968519  0.13042182 -0.038645    1.07803214  0.6147262   0.3534484\n",
      "  0.87698179  1.09941684  0.63636978 -0.53014086  0.25245583  0.4063113\n",
      "  1.12233534  0.59533207  0.75846107  0.17605342  0.69031839  1.20784561\n",
      "  0.82229884  0.98422463  0.50847471 -0.01009141 -0.15559816  0.12132875]\n",
      "epoch 265\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010453101775531333 R2: 0.9409567491170178 time: 1703262296.2828906\n",
      "batch_idx: 1 loss: 0.000647374069249351 R2: 0.9410810432631898 time: 1703262303.81782\n",
      "Training [88%] Loss: 0.0008463421234012421 time: 1703262303.81782\n",
      "weight: [ 1.11997159  0.13015077 -0.03953773  1.07754234  0.61444185  0.35476958\n",
      "  0.87863746  1.10186907  0.6383103  -0.53207686  0.25216768  0.40619982\n",
      "  1.12230418  0.59455744  0.75819003  0.17535156  0.69083536  1.20849017\n",
      "  0.82495698  0.98496355  0.50684451 -0.01246958 -0.15533635  0.12164106]\n",
      "epoch 266\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001041264769069149 R2: 0.9412048973883886 time: 1703262311.3950295\n",
      "batch_idx: 1 loss: 0.0006442707250495997 R2: 0.9413279207527203 time: 1703262318.9977098\n",
      "Training [89%] Loss: 0.0008427677470593743 time: 1703262318.9977098\n",
      "weight: [ 1.12025137  0.12988865 -0.04040995  1.07706446  0.61416009  0.35608509\n",
      "  0.88027334  1.10430401  0.64017393 -0.53400948  0.25187822  0.40608791\n",
      "  1.12226142  0.59376763  0.7579279   0.17462993  0.69135734  1.20914266\n",
      "  0.8276081   0.9856898   0.50519611 -0.01484067 -0.15507263  0.1219551 ]\n",
      "epoch 267\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010372577936855459 R2: 0.9414504270629325 time: 1703262326.9525306\n",
      "batch_idx: 1 loss: 0.0006412020693736158 R2: 0.9415721892201082 time: 1703262334.5325837\n",
      "Training [89%] Loss: 0.0008392299315295808 time: 1703262334.5325837\n",
      "weight: [ 1.12052461  0.12963573 -0.04126126  1.07659873  0.61388106  0.35739495\n",
      "  0.88188945  1.10672193  0.64196095 -0.53593853  0.25158736  0.40597546\n",
      "  1.12220699  0.59296317  0.75767498  0.17388861  0.69188474  1.2098034\n",
      "  0.83025208  0.98640316  0.50352938 -0.01720448 -0.15480712  0.12227075]\n",
      "epoch 268\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010332889298289194 R2: 0.9416933601902289 time: 1703262342.2328753\n",
      "batch_idx: 1 loss: 0.0006381678153738643 R2: 0.9418138707802892 time: 1703262349.9978478\n",
      "Training [89%] Loss: 0.0008357283726013918 time: 1703262349.9978478\n",
      "weight: [ 1.12079137  0.12939228 -0.04209122  1.07614536  0.61360488  0.35869922\n",
      "  0.88348583  1.10912314  0.64367164 -0.53786385  0.25129505  0.40586243\n",
      "  1.12214082  0.59214462  0.75743153  0.17312769  0.69241797  1.21047267\n",
      "  0.83288882  0.98710341  0.50184418 -0.01956081 -0.15453993  0.12258785]\n",
      "epoch 269\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010293578603057453 R2: 0.9419337189397771 time: 1703262357.6328585\n",
      "batch_idx: 1 loss: 0.0006351676768792677 R2: 0.9420529876610002 time: 1703262365.2479618\n",
      "Training [90%] Loss: 0.0008322627685925065 time: 1703262365.2479618\n",
      "weight: [ 1.12105176  0.12915856 -0.04289941  1.07570455  0.61333169  0.35999792\n",
      "  0.88506253  1.11150791  0.64530627 -0.53978528  0.2510012   0.40574872\n",
      "  1.12206285  0.59131252  0.75719782  0.17234728  0.69295739  1.21115074\n",
      "  0.8355182   0.98779036  0.50014039 -0.02190947 -0.15427117  0.12290628]\n",
      "epoch 270\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010254642728279822 R2: 0.9421715255793444 time: 1703262372.8461561\n",
      "batch_idx: 1 loss: 0.0006322013689473315 R2: 0.9422895621817482 time: 1703262380.4247885\n",
      "Training [90%] Loss: 0.0008288328208876569 time: 1703262380.4247885\n",
      "weight: [ 1.12130586  0.12893483 -0.04368542  1.07527645  0.61306158  0.3612911\n",
      "  0.88661957  1.11387652  0.64686511 -0.54170266  0.25070575  0.40563426\n",
      "  1.12197304  0.59046747  0.75697409  0.17154751  0.69350339  1.21183784\n",
      "  0.83814011  0.98846383  0.49841792 -0.02425026 -0.15400097  0.12322591]\n",
      "epoch 271\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010216078604697563 R2: 0.9424068024545889 time: 1703262388.0727146\n",
      "batch_idx: 1 loss: 0.0006292686083933972 R2: 0.9425236167342625 time: 1703262395.572796\n",
      "Training [90%] Loss: 0.0008254382344315768 time: 1703262395.572796\n",
      "weight: [ 1.12155377  0.12872133 -0.04444883  1.07486123  0.61279465  0.36257878\n",
      "  0.88815703  1.11622923  0.64834846 -0.54361583  0.25040862  0.40551899\n",
      "  1.12187133  0.58961007  0.75676059  0.17072853  0.69405631  1.21253418\n",
      "  0.84075445  0.98912366  0.49667666 -0.02658299 -0.15372944  0.12354659]\n",
      "epoch 272\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010177883220498167 R2: 0.9426395719697427 time: 1703262403.4276526\n",
      "batch_idx: 1 loss: 0.0006263691142790504 R2: 0.9427551737640056 time: 1703262411.0228834\n",
      "Training [91%] Loss: 0.0008220787181644335 time: 1703262411.0228834\n",
      "weight: [ 1.12179559  0.12851829 -0.04518923  1.07445901  0.61253101  0.363861\n",
      "  0.88967494  1.11856629  0.64975659 -0.54552463  0.25010975  0.40540284\n",
      "  1.12175768  0.58874091  0.75655754  0.16989048  0.69461649  1.21323994\n",
      "  0.84336112  0.9897697   0.49491651 -0.02890745 -0.15345668  0.12386819]\n",
      "epoch 273\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010140053624518224 R2: 0.9428698565694382 time: 1703262418.812585\n",
      "batch_idx: 1 loss: 0.0006235026083453558 R2: 0.9429842557523116 time: 1703262426.3812437\n",
      "Training [91%] Loss: 0.0008187539853985891 time: 1703262426.3812437\n",
      "weight: [ 1.12203142  0.12832592 -0.04590619  1.07406989  0.61227074  0.36513778\n",
      "  0.89117338  1.12088795  0.65108978 -0.54742892  0.24980907  0.40528573\n",
      "  1.12163208  0.58786063  0.75636517  0.16903355  0.69518424  1.21395526\n",
      "  0.84596     0.99040181  0.49313741 -0.03122347 -0.15318283  0.12419057]\n",
      "epoch 274\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001010258692873949 R2: 0.9430976787214223 time: 1703262433.9474945\n",
      "batch_idx: 1 loss: 0.0006206688154012807 R2: 0.9432108851991508 time: 1703262441.43771\n",
      "Training [91%] Loss: 0.0008154637541376148 time: 1703262441.43771\n",
      "weight: [ 1.12226138  0.12814443 -0.04659933  1.07369396  0.6120139   0.36640915\n",
      "  0.8926524   1.12319444  0.65234834 -0.54932854  0.24950651  0.4051676\n",
      "  1.1214945   0.58696988  0.75618368  0.16815794  0.69575987  1.21468026\n",
      "  0.848551    0.99101989  0.49133928 -0.03353084 -0.15290798  0.1245136 ]\n",
      "epoch 275\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010065480309883264 R2: 0.9433230608996233 time: 1703262449.1276414\n",
      "batch_idx: 1 loss: 0.0006178674636697557 R2: 0.9434350846064137 time: 1703262456.677674\n",
      "Training [92%] Loss: 0.000812207747329041 time: 1703262456.677674\n",
      "weight: [ 1.12248557  0.12797401 -0.04726823  1.07333128  0.61176057  0.36767514\n",
      "  0.89411207  1.12548599  0.65353255 -0.55122336  0.24920201  0.40504839\n",
      "  1.12134493  0.5860693   0.75601326  0.16726384  0.69634363  1.21541503\n",
      "  0.851134    0.99162385  0.48952205 -0.03582937 -0.15263227  0.12483714]\n",
      "epoch 276\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010028731010136556 R2: 0.9435460255674547 time: 1703262464.2876747\n",
      "batch_idx: 1 loss: 0.0006150982850734026 R2: 0.9436568764612 time: 1703262471.8229306\n",
      "Training [92%] Loss: 0.0008089856930435292 time: 1703262471.8229306\n",
      "weight: [ 1.12270412  0.12781483 -0.04791251  1.0729819   0.61151082  0.36893576\n",
      "  0.89555248  1.12776282  0.65464271 -0.55311323  0.2488955   0.40492804\n",
      "  1.12118337  0.58515956  0.75585409  0.16635149  0.6969358   1.21615962\n",
      "  0.85370893  0.99221363  0.4876857  -0.03811889 -0.15235579  0.12516105]\n",
      "epoch 277\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009992336337119173 R2: 0.9437665951613112 time: 1703262479.3945968\n",
      "batch_idx: 1 loss: 0.0006123610154542557 R2: 0.9438762832188494 time: 1703262486.9039602\n",
      "Training [92%] Loss: 0.0008057973245830866 time: 1703262486.9039602\n",
      "weight: [ 1.12291714  0.12766707 -0.04853176  1.07264585  0.61126468  0.37019106\n",
      "  0.89697368  1.13002516  0.65567913 -0.55499802  0.24858692  0.40480648\n",
      "  1.12100982  0.58424135  0.75570633  0.16542112  0.69753658  1.21691405\n",
      "  0.85627566  0.99278918  0.48583016 -0.04039919 -0.15207868  0.1254852 ]\n",
      "epoch 278\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00099562936630132 R2: 0.9439847920739133 time: 1703262494.34258\n",
      "batch_idx: 1 loss: 0.0006096553947377787 R2: 0.9440933272857345 time: 1703262501.8746629\n",
      "Training [93%] Loss: 0.0008026423805195494 time: 1703262501.8746629\n",
      "weight: [ 1.12312475  0.12753087 -0.04912561  1.07232314  0.61102222  0.37144105\n",
      "  0.89837578  1.1322732   0.65664212 -0.55687759  0.2482762   0.40468365\n",
      "  1.12082432  0.58331534  0.75557013  0.16447301  0.69814619  1.21767831\n",
      "  0.85883411  0.99335048  0.48395543 -0.04267009 -0.15180105  0.12580945]\n",
      "epoch 279\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009920600422800257 R2: 0.9442006386371136 time: 1703262509.402615\n",
      "batch_idx: 1 loss: 0.0006069811670379721 R2: 0.944308031001564 time: 1703262516.867591\n",
      "Training [93%] Loss: 0.0007995206046589989 time: 1703262516.867591\n",
      "weight: [ 1.12332707  0.12740636 -0.04969368  1.07201376  0.61078347  0.37268576\n",
      "  0.89975884  1.13450714  0.65753198 -0.55875181  0.2479633   0.4045595\n",
      "  1.12062688  0.58238223  0.75544561  0.16350742  0.69876481  1.21845236\n",
      "  0.86138417  0.99389755  0.48206148 -0.04493141 -0.15152301  0.12613366]\n",
      "epoch 280\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000988525411174813 R2: 0.94441415710417 time: 1703262524.347771\n",
      "batch_idx: 1 loss: 0.0006043380806929674 R2: 0.9445204166209031 time: 1703262531.8812113\n",
      "Training [93%] Loss: 0.0007964317459338902 time: 1703262531.8812113\n",
      "weight: [ 1.12352423  0.12729365 -0.05023561  1.07171769  0.61054848  0.37392522\n",
      "  0.90112295  1.13672719  0.65834904 -0.56062055  0.24764814  0.40443398\n",
      "  1.12041755  0.58144272  0.7553329   0.16252465  0.69939258  1.21923612\n",
      "  0.86392575  0.99443041  0.4801483  -0.04718295 -0.15124469  0.12645769]\n",
      "epoch 281\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009850252282244934 R2: 0.9446253696314628 time: 1703262539.2829623\n",
      "batch_idx: 1 loss: 0.0006017258882382979 R2: 0.9447305062938371 time: 1703262546.8686285\n",
      "Training [94%] Loss: 0.0007933755582313956 time: 1703262546.8686285\n",
      "weight: [ 1.12371637  0.12719284 -0.05075103  1.07143489  0.61031726  0.37515947\n",
      "  0.90246821  1.13893353  0.65909362 -0.56248369  0.24733067  0.40430703\n",
      "  1.12019639  0.58049752  0.7552321   0.16152501  0.70002963  1.2200295\n",
      "  0.86645876  0.99494912  0.4782159  -0.04942453 -0.15096619  0.12678142]\n",
      "epoch 282\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000981559253996496 R2: 0.9448342982593225 time: 1703262554.3025854\n",
      "batch_idx: 1 loss: 0.0005991443463280162 R2: 0.9449383220459353 time: 1703262561.7279365\n",
      "Training [94%] Loss: 0.0007903518001622561 time: 1703262561.7279365\n",
      "weight: [ 1.1239036   0.12710401 -0.05123959  1.0711653   0.61008984  0.37638853\n",
      "  0.9037947   1.14112634  0.65976606 -0.56434112  0.24701084  0.40417859\n",
      "  1.11996345  0.57954733  0.75514327  0.16050881  0.70067606  1.22083235\n",
      "  0.8689831   0.99545376  0.4762643  -0.05165597 -0.15068763  0.12710469]\n",
      "epoch 283\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009781272539474456 R2: 0.9450409648919684 time: 1703262569.2025485\n",
      "batch_idx: 1 loss: 0.0005965932156003924 R2: 0.9451438857573324 time: 1703262576.767801\n",
      "Training [94%] Loss: 0.000787360234773919 time: 1703262576.767801\n",
      "weight: [ 1.12408606  0.12702723 -0.05170095  1.07090886  0.60986625  0.37761244\n",
      "  0.90510253  1.1433058   0.66036669 -0.56619271  0.24668859  0.40404863\n",
      "  1.11971882  0.57859285  0.75506649  0.15947639  0.70133194  1.22164452\n",
      "  0.87149868  0.99594444  0.47429352 -0.05387708 -0.15040914  0.12742739]\n",
      "epoch 284\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009747289979481303 R2: 0.9452453912767715 time: 1703262584.2867174\n",
      "batch_idx: 1 loss: 0.0005940722604911224 R2: 0.9453472191409589 time: 1703262591.8726425\n",
      "Training [95%] Loss: 0.0007844006292196264 time: 1703262591.8726425\n",
      "weight: [ 1.12426387  0.12696254 -0.05213477  1.07066548  0.60964649  0.37883124\n",
      "  0.90639178  1.14547209  0.66089585 -0.56803835  0.24636386  0.40391708\n",
      "  1.11946257  0.57763479  0.7550018   0.15842811  0.70199731  1.22246582\n",
      "  0.87400541  0.9964213   0.47230361 -0.0560877  -0.15013083  0.12774936]\n",
      "epoch 285\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009713642597817202 R2: 0.9454475989828197 time: 1703262599.395787\n",
      "batch_idx: 1 loss: 0.0005915812490087012 R2: 0.9455483437202188 time: 1703262606.8926713\n",
      "Training [95%] Loss: 0.0007814727543952106 time: 1703262606.8926713\n",
      "weight: [ 1.12443717  0.12690996 -0.05254073  1.07043507  0.60943059  0.38004497\n",
      "  0.90766255  1.14762537  0.66135391 -0.56987793  0.2460366   0.40378391\n",
      "  1.11919482  0.57667385  0.75494922  0.15736432  0.70267219  1.22329605\n",
      "  0.87650319  0.9968845   0.47029462 -0.05828762 -0.14985281  0.12807048]\n",
      "epoch 286\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009680328166244 R2: 0.9456476093788316 time: 1703262614.4529293\n",
      "batch_idx: 1 loss: 0.0005891199524785105 R2: 0.9457472808062851 time: 1703262622.0229435\n",
      "Training [95%] Loss: 0.0007785763845514552 time: 1703262622.0229435\n",
      "weight: [ 1.12460608  0.12686951 -0.05291851  1.07021751  0.60921855  0.38125367\n",
      "  0.90891495  1.14976581  0.66174122 -0.57171135  0.24570676  0.40364906\n",
      "  1.11891566  0.57571071  0.75490876  0.15628541  0.70335657  1.22413496\n",
      "  0.87899193  0.9973342   0.46826659 -0.06047668 -0.14957521  0.12839061]\n",
      "epoch 287\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009647344485291835 R2: 0.9458454436107926 time: 1703262629.4095166\n",
      "batch_idx: 1 loss: 0.0005866881452579349 R2: 0.9459440514751447 time: 1703262636.8877401\n",
      "Training [96%] Loss: 0.0007757112968935592 time: 1703262636.8877401\n",
      "weight: [ 1.12477074  0.12684117 -0.05326781  1.07001269  0.60901036  0.38245739\n",
      "  0.91014907  1.15189357  0.66205814 -0.57353851  0.2453743   0.40351251\n",
      "  1.11862522  0.57474605  0.75488043  0.15519176  0.70405041  1.22498232\n",
      "  0.88147155  0.99777063  0.46621962 -0.06265471 -0.14929814  0.12870961]\n",
      "epoch 288\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009614689379283985 R2: 0.9460411225795722 time: 1703262644.5827687\n",
      "batch_idx: 1 loss: 0.0005842856044360298 R2: 0.946138676544755 time: 1703262652.2170799\n",
      "Training [96%] Loss: 0.0007728772711822142 time: 1703262652.2170799\n",
      "weight: [ 1.12493126  0.12682492 -0.05358833  1.06982048  0.60880604  0.38365619\n",
      "  0.91136502  1.1540088   0.66230506 -0.57535931  0.24503915  0.40337419\n",
      "  1.11832364  0.57378054  0.75486417  0.15408377  0.70475365  1.22583784\n",
      "  0.88394196  0.99819401  0.46415378 -0.06482153 -0.14902172  0.12902735]\n",
      "epoch 289\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009582360691621038 R2: 0.946234666918724 time: 1703262659.862953\n",
      "batch_idx: 1 loss: 0.0005819121095296026 R2: 0.9463311765527533 time: 1703262667.6376803\n",
      "Training [96%] Loss: 0.0007700740893458531 time: 1703262667.6376803\n",
      "weight: [ 1.12508778  0.12682071 -0.05387978  1.06964074  0.60860558  0.38485012\n",
      "  0.9125629   1.15611166  0.66248235 -0.57717365  0.24470127  0.40323409\n",
      "  1.11801105  0.57281482  0.75485996  0.15296186  0.7054662   1.22670125\n",
      "  0.88640306  0.99860457  0.46206916 -0.06697696 -0.14874606  0.12934369]\n",
      "epoch 290\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009550356280469083 R2: 0.9464260969728213 time: 1703262675.2786567\n",
      "batch_idx: 1 loss: 0.0005795674421793551 R2: 0.946521571734913 time: 1703262682.7698615\n",
      "Training [97%] Loss: 0.0007673015351131317 time: 1703262682.7698615\n",
      "weight: [ 1.12524041  0.12682847 -0.05414189  1.06947331  0.60840897  0.38603923\n",
      "  0.91374282  1.1582023   0.66259042 -0.57898146  0.24436061  0.40309214\n",
      "  1.11768761  0.57184954  0.75486773  0.15182643  0.70618796  1.22757224\n",
      "  0.88885476  0.99900258  0.45996588 -0.06912085 -0.14847129  0.1296585 ]\n",
      "epoch 291\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009518674014991457 R2: 0.9466154327767946 time: 1703262690.4028025\n",
      "batch_idx: 1 loss: 0.0005772513858550011 R2: 0.9467098820047178 time: 1703262698.4292054\n",
      "Training [97%] Loss: 0.0007645593936770734 time: 1703262698.4292054\n",
      "weight: [ 1.12538928  0.12684814 -0.05437438  1.06931805  0.60821621  0.38722361\n",
      "  0.91490488  1.16028086  0.66262967 -0.58078264  0.24401712  0.40294832\n",
      "  1.11735348  0.57088531  0.75488739  0.15067793  0.7069188   1.22845051\n",
      "  0.89129699  0.99938833  0.45784405 -0.07125302 -0.14819751  0.12997164]\n",
      "epoch 292\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009487311772161733 R2: 0.9468026940364964 time: 1703262706.4279003\n",
      "batch_idx: 1 loss: 0.0005749637255809648 R2: 0.9468961269345069 time: 1703262714.3979914\n",
      "Training [97%] Loss: 0.0007618474513985691 time: 1703262714.3979914\n",
      "weight: [ 1.1255345   0.1268796  -0.054577    1.06917479  0.60802729  0.3884033\n",
      "  0.91604918  1.16234749  0.66260052 -0.58257711  0.24367076  0.4028026\n",
      "  1.11700883  0.56992271  0.75491886  0.14951678  0.70765855  1.22933574\n",
      "  0.89372964  0.99976209  0.4557038  -0.0733733  -0.14792485  0.13028298]\n",
      "epoch 293\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009456267434210472 R2: 0.9469879001108128 time: 1703262722.1584299\n",
      "batch_idx: 1 loss: 0.0005727042476854291 R2: 0.9470803257384335 time: 1703262730.0726075\n",
      "Training [98%] Loss: 0.0007591654955532382 time: 1703262730.0726075\n",
      "weight: [ 1.12567619  0.12692275 -0.05474949  1.06904336  0.60784219  0.38957839\n",
      "  0.91717582  1.16440233  0.66250338 -0.5843648   0.24332148  0.40265493\n",
      "  1.11665386  0.56896231  0.75496201  0.14834343  0.70840707  1.23022761\n",
      "  0.89615263  1.00012418  0.45354528 -0.07548155 -0.14765343  0.13059238]\n",
      "epoch 294\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009425538886778554 R2: 0.9471710699957254 time: 1703262738.1628923\n",
      "batch_idx: 1 loss: 0.0005704727395762618 R2: 0.9472624972574503 time: 1703262745.8378384\n",
      "Training [98%] Loss: 0.0007565133141270587 time: 1703262745.8378384\n",
      "weight: [ 1.12581444  0.12697746 -0.05489161  1.06892358  0.60766091  0.39074895\n",
      "  0.91828491  1.16644552  0.66233869 -0.58614563  0.24296924  0.40250528\n",
      "  1.11628875  0.56800467  0.75501672  0.14715832  0.70916414  1.23112578\n",
      "  0.89856586  1.00047491  0.45136863 -0.07757761 -0.14738337  0.13089971]\n",
      "epoch 295\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009395124017762535 R2: 0.9473522223105142 time: 1703262753.4927819\n",
      "batch_idx: 1 loss: 0.0005682689895508446 R2: 0.9474426599466673 time: 1703262761.2127576\n",
      "Training [98%] Loss: 0.000753890695663549 time: 1703262761.2127576\n",
      "weight: [ 1.12594937  0.12704358 -0.05500313  1.06881527  0.60748343  0.39191506\n",
      "  0.91937655  1.1684772   0.6621069  -0.58791954  0.24261398  0.40235361\n",
      "  1.1159137   0.56705028  0.75508283  0.14596191  0.70992958  1.23202994\n",
      "  0.90096925  1.0008146   0.44917402 -0.07966131 -0.14711477  0.13120484]\n",
      "epoch 296\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009365020716816972 R2: 0.9475313752862841 time: 1703262769.137665\n",
      "batch_idx: 1 loss: 0.0005660927866402889 R2: 0.9476208318652366 time: 1703262777.062645\n",
      "Training [99%] Loss: 0.000751297429160993 time: 1703262777.062645\n",
      "weight: [ 1.12608107  0.12712095 -0.05508382  1.06871826  0.60730972  0.39307681\n",
      "  0.92045085  1.1704975   0.66180846 -0.58968647  0.24225566  0.4021999\n",
      "  1.11552892  0.56609964  0.7551602   0.14475465  0.71070317  1.23293974\n",
      "  0.90336269  1.00114357  0.44696164 -0.0817325  -0.14684777  0.13150762]\n",
      "epoch 297\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000933522687550945 R2: 0.9477085467570177 time: 1703262784.632686\n",
      "batch_idx: 1 loss: 0.0005639439204863792 R2: 0.947797030668774 time: 1703262792.359022\n",
      "Training [99%] Loss: 0.0007487333040186621 time: 1703262792.359022\n",
      "weight: [ 1.12620964  0.12720939 -0.05513347  1.06863235  0.60713979  0.39423429\n",
      "  0.92150789  1.17250656  0.66144386 -0.59144635  0.24189423  0.40204411\n",
      "  1.11513463  0.56515321  0.75524865  0.14353701  0.71148468  1.23385487\n",
      "  0.9057461   1.00146215  0.44473166 -0.08379105 -0.14658247  0.13180793]\n",
      "epoch 298\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009305740388062167 R2: 0.9478837541532805 time: 1703262800.1079245\n",
      "batch_idx: 1 loss: 0.0005618221812532445 R2: 0.9479712736045183 time: 1703262807.6463287\n",
      "Training [99%] Loss: 0.0007461981100297306 time: 1703262807.6463287\n",
      "weight: [ 1.12633517  0.12730873 -0.05515185  1.06855735  0.6069736   0.39538758\n",
      "  0.92254778  1.1745045   0.66101356 -0.59319913  0.24152966  0.40188621\n",
      "  1.11473105  0.56421141  0.75534799  0.14230944  0.71227388  1.234775\n",
      "  0.90811938  1.00177068  0.44248428 -0.08583681 -0.146319    0.13210563]\n",
      "epoch 299\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009276559152589208 R2: 0.9480570144985065 time: 1703262815.0325847\n",
      "batch_idx: 1 loss: 0.0005597273595714312 R2: 0.9481435775091669 time: 1703262822.427983\n",
      "Training [100%] Loss: 0.0007436916374151761 time: 1703262822.427983\n",
      "weight: [ 1.12645774  0.12741876 -0.05513876  1.06849309  0.60681115  0.39653678\n",
      "  0.92357061  1.17649147  0.66051806 -0.59494475  0.24116188  0.40172617\n",
      "  1.11431842  0.56327463  0.75545802  0.14107241  0.71307051  1.2356998\n",
      "  0.91048243  1.00206948  0.44021972 -0.08786963 -0.14605748  0.13240058]\n",
      "epoch 300\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000924768107276718 R2: 0.9482283444079587 time: 1703262829.9628713\n",
      "batch_idx: 1 loss: 0.0005576592465093405 R2: 0.948313958809323 time: 1703262837.5130322\n",
      "Training [100%] Loss: 0.0007412136768930292 time: 1703262837.5130322\n",
      "weight: [ 1.12657743  0.12753926 -0.05509401  1.06843936  0.6066524   0.397682\n",
      "  0.92457647  1.17846759  0.65995788 -0.59668317  0.24079086  0.40156396\n",
      "  1.11389696  0.56234325  0.75557852  0.13982639  0.71387433  1.23662896\n",
      "  0.91283514  1.00235888  0.43793821 -0.08988938 -0.14579803  0.13269266]\n",
      "train_MSE: 0.0007443012569973778\n",
      "train_RMSE: 0.027281885143761193\n",
      "train_MAE: 0.022608652774405734\n",
      "train_MAPE: 0.04918720607979538\n",
      "train_R2: 0.948313958809323\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "weights =[0.68756473 , 1.2864305 ,  0.5411694 , -0.01524038 , 0.5852044 ,  0.6762012,\n",
    "  0.35593897 , 0.22628789,  0.38244092,  0.35140917,  0.86482936 , 0.8531242,\n",
    "  0.09241156 , 0.6720707  , 0.38071635,  0.95416117 , 0.63409   ,  0.40179932,\n",
    "  0.7345088  , 0.6243114  , 0.3178202 , -0.2618623  , 0.18122938,  1.0447433,\n",
    "  0.48699683 , 0.7739934  , 0.38703147 , 0.48046085,  0.5525667 ,  0.52838504,\n",
    "  0.28538367 , 0.30099392,  0.74503726 , 0.67772216,  0.3839896 ,  0.417687]\n",
    "weights = npp.array(weights, requires_grad=True)\n",
    "'''\n",
    "weights = params\n",
    "loss_list=[]\n",
    "r2_list=[]\n",
    "\n",
    "n_epochs=300\n",
    "\n",
    "start_time=time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss  = []\n",
    "    total_r2  = []\n",
    "    print(f\"epoch {epoch+1}\\n-------------------------------\")\n",
    "    for it, batch_index in enumerate (chain(*[X_batches])):\n",
    "        # Update the weights by one optimizer step\n",
    "        \n",
    "        X_batch = X[batch_index]\n",
    "        Y_batch = Y[batch_index]\n",
    "        weights, _, _ = opt.step(cost, weights, X_batch, Y_batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        predictions = [QNN(weights, x) for x in X]\n",
    "        r2 = R2(Y, predictions)\n",
    "        cost_t=cost(weights,X_batch,Y_batch)\n",
    "        total_loss.append(cost_t)\n",
    "        total_r2.append(r2)\n",
    "        end_timet=time.time()\n",
    "        print(\"batch_idx:\",it,\"loss:\",cost_t,\"R2:\",r2,\"time:\",end_timet)\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    r2_list.append(sum(total_r2)/len(total_r2))\n",
    "    print('Training [{:.0f}%]'.format(100. * (epoch + 1) / n_epochs),\"Loss:\", loss_list[-1], \"time:\",end_timet)\n",
    "    print(\"weight:\",weights)\n",
    "    \n",
    "    \n",
    "predictions = [QNN(weights, x) for x in X]\n",
    "\n",
    "train_R2 = R2(Y, predictions)\n",
    "train_MSE=metrics.mean_squared_error(Y,predictions)\n",
    "train_RMSE=train_MSE**(1/2)\n",
    "train_MAE=metrics.mean_absolute_error(Y,predictions)\n",
    "train_MAPE=metrics.mean_absolute_percentage_error(Y,predictions)\n",
    "\n",
    "print(\"train_MSE:\",train_MSE)\n",
    "print(\"train_RMSE:\",train_RMSE)\n",
    "print(\"train_MAE:\",train_MAE)\n",
    "print(\"train_MAPE:\",train_MAPE)\n",
    "print(\"train_R2:\",train_R2)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "plt.title(\"MSE value against epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.plot(range(len(loss_list)), np.log(loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c5609a-73ee-4deb-86d0-d6a744439104",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006811364866973042 R2: 0.9599086559770006 time: 1703172820.8441331\n",
      "batch_idx: 1 loss: 0.0004708969714715788 R2: 0.9599401679256403 time: 1703172829.2799776\n",
      "Training [1%] Loss: 0.0005760167290844415 time: 1703172829.2799776\n",
      "weight: [ 0.98045622  0.12931449  0.10444879  0.93734827  0.61615549  0.43834824\n",
      " -0.07251746  0.46293981  0.2990797  -0.37889624  0.55840489  0.33134531\n",
      "  0.57897239  0.06578474  0.62843375  0.16119853  0.19200402  0.65604726\n",
      "  0.55744941  0.53950171  0.52616863  0.90271623 -0.82927669 -0.81058041]\n",
      "epoch 2\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006800481521733737 R2: 0.9599689775965177 time: 1703172837.1959555\n",
      "batch_idx: 1 loss: 0.00047022035179802174 R2: 0.9600003298216528 time: 1703172844.9777603\n",
      "Training [2%] Loss: 0.0005751342519856976 time: 1703172844.9777603\n",
      "weight: [ 0.98073374  0.12979812  0.10458807  0.93652219  0.61509217  0.43965188\n",
      " -0.07347517  0.45969057  0.298575   -0.37882577  0.56080743  0.33008931\n",
      "  0.57802347  0.06483989  0.62935265  0.16079871  0.19227847  0.65633312\n",
      "  0.55577629  0.53830805  0.52606211  0.90260882 -0.8295292  -0.80990238]\n",
      "epoch 3\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006789689405680983 R2: 0.9600288859526664 time: 1703172852.7624233\n",
      "batch_idx: 1 loss: 0.0004695469940406565 R2: 0.9600600798029364 time: 1703172860.593613\n",
      "Training [3%] Loss: 0.0005742579673043773 time: 1703172860.593613\n",
      "weight: [ 0.98101122  0.13028038  0.10472421  0.93570193  0.61403319  0.44095254\n",
      " -0.07443649  0.45641322  0.29810903 -0.37874952  0.56322452  0.32882585\n",
      "  0.57708208  0.06390534  0.63026516  0.16040755  0.19255279  0.65661837\n",
      "  0.55410467  0.53711132  0.52595147  0.90249859 -0.82979235 -0.80921077]\n",
      "epoch 4\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006778987155880254 R2: 0.9600883843888036 time: 1703172868.5812733\n",
      "batch_idx: 1 loss: 0.0004688769398794198 R2: 0.9601194211068925 time: 1703172876.4910803\n",
      "Training [4%] Loss: 0.0005733878277337226 time: 1703172876.4910803\n",
      "weight: [ 0.98128867  0.13076116  0.1048571   0.93488745  0.61297872  0.44225012\n",
      " -0.07540109  0.45310813  0.29768239 -0.37866755  0.5656562   0.32755498\n",
      "  0.57614814  0.06298102  0.6311713   0.16002492  0.19282715  0.65690316\n",
      "  0.55243455  0.53591167  0.52583682  0.9023856  -0.83006614 -0.80850599]\n",
      "epoch 5\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006768373452695995 R2: 0.9601474760796714 time: 1703172884.2113354\n",
      "batch_idx: 1 loss: 0.00046821023043754783 R2: 0.9601783568083752 time: 1703172891.9634645\n",
      "Training [5%] Loss: 0.0005725237878535736 time: 1703172891.9634645\n",
      "weight: [ 0.98156611  0.13124032  0.10498661  0.93407874  0.6119289   0.44354451\n",
      " -0.07636866  0.44977569  0.29729564 -0.37857991  0.56810248  0.32627678\n",
      "  0.57522159  0.06206686  0.63207111  0.1596507   0.19310166  0.65718764\n",
      "  0.55076591  0.53470921  0.52571826  0.90226991 -0.8303505  -0.80778848]\n",
      "epoch 6\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006757847018986211 R2: 0.9602061640398413 time: 1703172899.9506633\n",
      "batch_idx: 1 loss: 0.00046754690618309194 R2: 0.9602368898279796 time: 1703172907.8593402\n",
      "Training [6%] Loss: 0.0005716658040408565 time: 1703172907.8593402\n",
      "weight: [ 0.98184353  0.13171774  0.10511264  0.93327577  0.61088388  0.44483558\n",
      " -0.07733886  0.44641629  0.2969493  -0.37848666  0.57056338  0.3249913\n",
      "  0.57430236  0.06116278  0.63296463  0.15928478  0.19337647  0.65747194\n",
      "  0.54909877  0.53350408  0.52559587  0.90215156 -0.83064538 -0.80705864]\n",
      "epoch 7\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006747406619331141 R2: 0.9602644511318281 time: 1703172915.627648\n",
      "batch_idx: 1 loss: 0.0004668870068385891 R2: 0.960295022939978 time: 1703172923.6161823\n",
      "Training [7%] Loss: 0.0005708138343858515 time: 1703172923.6161823\n",
      "weight: [ 0.98212095  0.13219331  0.10523506  0.9324785   0.60984378  0.44612323\n",
      " -0.07831139  0.44303036  0.29664386 -0.37838786  0.57303891  0.32369861\n",
      "  0.5733904   0.0602687   0.63385188  0.15892704  0.19365172  0.65775621\n",
      "  0.54743311  0.5322964   0.52546974  0.9020306  -0.83095072 -0.8063169 ]\n",
      "epoch 8\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006737051059288281 R2: 0.9603223400738867 time: 1703172931.3822002\n",
      "batch_idx: 1 loss: 0.00046623057129838917 R2: 0.960352758779943 time: 1703172939.1205719\n",
      "Training [8%] Loss: 0.0005699678386136087 time: 1703172939.1205719\n",
      "weight: [ 0.98239837  0.1326669   0.10535377  0.93168691  0.60880874  0.44740736\n",
      " -0.07928592  0.43961834  0.29637975 -0.37828357  0.57552906  0.32239876\n",
      "  0.57248564  0.05938454  0.63473292  0.15857737  0.19392752  0.65804058\n",
      "  0.54576896  0.5310863   0.52533997  0.90190709 -0.83126645 -0.80556366]\n",
      "epoch 9\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000672677918466742 R2: 0.9603798334475002 time: 1703172947.022623\n",
      "batch_idx: 1 loss: 0.00046557763755328805 R2: 0.9604100998520717 time: 1703172954.8442214\n",
      "Training [9%] Loss: 0.000569127778010015 time: 1703172954.8442214\n",
      "weight: [ 0.98267581  0.13313838  0.10546864  0.93090097  0.60777888  0.44868787\n",
      " -0.08026213  0.43618067  0.29615735 -0.37817386  0.57803385  0.32109181\n",
      "  0.57158803  0.0585102   0.63560777  0.15823566  0.19420402  0.65832518\n",
      "  0.54410633  0.5298739   0.52520664  0.90178109 -0.83159248 -0.80479933]\n",
      "epoch 10\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006716589880818846 R2: 0.9604369337046095 time: 1703172962.7012863\n",
      "batch_idx: 1 loss: 0.00046492824262205567 R2: 0.9604670485362281 time: 1703172970.3972769\n",
      "Training [10%] Loss: 0.0005682936153519702 time: 1703172970.3972769\n",
      "weight: [ 0.98295325  0.13360764  0.10557957  0.93012065  0.60675429  0.44996466\n",
      " -0.08123971  0.43271784  0.295977   -0.3780588   0.58055326  0.31977781\n",
      "  0.57069749  0.05764558  0.63647648  0.15790179  0.19448133  0.65861015\n",
      "  0.54244522  0.52865933  0.52506982  0.90165264 -0.83192871 -0.80402431]\n",
      "epoch 11\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006706482071928614 R2: 0.9604936431745588 time: 1703172978.2106044\n",
      "batch_idx: 1 loss: 0.0004642824224895801 R2: 0.9605236070947221 time: 1703172985.9842117\n",
      "Training [11%] Loss: 0.0005674653148412208 time: 1703172985.9842117\n",
      "weight: [ 0.98323072  0.13407456  0.10568644  0.92934592  0.60573508  0.45123764\n",
      " -0.08221834  0.42923034  0.295839   -0.37793845  0.58308729  0.31845681\n",
      "  0.56981398  0.05679059  0.6373391   0.15757568  0.19475958  0.65889561\n",
      "  0.54078567  0.5274427   0.52492959  0.9015218  -0.83227504 -0.803239  ]\n",
      "epoch 12\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000669645472031411 R2: 0.9605499640708148 time: 1703172993.8558843\n",
      "batch_idx: 1 loss: 0.0004636402120511883 R2: 0.9605797776788559 time: 1703173001.6553032\n",
      "Training [12%] Loss: 0.0005666428420412997 time: 1703173001.6553032\n",
      "weight: [ 0.98350821  0.13453901  0.10578914  0.92857674  0.60472134  0.45250673\n",
      " -0.08319771  0.42571867  0.29574361 -0.3778129   0.58563591  0.31712886\n",
      "  0.56893744  0.05594511  0.63819566  0.1572572   0.19503888  0.65918169\n",
      "  0.53912769  0.52622413  0.52478603  0.90138863 -0.83263137 -0.8024438 ]\n",
      "epoch 13\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006686506825714782 R2: 0.9606058984974524 time: 1703173009.4400542\n",
      "batch_idx: 1 loss: 0.0004630016450630203 R2: 0.9606355623352203 time: 1703173017.3948786\n",
      "Training [13%] Loss: 0.0005658261638172492 time: 1703173017.3948786\n",
      "weight: [ 0.98378574  0.13500088  0.10588755  0.9278131   0.60371315  0.45377183\n",
      " -0.08417753  0.42218337  0.29569102 -0.37768223  0.58819911  0.31579399\n",
      "  0.56806782  0.05510904  0.63904623  0.15694627  0.19531936  0.6594685\n",
      "  0.53747132  0.52500373  0.52463921  0.90125319 -0.83299756 -0.80163908]\n",
      "epoch 14\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006676637424571988 R2: 0.9606614484554186 time: 1703173025.336292\n",
      "batch_idx: 1 loss: 0.00046236675409802553 R2: 0.9606909630118073 time: 1703173033.132288\n",
      "Training [14%] Loss: 0.0005650152482776121 time: 1703173033.132288\n",
      "weight: [ 0.9840633   0.13546004  0.10598156  0.92705495  0.60271059  0.45503288\n",
      " -0.08515747  0.41862499  0.29568139 -0.3775465   0.59077687  0.31445226\n",
      "  0.56720506  0.05428225  0.63989083  0.15664277  0.19560112  0.65975617\n",
      "  0.53581658  0.52378163  0.52448919  0.90111552 -0.83337348 -0.80082523]\n",
      "epoch 15\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006666845589292618 R2: 0.9607166158486151 time: 1703173040.9101136\n",
      "batch_idx: 1 loss: 0.000461735570507397 R2: 0.9607459815639038 time: 1703173048.6089792\n",
      "Training [15%] Loss: 0.0005642100647183293 time: 1703173048.6089792\n",
      "weight: [ 0.9843409   0.13591637  0.10607106  0.92630227  0.60171373  0.4562898\n",
      " -0.08613725  0.41504408  0.29571483 -0.3774058   0.59336913  0.3131037\n",
      "  0.56634912  0.05346465  0.64072953  0.15634662  0.19588428  0.66004481\n",
      "  0.53416351  0.52255793  0.52433603  0.90097569 -0.83375899 -0.80000264]\n",
      "epoch 16\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00066571304274936 R2: 0.9607714024897783 time: 1703173056.3822527\n",
      "batch_idx: 1 loss: 0.0004611081243871388 R2: 0.9608006197598116 time: 1703173064.2383864\n",
      "Training [16%] Loss: 0.0005634105835682494 time: 1703173064.2383864\n",
      "weight: [ 0.98461854  0.13636977  0.10615594  0.92555503  0.60072262  0.45754251\n",
      " -0.08711657  0.41144124  0.29579141 -0.37726022  0.59597588  0.31174833\n",
      "  0.56549994  0.05265609  0.64156236  0.15605771  0.19616894  0.66033453\n",
      "  0.53251215  0.52133274  0.5241798   0.90083375 -0.83415395 -0.79917166]\n",
      "epoch 17\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006647491081221417 R2: 0.9608258101061959 time: 1703173071.9212325\n",
      "batch_idx: 1 loss: 0.0004604844445494962 R2: 0.9608548792863971 time: 1703173079.7621872\n",
      "Training [17%] Loss: 0.0005626167763358189 time: 1703173079.7621872\n",
      "weight: [ 0.98489622  0.1368201   0.1062361   0.92481318  0.59973732  0.45879095\n",
      " -0.08809513  0.40781706  0.29591114 -0.37710984  0.59859707  0.31038619\n",
      "  0.56465747  0.05185648  0.64238939  0.15577595  0.19645521  0.66062544\n",
      "  0.53086255  0.52010618  0.52402055  0.90068977 -0.83455819 -0.79833268]\n",
      "epoch 18\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006637926726145775 R2: 0.96087984034526 time: 1703173087.644028\n",
      "batch_idx: 1 loss: 0.0004598645584989217 R2: 0.9609087617544823 time: 1703173095.7533748\n",
      "Training [18%] Loss: 0.0005618286155567496 time: 1703173095.7533748\n",
      "weight: [ 0.98517396  0.13726726  0.10631141  0.92407671  0.59875787  0.46003505\n",
      " -0.08907264  0.40417217  0.29607398 -0.37695475  0.60123264  0.3090173\n",
      "  0.56382168  0.05106567  0.64321065  0.15550126  0.19674319  0.66091764\n",
      "  0.52921476  0.51887833  0.52385833  0.90054379 -0.83497155 -0.79748606]\n",
      "epoch 19\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006628436570724111 R2: 0.96093349477987 time: 1703173103.6390252\n",
      "batch_idx: 1 loss: 0.0004592484924123054 R2: 0.9609622687040934 time: 1703173111.3499212\n",
      "Training [19%] Loss: 0.0005610460747423583 time: 1703173111.3499212\n",
      "weight: [ 0.98545175  0.13771111  0.10638178  0.92334558  0.59778431  0.46127477\n",
      " -0.09004883  0.40050721  0.29627987 -0.37679503  0.60388254  0.30764168\n",
      "  0.56299252  0.05028354  0.6440262   0.15523353  0.19703297  0.66121123\n",
      "  0.52756882  0.51764932  0.52369319  0.90039588 -0.83539385 -0.79663215]\n",
      "epoch 20\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006619019855335877 R2: 0.9609867749136896 time: 1703173119.290713\n",
      "batch_idx: 1 loss: 0.00045863627112314954 R2: 0.9610154016095626 time: 1703173127.105089\n",
      "Training [20%] Loss: 0.0005602691283283686 time: 1703173127.105089\n",
      "weight: [ 0.98572959  0.13815156  0.10644709  0.92261975  0.59681667  0.46251003\n",
      " -0.09102341  0.39682284  0.29652866 -0.3766308   0.60654672  0.30625936\n",
      "  0.56216995  0.04950996  0.6448361   0.15497268  0.19732464  0.66150632\n",
      "  0.52592479  0.51641923  0.52352518  0.9002461  -0.83582492 -0.7957713 ]\n",
      "epoch 21\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006609675851385313 R2: 0.9610396821862885 time: 1703173135.0462801\n",
      "batch_idx: 1 loss: 0.00045802791810936735 R2: 0.961068161884526 time: 1703173143.2254763\n",
      "Training [21%] Loss: 0.0005594977516239493 time: 1703173143.2254763\n",
      "weight: [ 0.98600748  0.13858848  0.10650724  0.9218992   0.59585498  0.46374081\n",
      " -0.09199612  0.39311973  0.29682019 -0.37646212  0.60922511  0.30487033\n",
      "  0.56135392  0.04874481  0.64564038  0.15471862  0.19761831  0.661803\n",
      "  0.52428273  0.51518817  0.52335433  0.90009449 -0.83626456 -0.79490388]\n",
      "epoch 22\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006600403860373113 R2: 0.9610922179781405 time: 1703173150.966755\n",
      "batch_idx: 1 loss: 0.000457423455484422 R2: 0.9611205508867824 time: 1703173158.8092399\n",
      "Training [22%] Loss: 0.0005587319207608667 time: 1703173158.8092399\n",
      "weight: [ 0.98628543  0.13902175  0.10656212  0.92118389  0.59489925  0.46496704\n",
      " -0.09296667  0.38939858  0.29715423 -0.37628912  0.61191764  0.30347461\n",
      "  0.56054441  0.04798796  0.64643911  0.15447127  0.19791404  0.66210135\n",
      "  0.52264271  0.51395624  0.52318068  0.89994113 -0.83671258 -0.79403021]\n",
      "epoch 23\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000659120321293636 R2: 0.9611443836155267 time: 1703173166.6792774\n",
      "batch_idx: 1 loss: 0.00045682290399153854 R2: 0.9611725699230573 time: 1703173174.6273916\n",
      "Training [23%] Loss: 0.0005579716126425873 time: 1703173174.6273916\n",
      "weight: [ 0.98656343  0.13945126  0.10661162  0.92047379  0.5939495   0.46618868\n",
      " -0.09393482  0.38566011  0.29753051 -0.37611187  0.61462423  0.3020722\n",
      "  0.55974137  0.04723926  0.64723234  0.15423054  0.19821194  0.66240147\n",
      "  0.52100478  0.51272352  0.52300427  0.89978606 -0.83716877 -0.79315065]\n",
      "epoch 24\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006582073267857749 R2: 0.9611961803753288 time: 1703173182.4895504\n",
      "batch_idx: 1 loss: 0.00045622628300068734 R2: 0.9612242202536644 time: 1703173190.3317213\n",
      "Training [24%] Loss: 0.0005572168048932312 time: 1703173190.3317213\n",
      "weight: [ 0.98684149  0.1398769   0.10665565  0.91976887  0.59300574  0.4674057\n",
      " -0.0949003   0.38190504  0.29794871 -0.37593048  0.61734482  0.30066311\n",
      "  0.55894478  0.04649859  0.64802011  0.15399635  0.19851207  0.66270344\n",
      "  0.51936903  0.51149011  0.52282512  0.89962936 -0.83763294 -0.79226553]\n",
      "epoch 25\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006573013411044703 R2: 0.9612476094897058 time: 1703173198.1811185\n",
      "batch_idx: 1 loss: 0.0004556336105081565 R2: 0.961275503097068 time: 1703173206.1212225\n",
      "Training [25%] Loss: 0.0005564674758063133 time: 1703173206.1212225\n",
      "weight: [ 0.9871196   0.14029855  0.10669409  0.91906909  0.59206797  0.46861806\n",
      " -0.09586286  0.37813414  0.29840848 -0.37574505  0.6200793   0.29924731\n",
      "  0.5581546   0.04576581  0.64880248  0.15376861  0.19881451  0.66300733\n",
      "  0.51773552  0.51025609  0.52264327  0.89947107 -0.83810485 -0.79137517]\n",
      "epoch 26\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006564023054479547 R2: 0.9612986721506994 time: 1703173213.9169698\n",
      "batch_idx: 1 loss: 0.00045504490313838015 R2: 0.9613264196343655 time: 1703173221.7847757\n",
      "Training [26%] Loss: 0.0005557236042931674 time: 1703173221.7847757\n",
      "weight: [ 0.98739777  0.1407161   0.10672685  0.91837444  0.59113618  0.46982572\n",
      " -0.09682226  0.37434817  0.2989094  -0.37555569  0.62282759  0.29782482\n",
      "  0.5573708   0.04504079  0.6495795   0.15354725  0.19911934  0.66331323\n",
      "  0.51610434  0.50902156  0.52245873  0.89931125 -0.83858431 -0.79047991]\n",
      "epoch 27\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006555101635142078 R2: 0.9613493695147353 time: 1703173229.520865\n",
      "batch_idx: 1 loss: 0.00045446017614794753 R2: 0.9613769710136756 time: 1703173237.3658235\n",
      "Training [27%] Loss: 0.0005549851698310776 time: 1703173237.3658235\n",
      "weight: [ 0.98767599  0.14112944  0.10675382  0.91768486  0.59021038  0.47102867\n",
      " -0.09777825  0.37054792  0.29945101 -0.37536248  0.6255896   0.29639561\n",
      "  0.55659337  0.0443234   0.65035122  0.15333217  0.19942662  0.66362121\n",
      "  0.51447555  0.50778659  0.52227153  0.89914997 -0.83907107 -0.78958007]\n",
      "epoch 28\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006546248613906385 R2: 0.9613997027070459 time: 1703173245.1178844\n",
      "batch_idx: 1 loss: 0.0004538794434314767 R2: 0.9614271583544568 time: 1703173253.2470224\n",
      "Training [28%] Loss: 0.0005542521524110576 time: 1703173253.2470224\n",
      "weight: [ 0.98795426  0.14153845  0.10677491  0.91700034  0.58929054  0.47222688\n",
      " -0.09873061  0.3667342   0.30003281 -0.37516555  0.62836523  0.29495966\n",
      "  0.55582226  0.0436135   0.65111769  0.15312331  0.19973642  0.66393133\n",
      "  0.51284925  0.50655128  0.52208167  0.89898729 -0.8395649  -0.78867597]\n",
      "epoch 29\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006537463474414245 R2: 0.9614496728260107 time: 1703173260.979716\n",
      "batch_idx: 1 loss: 0.00045330271752922304 R2: 0.9614769827517475 time: 1703173268.7986398\n",
      "Training [29%] Loss: 0.0005535245324853237 time: 1703173268.7986398\n",
      "weight: [ 0.98823257  0.14194303  0.10679001  0.91632084  0.58837666  0.47342032\n",
      " -0.0996791   0.36290784  0.30065426 -0.374965    0.63115437  0.29351695\n",
      "  0.55505747  0.04291096  0.65187897  0.15292058  0.20004881  0.66424367\n",
      "  0.51122553  0.50531568  0.52188918  0.89882325 -0.84006559 -0.78776791]\n",
      "epoch 30\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006528745721926356 R2: 0.9614992809474139 time: 1703173276.598517\n",
      "batch_idx: 1 loss: 0.00045273000963619954 R2: 0.9615264452803276 time: 1703173284.4295661\n",
      "Training [30%] Loss: 0.0005528022909144176 time: 1703173284.4295661\n",
      "weight: [ 0.98851092  0.14234306  0.10679903  0.91564633  0.58746871  0.47460898\n",
      " -0.10062351  0.35906969  0.30131476 -0.37476093  0.63395692  0.29206745\n",
      "  0.55429897  0.04221564  0.65263511  0.1527239   0.20036384  0.66455829\n",
      "  0.50960446  0.5040799   0.52169407  0.89865792 -0.84057288 -0.78685622]\n",
      "epoch 31\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006520094882155664 R2: 0.9615485281286269 time: 1703173292.259407\n",
      "batch_idx: 1 loss: 0.0004521613296126661 R2: 0.9615755469988165 time: 1703173300.3390815\n",
      "Training [31%] Loss: 0.0005520854089141162 time: 1703173300.3390815\n",
      "weight: [ 0.98878932  0.14273844  0.10680186  0.91497677  0.58656667  0.47579284\n",
      " -0.10156362  0.35522061  0.30201366 -0.37455344  0.63677276  0.29061113\n",
      "  0.55354675  0.04152741  0.65338616  0.1525332   0.20068157  0.66487525\n",
      "  0.50798616  0.50284399  0.52149633  0.89849136 -0.84108653 -0.78594119]\n",
      "epoch 32\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006511510500084053 R2: 0.961597415412726 time: 1703173308.1090648\n",
      "batch_idx: 1 loss: 0.00045159668599573083 R2: 0.9616242889537003 time: 1703173315.9926436\n",
      "Training [32%] Loss: 0.0005513738680020681 time: 1703173315.9926436\n",
      "weight: [ 0.98906775  0.14312906  0.10679842  0.91431215  0.58567051  0.47697189\n",
      " -0.10249923  0.35136147  0.30275031 -0.37434265  0.63960179  0.28914795\n",
      "  0.55280078  0.04084614  0.65413216  0.15234838  0.20100205  0.6651946\n",
      "  0.50637071  0.50160803  0.52129597  0.89832363 -0.84160631 -0.78502313]\n",
      "epoch 33\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006502992138766691 R2: 0.961645943832522 time: 1703173323.7549558\n",
      "batch_idx: 1 loss: 0.0004510360860120007 R2: 0.9616726721832756 time: 1703173331.7269998\n",
      "Training [33%] Loss: 0.0005506676499443349 time: 1703173331.7269998\n",
      "weight: [ 0.98934621  0.14351481  0.10678861  0.91365243  0.58478021  0.47814612\n",
      " -0.10343014  0.3474932   0.30352395 -0.37412867  0.64244388  0.28767788\n",
      "  0.55206107  0.04017169  0.65487318  0.15216939  0.20132533  0.6655164\n",
      "  0.5047582   0.50037208  0.52109299  0.89815478 -0.84213195 -0.78410234]\n",
      "epoch 34\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006494539378126627 R2: 0.9616941144145137 time: 1703173339.6054103\n",
      "batch_idx: 1 loss: 0.0004504795355909739 R2: 0.9617206977215454 time: 1703173347.4209208\n",
      "Training [34%] Loss: 0.0005499667367018183 time: 1703173347.4209208\n",
      "weight: [ 0.9896247   0.14389559  0.10677234  0.91299758  0.58389573  0.47931553\n",
      " -0.10435614  0.3436167   0.30433385 -0.3739116   0.6452989   0.28620087\n",
      "  0.55132759  0.03950394  0.65560925  0.15199612  0.20165146  0.6658407\n",
      "  0.50314876  0.49913623  0.52088739  0.89798487 -0.84266322 -0.78317911]\n",
      "epoch 35\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006486151813743271 R2: 0.9617419281827939 time: 1703173355.2508006\n",
      "batch_idx: 1 loss: 0.0004499270393791523 R2: 0.9617683666020296 time: 1703173362.8773549\n",
      "Training [35%] Loss: 0.0005492711103767397 time: 1703173362.8773549\n",
      "weight: [ 0.9899032   0.14427128  0.10674951  0.91234757  0.58301703  0.48048011\n",
      " -0.10527707  0.33973291  0.30517917 -0.37369155  0.64816674  0.28471686\n",
      "  0.55060034  0.03884276  0.65634044  0.15182851  0.20198048  0.66616755\n",
      "  0.50154246  0.49790053  0.52067916  0.89781395 -0.84319986 -0.78225374]\n",
      "epoch 36\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006477829055638608 R2: 0.9617893861628393 time: 1703173370.7395406\n",
      "batch_idx: 1 loss: 0.0004493786007546003 R2: 0.9618156798615024 time: 1703173378.642711\n",
      "Training [36%] Loss: 0.0005485807531592306 time: 1703173378.642711\n",
      "weight: [ 0.99018172  0.14464179  0.10672004  0.91170237  0.58214409  0.48163986\n",
      " -0.10619272  0.3358428   0.30605908 -0.37346863  0.65104726  0.28322582\n",
      "  0.54987932  0.03818801  0.65706679  0.15166648  0.20231243  0.66649698\n",
      "  0.49993943  0.49666505  0.52046829  0.8976421  -0.84374161 -0.78132651]\n",
      "epoch 37\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006469570727063903 R2: 0.96183648938526 time: 1703173386.3079844\n",
      "batch_idx: 1 loss: 0.0004488342218419183 R2: 0.9618626385436689 time: 1703173394.7117696\n",
      "Training [37%] Loss: 0.0005478956472741543 time: 1703173394.7117696\n",
      "weight: [ 0.99046024  0.14500701  0.10668383  0.91106195  0.58127685  0.48279479\n",
      " -0.10710294  0.33194734  0.30697269 -0.37324296  0.65394033  0.28172767\n",
      "  0.54916453  0.03753957  0.65778835  0.15150994  0.20264735  0.66682906\n",
      "  0.49833978  0.49542984  0.52025477  0.89746935 -0.84428822 -0.78039771]\n",
      "epoch 38\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006461376463290913 R2: 0.9618832388894483 time: 1703173402.535576\n",
      "batch_idx: 1 loss: 0.00044829390352741255 R2: 0.9619092437027461 time: 1703173410.4279072\n",
      "Training [38%] Loss: 0.000547215774928252 time: 1703173410.4279072\n",
      "weight: [ 0.99073876  0.14536685  0.1066408   0.91042629  0.58041528  0.48394489\n",
      " -0.10800755  0.32804752  0.30791907 -0.37301464  0.65684581  0.28022236\n",
      "  0.54845595  0.03689731  0.65850517  0.15135881  0.20298527  0.6671638\n",
      "  0.49674361  0.49419497  0.52003859  0.89729578 -0.84483943 -0.77946761]\n",
      "epoch 39\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006453245910410858 R2: 0.9619296357271552 time: 1703173418.1638994\n",
      "batch_idx: 1 loss: 0.0004477576454744647 R2: 0.9619554964069834 time: 1703173425.9936032\n",
      "Training [39%] Loss: 0.0005465411182577753 time: 1703173425.9936032\n",
      "weight: [ 0.99101727  0.14572119  0.10659086  0.90979537  0.57955933  0.48509018\n",
      " -0.10890641  0.32414435  0.30889725 -0.37278377  0.65976357  0.27870983\n",
      "  0.54775361  0.0362611   0.6592173   0.15121301  0.20332623  0.66750126\n",
      "  0.49515103  0.49296049  0.51981973  0.89712143 -0.84539498 -0.7785365 ]\n",
      "epoch 40\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000644517872414424 R2: 0.9619756809659854 time: 1703173433.7644126\n",
      "batch_idx: 1 loss: 0.00044722544613889925 R2: 0.9620013977420883 time: 1703173441.8390298\n",
      "Training [40%] Loss: 0.0005458716592766615 time: 1703173441.8390298\n",
      "weight: [ 0.99129576  0.14606995  0.10653393  0.90916914  0.57870896  0.48623066\n",
      " -0.10979934  0.32023886  0.30990623 -0.37255048  0.66269347  0.27719\n",
      "  0.5470575   0.03563083  0.65992479  0.15107245  0.20367026  0.66784145\n",
      "  0.49356217  0.49172647  0.51959816  0.89694636 -0.84595461 -0.77760465]\n",
      "epoch 41\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006437174568665555 R2: 0.9620213756927989 time: 1703173449.833134\n",
      "batch_idx: 1 loss: 0.00044669730278432433 R2: 0.9620469488145786 time: 1703173457.6165876\n",
      "Training [41%] Loss: 0.0005452073798254399 time: 1703173457.6165876\n",
      "weight: [ 0.99157422  0.14641302  0.10646993  0.90854759  0.57786412  0.48736634\n",
      " -0.11068622  0.31633211  0.31094497 -0.37231487  0.66563536  0.27566281\n",
      "  0.54636762  0.03500636  0.66062768  0.15093706  0.20401738  0.66818443\n",
      "  0.49197713  0.49049294  0.51937388  0.89677062 -0.84651807 -0.77667232]\n",
      "epoch 42\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006429233115444626 R2: 0.9620667210170197 time: 1703173466.0457983\n",
      "batch_idx: 1 loss: 0.00044617321149739865 R2: 0.9620921507550262 time: 1703173474.167096\n",
      "Training [42%] Loss: 0.0005445482615209306 time: 1703173474.167096\n",
      "weight: [ 0.99185264  0.14675031  0.10639877  0.90793069  0.57702477  0.48849725\n",
      " -0.1115669   0.31242515  0.31201239 -0.37207704  0.66858909  0.27412818\n",
      "  0.545684    0.03438759  0.66132603  0.15080674  0.20436761  0.6685302\n",
      "  0.49039605  0.48925997  0.51914685  0.89659427 -0.8470851  -0.7757398 ]\n",
      "epoch 43\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006421354042108953 R2: 0.9621117180738705 time: 1703173481.8573992\n",
      "batch_idx: 1 loss: 0.0004456531672028946 R2: 0.9621370047212352 time: 1703173489.7834396\n",
      "Training [43%] Loss: 0.0005438942857068949 time: 1703173489.7834396\n",
      "weight: [ 0.99213101  0.14708172  0.10632037  0.90731842  0.57619084  0.48962339\n",
      " -0.11244125  0.30851906  0.3131074  -0.37183712  0.67155453  0.27258603\n",
      "  0.54500665  0.03377438  0.66201988  0.15068141  0.20472099  0.66887881\n",
      "  0.48881903  0.48802761  0.51891705  0.89641737 -0.84765544 -0.77480733]\n",
      "epoch 44\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006413537031328992 R2: 0.9621563680274858 time: 1703173497.7236989\n",
      "batch_idx: 1 loss: 0.000445137163678571 R2: 0.9621815119012964 time: 1703173505.601394\n",
      "Training [44%] Loss: 0.0005432454334057351 time: 1703173505.601394\n",
      "weight: [ 0.99240933  0.14740716  0.10623467  0.90671075  0.5753623   0.49074478\n",
      " -0.11330914  0.30461496  0.31422883 -0.3715952   0.67453152  0.27103629\n",
      "  0.54433557  0.03316663  0.66270929  0.15056098  0.20507752  0.66923027\n",
      "  0.48724621  0.4867959   0.51868446  0.89623996 -0.84822883 -0.77387518]\n",
      "epoch 45\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000640578176972997 R2: 0.96220067207394 time: 1703173513.399723\n",
      "batch_idx: 1 loss: 0.000444625193569769 R2: 0.9622256735165606 time: 1703173521.09481\n",
      "Training [45%] Loss: 0.000542601685271383 time: 1703173521.09481\n",
      "weight: [ 0.99268758  0.14772654  0.10614158  0.90610767  0.57453909  0.49186143\n",
      " -0.11417047  0.30071394  0.31537553 -0.37135139  0.67751992  0.26947886\n",
      "  0.5436708   0.03256421  0.66339429  0.15044536  0.20543723  0.66958461\n",
      "  0.4856777   0.48556489  0.51844904  0.8960621  -0.84880501 -0.77294361]\n",
      "epoch 46\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006398087946831714 R2: 0.9622446314441644 time: 1703173528.9540696\n",
      "batch_idx: 1 loss: 0.0004441172484037518 R2: 0.9622694908244961 time: 1703173536.8288512\n",
      "Training [46%] Loss: 0.0005419630215434616 time: 1703173536.8288512\n",
      "weight: [ 0.99296574  0.14803976  0.10604102  0.90550913  0.57372115  0.49297338\n",
      " -0.11502512  0.29681715  0.31654628 -0.3711058   0.68051956  0.26791366\n",
      "  0.54301234  0.03196701  0.66407493  0.15033445  0.20580013  0.66994185\n",
      "  0.48411364  0.48433464  0.51821076  0.89588385 -0.84938373 -0.77201287]\n",
      "epoch 47\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006390455254020221 R2: 0.9622882474067607 time: 1703173544.472253\n",
      "batch_idx: 1 loss: 0.00044361331860367397 R2: 0.9623129651214442 time: 1703173552.3513312\n",
      "Training [47%] Loss: 0.000541329422002848 time: 1703173552.3513312\n",
      "weight: [ 0.99324381  0.14834674  0.10593293  0.90491513  0.57290845  0.49408064\n",
      " -0.11587298  0.29292573  0.31773985 -0.37085854  0.68353031  0.2663406\n",
      "  0.54236024  0.03137491  0.66475127  0.15022817  0.20616624  0.67030201\n",
      "  0.48255414  0.48310517  0.51796959  0.89570525 -0.84996474 -0.77108322]\n",
      "epoch 48\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006382883383552163 R2: 0.962331521270696 time: 1703173560.2284372\n",
      "batch_idx: 1 loss: 0.0004431133935022689 R2: 0.9623560977452568 time: 1703173568.1058555\n",
      "Training [48%] Loss: 0.0005407008659287426 time: 1703173568.1058555\n",
      "weight: [ 0.99352177  0.14864739  0.10581724  0.90432565  0.57210091  0.49518324\n",
      " -0.11671396  0.28904084  0.31895498 -0.37060972  0.686552    0.26475959\n",
      "  0.5417145   0.03078781  0.66542334  0.15012642  0.20653557  0.6706651\n",
      "  0.48099934  0.48187654  0.5177255   0.89552635 -0.85054778 -0.77015488]\n",
      "epoch 49\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006375372027595193 R2: 0.9623744543878872 time: 1703173575.9514961\n",
      "batch_idx: 1 loss: 0.00044261746135516985 R2: 0.9623988900778192 time: 1703173583.6927824\n",
      "Training [49%] Loss: 0.0005400773320573446 time: 1703173583.6927824\n",
      "weight: [ 0.99379962  0.14894162  0.10569388  0.90374065  0.5712985   0.4962812\n",
      " -0.11754798  0.28516367  0.32019038 -0.37035943  0.68958449  0.26317053\n",
      "  0.54107517  0.0302056   0.66609119  0.1500291   0.20690813  0.67103115\n",
      "  0.47944936  0.48064879  0.51747845  0.89534721 -0.85113261 -0.76922812]\n",
      "epoch 50\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00063679208773054 R2: 0.9624170481556604 time: 1703173591.4604266\n",
      "batch_idx: 1 loss: 0.0004421255093538871 R2: 0.9624413435474569 time: 1703173599.2393532\n",
      "Training [50%] Loss: 0.0005394587985422135 time: 1703173599.2393532\n",
      "weight: [ 0.99407733  0.14922936  0.10556279  0.90316013  0.57050114  0.49737455\n",
      " -0.11837494  0.28129541  0.32144473 -0.37010779  0.69262762  0.26157333\n",
      "  0.54044228  0.02962816  0.66675486  0.14993612  0.20728393  0.67140016\n",
      "  0.47790434  0.47942195  0.5172284   0.89516788 -0.85171897 -0.76830316]\n",
      "epoch 51\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006360529621943868 R2: 0.962459304019094 time: 1703173607.259767\n",
      "batch_idx: 1 loss: 0.000441637523638491 R2: 0.9624834596312084 time: 1703173615.2463555\n",
      "Training [51%] Loss: 0.000538845242916439 time: 1703173615.2463555\n",
      "weight: [ 0.99435489  0.14951051  0.10542389  0.90258406  0.5697088   0.49846332\n",
      " -0.11919477  0.27743726  0.32271668 -0.36985489  0.69568123  0.25996789\n",
      "  0.53981585  0.0290554   0.6674144   0.14984737  0.20766297  0.67177214\n",
      "  0.4763644   0.47819608  0.51697533  0.8949884  -0.85230663 -0.76738024]\n",
      "epoch 52\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006353197948033567 R2: 0.9625012234732282 time: 1703173623.2182882\n",
      "batch_idx: 1 loss: 0.00044115348930995075 R2: 0.9625252398569801 time: 1703173631.047226\n",
      "Training [52%] Loss: 0.0005382366420566537 time: 1703173631.047226\n",
      "weight: [ 0.99463229  0.149785    0.10527713  0.90201242  0.56892141  0.49954754\n",
      " -0.12000741  0.27359046  0.32400488 -0.36960085  0.69874517  0.2583541\n",
      "  0.53919594  0.0284872   0.66806986  0.14976275  0.20804526  0.67214712\n",
      "  0.47482967  0.47697121  0.51671918  0.89480882 -0.85289533 -0.7664596 ]\n",
      "epoch 53\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006345925538558205 R2: 0.962542808065151 time: 1703173638.7545352\n",
      "batch_idx: 1 loss: 0.0004406733904422378 R2: 0.9625666858055666 time: 1703173646.6803176\n",
      "Training [53%] Loss: 0.0005376329721490292 time: 1703173646.6803176\n",
      "weight: [ 0.99490951  0.15005275  0.10512245  0.9014452   0.56813893  0.50062723\n",
      " -0.12081279  0.26975622  0.32530794 -0.36934575  0.70181929  0.25673187\n",
      "  0.53858258  0.02792347  0.66872128  0.14968215  0.20843082  0.6725251\n",
      "  0.4733003   0.47574737  0.51645992  0.89462919 -0.85348485 -0.76554146]\n",
      "epoch 54\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006338712072203665 R2: 0.9625840593959445 time: 1703173654.4481502\n",
      "batch_idx: 1 loss: 0.00044019721009411455 R2: 0.9626077991125375 time: 1703173662.2473404\n",
      "Training [54%] Loss: 0.0005370342086572405 time: 1703173662.2473404\n",
      "weight: [ 0.99518654  0.15031369  0.10495979  0.90088238  0.56736129  0.50170244\n",
      " -0.12161085  0.26593581  0.32662445 -0.36908971  0.70490343  0.25510109\n",
      "  0.53797582  0.02736409  0.66936869  0.14960548  0.20881963  0.67290608\n",
      "  0.4717764   0.47452461  0.51619752  0.89444956 -0.85407494 -0.76462603]\n",
      "epoch 55\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006331557222642966 R2: 0.962624979122509 time: 1703173670.2021637\n",
      "batch_idx: 1 loss: 0.00043972493032081025 R2: 0.9626485814699877 time: 1703173678.0173635\n",
      "Training [55%] Loss: 0.0005364403262925534 time: 1703173678.0173635\n",
      "weight: [ 0.99546337  0.15056774  0.10478911  0.90032394  0.56658844  0.50277319\n",
      " -0.12240155  0.26213049  0.32795298 -0.36883282  0.70799743  0.25346165\n",
      "  0.5373757   0.02680898  0.67001215  0.14953263  0.2092117   0.67329008\n",
      "  0.47025811  0.47330296  0.51593193  0.89426996 -0.85466536 -0.76371355]\n",
      "epoch 56\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000632446065786587 R2: 0.962665568959227 time: 1703173685.8850787\n",
      "batch_idx: 1 loss: 0.00043925653218546536 R2: 0.9626890346281514 time: 1703173693.7734818\n",
      "Training [56%] Loss: 0.0005358512989860262 time: 1703173693.7734818\n",
      "weight: [ 0.99573996  0.15081483  0.10461033  0.89976986  0.56582033  0.50383951\n",
      " -0.12318484  0.25834151  0.3292921  -0.36857518  0.71110116  0.25181345\n",
      "  0.53678227  0.02625804  0.67065169  0.14946347  0.20960704  0.6736771\n",
      "  0.46874558  0.47208246  0.5156631   0.89409046 -0.8552559  -0.76280422]\n",
      "epoch 57\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006317422039552678 R2: 0.9627058306795131 time: 1703173701.6035006\n",
      "batch_idx: 1 loss: 0.00043879199577048593 R2: 0.9627291603968711 time: 1703173709.325616\n",
      "Training [57%] Loss: 0.0005352670998628769 time: 1703173709.325616\n",
      "weight: [ 0.99601632  0.15105488  0.10442343  0.89922014  0.5650569   0.50490145\n",
      " -0.12396068  0.25457018  0.33064033 -0.36831689  0.71421444  0.25015638\n",
      "  0.53619559  0.02571116  0.67128736  0.14939792  0.21000564  0.67406716\n",
      "  0.46723892  0.47086314  0.51539101  0.89391108 -0.85584632 -0.76189825]\n",
      "epoch 58\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006310441022493686 R2: 0.9627457661172023 time: 1703173717.1708827\n",
      "batch_idx: 1 loss: 0.0004383313001888457 R2: 0.9627689606469267 time: 1703173725.254077\n",
      "Training [58%] Loss: 0.0005346877012191071 time: 1703173725.254077\n",
      "weight: [ 0.99629241  0.15128784  0.10422834  0.89867476  0.56429811  0.50595903\n",
      " -0.12472905  0.25081778  0.3319962  -0.36805805  0.71733714  0.24849033\n",
      "  0.53561572  0.02516826  0.6719192   0.14933584  0.21040751  0.67446025\n",
      "  0.46573827  0.46964504  0.5151156   0.89373188 -0.8564364  -0.76099585]\n",
      "epoch 59\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006303517254053251 R2: 0.9627853771678095 time: 1703173733.1623068\n",
      "batch_idx: 1 loss: 0.0004378744235953719 R2: 0.9628084373112242 time: 1703173740.9212098\n",
      "Training [59%] Loss: 0.0005341130745003485 time: 1703173740.9212098\n",
      "weight: [ 0.99656823  0.15151364  0.10402503  0.89813371  0.56354389  0.50701231\n",
      " -0.12548992  0.24708561  0.33335823 -0.36779875  0.7204691   0.24681518\n",
      "  0.53504271  0.02462924  0.67254724  0.14927713  0.21081264  0.67485638\n",
      "  0.46424378  0.4684282   0.51483684  0.8935529  -0.85702592 -0.76009722]\n",
      "epoch 60\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006296650373679555 R2: 0.9628246657896262 time: 1703173748.7774587\n",
      "batch_idx: 1 loss: 0.00043742134319808216 R2: 0.9628475923858252 time: 1703173756.701052\n",
      "Training [60%] Loss: 0.0005335431902830188 time: 1703173756.701052\n",
      "weight: [ 0.99684376  0.15173222  0.10381345  0.89759696  0.56279419  0.5080613\n",
      " -0.12624328  0.24337498  0.33472491 -0.36753909  0.72361017  0.24513084\n",
      "  0.53447663  0.024094    0.67317153  0.14922168  0.21122104  0.67525555\n",
      "  0.46275556  0.46721264  0.51455468  0.89337417 -0.85761466 -0.75920256]\n",
      "epoch 61\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006289840012458877 R2: 0.9628636340046957 time: 1703173764.4992836\n",
      "batch_idx: 1 loss: 0.0004369720352696401 R2: 0.9628864279308516 time: 1703173772.4115794\n",
      "Training [61%] Loss: 0.0005329780182577639 time: 1703173772.4115794\n",
      "weight: [ 0.99711897  0.15194351  0.10359356  0.89706452  0.56204896  0.50910605\n",
      " -0.12698911  0.23968722  0.33609472 -0.36727916  0.72676021  0.24343718\n",
      "  0.53391753  0.02356247  0.67379211  0.14916936  0.21163269  0.67565777\n",
      "  0.46127376  0.4659984   0.51426908  0.89319574 -0.85820242 -0.75831205]\n",
      "epoch 62\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006283085792715104 R2: 0.9629022838996162 time: 1703173780.2091136\n",
      "batch_idx: 1 loss: 0.00043652647515895327 R2: 0.9629249460712217 time: 1703173788.1344223\n",
      "Training [62%] Loss: 0.0005324175272152318 time: 1703173788.1344223\n",
      "weight: [ 0.99739385  0.15214745  0.10336534  0.89653637  0.56130815  0.51014661\n",
      " -0.12772741  0.23602364  0.33746615 -0.36701905  0.72991906  0.2417341\n",
      "  0.5333655   0.02303455  0.67440902  0.14912006  0.2120476   0.67606304\n",
      "  0.45979851  0.46478552  0.51397999  0.89301765 -0.85878899 -0.75742588]\n",
      "epoch 63\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006276387327652711 R2: 0.9629406176262207 time: 1703173795.9967175\n",
      "batch_idx: 1 loss: 0.0004360846373030456 R2: 0.9629631489972545 time: 1703173804.1586602\n",
      "Training [63%] Loss: 0.0005318616850341583 time: 1703173804.1586602\n",
      "weight: [ 0.99766838  0.152344    0.10312873  0.89601251  0.56057171  0.511183\n",
      " -0.12845818  0.23238557  0.33883767 -0.36675886  0.73308659  0.24002147\n",
      "  0.5328206   0.02251016  0.67502229  0.14907366  0.21246576  0.67647137\n",
      "  0.45832994  0.46357402  0.51368738  0.89283993 -0.85937417 -0.75654424]\n",
      "epoch 64\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000626974422104442 R2: 0.962978637402091 time: 1703173812.258102\n",
      "batch_idx: 1 loss: 0.0004356464952391879 R2: 0.9630010389651218 time: 1703173820.119363\n",
      "Training [64%] Loss: 0.000531310458671815 time: 1703173820.119363\n",
      "weight: [ 0.99794254  0.15253311  0.10288372  0.89549291  0.55983958  0.51221527\n",
      " -0.12918143  0.22877436  0.34020774 -0.36649867  0.73626266  0.2382992\n",
      "  0.53228291  0.0219892   0.67563197  0.14903005  0.21288718  0.67688275\n",
      "  0.45686819  0.46236394  0.5133912   0.89266263 -0.85995775 -0.75566729]\n",
      "epoch 65\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006263156066960484 R2: 0.9630163455109397 time: 1703173827.9296176\n",
      "batch_idx: 1 loss: 0.00043521202161739476 R2: 0.9630386182971454 time: 1703173835.5661886\n",
      "Training [65%] Loss: 0.0005307638141567216 time: 1703173835.5661886\n",
      "weight: [ 0.99821632  0.15271471  0.10263028  0.89497758  0.55911171  0.51324347\n",
      " -0.12989717  0.22519133  0.34157482 -0.36623857  0.73944711  0.23656716\n",
      "  0.5317525   0.0214716   0.67623808  0.14898909  0.21331184  0.67729719\n",
      "  0.45541338  0.46115532  0.51309141  0.89248577 -0.86053954 -0.75479521]\n",
      "epoch 66\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006256622449541201 R2: 0.9630537443028333 time: 1703173843.5180302\n",
      "batch_idx: 1 loss: 0.000434781188213363 R2: 0.9630758893819646 time: 1703173851.4599833\n",
      "Training [66%] Loss: 0.0005302217165837416 time: 1703173851.4599833\n",
      "weight: [ 0.99848968  0.15288878  0.10236838  0.89446651  0.55838806  0.51426762\n",
      " -0.13060542  0.22163782  0.34293738 -0.36597866  0.74263981  0.23482524\n",
      "  0.53122945  0.02095728  0.67684068  0.14895068  0.21373975  0.6777147\n",
      "  0.45396566  0.45994817  0.51278797  0.89230941 -0.86111936 -0.75392817]\n",
      "epoch 67\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006250142942809813 R2: 0.9630908361942832 time: 1703173859.258315\n",
      "batch_idx: 1 loss: 0.0004343539659418637 R2: 0.9631128546745458 time: 1703173866.9940789\n",
      "Training [67%] Loss: 0.0005296841301114225 time: 1703173866.9940789\n",
      "weight: [ 0.99876261  0.15305525  0.10209799  0.89395969  0.55766857  0.51528778\n",
      " -0.1313062   0.21811518  0.34429386 -0.36571901  0.74584064  0.23307334\n",
      "  0.53071385  0.02044615  0.6774398   0.14891469  0.2141709   0.67813526\n",
      "  0.45252515  0.45874254  0.51248084  0.89213356 -0.86169701 -0.75306633]\n",
      "epoch 68\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006243717110525542 R2: 0.9631276236681809 time: 1703173874.8084426\n",
      "batch_idx: 1 loss: 0.00043393032487069937 R2: 0.9631495166960496 time: 1703173882.6092236\n",
      "Training [68%] Loss: 0.0005291510179616268 time: 1703173882.6092236\n",
      "weight: [ 0.99903509  0.1532141   0.10181911  0.89345712  0.55695319  0.51630398\n",
      " -0.13199955  0.21462475  0.34564272 -0.36545971  0.74904944  0.23131133\n",
      "  0.53020579  0.01993814  0.67803547  0.148881    0.21460528  0.67855889\n",
      "  0.45109198  0.45753845  0.51216996  0.89195826 -0.86227233 -0.75220984]\n",
      "epoch 69\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006237344506076121 R2: 0.9631641092735983 time: 1703173890.4873292\n",
      "batch_idx: 1 loss: 0.0004335102342352501 R2: 0.9631858780335636 time: 1703173898.3196929\n",
      "Training [69%] Loss: 0.0005286223424214311 time: 1703173898.3196929\n",
      "weight: [ 0.99930711  0.15336528  0.10153171  0.89295878  0.55624188  0.51731626\n",
      " -0.13268551  0.21116787  0.34698243 -0.36520086  0.7522661   0.22953911\n",
      "  0.52970536  0.01943317  0.67862773  0.14884949  0.2150429   0.67898558\n",
      "  0.44966629  0.45633594  0.51185531  0.89178355 -0.86284513 -0.75135884]\n",
      "epoch 70\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006231024672407164 R2: 0.9632002956254417 time: 1703173906.178976\n",
      "batch_idx: 1 loss: 0.0004330936624536919 R2: 0.9632219413396849 time: 1703173914.065528\n",
      "Training [70%] Loss: 0.0005280980648472042 time: 1703173914.065528\n",
      "weight: [ 0.99957863  0.15350876  0.10123579  0.89246469  0.55553459  0.51832468\n",
      " -0.1333641   0.20774587  0.34831144 -0.36494252  0.75549048  0.22775656\n",
      "  0.52921265  0.01893115  0.67921661  0.14882004  0.21548374  0.67941535\n",
      "  0.44824821  0.45513504  0.51153683  0.89160946 -0.86341524 -0.7505135 ]\n",
      "epoch 71\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006224757141988793 R2: 0.9632361854039788 time: 1703173921.8573627\n",
      "batch_idx: 1 loss: 0.00043268057714291057 R2: 0.9632577093319673 time: 1703173929.8917196\n",
      "Training [71%] Loss: 0.000527578145670895 time: 1703173929.8917196\n",
      "weight: [ 0.99984964  0.15364451  0.10093132  0.89197483  0.55483127  0.51932927\n",
      " -0.1340354   0.20436009  0.34962823 -0.36468478  0.75872246  0.22596358\n",
      "  0.52872776  0.01843203  0.67980216  0.14879253  0.2159278   0.67984818\n",
      "  0.44683786  0.45393577  0.51121449  0.89143602 -0.8639825  -0.74967394]\n",
      "epoch 72\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006218541436816956 R2: 0.963271781354208 time: 1703173937.6688566\n",
      "batch_idx: 1 loss: 0.00043227094513518415 R2: 0.9632931847922415 time: 1703173945.7490015\n",
      "Training [72%] Loss: 0.0005270625444084399 time: 1703173945.7490015\n",
      "weight: [ 1.00012011  0.1537725   0.10061832  0.8914892   0.55413187  0.52033007\n",
      " -0.13469944  0.20101184  0.35093127 -0.36442772  0.76196191  0.22416006\n",
      "  0.52825079  0.01793572  0.6803844   0.14876684  0.21637509  0.68028408\n",
      "  0.44543537  0.45273817  0.51088825  0.89126325 -0.86454674 -0.7488403 ]\n",
      "epoch 73\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006212377068448568 R2: 0.9633070862851104 time: 1703173953.5703201\n",
      "batch_idx: 1 loss: 0.00043186473249566537 R2: 0.9633283705657826 time: 1703173961.6582541\n",
      "Training [73%] Loss: 0.000526551219670261 time: 1703173961.6582541\n",
      "weight: [ 1.00039003  0.1538927   0.10029677  0.8910078   0.55343634  0.52132713\n",
      " -0.13535628  0.19770246  0.35221905 -0.36417143  0.76520871  0.22234587\n",
      "  0.52778184  0.01744215  0.68096337  0.14874286  0.21682559  0.68072306\n",
      "  0.44404088  0.45154226  0.51055807  0.89109119 -0.86510781 -0.7480127 ]\n",
      "epoch 74\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006206263538068875 R2: 0.9633421030687754 time: 1703173969.438178\n",
      "batch_idx: 1 loss: 0.00043146190454070683 R2: 0.9633632695603728 time: 1703173977.1736956\n",
      "Training [74%] Loss: 0.0005260441291737971 time: 1703173977.1736956\n",
      "weight: [ 1.00065937  0.1540051   0.09996668  0.89053063  0.55274465  0.52232049\n",
      " -0.136006    0.19443325  0.35349006 -0.36391597  0.76846275  0.22052093\n",
      "  0.52732102  0.01695125  0.6815391   0.14872048  0.21727931  0.68116511\n",
      "  0.4426545   0.45034808  0.5102239   0.89091986 -0.86566556 -0.74719128]\n",
      "epoch 75\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000620020033658973 R2: 0.9633768346393742 time: 1703173985.0270336\n",
      "batch_idx: 1 loss: 0.0004310624258570827 R2: 0.9633978847452156 time: 1703173993.105934\n",
      "Training [75%] Loss: 0.0005255412297580278 time: 1703173993.105934\n",
      "weight: [ 1.00092811  0.15410968  0.09962804  0.89005769  0.55205674  0.52331019\n",
      " -0.13664866  0.19120551  0.35474282 -0.36366143  0.77172391  0.21868512\n",
      "  0.52686844  0.01646296  0.68211163  0.14869957  0.21773623  0.68161023\n",
      "  0.44127637  0.44915566  0.50988571  0.89074929 -0.86621984 -0.74637615]\n",
      "epoch 76\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006194186944776983 R2: 0.9634112839920379 time: 1703174001.2944453\n",
      "batch_idx: 1 loss: 0.0004306662603220766 R2: 0.9634322191497404 time: 1703174009.1974144\n",
      "Training [76%] Loss: 0.0005250424773998875 time: 1703174009.1974144\n",
      "weight: [ 1.00119624  0.15420642  0.09928087  0.88958899  0.55137258  0.52429628\n",
      " -0.13728434  0.18802054  0.35597584 -0.36340788  0.77499208  0.21683832\n",
      "  0.52642422  0.01597719  0.682681    0.14868002  0.21819637  0.68205844\n",
      "  0.43990661  0.44796501  0.50954346  0.89057951 -0.86677051 -0.74556741]\n",
      "epoch 77\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006188222833405784 R2: 0.9634454541815931 time: 1703174017.0965436\n",
      "batch_idx: 1 loss: 0.0004302733711245842 R2: 0.9634662758622767 time: 1703174024.943117\n",
      "Training [77%] Loss: 0.0005245478272325813 time: 1703174024.943117\n",
      "weight: [ 1.00146372  0.1542953   0.09892518  0.88912452  0.55069211  0.5252788\n",
      " -0.13791312  0.18487961  0.35718767 -0.36315539  0.77826715  0.21498045\n",
      "  0.52598846  0.0154939   0.68324723  0.14866174  0.2186597   0.68250972\n",
      "  0.43854535  0.44677617  0.5091971   0.89041054 -0.86731742 -0.74476518]\n",
      "epoch 78\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006182307463441602 R2: 0.9634793483211931 time: 1703174032.8355236\n",
      "batch_idx: 1 loss: 0.00042988372078706365 R2: 0.9635000580286286 time: 1703174040.7990534\n",
      "Training [78%] Loss: 0.0005240572335656119 time: 1703174040.7990534\n",
      "weight: [ 1.00173053  0.15437633  0.09856098  0.88866429  0.5500153   0.5262578\n",
      " -0.13853508  0.18178398  0.35837686 -0.36290405  0.78154902  0.2131114\n",
      "  0.5255613   0.01501301  0.68381036  0.1486446   0.21912624  0.68296409\n",
      "  0.4371927   0.44558918  0.5088466   0.8902424  -0.86786046 -0.74396956]\n",
      "epoch 79\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006176440286246469 R2: 0.9635129695808289 time: 1703174048.657224\n",
      "batch_idx: 1 loss: 0.00042949727118854226 R2: 0.9635335688505247 time: 1703174056.5691915\n",
      "Training [79%] Loss: 0.0005235706499065946 time: 1703174056.5691915\n",
      "weight: [ 1.00199666  0.15444949  0.09818829  0.8882083   0.5493421   0.52723331\n",
      " -0.13915032  0.1787349   0.359542   -0.36265391  0.78483758  0.21123106\n",
      "  0.52514286  0.01453446  0.68437041  0.14862852  0.21959599  0.68342155\n",
      "  0.43584879  0.44440404  0.50849193  0.89007512 -0.86839949 -0.74318065]\n",
      "epoch 80\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006170620743807354 R2: 0.9635463211857431 time: 1703174064.6611066\n",
      "batch_idx: 1 loss: 0.00042911398358857946 R2: 0.9635668115839666 time: 1703174072.7899606\n",
      "Training [80%] Loss: 0.0005230880289846575 time: 1703174072.7899606\n",
      "weight: [ 1.00226208  0.15451479  0.09780712  0.88775656  0.54867247  0.52820538\n",
      " -0.13975893  0.1757336   0.36068168 -0.36240505  0.78813274  0.20933933\n",
      "  0.52473326  0.01405818  0.68492743  0.14861337  0.22006893  0.68388209\n",
      "  0.43451374  0.4432208   0.50813303  0.88990872 -0.86893439 -0.74239853]\n",
      "epoch 81\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006164848268986423 R2: 0.9635794064147258 time: 1703174080.6930676\n",
      "batch_idx: 1 loss: 0.0004287338186521374 R2: 0.9635997895374826 time: 1703174088.5529246\n",
      "Training [81%] Loss: 0.0005226093227753898 time: 1703174088.5529246\n",
      "weight: [ 1.00252677  0.15457223  0.09741751  0.88730907  0.54800637  0.52917406\n",
      " -0.14036101  0.17278129  0.36179452 -0.36215753  0.7914344   0.20743612\n",
      "  0.52433263  0.01358411  0.68548145  0.14859908  0.22054506  0.68434573\n",
      "  0.43318767  0.44203947  0.50776987  0.88974321 -0.86946504 -0.74162329]\n",
      "epoch 82\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006159122285790801 R2: 0.9636122285983288 time: 1703174096.3906667\n",
      "batch_idx: 1 loss: 0.0004283567364755078 R2: 0.9636325060702731 time: 1703174104.3153307\n",
      "Training [82%] Loss: 0.000522134482527294 time: 1703174104.3153307\n",
      "weight: [ 1.0027907   0.15462182  0.09701948  0.88686583  0.54734375  0.53013939\n",
      " -0.14095668  0.16987916  0.36287919 -0.36191144  0.79474247  0.20552133\n",
      "  0.52394111  0.0131122   0.68603249  0.14858555  0.2210244   0.68481247\n",
      "  0.43187069  0.44086009  0.50740243  0.88957863 -0.86999132 -0.74085501]\n",
      "epoch 83\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006153442209660353 R2: 0.9636447911169699 time: 1703174112.0534124\n",
      "batch_idx: 1 loss: 0.00042798269661311033 R2: 0.9636649645902816 time: 1703174119.899713\n",
      "Training [83%] Loss: 0.0005216634587895729 time: 1703174119.899713\n",
      "weight: [ 1.00305386  0.15466356  0.09661306  0.88642687  0.54668459  0.53110141\n",
      " -0.14154603  0.16702837  0.36393435 -0.36166683  0.79805686  0.20359486\n",
      "  0.52355884  0.01264238  0.68658058  0.14857268  0.22150694  0.6852823\n",
      "  0.43056293  0.43968267  0.50703065  0.88941498 -0.87051313 -0.74009377]\n",
      "epoch 84\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006147807447772072 R2: 0.9636770973989719 time: 1703174127.683151\n",
      "batch_idx: 1 loss: 0.0004276116581052437 R2: 0.9636971685521658 time: 1703174135.4840205\n",
      "Training [84%] Loss: 0.0005211962014412255 time: 1703174135.4840205\n",
      "weight: [ 1.00331623  0.15469747  0.09619828  0.88599217  0.54602883  0.53206016\n",
      " -0.14212919  0.16423006  0.36495871 -0.36142376  0.80137748  0.20165662\n",
      "  0.52318596  0.01217459  0.68712577  0.1485604   0.22199267  0.68575525\n",
      "  0.4292645   0.43850724  0.5066545   0.88925229 -0.87103037 -0.73933964]\n",
      "epoch 85\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006142217399359342 R2: 0.9637091509184963 time: 1703174143.356739\n",
      "batch_idx: 1 loss: 0.0004272435795067561 R2: 0.9637291214552024 time: 1703174151.1227205\n",
      "Training [85%] Loss: 0.0005207326597213451 time: 1703174151.1227205\n",
      "weight: [ 1.00357777  0.15472357  0.09577518  0.88556176  0.54537644  0.53301569\n",
      " -0.14270627  0.16148537  0.36595101 -0.36118231  0.80470427  0.19970651\n",
      "  0.52282261  0.01170878  0.68766807  0.14854862  0.22248161  0.6862313\n",
      "  0.42797552  0.43733383  0.50627395  0.88909057 -0.87154294 -0.73859267]\n",
      "epoch 86\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006136671456044516 R2: 0.9637409551934157 time: 1703174158.9536953\n",
      "batch_idx: 1 loss: 0.00042687841891650294 R2: 0.9637608268411142 time: 1703174166.8645291\n",
      "Training [86%] Loss: 0.0005202727822604773 time: 1703174166.8645291\n",
      "weight: [ 1.00383847  0.15474187  0.09534381  0.88513564  0.54472739  0.53396803\n",
      " -0.14327741  0.15879536  0.36691002 -0.36094254  0.80803713  0.19774445\n",
      "  0.52246895  0.01124489  0.68820752  0.14853728  0.22297375  0.68671047\n",
      "  0.42669609  0.43616246  0.50588895  0.88892984 -0.87205073 -0.73785294]\n",
      "epoch 87\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006131169002183267 R2: 0.9637725137831236 time: 1703174174.56944\n",
      "batch_idx: 1 loss: 0.0004265161340076892 R2: 0.9637922882918246 time: 1703174182.5506973\n",
      "Training [87%] Loss: 0.000519816517113008 time: 1703174182.5506973\n",
      "weight: [ 1.00409831  0.1547524   0.0949042   0.88471382  0.54408163  0.53491724\n",
      " -0.14384272  0.15616112  0.36783455 -0.3607045   0.811376    0.19577034\n",
      "  0.52212512  0.01078287  0.68874416  0.14852629  0.22346909  0.68719275\n",
      "  0.42542633  0.43499315  0.50549948  0.88877011 -0.87255366 -0.7371205 ]\n",
      "epoch 88\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006125709415219223 R2: 0.9638038302862599 time: 1703174190.3324876\n",
      "batch_idx: 1 loss: 0.00042615668205890877 R2: 0.9638235094271698 time: 1703174198.2024224\n",
      "Training [88%] Loss: 0.0005193638117904155 time: 1703174198.2024224\n",
      "weight: [ 1.00435727  0.1547552   0.0944564   0.88429632  0.54343912  0.53586336\n",
      " -0.14440235  0.15358366  0.36872344 -0.36046826  0.8147208   0.19378411\n",
      "  0.52179128  0.01032266  0.689278    0.14851561  0.22396764  0.68767817\n",
      "  0.42416636  0.43382591  0.5051055   0.8886114  -0.87305165 -0.7363954 ]\n",
      "epoch 89\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006120292066047638 R2: 0.963834908338405 time: 1703174205.9604635\n",
      "batch_idx: 1 loss: 0.00042580001998592513 R2: 0.9638544939025444 time: 1703174213.8153026\n",
      "Training [89%] Loss: 0.0005189146132953445 time: 1703174213.8153026\n",
      "weight: [ 1.00461532  0.15475028  0.09400047  0.88388314  0.54279983  0.53680642\n",
      " -0.14495642  0.15106399  0.36957558 -0.36023387  0.81807146  0.19178566\n",
      "  0.5214676   0.00986421  0.68980908  0.14850516  0.22446941  0.68816672\n",
      "  0.42291626  0.43266078  0.50470696  0.88845373 -0.8735446  -0.73567768]\n",
      "epoch 90\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006114916319385788 R2: 0.9638657516097002 time: 1703174221.6022441\n",
      "batch_idx: 1 loss: 0.0004254461043740449 R2: 0.9638852454064974 time: 1703174229.4462378\n",
      "Training [90%] Loss: 0.0005184688681563118 time: 1703174229.4462378\n",
      "weight: [ 1.00487245  0.1547377   0.09353645  0.88347429  0.54216373  0.53774646\n",
      " -0.14550509  0.14860309  0.37038988 -0.3600014   0.82142793  0.18977492\n",
      "  0.52115423  0.00940746  0.69033743  0.14849491  0.22497439  0.68865841\n",
      "  0.42167617  0.43149778  0.50430384  0.8882971  -0.87403245 -0.73496739]\n",
      "epoch 91\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006109581534149916 R2: 0.963896363802452 time: 1703174237.2434123\n",
      "batch_idx: 1 loss: 0.00042509489151110495 R2: 0.963915767658311 time: 1703174245.1553576\n",
      "Training [91%] Loss: 0.0005180265224630483 time: 1703174245.1553576\n",
      "weight: [ 1.00512863  0.15471748  0.0930644   0.8830698   0.54153077  0.53868354\n",
      " -0.14604849  0.14620187  0.37116531 -0.35977091  0.82479015  0.1877518\n",
      "  0.52085134  0.00895236  0.69086308  0.1484848   0.22548259  0.68915324\n",
      "  0.42044617  0.43033691  0.50389609  0.88814153 -0.87451512 -0.73426457]\n",
      "epoch 92\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006104287063836095 R2: 0.9639267486486768 time: 1703174252.9691234\n",
      "batch_idx: 1 loss: 0.00042474633742087514 R2: 0.9639460644055193 time: 1703174260.8474264\n",
      "Training [92%] Loss: 0.0005175875219022423 time: 1703174260.8474264\n",
      "weight: [ 1.00538383  0.15468967  0.09258438  0.88266968  0.54090093  0.53961769\n",
      " -0.14658677  0.14386125  0.37190089 -0.35954244  0.82815805  0.18571622\n",
      "  0.52055911  0.00849888  0.69138606  0.14847479  0.22599402  0.68965124\n",
      "  0.41922638  0.4291782   0.50348369  0.88798703 -0.87499255 -0.73356924]\n",
      "epoch 93\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006099032256904962 R2: 0.9639569099076303 time: 1703174268.747293\n",
      "batch_idx: 1 loss: 0.00042440039789693325 R2: 0.9639761394214256 time: 1703174277.0374894\n",
      "Training [93%] Loss: 0.0005171518117937147 time: 1703174277.0374894\n",
      "weight: [ 1.00563805  0.15465432  0.09209646  0.88227393  0.54027416  0.54054895\n",
      " -0.14712009  0.14158209  0.37259566 -0.35931605  0.83153158  0.1836681\n",
      "  0.52027771  0.00804694  0.69190639  0.14846486  0.22650869  0.69015239\n",
      "  0.41801689  0.42802167  0.5030666   0.88783362 -0.87546465 -0.73288144]\n",
      "epoch 94\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006093816457167525 R2: 0.9639868513633163 time: 1703174284.9024167\n",
      "batch_idx: 1 loss: 0.00042405702853680105 R2: 0.9640059965025858 time: 1703174292.8017337\n",
      "Training [94%] Loss: 0.0005167193371267768 time: 1703174292.8017337\n",
      "weight: [ 1.00589126  0.15461147  0.09160069  0.88188258  0.53965044  0.54147736\n",
      " -0.14764859  0.13936521  0.37324873 -0.35909179  0.8349107   0.18160738\n",
      "  0.52000731  0.00759652  0.69242411  0.14845499  0.2270266   0.69065672\n",
      "  0.41681781  0.42686733  0.50264479  0.88768129 -0.87593138 -0.73220119]\n",
      "epoch 95\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006088639004172094 R2: 0.9640165768219695 time: 1703174300.6005976\n",
      "batch_idx: 1 loss: 0.0004237161847763407 R2: 0.9640356394662936 time: 1703174308.354938\n",
      "Training [95%] Loss: 0.000516290042596775 time: 1703174308.354938\n",
      "weight: [ 1.00614345  0.15456118  0.09109714  0.88149564  0.53902973  0.54240297\n",
      " -0.14817245  0.1372114   0.37385926 -0.35886972  0.83829536  0.17953397\n",
      "  0.51974811  0.00714755  0.69293925  0.14844515  0.22754777  0.69116423\n",
      "  0.41562924  0.4257152   0.50221821  0.88753007 -0.87639268 -0.73152852]\n",
      "epoch 96\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006083499233590611 R2: 0.9640460901095486 time: 1703174316.263208\n",
      "batch_idx: 1 loss: 0.0004233778219242718 R2: 0.9640650721480533 time: 1703174324.4566429\n",
      "Training [96%] Loss: 0.0005158638726416665 time: 1703174324.4566429\n",
      "weight: [ 1.00639458  0.15450351  0.09058589  0.88111313  0.53841199  0.54332581\n",
      " -0.14869182  0.13512141  0.37442643 -0.35864989  0.84168551  0.17744781\n",
      "  0.51950028  0.00669999  0.69345183  0.14843534  0.22807219  0.69167493\n",
      "  0.41445127  0.42456529  0.50178683  0.88737995 -0.87684848 -0.73086344]\n",
      "epoch 97\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006078396477602714 R2: 0.964075395069211 time: 1703174332.238607\n",
      "batch_idx: 1 loss: 0.0004230418951967145 R2: 0.9640942983990607 time: 1703174339.989377\n",
      "Training [97%] Loss: 0.0005154407714784929 time: 1703174339.989377\n",
      "weight: [ 1.00664464  0.15443852  0.09006701  0.88073506  0.5377972   0.54424593\n",
      " -0.14920686  0.13309594  0.37494952 -0.35843235  0.84508111  0.17534883\n",
      "  0.51926403  0.00625381  0.69396188  0.14842555  0.22859989  0.69218883\n",
      "  0.413284    0.42341761  0.50135063  0.88723096 -0.87729875 -0.73020596]\n",
      "epoch 98\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006073330065277875 R2: 0.9641044955588074 time: 1703174347.9297106\n",
      "batch_idx: 1 loss: 0.00042270835975168124 R2: 0.9641233220836913 time: 1703174355.9559295\n",
      "Training [98%] Loss: 0.0005150206831397344 time: 1703174355.9559295\n",
      "weight: [ 1.00689362  0.15436627  0.08954057  0.88036146  0.53718531  0.54516335\n",
      " -0.14971774  0.13113567  0.37542781 -0.35821714  0.84848213  0.17323696\n",
      "  0.51903953  0.00580894  0.69446944  0.1484158   0.22913087  0.69270595\n",
      "  0.41212752  0.42227219  0.50090955  0.88708309 -0.87774343 -0.72955609]\n",
      "epoch 99\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006068299322952565 R2: 0.9641333954483862 time: 1703174363.8269615\n",
      "batch_idx: 1 loss: 0.00042237717072342166 R2: 0.9641521470770151 time: 1703174371.664351\n",
      "Training [99%] Loss: 0.000514603551509339 time: 1703174371.664351\n",
      "weight: [ 1.00714149  0.15428683  0.08900664  0.87999234  0.53657631  0.54607813\n",
      " -0.15022462  0.12924121  0.37586069 -0.35800431  0.85188854  0.17111213\n",
      "  0.518827    0.00536535  0.69497452  0.14840611  0.22966515  0.69322629\n",
      "  0.41098193  0.42112902  0.50046358  0.88693635 -0.87818248 -0.72891385]\n",
      "epoch 100\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006063303574603263 R2: 0.9641620986177196 time: 1703174379.7246952\n",
      "batch_idx: 1 loss: 0.0004220482832564913 R2: 0.9641807772623203 time: 1703174387.618767\n",
      "Training [100%] Loss: 0.0005141893203584088 time: 1703174387.618767\n",
      "weight: [ 1.00738823  0.15420027  0.08846532  0.87962772  0.53597016  0.5469903\n",
      " -0.15072769  0.12741316  0.37624755 -0.35779392  0.8553003   0.16897428\n",
      "  0.51862664  0.00492299  0.69547717  0.14839648  0.23020273  0.69374987\n",
      "  0.40984732  0.41998812  0.50001267  0.88679075 -0.87861586 -0.72827923]\n",
      "train_MSE: 0.0005158122366147476\n",
      "train_RMSE: 0.022711500096091134\n",
      "train_MAE: 0.01862744687883739\n",
      "train_MAPE: 0.041242098082472194\n",
      "train_R2: 0.9641807772623203\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs=100\n",
    "\n",
    "start_time=time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss  = []\n",
    "    total_r2  = []\n",
    "    print(f\"epoch {epoch+1}\\n-------------------------------\")\n",
    "    for it, batch_index in enumerate (chain(*[X_batches])):\n",
    "        # Update the weights by one optimizer step\n",
    "        \n",
    "        X_batch = X[batch_index]\n",
    "        Y_batch = Y[batch_index]\n",
    "        weights, _, _ = opt.step(cost, weights, X_batch, Y_batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        predictions = [QNN(weights, x) for x in X]\n",
    "        r2 = R2(Y, predictions)\n",
    "        cost_t=cost(weights,X_batch,Y_batch)\n",
    "        total_loss.append(cost_t)\n",
    "        total_r2.append(r2)\n",
    "        end_timet=time.time()\n",
    "        print(\"batch_idx:\",it,\"loss:\",cost_t,\"R2:\",r2,\"time:\",end_timet)\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    r2_list.append(sum(total_r2)/len(total_r2))\n",
    "    print('Training [{:.0f}%]'.format(100. * (epoch + 1) / n_epochs),\"Loss:\", loss_list[-1], \"time:\",end_timet)\n",
    "    print(\"weight:\",weights)\n",
    "    \n",
    "    \n",
    "predictions = [QNN(weights, x) for x in X]\n",
    "\n",
    "train_R2 = R2(Y, predictions)\n",
    "train_MSE=metrics.mean_squared_error(Y,predictions)\n",
    "train_RMSE=train_MSE**(1/2)\n",
    "train_MAE=metrics.mean_absolute_error(Y,predictions)\n",
    "train_MAPE=metrics.mean_absolute_percentage_error(Y,predictions)\n",
    "\n",
    "print(\"train_MSE:\",train_MSE)\n",
    "print(\"train_RMSE:\",train_RMSE)\n",
    "print(\"train_MAE:\",train_MAE)\n",
    "print(\"train_MAPE:\",train_MAPE)\n",
    "print(\"train_R2:\",train_R2)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "plt.title(\"MSE value against epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.plot(range(len(loss_list)), np.log(loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90deb265-6d46-4ecd-882d-03a49eb3e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=xtv_test_log\n",
    "Y_test=ytv_test_log\n",
    "test_predictions = [QNN(weights, x) for x in X_test]\n",
    "\n",
    "test_R2 = R2(Y_test, test_predictions)\n",
    "test_MSE=metrics.mean_squared_error(Y_test,test_predictions)\n",
    "test_RMSE=test_MSE**(1/2)\n",
    "test_MAE=metrics.mean_absolute_error(Y_test,test_predictions)\n",
    "test_MAPE=metrics.mean_absolute_percentage_error(Y_test,test_predictions)\n",
    "\n",
    "print(\"test_MSE:\",test_MSE)\n",
    "print(\"test_RMSE:\",test_RMSE)\n",
    "print(\"test_MAE:\",test_MAE)\n",
    "print(\"test_MAPE:\",test_MAPE)\n",
    "print(\"test_R2:\",test_R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
