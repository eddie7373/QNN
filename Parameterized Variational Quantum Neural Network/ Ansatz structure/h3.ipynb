{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586edb7a-4b3b-475e-8736-e85f04cf1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as npp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# set the random seed\n",
    "npp.random.seed(42)\n",
    "\n",
    "# create a device to execute the circuit on\n",
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "@qml.qnode(dev, diff_method=\"parameter-shift\", interface=\"autograd\")\n",
    "def circuit(params,inputs):\n",
    "    qml.RY(inputs[0], wires=0)\n",
    "    qml.RY(inputs[1], wires=1)\n",
    "    qml.RY(inputs[2], wires=2)\n",
    "    qml.RY(inputs[3], wires=3)\n",
    "    \n",
    "\n",
    "    qml.U3(params[0],params[1],params[2], wires=0)\n",
    "    qml.U3(params[3],params[4],params[5], wires=1)\n",
    "    qml.U3(params[6],params[7],params[8], wires=2)\n",
    "    qml.U3(params[9],params[10],params[11], wires=3)\n",
    "    \n",
    "\n",
    "    qml.broadcast(qml.CNOT, wires=[0, 1, 2,3], pattern=\"double\")\n",
    "    '''\n",
    "    qml.RY(inputs[0]*1.5, wires=0)\n",
    "    qml.RY(inputs[1]*1.5, wires=1)\n",
    "    qml.RY(inputs[2]*1.5, wires=2)\n",
    "    qml.RY(inputs[3]*1.5, wires=3)\n",
    "'''\n",
    "    qml.U3(params[12],params[13],params[14], wires=0)\n",
    "    qml.U3(params[15],params[16],params[17], wires=1)\n",
    "    qml.U3(params[18],params[19],params[20], wires=2)\n",
    "    qml.U3(params[21],params[22],params[23], wires=3)\n",
    "\n",
    "    qml.broadcast(qml.CNOT, wires=[0, 1, 2,3], pattern=\"double\")\n",
    "    \n",
    "    '''\n",
    "    qml.RY(inputs[0]*2, wires=0)\n",
    "    qml.RY(inputs[1]*2, wires=1)\n",
    "    qml.RY(inputs[2]*2, wires=2)\n",
    "    qml.RY(inputs[3]*2, wires=3)\n",
    "\n",
    "    qml.U3(params[24],params[25],params[26], wires=0)\n",
    "    qml.U3(params[27],params[28],params[29], wires=1)\n",
    "    qml.U3(params[30],params[31],params[32], wires=2)\n",
    "    qml.U3(params[33],params[34],params[35], wires=3)\n",
    "\n",
    "    qml.broadcast(qml.CNOT, wires=[0, 1, 2, 3], pattern=\"ring\")\n",
    "    '''\n",
    "    #return qml.expval(qml.PauliX(0) @ qml.PauliI(1)@ qml.PauliY(2)@ qml.PauliI(3))\n",
    "    return qml.expval(qml.PauliX(0) @  qml.PauliY(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a21f8a3e-a4ab-4c9d-bcf5-73c1b9429ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "def norminv(x):\n",
    "    return ((1.0/math.sqrt(2.0*math.pi)) * math.exp(-x*x*0.5))\n",
    "\n",
    "def d1(S0, K, r, T, sigma, q):\n",
    "    deno = (sigma * math.sqrt(T))\n",
    "    if (deno==0):\n",
    "        return 0\n",
    "    logReturns = math.log(S0/float(K)) if ((S0/float(K)) > 0.0) else 0.0\n",
    "    return (float(logReturns) + (float(r) - float(q) + float(sigma)*float(sigma)*0.5)*float(T)) / float(deno)\n",
    "    \n",
    "def d2(S0, K, r, T, sigma, q):\n",
    "        return d1(S0, K, r, T, sigma, q)-sigma*math.sqrt(T)\n",
    "        \n",
    "def bsformula(callput, S0, K, r, T, sigma, q=0):\n",
    "    N = stats.norm.cdf\n",
    "                \n",
    "    def optionValueOfCall(S0, K, r, T, sigma, q):       \n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        _d2 = d2(S0, K, r, T, sigma, q)\n",
    "        return S0*math.exp(-q*T)*N(_d1)- K*math.exp(-r*T)*N(_d2)\n",
    "      \n",
    "    def optionValueOfPut(S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        _d2 = d2(S0, K, r, T, sigma, q)\n",
    "        return float(K)*math.exp(-float(r)*float(T))*N(-_d2) - float(S0)*math.exp(-float(q)*float(T))*N(-_d1)\n",
    "        \n",
    "    def delta(callput, S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)        \n",
    "        if callput.lower() == \"call\":            \n",
    "            return N(_d1) * math.exp(-q*T)\n",
    "        else:\n",
    "            return (N(_d1)-1)* math.exp(-q*T)\n",
    "    \n",
    "    def vega(S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        return S0  * math.sqrt(T) * norminv(_d1)  * math.exp(-q*T)\n",
    "    \n",
    "    if callput.lower()==\"call\":\n",
    "        optionValue = optionValueOfCall(S0, K, r, T, sigma, q)\n",
    "    else:\n",
    "        optionValue = optionValueOfPut(S0, K, r, T, sigma, q)\n",
    "        \n",
    "    _delta = delta(callput, S0, K, r, T, sigma, q)\n",
    "    _vega = vega(S0, K, r, T, sigma, q)\n",
    "    \n",
    "    return (optionValue, _delta, _vega)\n",
    "\n",
    "def bsm_iv_generator(num_sample = 100,tao_bound=[0.01,2.0],  sigma_bound=[0.01,2.0], \n",
    "                     money_bound=[0.3,3.0], rr_bound=[0.01,0.2], callput='call', seed=42):\n",
    "    \n",
    "    # input parameters: when callput is not in 'call' or 'put', randomly generate the option price followed by root-finding methods to\n",
    "    # compute the corresponding implied vol\n",
    "    # return: X_input = [time,stock,rr, dividen, option_price]. Y_outpu  = volatility \n",
    "    np.random.seed(seed)\n",
    "    tao_min,tao_max = tao_bound[0],tao_bound[1]\n",
    "    \n",
    "    sigma_min, sigma_max = sigma_bound[0],sigma_bound[1]\n",
    "    moneyness_min,moneyness_max = money_bound[0],money_bound[1]\n",
    "    rr_min,rr_max = rr_bound[0],rr_bound[1]\n",
    "   \n",
    "    \n",
    "\n",
    "    num_sample = int(num_sample)\n",
    "    xx = np.zeros([num_sample,4],dtype='float')\n",
    "    \n",
    "   \n",
    "    xx[:,0] = np.random.uniform(sigma_min, sigma_max,xx.shape[0])\n",
    "    xx[:,1] = np.random.uniform(tao_min,tao_max,xx.shape[0])\n",
    "    xx[:,2] = np.random.uniform(moneyness_min,moneyness_max,xx.shape[0])\n",
    "    xx[:,3] = np.random.uniform(rr_min,rr_max,xx.shape[0])\n",
    "   \n",
    "    \n",
    "   \n",
    "    strike=1.0 #fixed strike\n",
    "    #callput = 'call' # call option\n",
    "    v = np.zeros(xx.shape[0]) # option value\n",
    "    k = np.ones(xx.shape[0]) # strike price, just in order to match the shape of v\n",
    "    \n",
    "    if callput in ['call','put']:        \n",
    "        for i in range(0,xx.shape[0]):        \n",
    "            sigma, T, S0, interest = xx[i,0],xx[i,1],xx[i,2],xx[i,3]\n",
    "            ## use the Black-Schole function in compfin.py\n",
    "            v[i] = bsformula(callput, S0, strike, interest, T, sigma)[0]              \n",
    "            \n",
    "  \n",
    "    v= v.reshape(xx.shape[0],1)     \n",
    "    xx_sample = np.concatenate((xx,v),axis=1) #sigma, time, s, r, v\n",
    "    \n",
    "    \n",
    "    X_input   = xx_sample[:,1:]   # time,stock,rr, option_price\n",
    "    Y_output  =  xx_sample[:,0] # sigma -implied volatility is the predictive variable.\n",
    "  \n",
    "    return X_input,Y_output\n",
    "#  log-transformation of the option value\n",
    "def logscale_vol(x_train_dat,y_train_dat,otm_lower=0.0000001):\n",
    "   # input data: x_train_dat = [time,stock,rr, option_price], y_train_dat = sigma  \n",
    "   \n",
    "    xtv_train_log=x_train_dat.copy()    \n",
    "    ytv_train_log =y_train_dat.copy()\n",
    "    \n",
    "    \n",
    "    #v_lower[v_lower<0.0]=0.0 # V=max(S-E*exp(-rt),0)  \n",
    "    xintrinsic_train=xtv_train_log[:,1]-1.0*np.exp(-1.0*xtv_train_log[:,2]*xtv_train_log[:,0])\n",
    "    xintrinsic_train[xintrinsic_train<0.0]=0.0 ## \\tilde{V} = max(S-E*exp(-rt),0)\n",
    "    xtv_train_log[:,-1] = xtv_train_log[:,-1] -xintrinsic_train\n",
    "    \n",
    "    ## remove intrisinc values below the threshold (otm_lower \\approx machine pricision)  \n",
    "   \n",
    "    ytv_train_log = ytv_train_log[~np.less(xtv_train_log[:,-1],otm_lower)]\n",
    "    xtv_train_log = xtv_train_log[~np.less(xtv_train_log[:,-1],otm_lower),:]\n",
    "    xtv_train_log[:,-1]=np.log(xtv_train_log[:,-1])\n",
    "\n",
    "    return xtv_train_log,ytv_train_log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce82ab6f-af86-47ed-9c2c-ddf97780cd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maturity time  range:\n",
      "0.5005522117123602 0.5986886936600517\n",
      "Stock price  range:\n",
      "0.9802780852212476 1.0188712833088385\n",
      "interest rate  range:\n",
      "0.030829391446392806 0.07928252270553005\n",
      "option value  range:\n",
      "0.09746900812834913 0.21773104905666268\n",
      "sigma range:\n",
      "0.308233797718321 0.6879639408647977\n",
      "(50, 4)\n",
      "maturity time  range:\n",
      "0.5005522117123602 0.5986886936600517\n",
      "Stock price  range:\n",
      "0.9802780852212476 1.0188712833088385\n",
      "interest rate  range:\n",
      "0.030829391446392806 0.07928252270553005\n",
      "time option-value  range:\n",
      "-2.614763769983766 -1.672877716398405\n",
      "sigma range:\n",
      "0.308233797718321 0.6879639408647977\n",
      "(40, 4)\n",
      "Parameters: [0.64203165 0.08413996 0.16162871 0.89855419 0.60642906 0.00919705\n",
      " 0.10147154 0.66350177 0.00506158 0.16080805 0.54873379 0.6918952\n",
      " 0.65196126 0.22426931 0.71217922 0.23724909 0.3253997  0.74649141\n",
      " 0.6496329  0.84922341 0.65761289 0.5683086  0.09367477 0.3677158 ]\n",
      "inputs: [0.26520237 0.24398964 0.97301055 0.39309772]\n",
      "Expectation value: -0.11126433619844336\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xin_input,Yin_output=bsm_iv_generator(num_sample = 50,tao_bound=[0.5,0.6],  sigma_bound=[0.3,0.7], \n",
    "                                      money_bound=[0.98,1.02], rr_bound=[0.03,0.08],callput='call')\n",
    "\n",
    "#check the data value range on each dimension\n",
    "## xin = [maturity time, Stock price, interest rate, dividend, option value]\n",
    "\n",
    "xlabel =  ['maturity time', 'Stock price', 'interest rate','option value']\n",
    "for i in range(0, len(xlabel)):\n",
    "    print(xlabel[i]+'  range:')\n",
    "    print(np.min(Xin_input[:,i]),np.max(Xin_input[:,i]))\n",
    "    \n",
    "print('sigma range:')\n",
    "print(np.min(Yin_output),np.max(Yin_output))\n",
    "print(np.shape(Xin_input))\n",
    "\n",
    "# generate and shuffle the data set into training and test part\n",
    "xtv_train_log_all,ytv_train_log_all=logscale_vol(Xin_input,Yin_output,otm_lower=1e-4)\n",
    "'''\n",
    "for i in range(4):\n",
    "    xtv_train_log_all[:,i]= min_max_normalization(xtv_train_log_all[:,i])\n",
    "'''\n",
    "#ytv_train_log_all=ytv_train_log_all/2\n",
    "xtv_train_log,xtv_test_log, ytv_train_log, ytv_test_log   = train_test_split(xtv_train_log_all,ytv_train_log_all,test_size=0.2,random_state=42)\n",
    "\n",
    "xlabel =  ['maturity time', 'Stock price', 'interest rate','time option-value']\n",
    "for i in range(0, len(xlabel)):\n",
    "    print(xlabel[i]+'  range:')\n",
    "    print(np.min(xtv_train_log_all[:,i]),np.max(xtv_train_log_all[:,i]))\n",
    "    \n",
    "print('sigma range:')\n",
    "print(np.min(ytv_train_log),np.max(ytv_train_log))\n",
    "## how many samples after cleaning\n",
    "print(np.shape(xtv_train_log))\n",
    "\n",
    "\n",
    "params = npp.random.random([24], requires_grad=True)\n",
    "inputs = npp.random.random([4], requires_grad=True)\n",
    "print(\"Parameters:\", params)\n",
    "print(\"inputs:\", inputs)\n",
    "print(\"Expectation value:\", circuit(params,inputs))\n",
    "\n",
    "\n",
    "qnode = qml.QNode(circuit, dev)\n",
    "qml.draw_mpl(circuit, decimals=1, style=\"sketch\")(params,inputs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc5c5020-7fea-46b3-85c1-c67a90814673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12383580769010298\n",
      "[-0.12383581 -0.1878739  -0.05792237  0.11297664 -0.27003224 -0.07192252\n",
      " -0.02179836  0.15544178  0.1461258   0.02157234  0.03786137  0.02351291\n",
      " -0.04164089 -0.2291002  -0.1878739  -0.02627522 -0.35266624 -0.34487098\n",
      " -0.08721625  0.13691176  0.15544178  0.01819673  0.18515848  0.15697399]\n",
      "[-0.12383581 -0.1878739  -0.05792237  0.11297664 -0.27003224 -0.07192252\n",
      " -0.02179836  0.15544178  0.1461258   0.02157234  0.03786137  0.02351291\n",
      " -0.04164089 -0.2291002  -0.1878739  -0.02627522 -0.35266624 -0.34487098\n",
      " -0.08721625  0.13691176  0.15544178  0.01819673  0.18515848  0.15697399]\n",
      "[-0.12383581 -0.1878739  -0.05792237  0.11297664 -0.27003224 -0.07192252\n",
      " -0.02179836  0.15544178  0.1461258   0.02157234  0.03786137  0.02351291\n",
      " -0.04164089 -0.2291002  -0.1878739  -0.02627522 -0.35266624 -0.34487098\n",
      " -0.08721625  0.13691176  0.15544178  0.01819673  0.18515848  0.15697399]\n"
     ]
    }
   ],
   "source": [
    "def parameter_shift_term(qnode,params,inputs, i):\n",
    "    shifted = params.copy()\n",
    "    shifted[i] += np.pi/2\n",
    "    forward = qnode(shifted,inputs)  # forward evaluation\n",
    "\n",
    "    shifted[i] -= np.pi\n",
    "    backward = qnode(shifted,inputs) # backward evaluation\n",
    "\n",
    "    return 0.5 * (forward - backward)\n",
    "\n",
    "# gradient with respect to the first parameter\n",
    "print(parameter_shift_term(circuit,params,inputs, 0))\n",
    "\n",
    "\n",
    "def parameter_shift(qnode, params,inputs):\n",
    "    gradients = np.zeros([len(params)])\n",
    "\n",
    "    for i in range(len(params)):\n",
    "        gradients[i] = parameter_shift_term(qnode,params,inputs, i)\n",
    "\n",
    "    return gradients\n",
    "\n",
    "print(parameter_shift(circuit, params,inputs))\n",
    "\n",
    "grad_function = qml.grad(circuit)\n",
    "print(grad_function(params,inputs)[0])\n",
    "\n",
    "\n",
    "print(qml.gradients.param_shift(circuit)(params,inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9715830-fa60-4d48-bbc4-27dc40dbdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from itertools import chain\n",
    "import time\n",
    "def QNN(weights, angles):\n",
    "    return circuit(weights, angles)\n",
    "\n",
    "def cost(weights, features, labels):\n",
    "    predictions = [QNN(weights, f) for f in features]\n",
    "    \n",
    "    return square_loss(labels, predictions)\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def R2(labels, predictions):\n",
    "\n",
    "    r2 = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        r2 = r2 + metrics.r2_score(labels, predictions)\n",
    "    r2 = r2 / len(labels)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48fdbeb0-8d5d-419e-be05-d99d3936b2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=xtv_train_log\n",
    "Y=ytv_train_log\n",
    "weights_init = npp.random.random([24], requires_grad=True)\n",
    "opt = qml.AdamOptimizer(0.01)\n",
    "batch_size = 20\n",
    "batches = len (X) // batch_size\n",
    "X_batches = npp.array_split(npp.arange(len(X)) , batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2218b3c-8997-4af9-84d6-318bffadf9d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.23420054055650247 R2: -15.801112425900172 time: 1703256843.177298\n",
      "batch_idx: 1 loss: 0.24517527637530376 R2: -15.503818509850657 time: 1703256849.2719202\n",
      "Training [0%] Loss: 0.2396879084659031 time: 1703256849.2719202\n",
      "weight: [ 0.62214526  0.06425139  0.14172187  0.91842131  0.58655984 -0.01066473\n",
      "  0.09917627  0.66095687  0.00261064  0.15873095  0.54618099  0.68934855\n",
      "  0.63208688  0.20436519  0.69229065  0.21737437  0.30548832  0.72658705\n",
      "  0.65218023  0.85033757  0.655068    0.57081138  0.09111916  0.36516694]\n",
      "epoch 2\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.22422163307613036 R2: -15.076578874843104 time: 1703256855.2819202\n",
      "batch_idx: 1 loss: 0.23063645235857227 R2: -14.524991997653348 time: 1703256861.347234\n",
      "Training [1%] Loss: 0.22742904271735132 time: 1703256861.347234\n",
      "weight: [ 0.60237928  0.044364    0.12181862  0.93827482  0.5666933  -0.03052314\n",
      "  0.11613838  0.67784683  0.01957913  0.17577893  0.56317175  0.70635599\n",
      "  0.61221694  0.18445836  0.67240326  0.19749804  0.28557895  0.70668028\n",
      "  0.63501211  0.83306708  0.67195795  0.55387991  0.1081444   0.38218587]\n",
      "epoch 3\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.207116368496646 R2: -13.858980140726434 time: 1703256867.556848\n",
      "batch_idx: 1 loss: 0.2096253297216759 R2: -13.094551560579543 time: 1703256873.6535401\n",
      "Training [1%] Loss: 0.20837084910916095 time: 1703256873.6535401\n",
      "weight: [ 0.58242844  0.02428397  0.10174835  0.95836218  0.54661695 -0.05060112\n",
      "  0.13436678  0.69610646  0.03806399  0.19414725  0.58147208  0.72468445\n",
      "  0.5921353   0.16439693  0.65232323  0.17742777  0.26562317  0.68669925\n",
      "  0.61637568  0.81459767  0.69021758  0.53563051  0.1265144   0.40054374]\n",
      "epoch 4\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.18430388635019096 R2: -12.247400191525745 time: 1703256879.6969676\n",
      "batch_idx: 1 loss: 0.18392170730235602 R2: -11.33628129101872 time: 1703256885.657142\n",
      "Training [1%] Loss: 0.1841127968262735 time: 1703256885.657142\n",
      "weight: [ 0.56273406  0.00397254  0.08145228  0.97868672  0.52630852 -0.07091401\n",
      "  0.1534594   0.71528335  0.05731368  0.21341271  0.60065731  0.74390077\n",
      "  0.57181934  0.14411103  0.63201179  0.15712965  0.24549754  0.66653935\n",
      "  0.59763776  0.79930681  0.70939447  0.51648335  0.14578275  0.41979921]\n",
      "epoch 5\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.1577701859588729 R2: -10.378466185265085 time: 1703256891.7323234\n",
      "batch_idx: 1 loss: 0.15548045423371795 R2: -9.388353283300203 time: 1703256897.9601507\n",
      "Training [2%] Loss: 0.15662532009629543 time: 1703256897.9601507\n",
      "weight: [ 0.54495882 -0.01658762  0.06089133  0.99923776  0.50573393 -0.09148897\n",
      "  0.17326352  0.73506148  0.07606021  0.23334451  0.62054229  0.76380902\n",
      "  0.55125344  0.12355448  0.61145164  0.13655798  0.22506108  0.64607314\n",
      "  0.58278159  0.79681509  0.72917261  0.49662801  0.16572786  0.43973639]\n",
      "epoch 6\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.1294323072406119 R2: -8.3819430346443 time: 1703256903.9419556\n",
      "batch_idx: 1 loss: 0.12595894141505293 R2: -7.3693124217862245 time: 1703256910.1132188\n",
      "Training [2%] Loss: 0.1276956243278324 time: 1703256910.1132188\n",
      "weight: [ 0.53312158 -0.03728543  0.04015721  1.01990366  0.48493903 -0.11227551\n",
      "  0.19365693  0.75440609  0.09028687  0.25370036  0.6409764   0.7842484\n",
      "  0.53052559  0.10281677  0.59075382  0.11575057  0.204266    0.62526043\n",
      "  0.57908341  0.80588523  0.74851721  0.47627106  0.18615299  0.46016625]\n",
      "epoch 7\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.10090159374948042 R2: -6.366881613359398 time: 1703256916.1869304\n",
      "batch_idx: 1 loss: 0.09687895259971176 R2: -5.386580700183573 time: 1703256922.1344168\n",
      "Training [2%] Loss: 0.09889027317459609 time: 1703256922.1344168\n",
      "weight: [ 0.53089298 -0.05786408  0.01949667  1.04047162  0.46405408 -0.1331416\n",
      "  0.21448813  0.77033845  0.09445351  0.27419942  0.66181235  0.80506306\n",
      "  0.50982708  0.08214032  0.57017517  0.09483015  0.18314959  0.60414315\n",
      "  0.58659322  0.82039279  0.76444957  0.45568567  0.20686602  0.48090744]\n",
      "epoch 8\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.07381475700361262 R2: -4.446381197971202 time: 1703256928.2321346\n",
      "batch_idx: 1 loss: 0.0699426064549974 R2: -3.5584045550149623 time: 1703256934.3068776\n",
      "Training [3%] Loss: 0.071878681729305 time: 1703256934.3068776\n",
      "weight: [ 5.37100334e-01 -7.79125625e-02 -6.70621261e-04  1.06064181e+00\n",
      "  4.43292567e-01 -1.53875241e-01  2.35541610e-01  7.78883648e-01\n",
      "  8.92135968e-02  2.94516752e-01  6.82876202e-01  8.26071778e-01\n",
      "  4.89434386e-01  6.19326903e-02  5.50126694e-01  7.40002981e-02\n",
      "  1.61827788e-01  5.82840103e-01  6.00253846e-01  8.37823289e-01\n",
      "  7.72994771e-01  4.35210271e-01  2.27644109e-01  5.01750140e-01]\n",
      "epoch 9\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.049883054017679486 R2: -2.739441760857702 time: 1703256940.3271494\n",
      "batch_idx: 1 loss: 0.04679590178579794 R2: -1.998602224454767 time: 1703256946.5119073\n",
      "Training [3%] Loss: 0.04833947790173872 time: 1703256946.5119073\n",
      "weight: [ 0.5487425  -0.09687692 -0.01976359  1.08004226  0.42295248 -0.17418361\n",
      "  0.25651301  0.77922076  0.07830396  0.31427562  0.70392304  0.84702567\n",
      "  0.46969755  0.04275987  0.53116234  0.05354877  0.14050416  0.56155639\n",
      "  0.61728296  0.85711804  0.77333189  0.41524397  0.24817459  0.52239369]\n",
      "epoch 10\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.030566750968069212 R2: -1.3483611444765278 time: 1703256952.4868858\n",
      "batch_idx: 1 loss: 0.028675993739035288 R2: -0.7917507364569795 time: 1703256958.5622756\n",
      "Training [3%] Loss: 0.02962137235355225 time: 1703256958.5622756\n",
      "weight: [ 0.56361946 -0.1141448  -0.03713681  1.09826236  0.40340874 -0.19370039\n",
      "  0.2769924   0.7734916   0.06435135  0.33305129  0.7245985   0.86757627\n",
      "  0.45102164  0.02526181  0.51389446  0.03384521  0.11948904  0.54060212\n",
      "  0.63638097  0.87768702  0.76760272  0.39625952  0.26801662  0.54240335]\n",
      "epoch 11\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.016723057729905823 R2: -0.3343922991605001 time: 1703256964.6119707\n",
      "batch_idx: 1 loss: 0.016105746520204606 R2: 0.027889120900867693 time: 1703256970.959097\n",
      "Training [4%] Loss: 0.016414402125055214 time: 1703256970.959097\n",
      "weight: [ 0.58020388 -0.12922093 -0.05227398  1.11491482  0.3850865  -0.2120095\n",
      "  0.29646371  0.76392386  0.04906269  0.3503741   0.74441926  0.8872679\n",
      "  0.43381979  0.00996735  0.49881833  0.01531926  0.09921712  0.52040926\n",
      "  0.65672035  0.89903239  0.75803498  0.37884287  0.28661257  0.56121814]\n",
      "epoch 12\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.008401926118188685 R2: 0.2966913762053955 time: 1703256977.1218898\n",
      "batch_idx: 1 loss: 0.008805154768832844 R2: 0.4822746518322524 time: 1703256983.0720763\n",
      "Training [4%] Loss: 0.008603540443510764 time: 1703256983.0720763\n",
      "weight: [ 0.59719822 -0.14190737 -0.06497851  1.12970532  0.36841235 -0.22868912\n",
      "  0.31433469  0.75199184  0.03357917  0.36572963  0.7627867   0.90556523\n",
      "  0.41844295 -0.00290188  0.48613188 -0.00158625  0.08024421  0.50152728\n",
      "  0.67751882  0.92050408  0.74610296  0.36372497  0.30335994  0.57822385]\n",
      "epoch 13\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.004881154841292265 R2: 0.5923717293980734 time: 1703256989.182095\n",
      "batch_idx: 1 loss: 0.005813498978618872 R2: 0.6409073491283487 time: 1703256995.3670166\n",
      "Training [4%] Loss: 0.005347326909955569 time: 1703256995.3670166\n",
      "weight: [ 0.61332372 -0.15236354 -0.07542773  1.14247715  0.35375247 -0.24336951\n",
      "  0.33000558  0.73843273  0.01849127  0.37855915  0.77904819  0.92192158\n",
      "  0.40511584 -0.01350084  0.47567571 -0.01647904  0.06320126  0.48457693\n",
      "  0.69783241  0.94107554  0.73254386  0.35176101  0.31772901  0.59287849]\n",
      "epoch 14\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.004862096071079166 R2: 0.6399723964173913 time: 1703257001.4339693\n",
      "batch_idx: 1 loss: 0.005727240178854459 R2: 0.6041340762279397 time: 1703257007.359954\n",
      "Training [5%] Loss: 0.005294668124966812 time: 1703257007.359954\n",
      "weight: [ 0.6273461  -0.16102435 -0.08407733  1.15321626  0.34135658 -0.25578909\n",
      "  0.34296649  0.72337081  0.00382595  0.38827443  0.79260562  0.93587607\n",
      "  0.39390788 -0.02227662  0.4670149  -0.02908029  0.04869759  0.47015475\n",
      "  0.71648883  0.95918159  0.71748193  0.34381551  0.32937831  0.60483915]\n",
      "epoch 15\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.006747710247765694 R2: 0.5475636131012213 time: 1703257013.5357175\n",
      "batch_idx: 1 loss: 0.006996960992221374 R2: 0.4822460656427129 time: 1703257019.6071515\n",
      "Training [5%] Loss: 0.006872335619993534 time: 1703257019.6071515\n",
      "weight: [ 0.63826197 -0.16846068 -0.0915122   1.16202763  0.33132516 -0.2658307\n",
      "  0.35289289  0.70654442 -0.01085563  0.39431529  0.80304174  0.94714701\n",
      "  0.38474357 -0.02982084  0.45957857 -0.03926676  0.03719676  0.45871201\n",
      "  0.73222712  0.97285381  0.70065554  0.34055105  0.33821654  0.61403179]\n",
      "epoch 16\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00897042391137592 R2: 0.4215768204013896 time: 1703257025.69836\n",
      "batch_idx: 1 loss: 0.008256062669535156 R2: 0.3721609163057097 time: 1703257031.6991196\n",
      "Training [5%] Loss: 0.008613243290455538 time: 1703257031.6991196\n",
      "weight: [ 0.64548335 -0.17525964 -0.0983243   1.16910269  0.3236064  -0.27352904\n",
      "  0.35970334  0.68764252 -0.02626146  0.39627015  0.81021348  0.95568495\n",
      "  0.37743626 -0.0367431   0.45277962 -0.04708142  0.02891506  0.45045669\n",
      "  0.74406117  0.98040103  0.68175364  0.34220894  0.34439654  0.62064504]\n",
      "epoch 17\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.010332361234851168 R2: 0.34373549567269673 time: 1703257037.9340575\n",
      "batch_idx: 1 loss: 0.008616848787357207 R2: 0.3363127155712315 time: 1703257044.1953385\n",
      "Training [6%] Loss: 0.009474605011104188 time: 1703257044.1953385\n",
      "weight: [ 0.64889    -0.18194255 -0.10503314  1.17468851  0.3180165  -0.27905349\n",
      "  0.36356348  0.66661983 -0.0430881   0.39402688  0.8142737   0.96166825\n",
      "  0.37172797 -0.04358449  0.44609671 -0.05271496  0.02378403  0.44531793\n",
      "  0.7516447   0.98124661  0.66073095  0.34852392  0.3482609   0.62506843]\n",
      "epoch 18\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.010250316469602314 R2: 0.35447132813458937 time: 1703257050.4421566\n",
      "batch_idx: 1 loss: 0.007812772922518408 R2: 0.39254675372648856 time: 1703257056.8521075\n",
      "Training [6%] Loss: 0.009031544696060361 time: 1703257056.8521075\n",
      "weight: [ 0.64876488 -0.18890127 -0.11202606  1.17906011  0.31427148 -0.28267849\n",
      "  0.36484777  0.6437533  -0.06172229  0.38786341  0.81562388  0.96545252\n",
      "  0.36732721 -0.05075035  0.43913798 -0.0564698   0.02147809  0.44297315\n",
      "  0.7553452   0.97606252  0.63786442  0.3588219   0.35026483  0.62780217]\n",
      "epoch 19\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00879217784867196 R2: 0.450403218878885 time: 1703257062.9189897\n",
      "batch_idx: 1 loss: 0.006132498935758975 R2: 0.5188804985143505 time: 1703257069.1320624\n",
      "Training [6%] Loss: 0.007462338392215467 time: 1703257069.1320624\n",
      "weight: [ 0.64570503 -0.19633243 -0.11949614  1.18249314  0.31201928 -0.28475392\n",
      "  0.36408381  0.61946327 -0.08210567  0.37841987  0.81483461  0.967502\n",
      "  0.36394296 -0.05844094  0.43170683 -0.05872041  0.02147398  0.44290585\n",
      "  0.75603997  0.9662198   0.61357439  0.37219603  0.350897    0.62936106]\n",
      "epoch 20\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.006522397601869785 R2: 0.5947797074092032 time: 1703257075.3041027\n",
      "batch_idx: 1 loss: 0.004215233349670837 R2: 0.668048980451297 time: 1703257081.691012\n",
      "Training [7%] Loss: 0.005368815475770311 time: 1703257081.691012\n",
      "weight: [ 0.64056506 -0.20416943 -0.12737601  1.1852353   0.31086714 -0.28568118\n",
      "  0.3618972   0.59421826 -0.10379995  0.36660472  0.81256916  0.96832626\n",
      "  0.3613137  -0.06658067  0.42386983 -0.05987789  0.02310876  0.44446204\n",
      "  0.75485978  0.95329602  0.58832938  0.38762347  0.35061446  0.63019102]\n",
      "epoch 21\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.004249961313230825 R2: 0.7346483594200419 time: 1703257087.8972235\n",
      "batch_idx: 1 loss: 0.002779830409894075 R2: 0.7866449597672299 time: 1703257094.0711858\n",
      "Training [7%] Loss: 0.00351489586156245 time: 1703257094.0711858\n",
      "weight: [ 0.63443359 -0.21203385 -0.1352885   1.18747885  0.31040623 -0.28589205\n",
      "  0.35895844  0.56866708 -0.12602632  0.35353347  0.80952112  0.96842973\n",
      "  0.35922978 -0.07476744  0.4160054  -0.06035921  0.02562816  0.44689774\n",
      "  0.75300033  0.93896719  0.56277821  0.4039676   0.34979871  0.63061068]\n",
      "epoch 22\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0027228252623023048 R2: 0.8217250620709959 time: 1703257100.2019966\n",
      "batch_idx: 1 loss: 0.0023100513413221386 R2: 0.8373818845527401 time: 1703257106.382189\n",
      "Training [7%] Loss: 0.0025164383018122217 time: 1703257106.382189\n",
      "weight: [ 0.62859551 -0.21924366 -0.14255208  1.18934219  0.3102401  -0.28582098\n",
      "  0.35592261  0.5439626  -0.14750047  0.34052966  0.80635757  0.96827045\n",
      "  0.35754568 -0.08228006  0.4087956  -0.06055609  0.02824237  0.44943409\n",
      "  0.75157827  0.92514999  0.53807372  0.41990254  0.34873375  0.63078629]\n",
      "epoch 23\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0022918318194281857 R2: 0.8352295802805652 time: 1703257112.5820847\n",
      "batch_idx: 1 loss: 0.0027601132372854524 R2: 0.8201637867803449 time: 1703257118.781962\n",
      "Training [8%] Loss: 0.002525972528356819 time: 1703257118.781962\n",
      "weight: [ 0.62438483 -0.2249325  -0.1482972   1.19087194  0.31002202 -0.28586194\n",
      "  0.3533538   0.52214581 -0.16617732  0.32909595  0.80365569  0.96822318\n",
      "  0.35617743 -0.08820116  0.40310675 -0.06079997  0.03021542  0.45134567\n",
      "  0.75148739  0.91406855  0.51625693  0.43388819  0.34760534  0.63074714]\n",
      "epoch 24\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0026772903460578765 R2: 0.7973516053351484 time: 1703257125.2770112\n",
      "batch_idx: 1 loss: 0.0035063745395199387 R2: 0.7762399784064159 time: 1703257131.5273426\n",
      "Training [8%] Loss: 0.0030918324427889076 time: 1703257131.5273426\n",
      "weight: [ 0.62286053 -0.22831881 -0.15173605  1.19207164  0.30949839 -0.2863115\n",
      "  0.3516448   0.50595043 -0.17953138  0.32066917  0.80183256  0.96854757\n",
      "  0.35508382 -0.09170162  0.39972044 -0.06132604  0.03099283  0.45208598\n",
      "  0.75326712  0.90778526  0.50006156  0.44441364  0.34651956  0.63044368]\n",
      "epoch 25\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.003140653510335087 R2: 0.7605954004033919 time: 1703257138.023215\n",
      "batch_idx: 1 loss: 0.003800617871568916 R2: 0.7571967210832715 time: 1703257144.4123032\n",
      "Training [8%] Loss: 0.0034706356909520015 time: 1703257144.4123032\n",
      "weight: [ 0.62445267 -0.22903262 -0.15249452  1.19294556  0.30854319 -0.28731814\n",
      "  0.35096439  0.49724752 -0.18595342  0.31611947  0.80108702  0.96936809\n",
      "  0.35423858 -0.09239039  0.39900664 -0.0622482   0.03032035  0.45140394\n",
      "  0.7570418   0.90723506  0.49135864  0.4505636   0.34553134  0.62982993]\n",
      "epoch 26\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0031172063262936396 R2: 0.7638016573492132 time: 1703257150.9173028\n",
      "batch_idx: 1 loss: 0.003391371627665827 R2: 0.7814141485386158 time: 1703257157.3772998\n",
      "Training [9%] Loss: 0.0032542889769797334 time: 1703257157.3772998\n",
      "weight: [ 0.62887271 -0.22727238 -0.15077325  1.19353063  0.30716453 -0.28886697\n",
      "  0.35126002  0.49564823 -0.18586015  0.31538038  0.80138362  0.97067484\n",
      "  0.35360911 -0.09048056  0.40076687 -0.06355836  0.02828011  0.44937941\n",
      "  0.76256623  0.91183824  0.48975935  0.45244777  0.34466518  0.62892472]\n",
      "epoch 27\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0026374757131491775 R2: 0.8035689289144552 time: 1703257163.5919087\n",
      "batch_idx: 1 loss: 0.0025941845887274303 R2: 0.8284874986425406 time: 1703257169.9919336\n",
      "Training [9%] Loss: 0.002615830150938304 time: 1703257169.9919336\n",
      "weight: [ 0.63532391 -0.22369663 -0.14723734  1.19389743  0.30547919 -0.29080904\n",
      "  0.35230634  0.4991193  -0.18110285  0.31756033  0.8024893   0.97234686\n",
      "  0.35315226 -0.08666914  0.40434263 -0.06515094  0.0252252   0.44635909\n",
      "  0.76934305  0.92007017  0.49323042  0.45106952  0.34391865  0.62781625]\n",
      "epoch 28\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0021058555477246376 R2: 0.8501428930870256 time: 1703257176.2919989\n",
      "batch_idx: 1 loss: 0.001879962334136543 R2: 0.8675331493384814 time: 1703257182.6037772\n",
      "Training [9%] Loss: 0.0019929089409305902 time: 1703257182.6037772\n",
      "weight: [ 0.64279343 -0.21918229 -0.14276976  1.19412666  0.30366849 -0.29291805\n",
      "  0.35377161  0.50514283 -0.17396583  0.32132134  0.80404362  0.97419041\n",
      "  0.35282395 -0.08187907  0.40885697 -0.06686143  0.02166014  0.44283901\n",
      "  0.77675056  0.93010687  0.49925395  0.44789643  0.34325632  0.62662165]\n",
      "epoch 29\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018612113718276843 R2: 0.8780461095437035 time: 1703257188.9119546\n",
      "batch_idx: 1 loss: 0.0015078409509292584 R2: 0.8826010129354593 time: 1703257195.362289\n",
      "Training [10%] Loss: 0.0016845261613784713 time: 1703257195.362289\n",
      "weight: [ 0.65029539 -0.21458838 -0.13823146  1.19428224  0.30192958 -0.29495308\n",
      "  0.35528903  0.5112768  -0.16666391  0.32522758  0.80564113  0.97598441\n",
      "  0.3525914  -0.0770119   0.41345088 -0.06850868  0.01811459  0.43934013\n",
      "  0.78415459  0.94015921  0.50538792  0.44448275  0.3426092   0.62543888]\n",
      "epoch 30\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019474836387815032 R2: 0.8821617452691575 time: 1703257201.9485433\n",
      "batch_idx: 1 loss: 0.0014379786765456926 R2: 0.878445252737731 time: 1703257208.6370788\n",
      "Training [10%] Loss: 0.001692731157663598 time: 1703257208.6370788\n",
      "weight: [ 0.65705427 -0.21058045 -0.13428537  1.19439788  0.30043136 -0.29671269\n",
      "  0.35652979  0.51549267 -0.16103564  0.32802676  0.80691464  0.97752752\n",
      "  0.3524387  -0.07276534  0.41745881 -0.06993476  0.0150342   0.43630068\n",
      "  0.79100835  0.94870331  0.50960379  0.44217361  0.34188885  0.62431987]\n",
      "epoch 31\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002170359392602509 R2: 0.8742095432894631 time: 1703257215.2321398\n",
      "batch_idx: 1 loss: 0.0014727908475125192 R2: 0.8702312921573819 time: 1703257221.747136\n",
      "Training [10%] Loss: 0.001821575120057514 time: 1703257221.747136\n",
      "weight: [ 0.66261632 -0.20754179 -0.13130986  1.19448137  0.29928261 -0.29807085\n",
      "  0.35726681  0.51652858 -0.15824301  0.32888024  0.80760687  0.97867898\n",
      "  0.35236312 -0.06954066  0.42049747 -0.0710357   0.0127052   0.43400202\n",
      "  0.79693695  0.95472005  0.5106397   0.44186316  0.34101479  0.62327351]\n",
      "epoch 32\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0023005749622138855 R2: 0.8690944741859038 time: 1703257228.7202184\n",
      "batch_idx: 1 loss: 0.001448791891027852 R2: 0.8698493942100711 time: 1703257235.732244\n",
      "Training [11%] Loss: 0.0018746834266208687 time: 1703257235.732244\n",
      "weight: [ 0.66686722 -0.2055749  -0.1294031   1.1945289   0.29851782 -0.29898989\n",
      "  0.35741213  0.51405308 -0.15862889  0.32748692  0.80761369  0.97938354\n",
      "  0.35236592 -0.06744428  0.42246435 -0.07177684  0.01122484  0.43253957\n",
      "  0.80178643  0.95784436  0.5081642   0.44386765  0.33994351  0.62228748]\n",
      "epoch 33\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002234369723596376 R2: 0.8739655036204436 time: 1703257242.9158325\n",
      "batch_idx: 1 loss: 0.0013325091450472866 R2: 0.8792342148870661 time: 1703257249.5869734\n",
      "Training [11%] Loss: 0.0017834394343218313 time: 1703257249.5869734\n",
      "weight: [ 0.66996957 -0.20456156 -0.12844493  1.1945384   0.2981008  -0.29951309\n",
      "  0.3570183   0.5085237  -0.16181846  0.32406276  0.80698929  0.97967482\n",
      "  0.35244381 -0.06635111  0.4234777  -0.0721911   0.01051597  0.43183722\n",
      "  0.80561915  0.95833446  0.50263482  0.44795594  0.33868495  0.62134925]\n",
      "epoch 34\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00202153915769804 R2: 0.886129660938248 time: 1703257256.1319406\n",
      "batch_idx: 1 loss: 0.0011961654354605616 R2: 0.8923116026777531 time: 1703257262.5271256\n",
      "Training [11%] Loss: 0.0016088522965793009 time: 1703257262.5271256\n",
      "weight: [ 0.67226301 -0.20423982 -0.12817433  1.1945155   0.29794159 -0.29974361\n",
      "  0.35624822  0.50091278 -0.16693985  0.3192189   0.80591651  0.9796589\n",
      "  0.35258494 -0.06598568  0.42379944 -0.07236356  0.01037186  0.43169139\n",
      "  0.8086591   0.95690936  0.49502391  0.45348499  0.33730051  0.62045427]\n",
      "epoch 35\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017912351673749557 R2: 0.8978748663739176 time: 1703257268.8222091\n",
      "batch_idx: 1 loss: 0.0011302840300459614 R2: 0.9014331877965874 time: 1703257275.0772798\n",
      "Training [12%] Loss: 0.0014607595987104587 time: 1703257275.0772798\n",
      "weight: [ 0.67416057 -0.20427717 -0.12826209  1.19447228  0.2979211  -0.29981651\n",
      "  0.35532548  0.49247343 -0.17283423  0.31380403  0.80465436  0.97948474\n",
      "  0.35276985 -0.06599896  0.42376209 -0.0724078   0.01051615  0.43183003\n",
      "  0.81120969  0.95454925  0.48658456  0.45956594  0.33588573  0.61960273]\n",
      "epoch 36\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016493520036118218 R2: 0.9032232258206859 time: 1703257281.4821494\n",
      "batch_idx: 1 loss: 0.001163522657918454 R2: 0.9033021619180092 time: 1703257287.7621017\n",
      "Training [12%] Loss: 0.001406437330765138 time: 1703257287.7621017\n",
      "weight: [ 0.67605443 -0.20433958 -0.12837875  1.19442285  0.29791832 -0.29986835\n",
      "  0.35447809  0.48454556 -0.17825125  0.30873338  0.80347518  0.97930887\n",
      "  0.35297537 -0.06604059  0.42369967 -0.0724393   0.01066739  0.43197609\n",
      "  0.81356951  0.95229279  0.47865669  0.46523919  0.33454532  0.61879341]\n",
      "epoch 37\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016142709793341959 R2: 0.9020634331629477 time: 1703257293.9870455\n",
      "batch_idx: 1 loss: 0.0012428020992780512 R2: 0.9006367681447849 time: 1703257300.5331492\n",
      "Training [12%] Loss: 0.0014285365393061234 time: 1703257300.5331492\n",
      "weight: [ 0.67823844 -0.20415803 -0.12825982  1.19437932  0.29783573 -0.30000899\n",
      "  0.35388736  0.47831562 -0.18209015  0.30479791  0.80260342  0.97926097\n",
      "  0.35317977 -0.06582851  0.42388123 -0.07255093  0.01059921  0.43190674\n",
      "  0.81596551  0.95102212  0.47242675  0.46967189  0.33336802  0.61802151]\n",
      "epoch 38\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016288513946122684 R2: 0.8990941934197922 time: 1703257306.5273156\n",
      "batch_idx: 1 loss: 0.00128487331040267 R2: 0.8987408534005296 time: 1703257312.730788\n",
      "Training [13%] Loss: 0.0014568623525074691 time: 1703257312.730788\n",
      "weight: [ 0.68085948 -0.2035822  -0.127758    1.19434972  0.29761779 -0.30030083\n",
      "  0.35365246  0.47452195 -0.18367642  0.30247647  0.80216817  0.97941717\n",
      "  0.35336736 -0.06520514  0.42445706 -0.07279541  0.01018472  0.43149706\n",
      "  0.81851487  0.95125959  0.46863307  0.4723576   0.33240673  0.61728161]\n",
      "epoch 39\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016300822582450477 R2: 0.8989129783656763 time: 1703257318.9650028\n",
      "batch_idx: 1 loss: 0.0012491171346277427 R2: 0.9004511703025315 time: 1703257325.391985\n",
      "Training [13%] Loss: 0.0014395996964363953 time: 1703257325.391985\n",
      "weight: [ 0.68391053 -0.20260321 -0.12686486  1.19433717  0.29725814 -0.30075069\n",
      "  0.35377803  0.47325175 -0.18293901  0.30182369  0.80218123  0.97978732\n",
      "  0.35353192 -0.0641611   0.42543605 -0.07317858  0.00941402  0.43073722\n",
      "  0.82121859  0.95305624  0.46736287  0.4732384   0.33166801  0.61657135]\n",
      "epoch 40\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016055978576797925 R2: 0.9021477883949102 time: 1703257331.561882\n",
      "batch_idx: 1 loss: 0.0011613898314931836 R2: 0.9043858670796181 time: 1703257337.7019873\n",
      "Training [13%] Loss: 0.001383493844586488 time: 1703257337.7019873\n",
      "weight: [ 0.68726523 -0.20133516 -0.12569205  1.19433938  0.29679411 -0.30131637\n",
      "  0.35418534  0.47397386 -0.18037023  0.30249221  0.80254637  0.9803198\n",
      "  0.35367799 -0.06281573  0.42670409 -0.07366461  0.00838052  0.42971909\n",
      "  0.82398229  0.95603041  0.46808498  0.47268274  0.33111312  0.61589121]\n",
      "epoch 41\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015865836159104439 R2: 0.9060697612126869 time: 1703257343.8622363\n",
      "batch_idx: 1 loss: 0.0010762700030371361 R2: 0.9074320225646885 time: 1703257349.9846823\n",
      "Training [14%] Loss: 0.00133142680947379 time: 1703257349.9846823\n",
      "weight: [ 0.6907386  -0.1999637  -0.12442052  1.19434854  0.29629095 -0.30192481\n",
      "  0.35474176  0.47577211 -0.17680941  0.30387285  0.80309536  0.98092168\n",
      "  0.35381968 -0.06136314  0.42807555 -0.07419084  0.00724251  0.42859835\n",
      "  0.8266548   0.95952847  0.46988323  0.47133606  0.33067001  0.61524047]\n",
      "epoch 42\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016005320286118173 R2: 0.9080213418634925 time: 1703257355.9640834\n",
      "batch_idx: 1 loss: 0.0010272201438814893 R2: 0.9080425523917388 time: 1703257362.2589583\n",
      "Training [14%] Loss: 0.0013138760862466533 time: 1703257362.2589583\n",
      "weight: [ 0.69415105 -0.19868293 -0.12323868  1.19435277  0.29582105 -0.30249571\n",
      "  0.35529965  0.47764489 -0.17317073  0.30528734  0.80363875  0.98148774\n",
      "  0.3539767  -0.06000614  0.42935633 -0.07468747  0.00617317  0.42754536\n",
      "  0.82907408  0.96283356  0.47175601  0.46991627  0.33025344  0.61461346]\n",
      "epoch 43\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016404370000383931 R2: 0.9077372559624844 time: 1703257368.3751297\n",
      "batch_idx: 1 loss: 0.0010108250639647282 R2: 0.9071342189033025 time: 1703257374.4273741\n",
      "Training [14%] Loss: 0.0013256310320015605 time: 1703257374.4273741\n",
      "weight: [ 0.69737631 -0.1976424  -0.12229094  1.19433946  0.29544404 -0.30296369\n",
      "  0.35573504  0.47877355 -0.1702011   0.30617157  0.80401678  0.98192941\n",
      "  0.3541686  -0.05890088  0.43039686 -0.07509669  0.00531374  0.42669906\n",
      "  0.8311104   0.96535892  0.47288467  0.46902021  0.32978767  0.61399979]\n",
      "epoch 44\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016748992785175511 R2: 0.9068402629157923 time: 1703257380.5671911\n",
      "batch_idx: 1 loss: 0.0010064351883172485 R2: 0.9065419871586122 time: 1703257386.895867\n",
      "Training [15%] Loss: 0.0013406672334173998 time: 1703257386.895867\n",
      "weight: [ 0.7003629  -0.19691721 -0.12164912  1.19429962  0.29519272 -0.30329336\n",
      "  0.35597641  0.47870255 -0.16831777  0.30620454  0.80413687  0.98219614\n",
      "  0.35440869 -0.05812561  0.43112205 -0.07538637  0.00474142  0.42613536\n",
      "  0.83269713  0.96678086  0.47281368  0.46898802  0.32922557  0.61338886]\n",
      "epoch 45\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001678929656857877 R2: 0.9068460057829764 time: 1703257393.5933888\n",
      "batch_idx: 1 loss: 0.001001800238648743 R2: 0.9071488628255502 time: 1703257399.821901\n",
      "Training [15%] Loss: 0.00134036494775331 time: 1703257399.821901\n",
      "weight: [ 0.70312957 -0.19650311 -0.1213082   1.19423106  0.2950679  -0.30348444\n",
      "  0.35601651  0.47739691 -0.16755491  0.30535562  0.8039892   0.98228427\n",
      "  0.35469993 -0.05767567  0.43153615 -0.07555539  0.00445833  0.42585633\n",
      "  0.83384198  0.96708416  0.47150803  0.46985358  0.3285582   0.61277478]\n",
      "epoch 46\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001652772646033458 R2: 0.9078823612799992 time: 1703257405.7849689\n",
      "batch_idx: 1 loss: 0.0010003543238509298 R2: 0.9084179406675521 time: 1703257411.9773197\n",
      "Training [15%] Loss: 0.0013265634849421938 time: 1703257411.9773197\n",
      "weight: [ 0.7057425  -0.19633118 -0.12120104  1.19413911  0.29504226 -0.30356715\n",
      "  0.35590536  0.47518272 -0.1676152   0.30384959  0.80363829  0.98223238\n",
      "  0.35503403 -0.05747894  0.43170808 -0.07562999  0.00440138  0.42579989\n",
      "  0.83461676  0.96652116  0.46929384  0.47138132  0.32781284  0.61215851]\n",
      "epoch 47\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016158105781752953 R2: 0.9090188452397042 time: 1703257418.1323433\n",
      "batch_idx: 1 loss: 0.0010098847478293455 R2: 0.909316413056551 time: 1703257424.4100225\n",
      "Training [16%] Loss: 0.0013128476630023204 time: 1703257424.4100225\n",
      "weight: [ 0.70828553 -0.19629463 -0.12122452  1.19403445  0.29507115 -0.30359034\n",
      "  0.35572853  0.47261009 -0.16799401  0.30207138  0.80319568  0.98210602\n",
      "  0.35539404 -0.05742382  0.43174463 -0.07565338  0.00446762  0.42586473\n",
      "  0.83513097  0.96550975  0.46672121  0.47316619  0.32704054  0.61154617]\n",
      "epoch 48\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001587164847543616 R2: 0.9094506428533073 time: 1703257430.457313\n",
      "batch_idx: 1 loss: 0.0010290430481821817 R2: 0.9094248735208735 time: 1703257436.5222878\n",
      "Training [16%] Loss: 0.001308103947862899 time: 1703257436.5222878\n",
      "weight: [ 0.71083301 -0.1962806  -0.12127031  1.19392941  0.29510664 -0.30360616\n",
      "  0.35557833  0.47027993 -0.16813962  0.30044118  0.80278301  0.98197678\n",
      "  0.35575949 -0.0573925   0.43175865 -0.07567196  0.00454683  0.42594239\n",
      "  0.83549917  0.96450284  0.46439105  0.47476494  0.32629823  0.61094536]\n",
      "epoch 49\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015726211443665191 R2: 0.9092402112913358 time: 1703257442.687016\n",
      "batch_idx: 1 loss: 0.0010461281163029463 R2: 0.9091692410073338 time: 1703257448.5919242\n",
      "Training [16%] Loss: 0.0013093746303347326 time: 1703257448.5919242\n",
      "weight: [ 0.71343247 -0.19620018 -0.12125341  1.19383408  0.29511085 -0.30365573\n",
      "  0.35552685  0.46867102 -0.16761338  0.29929183  0.80249637  0.98190194\n",
      "  0.35611256 -0.05729215  0.43183907 -0.07572238  0.00455214  0.42594739\n",
      "  0.83581214  0.96386117  0.46278214  0.47582588  0.32563098  0.61036179]\n",
      "epoch 50\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00156704794074406 R2: 0.9090303326572025 time: 1703257454.7438085\n",
      "batch_idx: 1 loss: 0.0010496719838825248 R2: 0.9091706236569946 time: 1703257460.895846\n",
      "Training [17%] Loss: 0.0013083599623132922 time: 1703257460.895846\n",
      "weight: [ 0.71609987 -0.19600893 -0.12113163  1.1937537   0.29506493 -0.3037595\n",
      "  0.35560807  0.46801119 -0.16620753  0.29878125  0.80238182  0.9819102\n",
      "  0.35644318 -0.05707643  0.43203032 -0.07582284  0.00444058  0.42583745\n",
      "  0.83611948  0.96376274  0.46212231  0.4761825   0.32505968  0.60979745]\n",
      "epoch 51\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015650248508011489 R2: 0.9092574755410782 time: 1703257466.9720795\n",
      "batch_idx: 1 loss: 0.0010382609538767125 R2: 0.9095767079516334 time: 1703257472.9721081\n",
      "Training [17%] Loss: 0.0013016429023389306 time: 1703257472.9721081\n",
      "weight: [ 0.71882639 -0.19571243 -0.12091047  1.19368764  0.29497141 -0.30391472\n",
      "  0.35581333  0.46823536 -0.16398181  0.2988658   0.80242831  0.98199727\n",
      "  0.35675161 -0.05675114  0.43232682 -0.07597077  0.00421847  0.42561877\n",
      "  0.83642629  0.96417534  0.46234649  0.47588267  0.32457713  0.60925014]\n",
      "epoch 52\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015664305114951823 R2: 0.9097828389852911 time: 1703257479.1233075\n",
      "batch_idx: 1 loss: 0.0010198674792024516 R2: 0.9100612079577063 time: 1703257485.1419244\n",
      "Training [17%] Loss: 0.0012931489953488169 time: 1703257485.1419244\n",
      "weight: [ 0.72159148 -0.19535588 -0.12063291  1.19363021  0.29485007 -0.30410009\n",
      "  0.35609965  0.46904225 -0.16121031  0.29933943  0.80257848  0.9821319\n",
      "  0.35704766 -0.05636336  0.43268338 -0.07614695  0.00393153  0.42533635\n",
      "  0.83670277  0.96489749  0.46315338  0.47514745  0.3241531   0.60871393]\n",
      "epoch 53\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015728906672657303 R2: 0.9102091290709853 time: 1703257491.3334002\n",
      "batch_idx: 1 loss: 0.0010036040403516393 R2: 0.9103084247522724 time: 1703257497.4920616\n",
      "Training [18%] Loss: 0.0012882473538086848 time: 1703257497.4920616\n",
      "weight: [ 0.72437608 -0.19500281 -0.12035904  1.19357283  0.29472907 -0.30428538\n",
      "  0.35640726  0.47001928 -0.15826736  0.2999188   0.80275227  0.98226942\n",
      "  0.35734682 -0.05597927  0.43303644 -0.07632395  0.00364447  0.42505383\n",
      "  0.83690231  0.9656472   0.4641304   0.47428068  0.32374568  0.60818044]\n",
      "epoch 54\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015822617929439596 R2: 0.9103635754691275 time: 1703257503.4673665\n",
      "batch_idx: 1 loss: 0.0009934944012005762 R2: 0.9103402670090894 time: 1703257509.642075\n",
      "Training [18%] Loss: 0.0012878780970722679 time: 1703257509.642075\n",
      "weight: [ 0.72717074 -0.19471149 -0.12014363  1.19350699  0.29463474 -0.30444242\n",
      "  0.35668002  0.4707843  -0.1554992   0.30034071  0.80287444  0.9823677\n",
      "  0.35766487 -0.05565947  0.43332777 -0.07647611  0.00341751  0.42483046\n",
      "  0.83698184  0.96616322  0.46489542  0.47356519  0.32331517  0.60764099]\n",
      "epoch 55\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001588626261480991 R2: 0.9104010413400628 time: 1703257515.771993\n",
      "batch_idx: 1 loss: 0.0009889107605768562 R2: 0.910393521532735 time: 1703257521.9890118\n",
      "Training [18%] Loss: 0.0012887685110289236 time: 1703257521.9890118\n",
      "weight: [ 0.72997675 -0.19451678 -0.12001921  1.19342702  0.29458333 -0.30455396\n",
      "  0.35688219  0.47109655 -0.15312377  0.30043934  0.80289724  0.98240035\n",
      "  0.3580126  -0.05544022  0.43352248 -0.07658758  0.00328759  0.42470258\n",
      "  0.83691851  0.96628486  0.46520767  0.47318032  0.32283555  0.60708907]\n",
      "epoch 56\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015871826912017856 R2: 0.9105378988755459 time: 1703257528.1604507\n",
      "batch_idx: 1 loss: 0.0009883330699311855 R2: 0.910610191669093 time: 1703257534.4221976\n",
      "Training [19%] Loss: 0.0012877578805664857 time: 1703257534.4221976\n",
      "weight: [ 0.7328015  -0.19442226 -0.11998884  1.19333176  0.29457697 -0.30461786\n",
      "  0.35700679  0.47090709 -0.1511851   0.30018203  0.80281143  0.98236323\n",
      "  0.35839246 -0.05532518  0.43361699 -0.07665623  0.00325946  0.42467485\n",
      "  0.83671766  0.96598872  0.46501821  0.47316333  0.32230048  0.60652221]\n",
      "epoch 57\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001578070345505508 R2: 0.9108061447267589 time: 1703257540.7669766\n",
      "batch_idx: 1 loss: 0.000991198858525768 R2: 0.9109188655842215 time: 1703257547.2625763\n",
      "Training [19%] Loss: 0.001284634602015638 time: 1703257547.2625763\n",
      "weight: [ 0.73565167 -0.19440311 -0.12002904  1.19322456  0.29460467 -0.30464595\n",
      "  0.35707381  0.47034276 -0.14956768  0.29965854  0.80264381  0.98227316\n",
      "  0.35879827 -0.05528847  0.43363615 -0.07669272  0.00330804  0.4247226\n",
      "  0.83641058  0.96537729  0.46445388  0.47342045  0.32172221  0.60594228]\n",
      "epoch 58\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015654837254180202 R2: 0.911078280923012 time: 1703257553.6519349\n",
      "batch_idx: 1 loss: 0.000996728294553636 R2: 0.9111746389074191 time: 1703257560.3322423\n",
      "Training [19%] Loss: 0.001281106009985828 time: 1703257560.3322423\n",
      "weight: [ 0.73852794 -0.19441723 -0.12010047  1.19311179  0.29464735 -0.30465858\n",
      "  0.35711995  0.46963843 -0.14805789  0.29903355  0.80244357  0.98216004\n",
      "  0.35921763 -0.05528629  0.43362203 -0.07671559  0.00339004  0.42480324\n",
      "  0.83604395  0.96462993  0.46374955  0.47377719  0.32112469  0.60535405]\n",
      "epoch 59\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001553906287477905 R2: 0.911256229123566 time: 1703257567.3783066\n",
      "batch_idx: 1 loss: 0.001002537746520074 R2: 0.9113346554107433 time: 1703257575.2270024\n",
      "Training [20%] Loss: 0.0012782220169989895 time: 1703257575.2270024\n",
      "weight: [ 0.74142403 -0.19442043 -0.120162    1.19300044  0.29468485 -0.30467721\n",
      "  0.35718428  0.46904462 -0.14642812  0.29848198  0.80226317  0.98205579\n",
      "  0.35963642 -0.05527269  0.43361883 -0.07674443  0.00345986  0.42487191\n",
      "  0.83566543  0.96393597  0.46315574  0.47404746  0.32053378  0.604763  ]\n",
      "epoch 60\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015455187596354015 R2: 0.9113734802693573 time: 1703257582.6282368\n",
      "batch_idx: 1 loss: 0.0010054608571377999 R2: 0.9114708364050521 time: 1703257590.3280923\n",
      "Training [20%] Loss: 0.0012754898083866006 time: 1703257590.3280923\n",
      "weight: [ 0.74433012 -0.19438039 -0.12018379  1.19289578  0.29470243 -0.30471746\n",
      "  0.35729505  0.4687415  -0.14451493  0.29812936  0.80214066  0.98198388\n",
      "  0.36004354 -0.05521406  0.43365887 -0.07679355  0.00348426  0.4248959\n",
      "  0.83531079  0.96343299  0.46285262  0.47409761  0.31996811  0.60417309]\n",
      "epoch 61\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015404420793358796 R2: 0.911522167080601 time: 1703257597.1470225\n",
      "batch_idx: 1 loss: 0.00100379232488525 R2: 0.9116529876477559 time: 1703257604.7391362\n",
      "Training [20%] Loss: 0.001272117202110565 time: 1703257604.7391362\n",
      "weight: [ 0.7472387  -0.19428511 -0.12015486  1.19279989  0.29469463 -0.30478511\n",
      "  0.35746184  0.46878666 -0.1422662   0.29801637  0.80208899  0.98195296\n",
      "  0.36043429 -0.05509796  0.43375415 -0.07686823  0.00345102  0.42486319\n",
      "  0.83499662  0.96316975  0.46289779  0.47388494  0.31943352  0.60358547]\n",
      "epoch 62\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015381606677996795 R2: 0.9117344293208116 time: 1703257612.413176\n",
      "batch_idx: 1 loss: 0.000998422987132577 R2: 0.9118706912069705 time: 1703257620.867342\n",
      "Training [21%] Loss: 0.0012682918274661281 time: 1703257620.867342\n",
      "weight: [ 0.75014963 -0.19414343 -0.12008348  1.19271134  0.29466554 -0.30487579\n",
      "  0.35767501  0.46911161 -0.13974389  0.29809686  0.80209523  0.98195623\n",
      "  0.36081134 -0.05493356  0.43389583 -0.07696448  0.00336947  0.42478296\n",
      "  0.83472012  0.96310394  0.46322273  0.47346017  0.31892265  0.60299826]\n",
      "epoch 63\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015380247435502912 R2: 0.9119645867896369 time: 1703257628.032015\n",
      "batch_idx: 1 loss: 0.0009918270348630478 R2: 0.9120714713936737 time: 1703257635.59872\n",
      "Training [21%] Loss: 0.0012649258892066695 time: 1703257635.59872\n",
      "weight: [ 0.75307148 -0.1939783  -0.11999074  1.19262624  0.29462582 -0.30497826\n",
      "  0.3579118   0.46956284 -0.13708656  0.29826637  0.80212875  0.98197624\n",
      "  0.36118293 -0.05474471  0.43406095 -0.07707194  0.0032636   0.4246788\n",
      "  0.83446525  0.96313169  0.46367396  0.47293708  0.31841904  0.60240736]\n",
      "epoch 64\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001538807163988977 R2: 0.9121634760924584 time: 1703257642.523985\n",
      "batch_idx: 1 loss: 0.0009862396149576465 R2: 0.9122365951052556 time: 1703257649.6324992\n",
      "Training [21%] Loss: 0.0012625233894733119 time: 1703257649.6324992\n",
      "weight: [ 0.75601853 -0.19381612 -0.11990078  1.19253985  0.29458778 -0.30507953\n",
      "  0.35814611  0.46996734 -0.13445018  0.29840698  0.80215446  0.98199267\n",
      "  0.36155927 -0.05455879  0.43422314 -0.07717862  0.0031611   0.42457796\n",
      "  0.83421214  0.96313428  0.46407846  0.47244416  0.31790395  0.60180792]\n",
      "epoch 65\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015386791989879369 R2: 0.9123330347709627 time: 1703257656.658483\n",
      "batch_idx: 1 loss: 0.0009827343378416935 R2: 0.9123947022087078 time: 1703257663.5819268\n",
      "Training [22%] Loss: 0.0012607067684148152 time: 1703257663.5819268\n",
      "weight: [ 0.75900456 -0.19367647 -0.11983138  1.19244849  0.29456069 -0.30516987\n",
      "  0.35835819  0.47019546 -0.13195154  0.29843043  0.80214583  0.98199016\n",
      "  0.36194848 -0.05439612  0.43436278 -0.07727548  0.0030827   0.42450082\n",
      "  0.83394638  0.96302318  0.46430659  0.47207795  0.31736308  0.60119604]\n",
      "epoch 66\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015361368399304655 R2: 0.912505103504411 time: 1703257670.8426604\n",
      "batch_idx: 1 loss: 0.0009814278339584533 R2: 0.9125753056406328 time: 1703257678.6940203\n",
      "Training [22%] Loss: 0.0012587823369444593 time: 1703257678.6940203\n",
      "weight: [ 0.76203635 -0.19356596 -0.11978841  1.19235078  0.29454777 -0.30524593\n",
      "  0.35854073  0.47019933 -0.1296338   0.29830451  0.8020931   0.98196322\n",
      "  0.36235371 -0.05426352  0.43447329 -0.0773594   0.00303553  0.42445442\n",
      "  0.8336647   0.96276756  0.46431046  0.47187434  0.31679091  0.60057001]\n",
      "epoch 67\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015309655713814118 R2: 0.9126931443230528 time: 1703257686.5242512\n",
      "batch_idx: 1 loss: 0.0009819169149561419 R2: 0.9127743036872922 time: 1703257694.215462\n",
      "Training [22%] Loss: 0.0012564412431687768 time: 1703257694.215462\n",
      "weight: [ 0.76510991 -0.19347756 -0.11976541  1.19224794  0.29454578 -0.30531113\n",
      "  0.35869979  0.47001669 -0.12746306  0.29805567  0.80200439  0.981917\n",
      "  0.36277227 -0.0541537   0.4345617  -0.0774335   0.00301233  0.4244316\n",
      "  0.83337572  0.96239719  0.46412781  0.47180542  0.31619132  0.59993067]\n",
      "epoch 68\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015242401939837653 R2: 0.9128822617447885 time: 1703257701.9856877\n",
      "batch_idx: 1 loss: 0.0009833877305306785 R2: 0.9129686427467572 time: 1703257709.0998473\n",
      "Training [23%] Loss: 0.001253813962257222 time: 1703257709.0998473\n",
      "weight: [ 0.76821114 -0.19339502 -0.11974767  1.19214309  0.29454707 -0.30537349\n",
      "  0.3588506   0.46974372 -0.12535292  0.29775027  0.80190014  0.98186404\n",
      "  0.36319705 -0.05404983  0.43464423 -0.07750525  0.00299604  0.42441559\n",
      "  0.83309591  0.96198295  0.46385485  0.47179966  0.31557476  0.59928077]\n",
      "epoch 69\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001517464825807193 R2: 0.9130576285574297 time: 1703257716.126568\n",
      "batch_idx: 1 loss: 0.0009846814419023065 R2: 0.913148428587999 time: 1703257722.97076\n",
      "Training [23%] Loss: 0.0012510731338547499 time: 1703257722.97076\n",
      "weight: [ 0.771321   -0.19330009 -0.11971876  1.19203993  0.29454294 -0.30544207\n",
      "  0.35901064  0.46949071 -0.12320447  0.29746409  0.80180388  0.98181874\n",
      "  0.36361955 -0.05393299  0.43473917 -0.07758308  0.00296736  0.42438737\n",
      "  0.83284308  0.96160513  0.46360183  0.47177493  0.3149534   0.59862365]\n",
      "epoch 70\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015117337038459875 R2: 0.9132249500802196 time: 1703257729.9314501\n",
      "batch_idx: 1 loss: 0.0009847106515492162 R2: 0.9133232399341649 time: 1703257737.0491247\n",
      "Training [23%] Loss: 0.0012482221776976019 time: 1703257737.0491247\n",
      "weight: [ 0.77442276 -0.1931794  -0.11966675  1.19194125  0.29452699 -0.30552354\n",
      "  0.35919284  0.46933869 -0.12094518  0.29725266  0.80173297  0.98179179\n",
      "  0.36403307 -0.05378936  0.43485985 -0.07767325  0.00291212  0.42433304\n",
      "  0.83263006  0.96132253  0.46344982  0.47167084  0.31433627  0.59796191]\n",
      "epoch 71\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015074695854073506 R2: 0.9133994263121293 time: 1703257744.1438599\n",
      "batch_idx: 1 loss: 0.0009830321257798939 R2: 0.9135032214847284 time: 1703257751.4921257\n",
      "Training [24%] Loss: 0.0012452508555936223 time: 1703257751.4921257\n",
      "weight: [ 0.77750854 -0.19302874 -0.11958794  1.19184807  0.29449713 -0.30562003\n",
      "  0.35940134  0.46931308 -0.11855259  0.29713344  0.80169303  0.98178673\n",
      "  0.3644351  -0.05361459  0.43501051 -0.07777776  0.0028258   0.42424812\n",
      "  0.83246109  0.96115373  0.46342421  0.47146842  0.31372632  0.59729643]\n",
      "epoch 72\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015045597493118625 R2: 0.9135853118831717 time: 1703257759.1591566\n",
      "batch_idx: 1 loss: 0.000980043866875107 R2: 0.913686229601605 time: 1703257767.0402415\n",
      "Training [24%] Loss: 0.0012423018080934848 time: 1703257767.0402415\n",
      "weight: [ 0.78058188 -0.19285316 -0.11948685  1.19175946  0.29445574 -0.30572904\n",
      "  0.35963128  0.46938226 -0.11605536  0.29708494  0.80167745  0.98179964\n",
      "  0.36482773 -0.05341391  0.43518609 -0.07789432  0.00271371  0.42413786\n",
      "  0.83233172  0.96107627  0.46349339  0.47119114  0.31312007  0.59662627]\n",
      "epoch 73\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015025088047425426 R2: 0.913774020955063 time: 1703257775.0143309\n",
      "batch_idx: 1 loss: 0.0009766364522176382 R2: 0.9138652867589723 time: 1703257782.448177\n",
      "Training [24%] Loss: 0.0012395726284800904 time: 1703257782.448177\n",
      "weight: [ 0.78365546 -0.19266357 -0.11937316  1.19167314  0.29440807 -0.30584512\n",
      "  0.35987193  0.4694785  -0.11351441  0.29706112  0.80167184  0.98182173\n",
      "  0.36521631 -0.05319862  0.43537569 -0.07801781  0.00258746  0.42401367\n",
      "  0.83223198  0.96104165  0.46358962  0.47088947  0.31250993  0.59594919]\n",
      "epoch 74\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001500565241758945 R2: 0.9139578631874729 time: 1703257789.406639\n",
      "batch_idx: 1 loss: 0.00097365237919462 R2: 0.9140403949127561 time: 1703257796.443891\n",
      "Training [25%] Loss: 0.0012371088104767825 time: 1703257796.443891\n",
      "weight: [ 0.78674496 -0.19247153 -0.11925707  1.19158656  0.29435973 -0.30596245\n",
      "  0.36011185  0.46953007 -0.11099417  0.29701316  0.80166069  0.98184351\n",
      "  0.36560689 -0.05298068  0.43556772 -0.07814278  0.00245946  0.42388776\n",
      "  0.83215103  0.96099822  0.46364119  0.47061698  0.3118877   0.59526267]\n",
      "epoch 75\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014979823247226252 R2: 0.9141379008063095 time: 1703257803.2620656\n",
      "batch_idx: 1 loss: 0.00097155769666879 R2: 0.9142177113121186 time: 1703257810.2988183\n",
      "Training [25%] Loss: 0.0012347700106957076 time: 1703257810.2988183\n",
      "weight: [ 0.7898618  -0.19228468 -0.11914523  1.191498    0.29431449 -0.30607714\n",
      "  0.36034344  0.46949031 -0.1085366   0.29690926  0.80163378  0.98185861\n",
      "  0.36600367 -0.05276799  0.43575457 -0.07826555  0.00233796  0.42376823\n",
      "  0.83208136  0.96091196  0.46360143  0.47040864  0.31124797  0.59456498]\n",
      "epoch 76\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00149436893055762 R2: 0.9143183981932166 time: 1703257817.4152644\n",
      "batch_idx: 1 loss: 0.0009703944876906596 R2: 0.9144004584020287 time: 1703257825.312903\n",
      "Training [25%] Loss: 0.00123238170912414 time: 1703257825.312903\n",
      "weight: [ 0.79300808 -0.19210437 -0.11903877  1.19140711  0.29427303 -0.3061885\n",
      "  0.36056548  0.46935251 -0.10614802  0.29674472  0.80158941  0.98186589\n",
      "  0.36640744 -0.05256193  0.43593489 -0.07838547  0.00222443  0.42365655\n",
      "  0.832021    0.96077709  0.46346363  0.47026957  0.3105899   0.59385581]\n",
      "epoch 77\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001489864299072638 R2: 0.9144996639563944 time: 1703257832.9808328\n",
      "batch_idx: 1 loss: 0.000969863534610183 R2: 0.9145856470165021 time: 1703257840.84566\n",
      "Training [26%] Loss: 0.0012298639168414104 time: 1703257840.84566\n",
      "weight: [ 0.79617577 -0.19192623 -0.11893381  1.19131498  0.29423317 -0.30629875\n",
      "  0.36078265  0.46914665 -0.10380204  0.29653974  0.80153386  0.98186909\n",
      "  0.36681561 -0.05235801  0.43611302 -0.07850466  0.00211414  0.42354806\n",
      "  0.831973    0.96061377  0.46325777  0.47017742  0.30991695  0.59313626]\n",
      "epoch 78\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014849892040582399 R2: 0.9146792649043369 time: 1703257848.4286208\n",
      "batch_idx: 1 loss: 0.0009694562066645633 R2: 0.9147692732705501 time: 1703257855.6248648\n",
      "Training [26%] Loss: 0.0012272227053614017 time: 1703257855.6248648\n",
      "weight: [ 0.79935033 -0.19174299 -0.11882402  1.19122343  0.29419123 -0.30641167\n",
      "  0.36100278  0.46892185 -0.10145528  0.29632746  0.80147767  0.9818746\n",
      "  0.36722361 -0.05214872  0.43629627 -0.07862672  0.00199909  0.42343489\n",
      "  0.83194297  0.96045566  0.46303297  0.47009544  0.30923491  0.59240825]\n",
      "epoch 79\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014803183765490196 R2: 0.9148572076550401 time: 1703257862.608624\n",
      "batch_idx: 1 loss: 0.0009686568915010097 R2: 0.9149509408988024 time: 1703257869.7911422\n",
      "Training [26%] Loss: 0.0012244876340250146 time: 1703257869.7911422\n",
      "weight: [ 0.8025171  -0.19154802 -0.11870365  1.19113424  0.29414381 -0.3065307\n",
      "  0.36123312  0.46872346 -0.09906776  0.29613843  0.80143061  0.98188837\n",
      "  0.36762705 -0.05192724  0.43649123 -0.07875495  0.00187195  0.42330982\n",
      "  0.83193589  0.96033366  0.46283458  0.46998961  0.3085492   0.59167364]\n",
      "epoch 80\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014762205111779547 R2: 0.9150364404413269 time: 1703257876.8491971\n",
      "batch_idx: 1 loss: 0.0009671753117852023 R2: 0.9151323659518125 time: 1703257884.1483052\n",
      "Training [27%] Loss: 0.0012216979114815785 time: 1703257884.1483052\n",
      "weight: [ 0.80566734 -0.19133814 -0.11856998  1.19104835  0.29408922 -0.30665756\n",
      "  0.36147744  0.46857509 -0.09661888  0.29598844  0.80139775  0.98191345\n",
      "  0.36802351 -0.0516903   0.43670111 -0.07889101  0.00172909  0.42316929\n",
      "  0.8319536   0.96026316  0.46268622  0.46984216  0.30786273  0.59093349]\n",
      "epoch 81\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014727687316034284 R2: 0.91521883818957 time: 1703257891.8732152\n",
      "batch_idx: 1 loss: 0.0009650682668543511 R2: 0.9153139778413882 time: 1703257899.725704\n",
      "Training [27%] Loss: 0.0012189184992288898 time: 1703257899.725704\n",
      "weight: [ 0.80880133 -0.1911145  -0.11842399  1.19096558  0.29402797 -0.30679169\n",
      "  0.36173495  0.46847228 -0.094113    0.2958743   0.80137799  0.98194903\n",
      "  0.36841341 -0.05143909  0.43692476 -0.07903442  0.00157168  0.42301444\n",
      "  0.83199404  0.9602397   0.4625834   0.4696564   0.30717504  0.59018768]\n",
      "epoch 82\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014697751706813239 R2: 0.9154031509800407 time: 1703257907.2700915\n",
      "batch_idx: 1 loss: 0.0009626627468875311 R2: 0.9154949295781452 time: 1703257915.3324213\n",
      "Training [27%] Loss: 0.0012162189587844275 time: 1703257915.3324213\n",
      "weight: [ 0.81192724 -0.1908815  -0.11826944  1.19088485  0.29396227 -0.30693084\n",
      "  0.36200132  0.46838905 -0.0915735   0.29577828  0.80136546  0.98199133\n",
      "  0.36879945 -0.05117816  0.43715776 -0.07918301  0.00140453  0.42285002\n",
      "  0.83205224  0.96024359  0.46250017  0.46945175  0.30648306  0.58943517]\n",
      "epoch 83\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014668944807229541 R2: 0.9155871552963353 time: 1703257922.7607799\n",
      "batch_idx: 1 loss: 0.000960350771693959 R2: 0.9156752938533037 time: 1703257930.0655446\n",
      "Training [28%] Loss: 0.0012136226262084565 time: 1703257930.0655446\n",
      "weight: [ 0.81505648 -0.19064449 -0.11811085  1.19080474  0.29389486 -0.30707221\n",
      "  0.36227113  0.46829281 -0.0890296   0.29567819  0.80135272  0.9820356\n",
      "  0.36918517 -0.05091303  0.43739476 -0.07933413  0.00123358  0.42268185\n",
      "  0.83212242  0.96025056  0.46240394  0.46925274  0.30578282  0.58867453]\n",
      "epoch 84\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014637780363802005 R2: 0.9157700812841802 time: 1703257937.7160864\n",
      "batch_idx: 1 loss: 0.0009584021021297583 R2: 0.9158563777347947 time: 1703257945.1611474\n",
      "Training [28%] Loss: 0.0012110900692549795 time: 1703257945.1611474\n",
      "weight: [ 8.18197937e-01 -1.90407429e-01 -1.17951509e-01  1.19072417e+00\n",
      "  2.93827776e-01 -3.07213733e-01  3.62540350e-01  4.68159891e-01\n",
      " -8.65025851e-02  2.95557881e-01  8.01334285e-01  9.82078283e-01\n",
      "  3.69573302e-01 -5.06477699e-02  4.37631827e-01 -7.94857837e-02\n",
      "  1.06323180e-03  4.22514275e-01  8.32200121e-01  9.60242731e-01\n",
      "  4.62271014e-01  4.69077204e-01  3.05071385e-01  5.87904666e-01]\n",
      "epoch 85\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014602328575700893 R2: 0.9159523039550207 time: 1703257953.0448728\n",
      "batch_idx: 1 loss: 0.0009568791698079551 R2: 0.916038940767893 time: 1703257960.916771\n",
      "Training [28%] Loss: 0.001208556013689022 time: 1703257960.916771\n",
      "weight: [ 8.21353827e-01 -1.90171445e-01 -1.17792333e-01  1.19064284e+00\n",
      "  2.93761610e-01 -3.07354812e-01  3.62807989e-01  4.67984813e-01\n",
      " -8.39976312e-02  2.95413517e-01  8.01308747e-01  9.82118370e-01\n",
      "  3.69964594e-01 -5.03835465e-02  4.37867812e-01 -7.96374053e-02\n",
      "  8.94745386e-04  4.22348532e-01  8.32283510e-01  9.60215194e-01\n",
      "  4.62095936e-01  4.68929307e-01  3.04348061e-01  5.87125308e-01]\n",
      "epoch 86\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014562978651620827 R2: 0.9161339507324187 time: 1703257968.8983424\n",
      "batch_idx: 1 loss: 0.0009556510865170696 R2: 0.9162222900253927 time: 1703257976.4907484\n",
      "Training [29%] Loss: 0.0012059744758395761 time: 1703257976.4907484\n",
      "weight: [ 8.24518921e-01 -1.89934969e-01 -1.17631959e-01  1.19056127e+00\n",
      "  2.93695485e-01 -3.07496316e-01  3.63076047e-01  4.67780162e-01\n",
      " -8.15039817e-02  2.95253464e-01  8.01278782e-01  9.82157458e-01\n",
      "  3.70357732e-01 -5.01187541e-02  4.38104288e-01 -7.97898528e-02\n",
      "  7.26281109e-04  4.22182812e-01  8.32373286e-01  9.60175908e-01\n",
      "  4.61891285e-01  4.68799573e-01  3.03614409e-01  5.86337037e-01]\n",
      "epoch 87\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014521901359300356 R2: 0.9163148771864094 time: 1703257983.359001\n",
      "batch_idx: 1 loss: 0.0009544759232300148 R2: 0.9164053155830627 time: 1703257990.9790177\n",
      "Training [29%] Loss: 0.001203333029580025 time: 1703257990.9790177\n",
      "weight: [ 8.27683335e-01 -1.89694979e-01 -1.17467836e-01  1.19048047e+00\n",
      "  2.93627722e-01 -3.07639921e-01  3.63348191e-01  4.67568306e-01\n",
      " -7.90022670e-02  2.95092713e-01  8.01249345e-01  9.82198603e-01\n",
      "  3.70750163e-01 -4.98502949e-02  4.38344277e-01 -7.99447730e-02\n",
      "  5.54291487e-04  4.22013623e-01  8.32471562e-01  9.60139840e-01\n",
      "  4.61679429e-01  4.68671092e-01  3.02873273e-01  5.85540959e-01]\n",
      "epoch 88\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001448168156761955 R2: 0.916495487393483 time: 1703257998.7206502\n",
      "batch_idx: 1 loss: 0.0009531207101922997 R2: 0.9165876054408535 time: 1703258005.7357202\n",
      "Training [29%] Loss: 0.0012006444334771273 time: 1703258005.7357202\n",
      "weight: [ 8.30837253e-01 -1.89448716e-01 -1.17297650e-01  1.19040141e+00\n",
      "  2.93556749e-01 -3.07787181e-01  3.63627846e-01  4.67369898e-01\n",
      " -7.64746574e-02  2.94945118e-01  8.01225070e-01  9.82244684e-01\n",
      "  3.71139412e-01 -4.95753435e-02  4.38590541e-01 -8.01037052e-02\n",
      "  3.75484122e-04  4.21837727e-01  8.32580308e-01  9.60120838e-01\n",
      "  4.61481021e-01  4.68528208e-01  3.02127328e-01  5.84738143e-01]\n",
      "epoch 89\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014444044299143817 R2: 0.91667662222179 time: 1703258012.9289412\n",
      "batch_idx: 1 loss: 0.0009514710294048661 R2: 0.9167692820424522 time: 1703258020.6567566\n",
      "Training [30%] Loss: 0.001197937729659624 time: 1703258020.6567566\n",
      "weight: [ 8.33975206e-01 -1.89194990e-01 -1.17120406e-01  1.19032458e+00\n",
      "  2.93481841e-01 -3.07938803e-01  3.63916664e-01  4.67194806e-01\n",
      " -7.39128240e-02  2.94817290e-01  8.01208182e-01  9.82297075e-01\n",
      "  3.71524213e-01 -4.92926898e-02  4.38844266e-01 -8.02673664e-02\n",
      "  1.88363998e-04  4.21653654e-01  8.32700162e-01  9.60125249e-01\n",
      "  4.61305930e-01  4.68363390e-01  3.01377897e-01  5.83929147e-01]\n",
      "epoch 90\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001440925832354769 R2: 0.9168586169323898 time: 1703258028.46868\n",
      "batch_idx: 1 loss: 0.0009495725312562365 R2: 0.9169504069467275 time: 1703258036.092204\n",
      "Training [30%] Loss: 0.0011952491818055027 time: 1703258036.092204\n",
      "weight: [ 8.37097868e-01 -1.88934550e-01 -1.16936701e-01  1.19024983e+00\n",
      "  2.93403341e-01 -3.08094427e-01  3.64214045e-01  4.67039360e-01\n",
      " -7.13203351e-02  2.94706750e-01  8.01197824e-01  9.82355201e-01\n",
      "  3.71904933e-01 -4.90031107e-02  4.39104706e-01 -8.04354244e-02\n",
      " -6.29632537e-06  4.21462163e-01  8.32830090e-01  9.60149985e-01\n",
      "  4.61150484e-01  4.68179362e-01  3.00624556e-01  5.83113822e-01]\n",
      "epoch 91\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014376270629490808 R2: 0.9170409761686031 time: 1703258043.0242107\n",
      "batch_idx: 1 loss: 0.000947583978553705 R2: 0.9171310181112802 time: 1703258050.1322486\n",
      "Training [30%] Loss: 0.0011926055207513928 time: 1703258050.1322486\n",
      "weight: [ 8.40210682e-01 -1.88669475e-01 -1.16748207e-01  1.19017655e+00\n",
      "  2.93322358e-01 -3.08252938e-01  3.64517771e-01  4.66890315e-01\n",
      " -6.87091442e-02  2.94604595e-01  8.01190924e-01  9.82417082e-01\n",
      "  3.72283168e-01 -4.87087446e-02  4.39369781e-01 -8.06068012e-02\n",
      " -2.06128329e-04  4.21265585e-01  8.32967931e-01  9.60185322e-01\n",
      "  4.61001438e-01  4.67986132e-01  2.99865603e-01  5.82291485e-01]\n",
      "epoch 92\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014343370909424228 R2: 0.9172229916211017 time: 1703258057.1570387\n",
      "batch_idx: 1 loss: 0.0009456799441126486 R2: 0.9173114253456085 time: 1703258064.2900596\n",
      "Training [31%] Loss: 0.0011900085175275358 time: 1703258064.2900596\n",
      "weight: [ 8.43320266e-01 -1.88402030e-01 -1.16556727e-01  1.19010401e+00\n",
      "  2.93240128e-01 -3.08413098e-01  3.64825332e-01  4.66732733e-01\n",
      " -6.60926644e-02  2.94500804e-01  8.01183999e-01  9.82480472e-01\n",
      "  3.72660786e-01 -4.84119178e-02  4.39637227e-01 -8.07802899e-02\n",
      " -4.08503228e-04  4.21066505e-01  8.33111429e-01  9.60220451e-01\n",
      "  4.60843857e-01  4.67795027e-01  2.99099076e-01  5.81461318e-01]\n",
      "epoch 93\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014309082161752362 R2: 0.9174043029042422 time: 1703258071.4979446\n",
      "batch_idx: 1 loss: 0.0009439646308255247 R2: 0.917492015962632 time: 1703258079.224455\n",
      "Training [31%] Loss: 0.0011874364235003804 time: 1703258079.224455\n",
      "weight: [ 8.46430558e-01 -1.88133613e-01 -1.16363351e-01  1.19003177e+00\n",
      "  2.93157414e-01 -3.08574142e-01  3.65135190e-01  4.66557477e-01\n",
      " -6.34792187e-02  2.94389275e-01  8.01174897e-01  9.82543984e-01\n",
      "  3.73038941e-01 -4.81140688e-02  4.39905644e-01 -8.09551485e-02\n",
      " -6.11800283e-04  4.20866517e-01  8.33259186e-01  9.60248724e-01\n",
      "  4.60668601e-01  4.67612997e-01  2.98323757e-01  5.80622801e-01]\n",
      "epoch 94\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014272861464898758 R2: 0.9175848493384544 time: 1703258087.1239731\n",
      "batch_idx: 1 loss: 0.0009424356893654243 R2: 0.9176728145233561 time: 1703258094.897564\n",
      "Training [31%] Loss: 0.00118486091792765 time: 1703258094.897564\n",
      "weight: [ 8.49540652e-01 -1.87864290e-01 -1.16168090e-01  1.18995986e+00\n",
      "  2.93074212e-01 -3.08736067e-01  3.65447402e-01  4.66364740e-01\n",
      " -6.08689656e-02  2.94270192e-01  8.01163653e-01  9.82607642e-01\n",
      "  3.73417547e-01 -4.78152709e-02  4.40174966e-01 -8.11313869e-02\n",
      " -8.16005032e-04  4.20665637e-01  8.33411092e-01  9.60270129e-01\n",
      "  4.60475864e-01  4.67439894e-01  2.97539670e-01  5.79775943e-01]\n",
      "epoch 95\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014235245512874805 R2: 0.9177646740194232 time: 1703258102.7953677\n",
      "batch_idx: 1 loss: 0.0009410028359366331 R2: 0.9178534637051501 time: 1703258110.0063484\n",
      "Training [32%] Loss: 0.001182263693612057 time: 1703258110.0063484\n",
      "weight: [ 8.52645268e-01 -1.87593048e-01 -1.15970098e-01  1.18988874e+00\n",
      "  2.92989869e-01 -3.08899500e-01  3.65763366e-01  4.66162477e-01\n",
      " -5.82552934e-02  2.94148976e-01  8.01152153e-01  9.82672673e-01\n",
      "  3.73795426e-01 -4.75144934e-02  4.40446208e-01 -8.13096471e-02\n",
      " -1.02244003e-03  4.20462562e-01  8.33568085e-01  9.60290163e-01\n",
      "  4.60273601e-01  4.67269644e-01  2.96747912e-01  5.78921224e-01]\n",
      "epoch 96\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014197408066445288 R2: 0.9179439581580631 time: 1703258117.1829288\n",
      "batch_idx: 1 loss: 0.0009395443571506565 R2: 0.9180335891931002 time: 1703258124.4196196\n",
      "Training [32%] Loss: 0.0011796425818975927 time: 1703258124.4196196\n",
      "weight: [ 0.85573738 -0.18731853 -0.11576827  1.18981905  0.29290351 -0.30906528\n",
      "  0.36608495  0.46596122 -0.05562936  0.29403279  0.80114293  0.98274073\n",
      "  0.37417098 -0.04721036  0.44072073 -0.08149079 -0.00123288  0.42025554\n",
      "  0.83373147  0.96031618  0.46007234  0.46709418  0.29594996  0.57805931]\n",
      "epoch 97\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014160460782178387 R2: 0.9181230244049375 time: 1703258131.6953602\n",
      "batch_idx: 1 loss: 0.0009379722609808542 R2: 0.9182130238233087 time: 1703258139.3921046\n",
      "Training [32%] Loss: 0.0011770091695993464 time: 1703258139.3921046\n",
      "weight: [ 0.85881145 -0.18703981 -0.11556185  1.18975124  0.29281451 -0.30923402\n",
      "  0.36641349  0.46576837 -0.05298504  0.29392671  0.80113779  0.98281303\n",
      "  0.374543   -0.04690192  0.44099945 -0.08167544 -0.00144859  0.42004334\n",
      "  0.83390221  0.96035336  0.45987949  0.4669078   0.29514688  0.57719071]\n",
      "epoch 98\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014124914134272509 R2: 0.9183020958133359 time: 1703258147.2251835\n",
      "batch_idx: 1 loss: 0.000936272775046329 R2: 0.9183917527967649 time: 1703258154.891907\n",
      "Training [33%] Loss: 0.0011743820942367899 time: 1703258154.891907\n",
      "weight: [ 0.86186554 -0.18675683 -0.11535078  1.18968546  0.29272276 -0.30940579\n",
      "  0.36674923  0.4655849  -0.05032184  0.29383151  0.80113706  0.98288979\n",
      "  0.37491117 -0.04658915  0.44128243 -0.08186371 -0.00166976  0.41982578\n",
      "  0.83408046  0.96040244  0.45969602  0.46670972  0.29433885  0.57631552]\n",
      "epoch 99\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014090530580428283 R2: 0.9184810886534975 time: 1703258162.6017413\n",
      "batch_idx: 1 loss: 0.0009345022422772994 R2: 0.9185698450548763 time: 1703258169.6085212\n",
      "Training [33%] Loss: 0.001171777650160064 time: 1703258169.6085212\n",
      "weight: [ 0.86490135 -0.18647033 -0.11513561  1.18962149  0.29262864 -0.30958023\n",
      "  0.36709138  0.46540584 -0.0476444   0.29374397  0.80113959  0.98297033\n",
      "  0.37527604 -0.0462728   0.44156892 -0.08205523 -0.00189555  0.41960366\n",
      "  0.8342657   0.96045997  0.45951696  0.46650373  0.29352522  0.57543345]\n",
      "epoch 100\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001405656582001702 R2: 0.918659707630197 time: 1703258176.5850735\n",
      "batch_idx: 1 loss: 0.0009327460202591979 R2: 0.9187474581946449 time: 1703258183.6667156\n",
      "Training [33%] Loss: 0.00116920130113045 time: 1703258183.6667156\n",
      "weight: [ 0.86792227 -0.18618136 -0.1149171   1.18955896  0.29253273 -0.30975673\n",
      "  0.36743871  0.46522369 -0.04495954  0.29365919  0.80114363  0.98305353\n",
      "  0.37563859 -0.04595393  0.4418579  -0.08224944 -0.00212474  0.4193782\n",
      "  0.83445711  0.96052079  0.45933482  0.46629555  0.29270494  0.57454402]\n",
      "epoch 101\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001402222943739072 R2: 0.918837684763578 time: 1703258190.9305825\n",
      "batch_idx: 1 loss: 0.0009310688100370452 R2: 0.9189247664196925 time: 1703258199.205192\n",
      "Training [34%] Loss: 0.0011666458768880587 time: 1703258199.205192\n",
      "weight: [ 0.87093078 -0.18589072 -0.11469584  1.1894976   0.29243549 -0.30993486\n",
      "  0.36779027  0.46503269 -0.04227259  0.29357341  0.80114784  0.98313854\n",
      "  0.37599955 -0.04563339  0.44214854 -0.08244588 -0.00235637  0.41915035\n",
      "  0.8346541   0.96058093  0.45914381  0.46608962  0.2918772   0.57364687]\n",
      "epoch 102\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013987111979997164 R2: 0.919014895837506 time: 1703258206.9566689\n",
      "batch_idx: 1 loss: 0.0009294843061775757 R2: 0.9191018126373158 time: 1703258214.932889\n",
      "Training [34%] Loss: 0.001164097752088646 time: 1703258214.932889\n",
      "weight: [ 0.87392666 -0.18559865 -0.11447199  1.18943738  0.292337   -0.31011453\n",
      "  0.36814587  0.46483145 -0.03958507  0.29348584  0.80115192  0.9832252\n",
      "  0.376359   -0.04531141  0.4424406  -0.08264448 -0.00259022  0.4189203\n",
      "  0.8348566   0.96063948  0.45894257  0.465887    0.29104182  0.57274191]\n",
      "epoch 103\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001395135254360929 R2: 0.9191913495864481 time: 1703258223.3106003\n",
      "batch_idx: 1 loss: 0.0009279561947158175 R2: 0.9192784675108638 time: 1703258231.5853271\n",
      "Training [34%] Loss: 0.0011615457245383732 time: 1703258231.5853271\n",
      "weight: [ 0.8769068  -0.18530486 -0.11424528  1.18937854  0.292237   -0.31029597\n",
      "  0.3685061   0.46462293 -0.03689476  0.29339856  0.80115663  0.98331405\n",
      "  0.37671636 -0.0449877   0.4427344  -0.08284552 -0.00282682  0.41868755\n",
      "  0.83506505  0.96069857  0.45873405  0.46568539  0.29019926  0.57182937]\n",
      "epoch 104\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013915481417067703 R2: 0.9193671596233738 time: 1703258239.2904568\n",
      "batch_idx: 1 loss: 0.0009264250162943053 R2: 0.9194545418632009 time: 1703258247.1890514\n",
      "Training [35%] Loss: 0.001158986579000538 time: 1703258247.1890514\n",
      "weight: [ 0.8798667  -0.18500879 -0.11401528  1.18932145  0.29213504 -0.31047959\n",
      "  0.36887189  0.46441207 -0.03419773  0.29331499  0.80116326  0.98340596\n",
      "  0.37707067 -0.04466171  0.44303047 -0.08304942 -0.003067    0.41845128\n",
      "  0.83528008  0.96076164  0.45852319  0.46548098  0.28935027  0.57090964]\n",
      "epoch 105\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013880071591839147 R2: 0.9195424907734638 time: 1703258254.8484068\n",
      "batch_idx: 1 loss: 0.0009248436569111203 R2: 0.9196299077879646 time: 1703258263.204911\n",
      "Training [35%] Loss: 0.0011564254080475174 time: 1703258263.204911\n",
      "weight: [ 0.88280255 -0.18471007 -0.11378169  1.18926642  0.29203079 -0.3106657\n",
      "  0.36924401  0.4642027  -0.03149103  0.29323782  0.8011728   0.98350163\n",
      "  0.37742119 -0.04433308  0.44332919 -0.08325653 -0.00331142  0.41821083\n",
      "  0.83550218  0.96083138  0.45831382  0.46527077  0.28849548  0.56998304]\n",
      "epoch 106\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001384542413393707 R2: 0.9197174496628764 time: 1703258270.8097305\n",
      "batch_idx: 1 loss: 0.0009232013066161288 R2: 0.9198045335373031 time: 1703258278.7441947\n",
      "Training [35%] Loss: 0.0011538718600049179 time: 1703258278.7441947\n",
      "weight: [ 0.88571267 -0.18440872 -0.11354449  1.18921356  0.29192416 -0.31085438\n",
      "  0.36962265  0.46399557 -0.02877434  0.29316765  0.8011855   0.98360124\n",
      "  0.37776764 -0.04400183  0.44363054 -0.08346694 -0.0035602   0.4179661\n",
      "  0.83573143  0.96090829  0.4581067   0.46505416  0.28763503  0.56904966]\n",
      "epoch 107\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013811452491991143 R2: 0.919892004209783 time: 1703258286.5218601\n",
      "batch_idx: 1 loss: 0.0009215237066200813 R2: 0.9199784686484234 time: 1703258294.0387468\n",
      "Training [36%] Loss: 0.0011513344779095977 time: 1703258294.0387468\n",
      "weight: [ 0.88859768 -0.18410512 -0.11330394  1.18916277  0.29181533 -0.31104543\n",
      "  0.37000744  0.46378835 -0.02605     0.29310301  0.80120081  0.98370446\n",
      "  0.37811029 -0.04366835  0.44393414 -0.08368048 -0.00381294  0.41771747\n",
      "  0.83596754  0.9609907   0.45789948  0.46483295  0.28676861  0.56810936]\n",
      "epoch 108\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013777795122943389 R2: 0.9200660173722215 time: 1703258301.1499455\n",
      "batch_idx: 1 loss: 0.0009198526407155131 R2: 0.9201518123772157 time: 1703258308.3430872\n",
      "Training [36%] Loss: 0.001148816076504926 time: 1703258308.3430872\n",
      "weight: [ 0.89145931 -0.18379982 -0.11306042  1.18911386  0.29170461 -0.31123855\n",
      "  0.37039779  0.46357737 -0.02332148  0.29304153  0.80121784  0.98381072\n",
      "  0.37844967 -0.04333321  0.44423943 -0.08389685 -0.00406899  0.41746558\n",
      "  0.83621003  0.96107597  0.45768849  0.46460997  0.28589567  0.56716186]\n",
      "epoch 109\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013744062878641382 R2: 0.9202393491088655 time: 1703258315.3155184\n",
      "batch_idx: 1 loss: 0.0009182195817564592 R2: 0.9203246529374903 time: 1703258322.616979\n",
      "Training [36%] Loss: 0.0011463129348102986 time: 1703258322.616979\n",
      "weight: [ 0.89429876 -0.18349328 -0.11281422  1.1890667   0.29159222 -0.31143352\n",
      "  0.37079323  0.46335983 -0.02059151  0.29298143  0.80123591  0.98391956\n",
      "  0.37878618 -0.04299688  0.44454598 -0.08411584 -0.00432787  0.41721091\n",
      "  0.83645851  0.96116208  0.45747096  0.46438738  0.2850158   0.56620696]\n",
      "epoch 110\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013710066887022403 R2: 0.9204119293678474 time: 1703258330.103695\n",
      "batch_idx: 1 loss: 0.0009166294403451921 R2: 0.9204970037195823 time: 1703258338.0257638\n",
      "Training [37%] Loss: 0.0011438180645237162 time: 1703258338.0257638\n",
      "weight: [ 0.8971156  -0.18318566 -0.11256544  1.18902128  0.29147822 -0.31163027\n",
      "  0.37119373  0.46313525 -0.01786083  0.29292245  0.80125489  0.98403094\n",
      "  0.37911983 -0.04265953  0.44485359 -0.0843374  -0.00458944  0.41695359\n",
      "  0.8367128   0.96124854  0.45724637  0.46416557  0.28412893  0.56524462]\n",
      "epoch 111\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013675898496044632 R2: 0.9205837738433689 time: 1703258345.4719715\n",
      "batch_idx: 1 loss: 0.00091506195620987 R2: 0.9206687968919034 time: 1703258353.0840158\n",
      "Training [37%] Loss: 0.0011413259029071665 time: 1703258353.0840158\n",
      "weight: [ 0.8999078  -0.18287692 -0.11231401  1.18897776  0.29136245 -0.31182894\n",
      "  0.37159962  0.46290528 -0.01512837  0.29286576  0.80127522  0.98414514\n",
      "  0.37945027 -0.04232113  0.44516233 -0.08456168 -0.00485394  0.41669339\n",
      "  0.83697293  0.96133633  0.4570164   0.46394323  0.28323536  0.56427501]\n",
      "epoch 112\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013641833388566861 R2: 0.9207549613035517 time: 1703258360.4387522\n",
      "batch_idx: 1 loss: 0.000913487305829153 R2: 0.9208399381636003 time: 1703258367.393449\n",
      "Training [37%] Loss: 0.0011388353223429197 time: 1703258367.393449\n",
      "weight: [ 0.90267271 -0.18256693 -0.11205983  1.18893634  0.29124473 -0.31202968\n",
      "  0.3720114   0.46267238 -0.01239236  0.29281305  0.80129756  0.98426262\n",
      "  0.379777   -0.04198154  0.44547233 -0.08478888 -0.00512173  0.41642996\n",
      "  0.837239    0.961427    0.4567835   0.46371842  0.2823355   0.56329835]\n",
      "epoch 113\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013608141875175808 R2: 0.9209255821174154 time: 1703258374.5867453\n",
      "batch_idx: 1 loss: 0.0009118850169012139 R2: 0.9210103662885535 time: 1703258381.4740922\n",
      "Training [38%] Loss: 0.0011363496022093974 time: 1703258381.4740922\n",
      "weight: [ 0.90540832 -0.18225563 -0.11180284  1.18889719  0.29112491 -0.31223262\n",
      "  0.37242942  0.46243824 -0.00965168  0.29276551  0.80132234  0.98438366\n",
      "  0.38009964 -0.04164075  0.44578363 -0.08501914 -0.00539303  0.41616307\n",
      "  0.83751098  0.9615215   0.45654936  0.46348982  0.28142966  0.56231483]\n",
      "epoch 114\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013574932038571564 R2: 0.9210956783121427 time: 1703258388.5963817\n",
      "batch_idx: 1 loss: 0.0009102546207932763 R2: 0.9211800779737949 time: 1703258395.6823382\n",
      "Training [38%] Loss: 0.0011338739123252163 time: 1703258395.6823382\n",
      "weight: [ 0.90811401 -0.18194319 -0.11154313  1.18886032  0.29100302 -0.31243773\n",
      "  0.37285372  0.46220286 -0.00690668  0.29272319  0.80134958  0.98450829\n",
      "  0.38041816 -0.0412989   0.44609606 -0.08525246 -0.00566777  0.4158928\n",
      "  0.83778864  0.96161962  0.45631399  0.46325739  0.28051785  0.56132446]\n",
      "epoch 115\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013542112861284635 R2: 0.9212652193530649 time: 1703258402.7131066\n",
      "batch_idx: 1 loss: 0.000908612722077814 R2: 0.9213491194639121 time: 1703258410.328862\n",
      "Training [38%] Loss: 0.0011314120041031389 time: 1703258410.328862\n",
      "weight: [ 0.9107904  -0.18162992 -0.11128089  1.18882567  0.29087918 -0.31264486\n",
      "  0.37328407  0.46196483 -0.00415887  0.29268517  0.8013789   0.98463625\n",
      "  0.38073278 -0.04095631  0.44640934 -0.0854887  -0.00594564  0.41561944\n",
      "  0.8380716   0.96172014  0.45607596  0.46302224  0.27959986  0.56032712]\n",
      "epoch 116\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001350948089682701 R2: 0.9214341324971359 time: 1703258418.038538\n",
      "batch_idx: 1 loss: 0.0009069801797214637 R2: 0.9215175548404353 time: 1703258425.5959752\n",
      "Training [39%] Loss: 0.0011289641347020823 time: 1703258425.5959752\n",
      "weight: [ 0.9134385  -0.18131614 -0.11101631  1.18879313  0.29075357 -0.31285386\n",
      "  0.37372018  0.46172239 -0.00141006  0.29265033  0.80140982  0.98476721\n",
      "  0.38104384 -0.04061334  0.44672312 -0.08572771 -0.00622629  0.41534335\n",
      "  0.83835942  0.9618216   0.45583351  0.46278574  0.27867541  0.55932266]\n",
      "epoch 117\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013476861350025086 R2: 0.9216023560291411 time: 1703258432.874061\n",
      "batch_idx: 1 loss: 0.0009053687114495024 R2: 0.9216854247310942 time: 1703258439.8422782\n",
      "Training [39%] Loss: 0.0011265274232260055 time: 1703258439.8422782\n",
      "weight: [ 0.91605872 -0.18100212 -0.11074955  1.18876263  0.29062629 -0.31306461\n",
      "  0.3741619   0.46147455  0.00133859  0.29261803  0.80144208  0.98490098\n",
      "  0.38135152 -0.04027024  0.44703714 -0.08596938 -0.00650947  0.41506478\n",
      "  0.83865174  0.96192308  0.45558567  0.46254867  0.27774435  0.55831099]\n",
      "epoch 118\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013444210610732467 R2: 0.9217698744182163 time: 1703258446.8442419\n",
      "batch_idx: 1 loss: 0.0009037751924194486 R2: 0.9218527227216905 time: 1703258453.7124603\n",
      "Training [39%] Loss: 0.0011240981267463476 time: 1703258453.7124603\n",
      "weight: [ 0.91865046 -0.18068797 -0.11048066  1.18873421  0.29049735 -0.3132771\n",
      "  0.37460931  0.46122158  0.00408699  0.29258848  0.80147572  0.98503761\n",
      "  0.38165576 -0.03992716  0.44735128 -0.08621373 -0.00679513  0.41478375\n",
      "  0.8389483   0.96202449  0.45533271  0.4623108   0.27680673  0.55729214]\n",
      "epoch 119\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013411622059979972 R2: 0.9219367210136842 time: 1703258460.8207617\n",
      "batch_idx: 1 loss: 0.0009021859735598443 R2: 0.922019407836015 time: 1703258468.7519376\n",
      "Training [40%] Loss: 0.0011216740897789209 time: 1703258468.7519376\n",
      "weight: [ 0.92121239 -0.18037375 -0.11020966  1.18870799  0.29036665 -0.3134914\n",
      "  0.37506266  0.46096464  0.00683578  0.29256246  0.80151105  0.98517728\n",
      "  0.38195633 -0.03958414  0.4476655  -0.08646084 -0.00708341  0.41450016\n",
      "  0.83924896  0.96212636  0.45507576  0.46207121  0.27586276  0.55626624]\n",
      "epoch 120\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013379245141193583 R2: 0.9221029535597012 time: 1703258476.0617251\n",
      "batch_idx: 1 loss: 0.0009005870934335943 R2: 0.9221854393098987 time: 1703258483.1500099\n",
      "Training [40%] Loss: 0.0011192558037764764 time: 1703258483.1500099\n",
      "weight: [ 0.92374317 -0.1800595  -0.10993656  1.18868406  0.29023413 -0.31370756\n",
      "  0.37552219  0.46070487  0.00958564  0.29254079  0.80154838  0.98532019\n",
      "  0.382253   -0.03924122  0.44797976 -0.08671079 -0.00737441  0.41421388\n",
      "  0.83955355  0.96222924  0.454816    0.46182898  0.27491266  0.55523342]\n",
      "epoch 121\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013347181561909579 R2: 0.9222686174051657 time: 1703258490.3125248\n",
      "batch_idx: 1 loss: 0.0008989731537520464 R2: 0.9223508049951834 time: 1703258497.4156404\n",
      "Training [40%] Loss: 0.0011168456549715022 time: 1703258497.4156404\n",
      "weight: [ 0.92624214 -0.17974532 -0.10966141  1.18866248  0.29009977 -0.3139256\n",
      "  0.37598804  0.46044275  0.01233663  0.29252378  0.8015878   0.98546642\n",
      "  0.38254567 -0.03889855  0.44829393 -0.08696361 -0.00766813  0.41392493\n",
      "  0.83986183  0.96233318  0.45455387  0.46158373  0.27395653  0.55419372]\n",
      "epoch 122\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013315427763218807 R2: 0.9224337203028405 time: 1703258504.4550185\n",
      "batch_idx: 1 loss: 0.0008973493890744351 R2: 0.9225155277273986 time: 1703258511.5855591\n",
      "Training [41%] Loss: 0.0011144460826981578 time: 1703258511.5855591\n",
      "weight: [ 0.92870942 -0.17943142 -0.10938432  1.18864323  0.28996361 -0.31414544\n",
      "  0.37646015  0.46017783  0.01508807  0.29251118  0.80162919  0.98561588\n",
      "  0.38283444 -0.03855631  0.44860784 -0.08721926 -0.00796443  0.41363344\n",
      "  0.8401735   0.96243763  0.45428895  0.46133581  0.2729943   0.55314712]\n",
      "epoch 123\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001328389322220458 R2: 0.9225982365970934 time: 1703258519.388161\n",
      "batch_idx: 1 loss: 0.0008957265605625634 R2: 0.9226796505029922 time: 1703258527.2188222\n",
      "Training [41%] Loss: 0.0011120579413915106 time: 1703258527.2188222\n",
      "weight: [ 0.93114565 -0.17911801 -0.1091054   1.18862624  0.28982577 -0.31436699\n",
      "  0.37693839  0.45990921  0.01783891  0.29250241  0.80167229  0.98576838\n",
      "  0.38311952 -0.03821474  0.44892124 -0.08747763 -0.00826309  0.41333964\n",
      "  0.8404882   0.96254172  0.45402033  0.46108591  0.27202581  0.55209351]\n",
      "epoch 124\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001325247176935137 R2: 0.9227621343554022 time: 1703258534.440651\n",
      "batch_idx: 1 loss: 0.0008941130456312623 R2: 0.9228432110091307 time: 1703258541.3812025\n",
      "Training [41%] Loss: 0.0011096801112831997 time: 1703258541.3812025\n",
      "weight: [ 0.93355127 -0.17880532 -0.10882477  1.18861147  0.28968632 -0.31459017\n",
      "  0.37742265  0.4596362   0.02058826  0.29249702  0.80171689  0.98592377\n",
      "  0.38340105 -0.03787406  0.44923394 -0.08773865 -0.00856391  0.4130437\n",
      "  0.84080562  0.96264474  0.45374733  0.4608346   0.27105095  0.55103283]\n",
      "epoch 125\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013221112184759174 R2: 0.9229254024705213 time: 1703258548.6412864\n",
      "batch_idx: 1 loss: 0.0008925097116993753 R2: 0.9230062224706307 time: 1703258555.5002797\n",
      "Training [42%] Loss: 0.0011073104650876464 time: 1703258555.5002797\n",
      "weight: [ 0.9359262  -0.17849348 -0.1085425   1.18859892  0.28954529 -0.31481495\n",
      "  0.37791295  0.45935873  0.02333574  0.292495    0.80176296  0.98608203\n",
      "  0.38367908 -0.03753442  0.44954577 -0.08800231 -0.00886681  0.41274571\n",
      "  0.84112551  0.9627464   0.45346985  0.46058193  0.2700697   0.54996507]\n",
      "epoch 126\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013189841840012826 R2: 0.9230880602474152 time: 1703258562.513223\n",
      "batch_idx: 1 loss: 0.00089091052152571 R2: 0.9231686742483273 time: 1703258569.564859\n",
      "Training [42%] Loss: 0.0011049473527634962 time: 1703258569.564859\n",
      "weight: [ 0.93826986 -0.17818261 -0.10825864  1.18858864  0.28940265 -0.31504133\n",
      "  0.37840944  0.45907726  0.02608146  0.29249668  0.80181062  0.98624324\n",
      "  0.38395351 -0.03719594  0.44985665 -0.08826864 -0.00917182  0.41244565\n",
      "  0.84144766  0.96284681  0.45318839  0.46032752  0.26908217  0.54889028]\n",
      "epoch 127\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013158734426627291 R2: 0.9232501467162075 time: 1703258576.7541487\n",
      "batch_idx: 1 loss: 0.0008893076219220391 R2: 0.9233305496433666 time: 1703258583.9308429\n",
      "Training [42%] Loss: 0.001102590532292384 time: 1703258583.9308429\n",
      "weight: [ 0.94058153 -0.17787278 -0.10797322  1.18858071  0.28925836 -0.31526935\n",
      "  0.37891226  0.45879245  0.02882565  0.29250252  0.80186004  0.98640752\n",
      "  0.38422422 -0.03685871  0.45016648 -0.08853768 -0.00947897  0.41214348\n",
      "  0.84177191  0.96294619  0.45290357  0.46007087  0.26808848  0.54780855]\n",
      "epoch 128\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001312785162245699 R2: 0.9234116987801689 time: 1703258592.2053788\n",
      "batch_idx: 1 loss: 0.0008876968614430951 R2: 0.9234918454896848 time: 1703258600.380046\n",
      "Training [43%] Loss: 0.001100241011844397 time: 1703258600.380046\n",
      "weight: [ 0.94286081 -0.1775641  -0.10768629  1.18857516  0.2891124  -0.31549901\n",
      "  0.37942153  0.45850459  0.03156826  0.29251276  0.8019113   0.98657493\n",
      "  0.38449113 -0.03652284  0.45047515 -0.08880946 -0.00978825  0.41183921\n",
      "  0.84209807  0.96304455  0.45261571  0.45981172  0.26708871  0.54671991]\n",
      "epoch 129\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013097201929061699 R2: 0.9235727337353554 time: 1703258607.7362683\n",
      "batch_idx: 1 loss: 0.0008860799403288825 R2: 0.9236525799817652 time: 1703258615.1187003\n",
      "Training [43%] Loss: 0.0010979000666175261 time: 1703258615.1187003\n",
      "weight: [ 0.94510777 -0.17725674 -0.10739794  1.18857199  0.28896481 -0.31573028\n",
      "  0.37993724  0.45821353  0.03430887  0.29252732  0.80196435  0.98674542\n",
      "  0.3847543  -0.03618849  0.45078252 -0.08908395 -0.0100996   0.41153292\n",
      "  0.84242591  0.96314158  0.45232465  0.4595502   0.26608282  0.54562436]\n",
      "epoch 130\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013066742023566378 R2: 0.9237332482687541 time: 1703258621.9224944\n",
      "batch_idx: 1 loss: 0.0008844622113314806 R2: 0.9238127855821319 time: 1703258628.9967005\n",
      "Training [43%] Loss: 0.0010955682068440591 time: 1703258628.9967005\n",
      "weight: [ 0.94732283 -0.17695084 -0.10710823  1.18857118  0.28881563 -0.3159631\n",
      "  0.38045936  0.45791879  0.0370468   0.2925459   0.80201904  0.98691892\n",
      "  0.38501386 -0.03585584  0.45108842 -0.08936112 -0.01041286  0.41122473\n",
      "  0.8427552   0.96323677  0.45202991  0.45928671  0.26507074  0.54452183]\n",
      "epoch 131\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0013036413390032427 R2: 0.9238932327127258 time: 1703258635.846944\n",
      "batch_idx: 1 loss: 0.0008828482928901814 R2: 0.9239724934970581 time: 1703258643.271949\n",
      "Training [44%] Loss: 0.001093244815946712 time: 1703258643.271949\n",
      "weight: [ 0.94950634 -0.17664657 -0.10681724  1.18857269  0.28866492 -0.31619742\n",
      "  0.38098785  0.45761996  0.03978142  0.29256829  0.80207525  0.98709533\n",
      "  0.3852699  -0.03552504  0.45139269 -0.08964091 -0.01072793  0.41091476\n",
      "  0.84308571  0.96332966  0.45173108  0.45902159  0.26405239  0.54341227]\n",
      "epoch 132\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001300618377394988 R2: 0.9240526879655926 time: 1703258651.129609\n",
      "batch_idx: 1 loss: 0.0008812388722490352 R2: 0.924131721228545 time: 1703258658.776399\n",
      "Training [44%] Loss: 0.0010909286248220115 time: 1703258658.776399\n",
      "weight: [ 0.95165838 -0.17634406 -0.10652503  1.18857652  0.2885127  -0.31643322\n",
      "  0.38152272  0.45731695  0.04251236  0.29259444  0.80213294  0.98727463\n",
      "  0.38552245 -0.03519624  0.45169519 -0.08992331 -0.01104475  0.41060308\n",
      "  0.84341725  0.96342003  0.45142807  0.45875492  0.26302776  0.54229569]\n",
      "epoch 133\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012976063826404868 R2: 0.9242116327947703 time: 1703258665.7503092\n",
      "batch_idx: 1 loss: 0.0008796307579182613 R2: 0.9242904719509395 time: 1703258672.597125\n",
      "Training [44%] Loss: 0.001088618570279374 time: 1703258672.597125\n",
      "weight: [ 0.95377873 -0.17604343 -0.10623165  1.18858272  0.28835894 -0.3166705\n",
      "  0.38206407  0.45700999  0.04523952  0.29262454  0.80219218  0.98745688\n",
      "  0.38577149 -0.03486955  0.45199583 -0.09020835 -0.01136329  0.41028969\n",
      "  0.84374967  0.96350786  0.45112111  0.45848653  0.26199689  0.5411721 ]\n",
      "epoch 134\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012946090843123435 R2: 0.9243700979895623 time: 1703258679.6381195\n",
      "batch_idx: 1 loss: 0.0008780196608642396 R2: 0.9244487447582188 time: 1703258686.631428\n",
      "Training [45%] Loss: 0.0010863143725882915 time: 1703258686.631428\n",
      "weight: [ 0.95586711 -0.17574476 -0.10593714  1.18859132  0.28820364 -0.31690928\n",
      "  0.38261201  0.45669938  0.04796288  0.29265883  0.80225306  0.98764214\n",
      "  0.38601694 -0.03454508  0.4522945  -0.09049604 -0.01168358  0.40997458\n",
      "  0.84408283  0.9635932   0.45081051  0.45821618  0.26095987  0.54004155]\n",
      "epoch 135\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012916296046265468 R2: 0.9245281131021942 time: 1703258693.728265\n",
      "batch_idx: 1 loss: 0.0008764033218799877 R2: 0.9246065466521761 time: 1703258700.959425\n",
      "Training [45%] Loss: 0.0010840164632532673 time: 1703258700.959425\n",
      "weight: [ 0.9579234  -0.17544817 -0.10564156  1.18860235  0.28804678 -0.31714954\n",
      "  0.38316662  0.45638528  0.05068228  0.29269744  0.8023156   0.98783045\n",
      "  0.38625878 -0.03422294  0.45259108 -0.09078641 -0.0120056   0.40965778\n",
      "  0.84441657  0.963676    0.4504964   0.45794378  0.25991672  0.53890407]\n",
      "epoch 136\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012886681306524751 R2: 0.9246856960853842 time: 1703258708.2646694\n",
      "batch_idx: 1 loss: 0.0008747826864179154 R2: 0.924763897329101 time: 1703258715.4204357\n",
      "Training [45%] Loss: 0.0010817254085351952 time: 1703258715.4204357\n",
      "weight: [ 0.95994781 -0.1751538  -0.10534497  1.18861581  0.28788838 -0.31739128\n",
      "  0.38372792  0.45606755  0.05339734  0.29274034  0.80237978  0.98802179\n",
      "  0.38649706 -0.03390328  0.45288546 -0.09107944 -0.01232928  0.40933933\n",
      "  0.84475074  0.96375603  0.45017868  0.45766943  0.25886743  0.53775964]\n",
      "epoch 137\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012857220671486577 R2: 0.9248428531549282 time: 1703258722.6294258\n",
      "batch_idx: 1 loss: 0.000873160564710917 R2: 0.9249208243796538 time: 1703258730.3455818\n",
      "Training [46%] Loss: 0.0010794413159297873 time: 1703258730.3455818\n",
      "weight: [ 0.96194067 -0.17486176 -0.10504741  1.18863169  0.28772847 -0.31763445\n",
      "  0.3842959   0.45574595  0.05610757  0.29278738  0.80244551  0.98821611\n",
      "  0.38673184 -0.03358622  0.4531775  -0.09137511 -0.01265454  0.40901933\n",
      "  0.84508515  0.96383298  0.44985707  0.45739338  0.25781195  0.53660823]\n",
      "epoch 138\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012827881871538432 R2: 0.9249995876476996 time: 1703258738.0171528\n",
      "batch_idx: 1 loss: 0.0008715391351460826 R2: 0.9250773535646173 time: 1703258745.3665152\n",
      "Training [46%] Loss: 0.0010771636611499628 time: 1703258745.3665152\n",
      "weight: [ 0.96390233 -0.17457219 -0.10474894  1.18864997  0.28756707 -0.31787903\n",
      "  0.38487057  0.45542025  0.05881252  0.29283845  0.80251272  0.98841338\n",
      "  0.3869632  -0.0332719   0.45346707 -0.0916734  -0.01298132  0.40869783\n",
      "  0.84541966  0.96390655  0.44953137  0.45711582  0.25675023  0.5354498 ]\n",
      "epoch 139\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012798649049858598 R2: 0.9251559099109155 time: 1703258752.3620095\n",
      "batch_idx: 1 loss: 0.0008699183070677562 R2: 0.9252335019158899 time: 1703258759.5626633\n",
      "Training [46%] Loss: 0.001074891606026808 time: 1703258759.5626633\n",
      "weight: [ 0.96583293 -0.1742852  -0.10444962  1.18867067  0.2874042  -0.318125\n",
      "  0.38545197  0.45509043  0.0615119   0.29289358  0.8025814   0.98861359\n",
      "  0.38719116 -0.03296044  0.45375406 -0.09197431 -0.01330957  0.40837488\n",
      "  0.84575411  0.96397659  0.44920155  0.4568368   0.25568228  0.53428437]\n",
      "epoch 140\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012769529703045503 R2: 0.925311840696328 time: 1703258766.5392148\n",
      "batch_idx: 1 loss: 0.0008682960302167231 R2: 0.925389278553993 time: 1703258773.5906632\n",
      "Training [47%] Loss: 0.0010726245002606366 time: 1703258773.5906632\n",
      "weight: [ 0.96773249 -0.1740009  -0.10414949  1.1886938   0.28723985 -0.31837238\n",
      "  0.38604018  0.45475661  0.06420555  0.29295288  0.80265158  0.98881678\n",
      "  0.3874157  -0.03265195  0.45403836 -0.09227784 -0.01363929  0.4080505\n",
      "  0.84608838  0.96404307  0.44886774  0.45655625  0.25460814  0.53311194]\n",
      "epoch 141\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001274054300917114 R2: 0.9254674064508089 time: 1703258780.6407604\n",
      "batch_idx: 1 loss: 0.0008666700265455614 R2: 0.9255446915738432 time: 1703258787.6750534\n",
      "Training [47%] Loss: 0.0010703621637313378 time: 1703258787.6750534\n",
      "weight: [ 0.96960102 -0.17371938 -0.10384859  1.1887194   0.287074   -0.31862115\n",
      "  0.38663528  0.45441896  0.06689334  0.29301649  0.8027233   0.989023\n",
      "  0.38763681 -0.03234653  0.45431988 -0.09258403 -0.01397045  0.40772468\n",
      "  0.84642235  0.96410596  0.44853009  0.45627406  0.25352782  0.53193254]\n",
      "epoch 142\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012711701140492948 R2: 0.9256226310746498 time: 1703258795.1302338\n",
      "batch_idx: 1 loss: 0.0008650394230492539 R2: 0.9256997548280784 time: 1703258803.454436\n",
      "Training [47%] Loss: 0.0010681047685492744 time: 1703258803.454436\n",
      "weight: [ 0.97143866 -0.17344076 -0.10354697  1.18874747  0.28690666 -0.31887131\n",
      "  0.38723733  0.45407752  0.06957502  0.29308448  0.80279657  0.98923226\n",
      "  0.38785447 -0.03204431  0.4545985  -0.09289286 -0.01430305  0.40739745\n",
      "  0.84675588  0.96416515  0.44818864  0.45599024  0.25244137  0.53074619]\n",
      "epoch 143\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001268299880859938 R2: 0.9257775308667207 time: 1703258811.108711\n",
      "batch_idx: 1 loss: 0.0008634050562487941 R2: 0.9258544894091398 time: 1703258818.3138793\n",
      "Training [48%] Loss: 0.001065852468554366 time: 1703258818.3138793\n",
      "weight: [ 0.97324572 -0.17316514 -0.10324469  1.18877802  0.28673784 -0.31912286\n",
      "  0.38784636  0.45373217  0.07225026  0.29315682  0.80287136  0.98944454\n",
      "  0.38806875 -0.03174539  0.45487411 -0.09320435 -0.01463702  0.40706886\n",
      "  0.84708884  0.96422048  0.4478433   0.4557049   0.25134874  0.52955286]\n",
      "epoch 144\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012654417793948602 R2: 0.925932116164262 time: 1703258825.2560759\n",
      "batch_idx: 1 loss: 0.0008617684146885124 R2: 0.9260089194040482 time: 1703258832.476974\n",
      "Training [48%] Loss: 0.0010636050970416863 time: 1703258832.476974\n",
      "weight: [ 0.97502257 -0.17289265 -0.10294178  1.18881104  0.28656755 -0.31937576\n",
      "  0.38846238  0.4533828   0.0749187   0.29323344  0.80294761  0.98965983\n",
      "  0.38827969 -0.0314499   0.45514661 -0.09351846 -0.01497233  0.40673896\n",
      "  0.8474211   0.96427171  0.44749392  0.4554182   0.25024993  0.52835254]\n",
      "epoch 145\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012625940707748076 R2: 0.9260863974606297 time: 1703258839.6333668\n",
      "batch_idx: 1 loss: 0.0008601302452582879 R2: 0.9261630659335408 time: 1703258846.9468813\n",
      "Training [48%] Loss: 0.0010613621580165477 time: 1703258846.9468813\n",
      "weight: [ 0.97676953 -0.17262337 -0.10263828  1.18884653  0.28639581 -0.31963001\n",
      "  0.38908544  0.4530293   0.07757999  0.29331433  0.80302529  0.98987812\n",
      "  0.38848734 -0.03115794  0.45541588 -0.09383521 -0.01530892  0.40640779\n",
      "  0.84775253  0.96431868  0.44714042  0.45513025  0.2491449   0.52714522]\n",
      "epoch 146\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012597561900129523 R2: 0.9262403905287904 time: 1703258854.6426425\n",
      "batch_idx: 1 loss: 0.0008584899624566247 R2: 0.9263169443698629 time: 1703258862.401169\n",
      "Training [49%] Loss: 0.0010591230762347886 time: 1703258862.401169\n",
      "weight: [ 0.97848684 -0.17235743 -0.10233425  1.1888845   0.28622262 -0.3198856\n",
      "  0.38971558  0.45267171  0.08023393  0.29339953  0.8031044   0.99009941\n",
      "  0.38869172 -0.03086962  0.45568183 -0.09415459 -0.01564678  0.40607537\n",
      "  0.84808302  0.96436131  0.44678283  0.45484108  0.24803367  0.5259309 ]\n",
      "epoch 147\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001256928740068659 R2: 0.9263941166391236 time: 1703258870.1171694\n",
      "batch_idx: 1 loss: 0.0008568462030426412 R2: 0.9264705665273306 time: 1703258877.481346\n",
      "Training [49%] Loss: 0.00105688747155565 time: 1703258877.481346\n",
      "weight: [ 0.98017464 -0.17209491 -0.10202972  1.18892496  0.28604796 -0.32014253\n",
      "  0.39035288  0.45231011  0.08288031  0.29348915  0.80318497  0.99032375\n",
      "  0.38889281 -0.03058506  0.45594435 -0.09447662 -0.01598589  0.40574172\n",
      "  0.84841246  0.96439953  0.44642123  0.45455064  0.24691627  0.5247096 ]\n",
      "epoch 148\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012541125610110461 R2: 0.9265475983578291 time: 1703258884.6793263\n",
      "batch_idx: 1 loss: 0.0008551979120112356 R2: 0.9266239453667422 time: 1703258892.0384195\n",
      "Training [49%] Loss: 0.0010546552365111408 time: 1703258892.0384195\n",
      "weight: [ 0.98183316 -0.17183591 -0.10172474  1.18896794  0.28587184 -0.32040079\n",
      "  0.3909974   0.45194458  0.08551897  0.29358325  0.80326699  0.99055115\n",
      "  0.38909062 -0.03030434  0.45620334 -0.09480131 -0.01632624  0.40540685\n",
      "  0.84874074  0.96443329  0.4460557   0.45425895  0.24579272  0.52348133]\n",
      "epoch 149\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012513077574883519 R2: 0.9267008548564958 time: 1703258899.1832952\n",
      "batch_idx: 1 loss: 0.0008535450107397928 R2: 0.926777098042703 time: 1703258906.0847318\n",
      "Training [50%] Loss: 0.0010524263841140723 time: 1703258906.0847318\n",
      "weight: [ 0.9834627  -0.17158054 -0.10141935  1.18901343  0.28569426 -0.32066039\n",
      "  0.39164919  0.45157509  0.08814962  0.29368187  0.80335047  0.99078163\n",
      "  0.38928517 -0.03002757  0.45645872 -0.09512865 -0.0166678   0.40507077\n",
      "  0.84906775  0.96446248  0.44568622  0.45396605  0.24466301  0.52224609]\n",
      "epoch 150\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001248513472191137 R2: 0.9268539005817354 time: 1703258913.6337414\n",
      "batch_idx: 1 loss: 0.0008518881721873621 R2: 0.9269300450382969 time: 1703258921.2026832\n",
      "Training [50%] Loss: 0.0010502008221892497 time: 1703258921.2026832\n",
      "weight: [ 0.98506361 -0.17132888 -0.10111359  1.18906144  0.28551522 -0.32092131\n",
      "  0.39230829  0.4512016   0.090772    0.293785    0.80343537  0.99101517\n",
      "  0.38947651 -0.02975486  0.45671037 -0.09545866 -0.01701055  0.40473353\n",
      "  0.8493934   0.96448696  0.44531272  0.45367206  0.24352714  0.52100388]\n",
      "epoch 151\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001245728475211667 R2: 0.9270067479039982 time: 1703258929.087113\n",
      "batch_idx: 1 loss: 0.0008502280220628421 R2: 0.9270828066059498 time: 1703258936.612096\n",
      "Training [50%] Loss: 0.0010479782486372546 time: 1703258936.612096\n",
      "weight: [ 0.98663626 -0.17108105 -0.1008075   1.18911197  0.28533474 -0.32118355\n",
      "  0.39297474  0.45082402  0.09338579  0.29389263  0.80352166  0.99125179\n",
      "  0.38966467 -0.02948631  0.45695821 -0.09579131 -0.01735445  0.40439516\n",
      "  0.84971758  0.9645066   0.44493515  0.4533771   0.2423851   0.51975469]\n",
      "epoch 152\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012429519648156514 R2: 0.9271594109889711 time: 1703258943.4743962\n",
      "batch_idx: 1 loss: 0.0008485645078469353 R2: 0.9272353997885865 time: 1703258950.4734464\n",
      "Training [51%] Loss: 0.0010457582363312934 time: 1703258950.4734464\n",
      "weight: [ 0.98818099 -0.17083712 -0.10050112  1.18916503  0.28515281 -0.32144709\n",
      "  0.39364858  0.45044236  0.09599076  0.29400478  0.80360933  0.99149147\n",
      "  0.38984968 -0.02922202  0.45720213 -0.09612663 -0.01769947  0.40405567\n",
      "  0.8500402   0.9645213   0.44455349  0.45308122  0.24123688  0.51849852]\n",
      "epoch 153\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001240183889783991 R2: 0.9273119074949685 time: 1703258957.4390008\n",
      "batch_idx: 1 loss: 0.0008468969303894278 R2: 0.9273878384119424 time: 1703258964.5219169\n",
      "Training [51%] Loss: 0.0010435404100867093 time: 1703258964.5219169\n",
      "weight: [ 0.98969805 -0.1705972  -0.10019448  1.18922062  0.28496943 -0.32171194\n",
      "  0.39432987  0.45005667  0.09858671  0.29412154  0.80369838  0.99173426\n",
      "  0.39003154 -0.02896208  0.45744206 -0.09646462 -0.01804562  0.40371508\n",
      "  0.85036118  0.96453101  0.44416779  0.45278445  0.2400825   0.51723538]\n",
      "epoch 154\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012374246000718793 R2: 0.9274642569714361 time: 1703258972.0287879\n",
      "batch_idx: 1 loss: 0.0008452245101290901 R2: 0.9275401356357229 time: 1703258979.661837\n",
      "Training [51%] Loss: 0.0010413245551004848 time: 1703258979.661837\n",
      "weight: [ 0.99118772 -0.17036137 -0.09988764  1.18927876  0.28478459 -0.3219781\n",
      "  0.39501869  0.44966698  0.10117345  0.29424297  0.80378881  0.99198017\n",
      "  0.39021026 -0.0287066   0.45767789 -0.09680528 -0.01839287  0.40337339\n",
      "  0.85068042  0.96453567  0.4437781   0.45248683  0.23892199  0.51596529]\n",
      "epoch 155\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012346742209993456 R2: 0.9276164777406516 time: 1703258987.404717\n",
      "batch_idx: 1 loss: 0.0008435469315481239 R2: 0.9276923065339308 time: 1703258995.2095091\n",
      "Training [52%] Loss: 0.0010391105762737347 time: 1703258995.2095091\n",
      "weight: [ 0.99265031 -0.17012973 -0.09958063  1.18933946  0.2845983  -0.32224556\n",
      "  0.39571508  0.44927333  0.10375076  0.29436911  0.80388064  0.99222922\n",
      "  0.39038585 -0.02845565  0.45790953 -0.09714864 -0.01874122  0.40303062\n",
      "  0.85099786  0.96453523  0.44338445  0.45218839  0.23775535  0.51468827]\n",
      "epoch 156\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012319323202708873 R2: 0.9277685850979018 time: 1703259002.7317858\n",
      "batch_idx: 1 loss: 0.0008418644095664803 R2: 0.9278443684905356 time: 1703259010.4761653\n",
      "Training [52%] Loss: 0.0010368983649186839 time: 1703259010.4761653\n",
      "weight: [ 0.99408617 -0.16990235 -0.09927348  1.18940272  0.28441054 -0.32251433\n",
      "  0.39641909  0.44887569  0.1063184   0.29449998  0.80397383  0.99248142\n",
      "  0.39055834 -0.02820935  0.4581369  -0.09749468 -0.01909065  0.40268679\n",
      "  0.85131341  0.96452958  0.44298681  0.45188925  0.23658259  0.5134043 ]\n",
      "epoch 157\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012291981051981299 R2: 0.927920592176634 time: 1703259017.4952536\n",
      "batch_idx: 1 loss: 0.0008401772951152017 R2: 0.9279963393597962 time: 1703259024.6649995\n",
      "Training [52%] Loss: 0.0010346877001566658 time: 1703259024.6649995\n",
      "weight: [ 0.99549569 -0.16967934 -0.09896623  1.18946855  0.28422134 -0.32278439\n",
      "  0.39713077  0.44847402  0.10887611  0.29463561  0.80406836  0.99273677\n",
      "  0.39072777 -0.02796777  0.45835991 -0.09784342 -0.01944113  0.40234192\n",
      "  0.851627    0.96451865  0.44258514  0.45158949  0.23540369  0.5121134 ]\n",
      "epoch 158\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012264709002373976 R2: 0.9280725123482896 time: 1703259031.6477435\n",
      "batch_idx: 1 loss: 0.0008384856293507748 R2: 0.928148235271508 time: 1703259038.5933256\n",
      "Training [53%] Loss: 0.0010324782647940863 time: 1703259038.5933256\n",
      "weight: [ 0.9968792  -0.16946078 -0.09865893  1.18953695  0.28403067 -0.32305575\n",
      "  0.39785017  0.44806832  0.11142368  0.29477603  0.80416422  0.99299529\n",
      "  0.39089414 -0.02773102  0.45857848 -0.09819485 -0.01979266  0.40199601\n",
      "  0.85193856  0.96450236  0.44217945  0.45128921  0.23421868  0.51081557]\n",
      "epoch 159\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012237504508660604 R2: 0.9282243608451678 time: 1703259045.544437\n",
      "batch_idx: 1 loss: 0.0008367890397407861 R2: 0.9283000700301092 time: 1703259053.024685\n",
      "Training [53%] Loss: 0.0010302697453034233 time: 1703259053.024685\n",
      "weight: [ 0.99823702 -0.16924674 -0.09835161  1.18960793  0.28383855 -0.3233284\n",
      "  0.39857733  0.44765863  0.11396089  0.29492129  0.8042614   0.993257\n",
      "  0.39105748 -0.02749917  0.45879251 -0.09854899 -0.02014522  0.40164908\n",
      "  0.85224803  0.96448065  0.44176975  0.45098846  0.23302756  0.50951083]\n",
      "epoch 160\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012210368172390208 R2: 0.9283761542862405 time: 1703259060.6604476\n",
      "batch_idx: 1 loss: 0.0008350870158246764 R2: 0.9284518564054094 time: 1703259068.1223443\n",
      "Training [53%] Loss: 0.0010280619165318485 time: 1703259068.1223443\n",
      "weight: [ 0.99956947 -0.16903732 -0.0980443   1.18968151  0.28364496 -0.32360235\n",
      "  0.39931233  0.44724498  0.11648757  0.29507146  0.80435991  0.99352192\n",
      "  0.39121779 -0.02727233  0.45900193 -0.09890585 -0.02049881  0.40130113\n",
      "  0.85255536  0.9644535   0.4413561   0.4506873   0.23183035  0.50819919]\n",
      "epoch 161\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012183300141044193 R2: 0.9285279088037592 time: 1703259075.4208145\n",
      "batch_idx: 1 loss: 0.0008333792643361258 R2: 0.9286036078981474 time: 1703259082.7723033\n",
      "Training [54%] Loss: 0.0010258546392202725 time: 1703259082.7723033\n",
      "weight: [ 1.00087686 -0.1688326  -0.09773706  1.18975769  0.28344989 -0.3238776\n",
      "  0.40005522  0.44682739  0.11900351  0.29522659  0.80445973  0.99379008\n",
      "  0.39137508 -0.02705057  0.45920666 -0.09926544 -0.02085343  0.40095217\n",
      "  0.85286047  0.96442086  0.44093851  0.45038579  0.23062708  0.50688067]\n",
      "epoch 162\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001215629753351782 R2: 0.9286796386152851 time: 1703259089.422192\n",
      "batch_idx: 1 loss: 0.0008316658178680429 R2: 0.9287553393305105 time: 1703259097.4695814\n",
      "Training [54%] Loss: 0.0010236477856099126 time: 1703259097.4695814\n",
      "weight: [ 1.00215955 -0.16863265 -0.0974299   1.18983647  0.28325335 -0.32415414\n",
      "  0.40080605  0.44640587  0.12150852  0.29538672  0.80456086  0.99406148\n",
      "  0.39152937 -0.02683397  0.4594066  -0.09962776 -0.02120906  0.40060221\n",
      "  0.85316332  0.96438267  0.440517    0.45008404  0.22941774  0.50555529]\n",
      "epoch 163\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012129355016447995 R2: 0.9288313562466051 time: 1703259105.8371878\n",
      "batch_idx: 1 loss: 0.000829946838804678 R2: 0.9289070658857528 time: 1703259113.0936134\n",
      "Training [54%] Loss: 0.0010214411702247387 time: 1703259113.0936134\n",
      "weight: [ 1.00341789 -0.16843757 -0.09712287  1.18991787  0.28305534 -0.32443198\n",
      "  0.40156486  0.44598042  0.12400237  0.29555188  0.80466326  0.99433614\n",
      "  0.39168068 -0.02662264  0.45960169 -0.09999281 -0.0215657   0.40025125\n",
      "  0.85346385  0.96433888  0.44009154  0.44978213  0.22820235  0.50422306]\n",
      "epoch 164\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012102467527845759 R2: 0.928983073963838 time: 1703259120.01228\n",
      "batch_idx: 1 loss: 0.0008282223419461582 R2: 0.9290588016701568 time: 1703259126.7623272\n",
      "Training [55%] Loss: 0.001019234547365367 time: 1703259126.7623272\n",
      "weight: [ 1.00465225 -0.16824741 -0.09681601  1.1900019   0.28285585 -0.32471112\n",
      "  0.40233172  0.44555104  0.12648487  0.29572213  0.80476694  0.99461407\n",
      "  0.39182904 -0.02641663  0.45979184 -0.10036062 -0.02192333  0.3998993\n",
      "  0.85376202  0.96428944  0.43966216  0.44948016  0.22698092  0.50288398]\n",
      "epoch 165\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012075632363249091 R2: 0.9291348049349496 time: 1703259133.747162\n",
      "batch_idx: 1 loss: 0.0008264920993197296 R2: 0.9292105591646915 time: 1703259140.7620447\n",
      "Training [55%] Loss: 0.0010170276678223194 time: 1703259140.7620447\n",
      "weight: [ 1.00586294 -0.16806227 -0.09650935  1.19008855  0.28265487 -0.32499155\n",
      "  0.40310666  0.44511776  0.12895583  0.29589751  0.80487187  0.9948953\n",
      "  0.39197444 -0.02621605  0.45997698 -0.10073118 -0.02228196  0.39954637\n",
      "  0.85405777  0.96423431  0.43922888  0.44917821  0.22575348  0.5015381 ]\n",
      "epoch 166\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0012048848832034295 R2: 0.929286563088582 time: 1703259148.0472662\n",
      "batch_idx: 1 loss: 0.0008247557856760409 R2: 0.929362349937972 time: 1703259155.212467\n",
      "Training [55%] Loss: 0.001014820334439735 time: 1703259155.212467\n",
      "weight: [ 1.0070503  -0.16788222 -0.09620293  1.19017784  0.28245241 -0.32527328\n",
      "  0.40388976  0.44468061  0.13141508  0.29607809  0.80497806  0.99517985\n",
      "  0.39211691 -0.02602096  0.46015703 -0.1011045  -0.02264158  0.39919246\n",
      "  0.85435107  0.96417348  0.43879174  0.44887635  0.22452003  0.50018541]\n",
      "epoch 167\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001202211617676728 R2: 0.9294383619747725 time: 1703259162.6851652\n",
      "batch_idx: 1 loss: 0.0008230131939585813 R2: 0.9295141857764454 time: 1703259169.7974045\n",
      "Training [56%] Loss: 0.0010126124058176546 time: 1703259169.7974045\n",
      "weight: [ 1.00821464 -0.16770733 -0.09589678  1.19026978  0.28224844 -0.32555631\n",
      "  0.40468106  0.44423964  0.13386244  0.29626393  0.80508548  0.99546774\n",
      "  0.39225646 -0.02583145  0.46033192 -0.1014806  -0.0230022   0.39883757\n",
      "  0.85464187  0.96410691  0.43835077  0.44857467  0.22328061  0.49882597]\n",
      "epoch 168\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011995431942056825 R2: 0.9295902138162255 time: 1703259176.5322704\n",
      "batch_idx: 1 loss: 0.0008212643109529733 R2: 0.9296660791128945 time: 1703259183.3424742\n",
      "Training [56%] Loss: 0.0010104037525793278 time: 1703259183.3424742\n",
      "weight: [ 1.00935633 -0.16753768 -0.09559095  1.19036437  0.28204298 -0.32584065\n",
      "  0.40548061  0.44379486  0.13629774  0.29645508  0.80519414  0.99575898\n",
      "  0.39239309 -0.0256476   0.46050158 -0.10185949 -0.0233638   0.3984817\n",
      "  0.85493013  0.96403457  0.43790598  0.44827326  0.22203524  0.49745978]\n",
      "epoch 169\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011968792235860029 R2: 0.929742129602942 time: 1703259192.2520194\n",
      "batch_idx: 1 loss: 0.0008195092046632116 R2: 0.9298180424425408 time: 1703259200.1874473\n",
      "Training [56%] Loss: 0.0010081942141246072 time: 1703259200.1874473\n",
      "weight: [ 1.01047569 -0.16737333 -0.09528547  1.19046163  0.28183601 -0.32612628\n",
      "  0.40628847  0.44334629  0.1387208   0.29665159  0.805304    0.9960536\n",
      "  0.39252683 -0.02546947  0.46066593 -0.10224116 -0.02372639  0.39812486\n",
      "  0.85521581  0.96395644  0.43745741  0.44797223  0.22078393  0.49608687]\n",
      "epoch 170\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001194219334460259 R2: 0.9298941199870605 time: 1703259207.2066758\n",
      "batch_idx: 1 loss: 0.000817747858513872 R2: 0.9299700874131671 time: 1703259213.8523011\n",
      "Training [57%] Loss: 0.0010059835964870655 time: 1703259213.8523011\n",
      "weight: [ 1.01157308 -0.16721436 -0.09498036  1.19056155  0.28162754 -0.32641322\n",
      "  0.40710469  0.44289394  0.14113143  0.29685352  0.80541505  0.99635161\n",
      "  0.39265769 -0.02529714  0.4608249  -0.10262562 -0.02408996  0.39776704\n",
      "  0.85549888  0.96387247  0.43700506  0.44767167  0.21952671  0.49470726]\n",
      "epoch 171\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011915632972058668 R2: 0.9300461960091976 time: 1703259220.687131\n",
      "batch_idx: 1 loss: 0.0008159801173473119 R2: 0.9301222244946674 time: 1703259227.4571943\n",
      "Training [57%] Loss: 0.0010037717072765894 time: 1703259227.4571943\n",
      "weight: [ 1.01264883 -0.16706083 -0.09467567  1.19066415  0.28141754 -0.32670147\n",
      "  0.40792931  0.44243786  0.14352949  0.29706092  0.80552728  0.99665302\n",
      "  0.39278569 -0.02513069  0.46097842 -0.1030129  -0.02445452  0.39740824\n",
      "  0.8557793   0.96378266  0.43654899  0.44737167  0.2182636   0.49332099]\n",
      "epoch 172\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011889109987812446 R2: 0.9301983689800075 time: 1703259234.1159685\n",
      "batch_idx: 1 loss: 0.0008142057791647979 R2: 0.9302744634576452 time: 1703259241.1406755\n",
      "Training [57%] Loss: 0.0010015583889730214 time: 1703259241.1406755\n",
      "weight: [ 1.01370324 -0.16691282 -0.09437144  1.19076942  0.28120603 -0.32699103\n",
      "  0.40876239  0.4419781   0.14591482  0.29727386  0.80564068  0.99695786\n",
      "  0.39291083 -0.02497018  0.46112643 -0.10340299 -0.02482006  0.39704847\n",
      "  0.85605703  0.96368699  0.43608922  0.44707232  0.21699463  0.49192808]\n",
      "epoch 173\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011862623159942165 R2: 0.9303506497442413 time: 1703259248.1022127\n",
      "batch_idx: 1 loss: 0.0008124247219529458 R2: 0.9304268140788781 time: 1703259255.2568038\n",
      "Training [58%] Loss: 0.000999343518973581 time: 1703259255.2568038\n",
      "weight: [ 1.01473665 -0.16677039 -0.0940677   1.1908774   0.28099299 -0.3272819\n",
      "  0.40960399  0.44151468  0.14828728  0.29749242  0.80575523  0.99726616\n",
      "  0.39303313 -0.02481569  0.46126887 -0.1037959  -0.0251866   0.39668772\n",
      "  0.85633205  0.96358545  0.43562581  0.44677372  0.21571984  0.49052859]\n",
      "epoch 174\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011836170250989536 R2: 0.9305030481220766 time: 1703259262.6573339\n",
      "batch_idx: 1 loss: 0.0008106369377415257 R2: 0.930579286349659 time: 1703259269.4974\n",
      "Training [58%] Loss: 0.0009971269814202397 time: 1703259269.4974\n",
      "weight: [ 1.0157494  -0.1666336  -0.09376448  1.19098806  0.28077842 -0.32757409\n",
      "  0.41045415  0.44104765  0.1506467   0.29771664  0.80587091  0.99757792\n",
      "  0.3931526  -0.02466727  0.46140566 -0.10419164 -0.02555412  0.39632599\n",
      "  0.85660433  0.96347803  0.43515878  0.44647596  0.21443924  0.48912252]\n",
      "epoch 175\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011809748297099396 R2: 0.9306555730428492 time: 1703259276.6087048\n",
      "batch_idx: 1 loss: 0.0008088424553679526 R2: 0.9307318900476671 time: 1703259284.192216\n",
      "Training [58%] Loss: 0.0009949086425389462 time: 1703259284.192216\n",
      "weight: [ 1.0167418  -0.16650251 -0.09346181  1.19110143  0.28056232 -0.32786759\n",
      "  0.41131291  0.44057704  0.15299294  0.29794659  0.8059877   0.99789316\n",
      "  0.39326926 -0.02452501  0.46153675 -0.10459022 -0.02592264  0.39596327\n",
      "  0.85687384  0.96336471  0.43468816  0.44617916  0.21315288  0.48770993]\n",
      "epoch 176\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011783354613541896 R2: 0.930808233136465 time: 1703259291.25313\n",
      "batch_idx: 1 loss: 0.0008070412450773213 R2: 0.9308846341796102 time: 1703259298.4071283\n",
      "Training [59%] Loss: 0.0009926883532157555 time: 1703259298.4071283\n",
      "weight: [ 1.01771418 -0.16637719 -0.09315974  1.19121751  0.28034467 -0.3281624\n",
      "  0.41218033  0.44010288  0.15532586  0.29818233  0.80610559  0.9982119\n",
      "  0.39338312 -0.02438896  0.46166207 -0.10499165 -0.02629216  0.39559956\n",
      "  0.85714055  0.96324548  0.434214    0.44588342  0.21186078  0.48629086]\n",
      "epoch 177\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011756987425612345 R2: 0.9309610371267738 time: 1703259305.4623408\n",
      "batch_idx: 1 loss: 0.0008052332019321545 R2: 0.9310375268623547 time: 1703259312.7920518\n",
      "Training [59%] Loss: 0.0009904659722466944 time: 1703259312.7920518\n",
      "weight: [ 1.01866687 -0.16625769 -0.09285829  1.1913363   0.28012547 -0.32845854\n",
      "  0.41305646  0.43962523  0.15764532  0.29842394  0.80622455  0.99853416\n",
      "  0.3934942  -0.02425919  0.46178157 -0.10539593 -0.02666268  0.39523487\n",
      "  0.85740443  0.96312034  0.43373635  0.44558883  0.21056298  0.48486533]\n",
      "epoch 178\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011730645560397662 R2: 0.9311139936580052 time: 1703259319.5373502\n",
      "batch_idx: 1 loss: 0.0008034182121584094 R2: 0.9311905756952397 time: 1703259326.337288\n",
      "Training [59%] Loss: 0.0009882413840990878 time: 1703259326.337288\n",
      "weight: [ 1.01960015 -0.16614407 -0.09255751  1.19145781  0.27990472 -0.32875601\n",
      "  0.41394135  0.43914413  0.1599512   0.29867148  0.80634457  0.99885996\n",
      "  0.3936025  -0.02413574  0.46189518 -0.10580307 -0.0270342   0.39486917\n",
      "  0.85766548  0.9629893   0.43325525  0.44529549  0.20925951  0.4834334 ]\n",
      "epoch 179\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011704327655387985 R2: 0.9312671108047853 time: 1703259333.4374976\n",
      "batch_idx: 1 loss: 0.000801596223038488 R2: 0.9313437881742204 time: 1703259340.6974866\n",
      "Training [60%] Loss: 0.0009860144942886433 time: 1703259340.6974866\n",
      "weight: [ 1.02051436 -0.16603639 -0.09225741  1.19158204  0.27968241 -0.3290548\n",
      "  0.41483504  0.43865964  0.16224337  0.29892503  0.80646562  0.99918931\n",
      "  0.39370805 -0.02401869  0.46200286 -0.10621309 -0.02740674  0.39450248\n",
      "  0.85792365  0.96285236  0.43277076  0.44500352  0.20795042  0.48199512]\n",
      "epoch 180\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011678031755498993 R2: 0.9314203958024804 time: 1703259348.2186244\n",
      "batch_idx: 1 loss: 0.0007997672453966622 R2: 0.9314971717171694 time: 1703259355.462123\n",
      "Training [60%] Loss: 0.0009837852104732808 time: 1703259355.462123\n",
      "weight: [ 1.0214098  -0.16593471 -0.09195804  1.19170901  0.27945854 -0.32935492\n",
      "  0.41573757  0.43817179  0.16452171  0.29918466  0.8065877   0.99952223\n",
      "  0.39381084 -0.0239081   0.46210455 -0.10662597 -0.02778029  0.39413477\n",
      "  0.85817894  0.9627095   0.43228292  0.44471301  0.20663575  0.48055052]\n",
      "epoch 181\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011651755645645126 R2: 0.9315738552376404 time: 1703259363.0321372\n",
      "batch_idx: 1 loss: 0.0007979312968109546 R2: 0.9316507333257137 time: 1703259371.2324772\n",
      "Training [60%] Loss: 0.0009815534306877335 time: 1703259371.2324772\n",
      "weight: [ 1.02228678 -0.16583906 -0.09165943  1.19183871  0.27923309 -0.32965638\n",
      "  0.416649    0.43768065  0.1667861   0.29945043  0.80671076  0.99985874\n",
      "  0.39391091 -0.023804    0.4622002  -0.10704175 -0.02815487  0.39376604\n",
      "  0.85843132  0.96256075  0.43179177  0.44442409  0.20531553  0.47909966]\n",
      "epoch 182\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011625497464870407 R2: 0.9317274954338612 time: 1703259378.4172957\n",
      "batch_idx: 1 loss: 0.0007960883529901805 R2: 0.9318044792800384 time: 1703259385.4575355\n",
      "Training [61%] Loss: 0.0009793190497386106 time: 1703259385.4575355\n",
      "weight: [ 1.0231456  -0.1657495  -0.09136161  1.19197115  0.27900607 -0.32995917\n",
      "  0.41756937  0.43718625  0.16903643  0.29972243  0.80683479  1.00019884\n",
      "  0.39400827 -0.02370646  0.46228975 -0.10746041 -0.02853049  0.3933963\n",
      "  0.85868078  0.96240611  0.43129738  0.44413684  0.20398982  0.47764259]\n",
      "epoch 183\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011599255928182264 R2: 0.9318813226027485 time: 1703259392.4624596\n",
      "batch_idx: 1 loss: 0.0007942383561379011 R2: 0.9319584151754794 time: 1703259399.6622887\n",
      "Training [61%] Loss: 0.0009770819744780637 time: 1703259399.6622887\n",
      "weight: [ 1.02398656 -0.16566609 -0.09106461  1.19210633  0.27877746 -0.33026329\n",
      "  0.41849872  0.43668867  0.17127259  0.30000073  0.80695976  1.00054256\n",
      "  0.39410292 -0.02361553  0.46237317 -0.10788197 -0.02890714  0.39302552\n",
      "  0.85892731  0.96224558  0.43079979  0.44385139  0.20265865  0.47617937]\n",
      "epoch 184\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011573029989243727 R2: 0.9320353426330217 time: 1703259406.572648\n",
      "batch_idx: 1 loss: 0.0007923812626900439 R2: 0.9321125462110655 time: 1703259413.542104\n",
      "Training [61%] Loss: 0.0009748421308072082 time: 1703259413.542104\n",
      "weight: [ 1.02480995 -0.16558886 -0.09076846  1.19224426  0.27854727 -0.33056876\n",
      "  0.41943709  0.43618796  0.17349449  0.30028541  0.80708565  1.00088991\n",
      "  0.39419489 -0.02353125  0.4624504  -0.10830643 -0.02928484  0.3926537\n",
      "  0.85917088  0.96207919  0.43029908  0.44356784  0.20132208  0.47471006]\n",
      "epoch 185\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011546818383584444 R2: 0.9321895607875395 time: 1703259420.722182\n",
      "batch_idx: 1 loss: 0.0007905170744079612 R2: 0.932266877387512 time: 1703259428.0823839\n",
      "Training [62%] Loss: 0.0009725994563832027 time: 1703259428.0823839\n",
      "weight: [ 1.02561606 -0.16551786 -0.09047319  1.19238494  0.27831549 -0.33087558\n",
      "  0.42038453  0.43568417  0.17570202  0.30057655  0.80721244  1.00124091\n",
      "  0.39428418 -0.02345368  0.4625214  -0.10873381 -0.02966361  0.39228083\n",
      "  0.85941148  0.96190695  0.42979529  0.4432863   0.19998016  0.4732347 ]\n",
      "epoch 186\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001152061955022649 R2: 0.9323439816387167 time: 1703259434.9564009\n",
      "batch_idx: 1 loss: 0.0007886458228043054 R2: 0.9324214134149529 time: 1703259442.0420473\n",
      "Training [62%] Loss: 0.0009703538889134773 time: 1703259442.0420473\n",
      "weight: [ 1.02640518 -0.16545313 -0.09017884  1.19252838  0.2780821  -0.33118374\n",
      "  0.42134107  0.43517737  0.17789509  0.30087422  0.8073401   1.00159556\n",
      "  0.39437082 -0.02338285  0.46258612 -0.10916409 -0.03004344  0.3919069\n",
      "  0.85964911  0.96172888  0.42928849  0.44300688  0.19863294  0.47175337]\n",
      "epoch 187\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011494431954865252 R2: 0.932498609274535 time: 1703259449.3324265\n",
      "batch_idx: 1 loss: 0.0007867675308245784 R2: 0.9325761584677992 time: 1703259456.8720443\n",
      "Training [62%] Loss: 0.0009681053631555518 time: 1703259456.8720443\n",
      "weight: [ 1.02717761 -0.16539471 -0.08988543  1.19267457  0.27784712 -0.33149326\n",
      "  0.42230677  0.43466761  0.18007362  0.30117851  0.80746859  1.00195389\n",
      "  0.39445483 -0.0233188   0.46264454 -0.1095973  -0.03042435  0.39153191\n",
      "  0.85988376  0.96154499  0.42877874  0.4427297   0.19728047  0.47026613]\n",
      "epoch 188\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011468254407746546 R2: 0.9326534475134454 time: 1703259464.5474834\n",
      "batch_idx: 1 loss: 0.0007848821963058779 R2: 0.9327311160699734 time: 1703259471.2772481\n",
      "Training [63%] Loss: 0.0009658538185402662 time: 1703259471.2772481\n",
      "weight: [ 1.02793361 -0.16534264 -0.08959299  1.19282352  0.27761052 -0.33180412\n",
      "  0.42328164  0.43415497  0.18223753  0.30148951  0.80759788  1.00231589\n",
      "  0.3945362  -0.02326158  0.46269661 -0.11003344 -0.03080635  0.39115583\n",
      "  0.8601154   0.96135532  0.4282661   0.44245487  0.19592281  0.46877304]\n",
      "epoch 189\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011442086036931253 R2: 0.9328084998929358 time: 1703259478.3193078\n",
      "batch_idx: 1 loss: 0.0007829898115795861 R2: 0.9328862892143917 time: 1703259485.6156569\n",
      "Training [63%] Loss: 0.0009635992076363557 time: 1703259485.6156569\n",
      "weight: [ 1.02867347 -0.16529695 -0.08930155  1.19297523  0.27737232 -0.33211635\n",
      "  0.42426574  0.43363951  0.18438673  0.30180729  0.80772796  1.00268159\n",
      "  0.39461498 -0.02321123  0.4627423  -0.11047251 -0.03118945  0.39077866\n",
      "  0.86034405  0.96115987  0.42775064  0.4421825   0.19456002  0.46727419]\n",
      "epoch 190\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011415926000465492 R2: 0.932963769474742 time: 1703259492.6654332\n",
      "batch_idx: 1 loss: 0.0007810903923213617 R2: 0.9330416805513411 time: 1703259499.702137\n",
      "Training [63%] Loss: 0.0009613414961839555 time: 1703259499.702137\n",
      "weight: [ 1.02939746 -0.16525768 -0.08901113  1.1931297   0.27713249 -0.33242993\n",
      "  0.4252591   0.4331213   0.18652116  0.30213196  0.80785879  1.00305099\n",
      "  0.39469116 -0.02316776  0.46278158 -0.11091451 -0.03157366  0.39040039\n",
      "  0.86056968  0.96095869  0.42723243  0.4419127   0.19319215  0.46576963]\n",
      "epoch 191\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011389773291446289 R2: 0.9331192587046265 time: 1703259507.0172052\n",
      "batch_idx: 1 loss: 0.0007791839827763387 R2: 0.9331972924276 time: 1703259513.9273736\n",
      "Training [64%] Loss: 0.0009590806559604838 time: 1703259513.9273736\n",
      "weight: [ 1.03010585 -0.16522485 -0.08872177  1.19328693  0.27689104 -0.33274488\n",
      "  0.42626176  0.43260041  0.18864076  0.30246358  0.80799034  1.00342411\n",
      "  0.39476477 -0.02313123  0.46281441 -0.11135945 -0.031959    0.390021\n",
      "  0.86079231  0.96075181  0.42671154  0.44164559  0.19181929  0.46425944]\n",
      "epoch 192\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011363626834493938 R2: 0.9332749694722816 time: 1703259521.1064246\n",
      "batch_idx: 1 loss: 0.000777270635392481 R2: 0.9333531267532138 time: 1703259528.1421864\n",
      "Training [64%] Loss: 0.0009568166594209374 time: 1703259528.1421864\n",
      "weight: [ 1.03079891 -0.16519849 -0.08843349  1.19344692  0.27664796 -0.33306119\n",
      "  0.42727374  0.43207691  0.19074546  0.30280226  0.80812256  1.00380095\n",
      "  0.39483583 -0.02310165  0.46284076 -0.11180734 -0.03234547  0.38964048\n",
      "  0.86101191  0.96053925  0.42618803  0.44138128  0.19044148  0.4627437 ]\n",
      "epoch 193\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011337485721242674 R2: 0.9334309032752879 time: 1703259535.347394\n",
      "batch_idx: 1 loss: 0.0007753503914432495 R2: 0.9335091848681885 time: 1703259542.2796845\n",
      "Training [64%] Loss: 0.0009545494817837585 time: 1703259542.2796845\n",
      "weight: [ 1.0314769  -0.16517863 -0.08814631  1.19360968  0.27640325 -0.33337887\n",
      "  0.42829508  0.43155087  0.1928352   0.30314808  0.80825544  1.00418151\n",
      "  0.39490436 -0.02307905  0.46286062 -0.11225817 -0.0327331   0.38925882\n",
      "  0.8612285   0.96032104  0.42566199  0.44111988  0.18905879  0.4612225 ]\n",
      "epoch 194\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011311349301686355 R2: 0.9335870612883099 time: 1703259549.3224049\n",
      "batch_idx: 1 loss: 0.0007734232840552551 R2: 0.9336654675582453 time: 1703259556.5895407\n",
      "Training [65%] Loss: 0.0009522791071119453 time: 1703259556.5895407\n",
      "weight: [ 1.03214008 -0.1651653  -0.08786026  1.1937752   0.2761569  -0.33369793\n",
      "  0.42932581  0.43102237  0.19490995  0.30350114  0.80838892  1.00456582\n",
      "  0.39497037 -0.02306346  0.46287396 -0.11271196 -0.03312189  0.388876\n",
      "  0.86144207  0.96009723  0.42513349  0.44086152  0.18767131  0.45969591]\n",
      "epoch 195\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001128521705227953 R2: 0.9337434442728911 time: 1703259563.2723627\n",
      "batch_idx: 1 loss: 0.0007714893566901851 R2: 0.9338219751804495 time: 1703259569.9922268\n",
      "Training [65%] Loss: 0.0009500055309590691 time: 1703259569.9922268\n",
      "weight: [ 1.03278871 -0.1651585  -0.08757536  1.19394347  0.27590891 -0.33401835\n",
      "  0.43036597  0.43049148  0.19696965  0.30386152  0.80852299  1.00495387\n",
      "  0.39503389 -0.02305489  0.46288076 -0.1131687  -0.03351186  0.38849202\n",
      "  0.86165261  0.95986785  0.42460261  0.44060629  0.18627909  0.45816403]\n",
      "epoch 196\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001125908840460315 R2: 0.9339000524530479 time: 1703259576.802308\n",
      "batch_idx: 1 loss: 0.0007695486737587535 R2: 0.9339787077402588 time: 1703259583.496509\n",
      "Training [65%] Loss: 0.0009477287571095342 time: 1703259583.496509\n",
      "weight: [ 1.03342303 -0.16515826 -0.08729164  1.19411451  0.27565927 -0.33434016\n",
      "  0.43141557  0.42995829  0.19901426  0.30422933  0.8086576   1.00534567\n",
      "  0.39509493 -0.02305337  0.462881   -0.1136284  -0.03390303  0.38810685\n",
      "  0.86186014  0.95963296  0.42406941  0.44035433  0.18488221  0.45662694]\n",
      "epoch 197\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011232962734874093 R2: 0.9340568855040552 time: 1703259590.472356\n",
      "batch_idx: 1 loss: 0.0007676013125385041 R2: 0.9341356648392575 time: 1703259597.1371176\n",
      "Training [66%] Loss: 0.0009454487930129567 time: 1703259597.1371176\n",
      "weight: [ 1.03404331 -0.1651646  -0.08700912  1.1942883   0.27540799 -0.33466335\n",
      "  0.43247466  0.42942287  0.20104376  0.30460467  0.8087927   1.00574122\n",
      "  0.39515352 -0.02305891  0.46287466 -0.11409105 -0.0342954   0.38772048\n",
      "  0.86206466  0.95939257  0.42353399  0.44010574  0.18348076  0.45508473]\n",
      "epoch 198\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011206839500601587 R2: 0.9342139426518867 time: 1703259603.962435\n",
      "batch_idx: 1 loss: 0.0007656473485977987 R2: 0.93429284557337 time: 1703259610.7724216\n",
      "Training [66%] Loss: 0.0009431656493289788 time: 1703259610.7724216\n",
      "weight: [ 1.03464978 -0.16517752 -0.08672781  1.19446484  0.27515505 -0.33498792\n",
      "  0.43354324  0.42888531  0.20305812  0.30498762  0.80892827  1.00614053\n",
      "  0.39520967 -0.02307152  0.46286174 -0.11455667 -0.034689    0.3873329\n",
      "  0.86226616  0.95914676  0.42299643  0.43986063  0.1820748   0.4535375 ]\n",
      "epoch 199\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011180718343883384 R2: 0.9343712227535124 time: 1703259617.5234852\n",
      "batch_idx: 1 loss: 0.0007636868525318669 R2: 0.9344502485083666 time: 1703259624.1375113\n",
      "Training [66%] Loss: 0.0009408793434601026 time: 1703259624.1375113\n",
      "weight: [ 1.03524269 -0.16519704 -0.08644775  1.19464413  0.27490045 -0.33531388\n",
      "  0.43462135  0.42834568  0.20505731  0.3053783   0.80906426  1.0065436\n",
      "  0.39526342 -0.02309121  0.46284222 -0.11502525 -0.03508384  0.38694408\n",
      "  0.86246466  0.95889555  0.4224568   0.43961913  0.18066443  0.45198535]\n",
      "epoch 200\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011154599046983512 R2: 0.9345287242687708 time: 1703259631.3820434\n",
      "batch_idx: 1 loss: 0.0007617198999647434 R2: 0.934607871752106 time: 1703259638.7822795\n",
      "Training [67%] Loss: 0.0009385899023315472 time: 1703259638.7822795\n",
      "weight: [ 1.03582228 -0.16522316 -0.08616894  1.19482617  0.27464419 -0.33564122\n",
      "  0.43570901  0.42780407  0.20704132  0.30577679  0.80920063  1.00695043\n",
      "  0.39531479 -0.023118    0.4628161  -0.11549679 -0.03547994  0.38655402\n",
      "  0.86266016  0.95863901  0.4219152   0.43938133  0.17924973  0.45042838]\n",
      "epoch 201\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011128481415194722 R2: 0.9346864451744998 time: 1703259645.9520938\n",
      "batch_idx: 1 loss: 0.0007597465809738638 R2: 0.9347657130268126 time: 1703259653.2781527\n",
      "Training [67%] Loss: 0.000936297361246668 time: 1703259653.2781527\n",
      "weight: [ 1.03638878 -0.16525588 -0.08589141  1.19501094  0.27438627 -0.33596996\n",
      "  0.43680624  0.42726058  0.20901014  0.30618321  0.80933734  1.00736102\n",
      "  0.39536379 -0.02315187  0.46278337 -0.1159713  -0.03587731  0.3861627\n",
      "  0.86285267  0.95837718  0.4213717   0.43914737  0.17783078  0.44886669]\n",
      "epoch 202\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001110236523561825 R2: 0.9348443829333105 time: 1703259660.5423064\n",
      "batch_idx: 1 loss: 0.0007577669978908591 R2: 0.9349237696583472 time: 1703259667.7611222\n",
      "Training [67%] Loss: 0.0009340017607263421 time: 1703259667.7611222\n",
      "weight: [ 1.03694242 -0.16529522 -0.08561517  1.19519845  0.27412668 -0.33630009\n",
      "  0.43791306  0.42671528  0.21096376  0.30659766  0.80947433  1.00777536\n",
      "  0.39541045 -0.02319284  0.46274403 -0.11644877 -0.03627597  0.38577009\n",
      "  0.8630422   0.95811013  0.4208264   0.43891734  0.17640767  0.44730039]\n",
      "epoch 203\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011076250348010343 R2: 0.9350025345493375 time: 1703259674.39744\n",
      "batch_idx: 1 loss: 0.0007557812558871624 R2: 0.9350820385104482 time: 1703259681.1723428\n",
      "Training [68%] Loss: 0.0009317031453440984 time: 1703259681.1723428\n",
      "weight: [ 1.03748344 -0.16534117 -0.08534024  1.19538868  0.27386542 -0.33663162\n",
      "  0.43902949  0.42616826  0.21290219  0.30702024  0.80961158  1.00819347\n",
      "  0.3954548  -0.0232409   0.46269809 -0.1169292  -0.03667594  0.38537619\n",
      "  0.86322876  0.9578379   0.42027938  0.43869136  0.1749805   0.4457296 ]\n",
      "epoch 204\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011050136725040704 R2: 0.9351608966351319 time: 1703259687.9323223\n",
      "batch_idx: 1 loss: 0.0007537894586744579 R2: 0.935240515954734 time: 1703259694.7154112\n",
      "Training [68%] Loss: 0.0009294015655892642 time: 1703259694.7154112\n",
      "weight: [ 1.03801207 -0.16539372 -0.08506663  1.19558164  0.27360249 -0.33696455\n",
      "  0.44015553  0.42561962  0.21482544  0.30745106  0.80974902  1.00861532\n",
      "  0.39549687 -0.02329605  0.46264554 -0.1174126  -0.03707723  0.38498097\n",
      "  0.86341236  0.95756055  0.41973074  0.43846955  0.17354936  0.44415441]\n",
      "epoch 205\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0011024024463732608 R2: 0.9353194654113212 time: 1703259701.5182295\n",
      "batch_idx: 1 loss: 0.0007517917136079901 R2: 0.9353991979119934 time: 1703259708.3523042\n",
      "Training [68%] Loss: 0.0009270970799906254 time: 1703259708.3523042\n",
      "weight: [ 1.03852851 -0.16545287 -0.08479436  1.19577731  0.27333789 -0.33729888\n",
      "  0.44129121  0.42506944  0.21673351  0.30789023  0.80988662  1.00904093\n",
      "  0.39553668 -0.02335827  0.46258639 -0.11789896 -0.03747988  0.38458442\n",
      "  0.86359303  0.95727816  0.41918056  0.438252    0.17211435  0.44257496]\n",
      "epoch 206\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010997913711889849 R2: 0.935478236653694 time: 1703259715.2945604\n",
      "batch_idx: 1 loss: 0.000749788138445726 R2: 0.935558079908968 time: 1703259722.2673833\n",
      "Training [69%] Loss: 0.0009247897548173554 time: 1703259722.2673833\n",
      "weight: [ 1.03903301 -0.1655186  -0.08452344  1.19597569  0.27307161 -0.33763462\n",
      "  0.44243654  0.42451782  0.21862643  0.30833785  0.81002432  1.00947028\n",
      "  0.39557426 -0.02342756  0.46252066 -0.11838827 -0.03788388  0.38418651\n",
      "  0.86377076  0.95699077  0.41862894  0.43803884  0.17067556  0.44099136]\n",
      "epoch 207\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001097180462844374 R2: 0.935637205665188 time: 1703259729.5174592\n",
      "batch_idx: 1 loss: 0.0007477788611861263 R2: 0.9357171570840108 time: 1703259736.2821383\n",
      "Training [69%] Loss: 0.0009224796620152502 time: 1703259736.2821383\n",
      "weight: [ 1.03952577 -0.16559091 -0.08425388  1.19617676  0.27280365 -0.33797176\n",
      "  0.44359153  0.42396485  0.22050423  0.30879403  0.81016208  1.00990336\n",
      "  0.39560964 -0.02350391  0.46244835 -0.11888055 -0.03828926  0.38378724\n",
      "  0.86394558  0.95669846  0.41807597  0.43783016  0.16923309  0.43940373]\n",
      "epoch 208\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001094569741988341 R2: 0.935796367309426 time: 1703259743.2471766\n",
      "batch_idx: 1 loss: 0.0007457640142072263 R2: 0.9358764241479379 time: 1703259749.947583\n",
      "Training [69%] Loss: 0.0009201668780977838 time: 1703259749.947583\n",
      "weight: [ 1.040007   -0.16566978 -0.0839857   1.19638051  0.27253401 -0.33831031\n",
      "  0.44475618  0.42341062  0.22236692  0.30925889  0.81029984  1.01034018\n",
      "  0.39564284 -0.02358729  0.46236947 -0.11937577 -0.03869605  0.38338657\n",
      "  0.86411751  0.95640129  0.41752175  0.43762608  0.16778706  0.4378122 ]\n",
      "epoch 209\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010919592394744396 R2: 0.9359557160615595 time: 1703259756.6868107\n",
      "batch_idx: 1 loss: 0.0007437437307701311 R2: 0.9360358753618716 time: 1703259763.2955458\n",
      "Training [70%] Loss: 0.0009178514851222854 time: 1703259763.2955458\n",
      "weight: [ 1.04047693 -0.1657552  -0.0837189   1.19658695  0.27226269 -0.33865026\n",
      "  0.44593051  0.42285524  0.22421456  0.30973255  0.81043755  1.01078071\n",
      "  0.39567391 -0.02367768  0.46228406 -0.11987395 -0.03910426  0.3829845\n",
      "  0.86428656  0.95609934  0.41696637  0.4374267   0.16633757  0.43621689]\n",
      "epoch 210\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010893489964610746 R2: 0.9361152460172304 time: 1703259770.0374732\n",
      "batch_idx: 1 loss: 0.0007417181477607316 R2: 0.9361955045646108 time: 1703259776.9566503\n",
      "Training [70%] Loss: 0.0009155335721109032 time: 1703259776.9566503\n",
      "weight: [ 1.04093575 -0.16584713 -0.08345349  1.19679604  0.27198968 -0.33899164\n",
      "  0.44711451  0.4222988   0.22604718  0.3102151   0.81057516  1.01122494\n",
      "  0.39570286 -0.02377507  0.46219213 -0.12037508 -0.0395139   0.382581\n",
      "  0.86445276  0.95579267  0.41640992  0.43723214  0.16488472  0.43461794]\n",
      "epoch 211\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001086739059775374 R2: 0.936274950861886 time: 1703259783.6625612\n",
      "batch_idx: 1 loss: 0.0007396874101295933 R2: 0.936355305215635 time: 1703259790.9977455\n",
      "Training [70%] Loss: 0.0009132132349524836 time: 1703259790.9977455\n",
      "weight: [ 1.04138368 -0.16594556 -0.08318948  1.1970078   0.271715   -0.33933442\n",
      "  0.44830819  0.42174139  0.22786484  0.31070667  0.81071262  1.01167287\n",
      "  0.39572974 -0.02387942  0.46209369 -0.12087915 -0.03992501  0.38217605\n",
      "  0.86461612  0.95548136  0.41585251  0.43704248  0.16342863  0.43301548]\n",
      "epoch 212\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010841294789982962 R2: 0.9364348238531968 time: 1703259798.4721854\n",
      "batch_idx: 1 loss: 0.0007376516710425327 R2: 0.9365152704052063 time: 1703259805.7056499\n",
      "Training [71%] Loss: 0.0009108905750204145 time: 1703259805.7056499\n",
      "weight: [ 1.04182091 -0.16605047 -0.08292686  1.19722219  0.27143863 -0.33967862\n",
      "  0.44951155  0.42118312  0.22966758  0.31120737  0.81084986  1.01212448\n",
      "  0.39575457 -0.02399071  0.46198879 -0.12138616 -0.04033759  0.38176963\n",
      "  0.86477667  0.95516548  0.41529424  0.43685783  0.16196941  0.43140966]\n",
      "epoch 213\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010815203085456312 R2: 0.9365948578458733 time: 1703259813.1621845\n",
      "batch_idx: 1 loss: 0.0007356110881146105 R2: 0.9366753928324476 time: 1703259820.152607\n",
      "Training [71%] Loss: 0.0009085656983301208 time: 1703259820.152607\n",
      "weight: [ 1.04224766 -0.16616182 -0.08266566  1.1974392   0.27116057 -0.34002424\n",
      "  0.45072459  0.42062407  0.23145548  0.31171732  0.81098684  1.01257976\n",
      "  0.3957774  -0.0241089   0.46187744 -0.1218961  -0.04075167  0.38136173\n",
      "  0.86493444  0.95484511  0.4147352   0.43667829  0.16050718  0.4298006 ]\n",
      "epoch 214\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010789116111424456 R2: 0.9367550453302774 time: 1703259826.9521053\n",
      "batch_idx: 1 loss: 0.0007335658210396145 R2: 0.9368356647940244 time: 1703259833.773637\n",
      "Training [71%] Loss: 0.00090623871609103 time: 1703259833.773637\n",
      "weight: [ 1.04266411 -0.16627957 -0.08240587  1.19765883  0.27088083 -0.34037128\n",
      "  0.45194731  0.42006437  0.23322859  0.31223663  0.8111235   1.01303868\n",
      "  0.39579824 -0.02423396  0.46175968 -0.12240896 -0.04116727  0.38095232\n",
      "  0.86508945  0.95452034  0.41417549  0.43650397  0.15904206  0.42818845]\n",
      "epoch 215\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001076303457850394 R2: 0.9369153784429043 time: 1703259840.5903442\n",
      "batch_idx: 1 loss: 0.0007315160333015634 R2: 0.9369960782070017 time: 1703259847.370532\n",
      "Training [72%] Loss: 0.0009039097455759786 time: 1703259847.370532\n",
      "weight: [ 1.04307046 -0.16640371 -0.08214749  1.19788106  0.27059941 -0.34071973\n",
      "  0.4531797   0.4195041   0.23498699  0.31276542  0.81125977  1.01350124\n",
      "  0.39581715 -0.02436585  0.46163555 -0.12292475 -0.04158441  0.38054139\n",
      "  0.86524172  0.95419124  0.41361522  0.43633495  0.15757416  0.42657336]\n",
      "epoch 216\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010736959249982494 R2: 0.9370758489498747 time: 1703259854.2421024\n",
      "batch_idx: 1 loss: 0.000729461894942377 R2: 0.9371566246421038 time: 1703259860.8256795\n",
      "Training [72%] Loss: 0.0009015789099703132 time: 1703259860.8256795\n",
      "weight: [ 1.04346691 -0.16653418 -0.08189052  1.19810587  0.27031631 -0.34106961\n",
      "  0.45442174  0.41894336  0.23673077  0.31330382  0.8113956   1.0139674\n",
      "  0.39583416 -0.02450453  0.46150508 -0.12344345 -0.04200311  0.3801289\n",
      "  0.86539128  0.95385789  0.41305448  0.43617134  0.15610361  0.42495548]\n",
      "epoch 217\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001071089092328986 R2: 0.9372364482403841 time: 1703259867.4725838\n",
      "batch_idx: 1 loss: 0.0007274035824421042 R2: 0.9373172953338125 time: 1703259874.2175353\n",
      "Training [72%] Loss: 0.0008992463373855451 time: 1703259874.2175353\n",
      "weight: [ 1.04385365 -0.16667095 -0.08163497  1.19833324  0.27003152 -0.34142091\n",
      "  0.45567345  0.41838226  0.23846     0.31385193  0.81153094  1.01443716\n",
      "  0.39584931 -0.02464996  0.46136831 -0.12396506 -0.04242339  0.37971486\n",
      "  0.86553817  0.95352039  0.41249339  0.43601322  0.15463054  0.42333495]\n",
      "epoch 218\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001068483044407266 R2: 0.9373971673493623 time: 1703259881.047462\n",
      "batch_idx: 1 loss: 0.0007253412761635936 R2: 0.9374780811696362 time: 1703259887.652149\n",
      "Training [73%] Loss: 0.0008969121602854298 time: 1703259887.652149\n",
      "weight: [ 1.04423086 -0.16681398 -0.08138083  1.19856316  0.26974506 -0.34177363\n",
      "  0.45693479  0.41782091  0.24017477  0.31440988  0.8116657   1.01491048\n",
      "  0.39586263 -0.02480208  0.46122528 -0.12448957 -0.04284527  0.37929922\n",
      "  0.86568241  0.95317881  0.41193203  0.43586069  0.15315506  0.42171193]\n",
      "epoch 219\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010658778727092103 R2: 0.9375579969877095 time: 1703259894.35738\n",
      "batch_idx: 1 loss: 0.0007232751589558979 R2: 0.9376389726889472 time: 1703259901.2524767\n",
      "Training [73%] Loss: 0.0008945765158325541 time: 1703259901.2524767\n",
      "weight: [ 1.04459873 -0.16696321 -0.08112809  1.19879561  0.26945692 -0.34212777\n",
      "  0.45820575  0.41725939  0.2418752   0.31497778  0.81179984  1.01538734\n",
      "  0.39587416 -0.02496085  0.46107604 -0.12501696 -0.04326877  0.37888198\n",
      "  0.86582404  0.95283325  0.41137052  0.43571384  0.15167732  0.42008659]\n",
      "epoch 220\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00106327367530266 R2: 0.9377189275518731 time: 1703259908.4822943\n",
      "batch_idx: 1 loss: 0.0007212054174024503 R2: 0.9377999601052798 time: 1703259915.752136\n",
      "Training [73%] Loss: 0.0008922395463525552 time: 1703259915.752136\n",
      "weight: [ 1.04495745 -0.16711861 -0.08087677  1.19903058  0.2691671  -0.34248334\n",
      "  0.45948633  0.41669783  0.24356137  0.31555576  0.8119333   1.01586773\n",
      "  0.39588396 -0.02512622  0.46092064 -0.12554724 -0.04369391  0.37846312\n",
      "  0.86596308  0.9524838   0.41080895  0.43557274  0.15019743  0.41845906]\n",
      "epoch 221\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010606705547171133 R2: 0.9378799491168899 time: 1703259922.5222797\n",
      "batch_idx: 1 loss: 0.0007191322434158738 R2: 0.9379610333328798 time: 1703259929.28672\n",
      "Training [74%] Loss: 0.0008899013990664935 time: 1703259929.28672\n",
      "weight: [ 1.0453072  -0.16728012 -0.08062683  1.19926803  0.26887561 -0.34284033\n",
      "  0.4607765   0.41613631  0.2452334   0.31614394  0.812066    1.0163516\n",
      "  0.39589205 -0.02529813  0.46075913 -0.12608038 -0.0441207   0.3780426\n",
      "  0.86609957  0.95213054  0.41024744  0.4354375   0.14871554  0.41682953]\n",
      "epoch 222\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001058068616936247 R2: 0.9380410514394135 time: 1703259936.0974061\n",
      "batch_idx: 1 loss: 0.0007170558337633414 R2: 0.9381221819957439 time: 1703259942.6975813\n",
      "Training [74%] Loss: 0.0008875622253497942 time: 1703259942.6975813\n",
      "weight: [ 1.04564816 -0.1674477  -0.0803783   1.19950795  0.26858245 -0.34319875\n",
      "  0.46207624  0.41557495  0.24689141  0.31674243  0.81219788  1.01683893\n",
      "  0.39589849 -0.02547651  0.46059156 -0.12661638 -0.04454918  0.37762042\n",
      "  0.86623355  0.95177357  0.40968608  0.43530818  0.14723177  0.41519814]\n",
      "epoch 223\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010554679724617026 R2: 0.9382022239804757 time: 1703259949.542564\n",
      "batch_idx: 1 loss: 0.0007149763882868265 R2: 0.9382833954248943 time: 1703259956.3871822\n",
      "Training [74%] Loss: 0.0008852221803742645 time: 1703259956.3871822\n",
      "weight: [ 1.0459805  -0.16762127 -0.08013114  1.19975031  0.26828762 -0.34355859\n",
      "  0.46338553  0.41501386  0.24853552  0.31735136  0.81232888  1.01732969\n",
      "  0.39590332 -0.02566132  0.46041799 -0.12715524 -0.04497936  0.37719656\n",
      "  0.86636505  0.95141299  0.40912498  0.43518487  0.14574627  0.41356507]\n",
      "epoch 224\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010528687374174804 R2: 0.9383634559297065 time: 1703259963.3242905\n",
      "batch_idx: 1 loss: 0.0007128941092423095 R2: 0.9384446626656479 time: 1703259970.1522706\n",
      "Training [75%] Loss: 0.0008828814233298949 time: 1703259970.1522706\n",
      "weight: [ 1.0463044  -0.16780079 -0.07988536  1.19999511  0.26799113 -0.34391985\n",
      "  0.46470434  0.41445312  0.25016585  0.31797084  0.81245892  1.01782385\n",
      "  0.39590658 -0.02585249  0.46023846 -0.12769692 -0.04541126  0.37677099\n",
      "  0.8664941   0.95104889  0.40856424  0.43506764  0.14425917  0.41193048]\n",
      "epoch 225\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001050271032917655 R2: 0.9385247362138209 time: 1703259977.0553398\n",
      "batch_idx: 1 loss: 0.0007108092022565631 R2: 0.9386059725001494 time: 1703259983.6075597\n",
      "Training [75%] Loss: 0.0008805401175871091 time: 1703259983.6075597\n",
      "weight: [ 1.04662003 -0.1679862  -0.07964095  1.2002423   0.26769298 -0.34428253\n",
      "  0.46603264  0.41389285  0.25178254  0.318601    0.81258795  1.01832137\n",
      "  0.39590832 -0.02604995  0.46005306 -0.12824144 -0.0458449   0.3763437\n",
      "  0.86662075  0.95068137  0.40800398  0.43495658  0.14277061  0.41029454]\n",
      "epoch 226\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010476749835903222 R2: 0.938686053496933 time: 1703259990.8026357\n",
      "batch_idx: 1 loss: 0.0007087218770728228 R2: 0.9387673134688723 time: 1703259998.6834357\n",
      "Training [75%] Loss: 0.0008781984303315725 time: 1703259998.6834357\n",
      "weight: [ 1.04692758 -0.16817743 -0.07939789  1.20049187  0.26739317 -0.34464664\n",
      "  0.46737041  0.41333316  0.25338572  0.31924195  0.81271589  1.01882223\n",
      "  0.39590859 -0.02625364  0.45986182 -0.12878876 -0.04628029  0.37591466\n",
      "  0.86674504  0.95031053  0.40744428  0.43485174  0.14128074  0.40865743]\n",
      "epoch 227\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010450807171788518 R2: 0.9388473961911716 time: 1703260005.9668188\n",
      "batch_idx: 1 loss: 0.0007066323468306784 R2: 0.9389286738788958 time: 1703260012.8326788\n",
      "Training [76%] Loss: 0.0008758565320047651 time: 1703260012.8326788\n",
      "weight: [ 1.0472272  -0.16837443 -0.07915617  1.2007438   0.26709172 -0.34501216\n",
      "  0.46871762  0.41277414  0.25497555  0.31989381  0.81284268  1.01932637\n",
      "  0.39590744 -0.02646348  0.45966483 -0.12933888 -0.04671746  0.37548386\n",
      "  0.866867    0.94993647  0.40688526  0.4347532   0.13978968  0.40701931]\n",
      "epoch 228\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001042488365326753 R2: 0.9390087524793268 time: 1703260019.8174574\n",
      "batch_idx: 1 loss: 0.0007045408268757452 R2: 0.9390900418076781 time: 1703260026.7372284\n",
      "Training [76%] Loss: 0.0008735145961012491 time: 1703260026.7372284\n",
      "weight: [ 1.04751906 -0.16857711 -0.07891578  1.20099805  0.26678862 -0.34537911\n",
      "  0.47007422  0.4122159   0.25655217  0.3205567   0.81296824  1.01983377\n",
      "  0.39590491 -0.0266794   0.45946214 -0.12989179 -0.04715643  0.37505129\n",
      "  0.86698667  0.94955928  0.40632703  0.43466102  0.1382976   0.40538037]\n",
      "epoch 229\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010398980639612716 R2: 0.9391701103343093 time: 1703260033.602287\n",
      "batch_idx: 1 loss: 0.0007024475345989414 R2: 0.9392514051166001 time: 1703260040.4321475\n",
      "Training [76%] Loss: 0.0008711727992801065 time: 1703260040.4321475\n",
      "weight: [ 1.04780333 -0.16878543 -0.0786767   1.2012546   0.26648388 -0.34574747\n",
      "  0.47144019  0.41165855  0.25811575  0.32123074  0.8130925   1.02034439\n",
      "  0.39590106 -0.02690133  0.45925383 -0.13044747 -0.04759721  0.37461691\n",
      "  0.8671041   0.94917908  0.40576967  0.43457527  0.13680464  0.40374077]\n",
      "epoch 230\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010373099525037837 R2: 0.9393314575272557 time: 1703260047.1165304\n",
      "batch_idx: 1 loss: 0.0007003526900991285 R2: 0.9394127514728888 time: 1703260053.91621\n",
      "Training [77%] Loss: 0.0008688313213014561 time: 1703260053.91621\n",
      "weight: [ 1.04808018 -0.16899929 -0.07843892  1.20151343  0.26617751 -0.34611725\n",
      "  0.47281548  0.41110219  0.25966643  0.32191603  0.81321539  1.02085817\n",
      "  0.39589594 -0.02712919  0.45903996 -0.1310059  -0.04803982  0.37418072\n",
      "  0.86721933  0.94879596  0.40521331  0.43449601  0.13531093  0.4021007 ]\n",
      "epoch 231\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010347241729282569 R2: 0.9394927816339488 time: 1703260060.6673896\n",
      "batch_idx: 1 loss: 0.0006982565163096846 R2: 0.939574068366887 time: 1703260067.920125\n",
      "Training [77%] Loss: 0.0008664903446189708 time: 1703260067.920125\n",
      "weight: [ 1.04834977 -0.16921865 -0.07820241  1.2017745   0.26586951 -0.34648844\n",
      "  0.47420006  0.41054691  0.26120439  0.32261271  0.81333684  1.02137509\n",
      "  0.3958896  -0.0273629   0.45882061 -0.13156707 -0.04848428  0.3737427\n",
      "  0.8673324   0.94841003  0.40465804  0.43442329  0.13381663  0.40046033]\n",
      "epoch 232\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010321408697443464 R2: 0.9396540700506089 time: 1703260075.3525252\n",
      "batch_idx: 1 loss: 0.0006961592382121457 R2: 0.9397353431205275 time: 1703260082.3425324\n",
      "Training [77%] Loss: 0.0008641500539782461 time: 1703260082.3425324\n",
      "weight: [ 1.04861225 -0.16944341 -0.07796717  1.20203779  0.2655599  -0.34686105\n",
      "  0.47559387  0.40999283  0.2627298   0.32332088  0.81345678  1.02189509\n",
      "  0.3958821  -0.02760238  0.45859585 -0.13213096 -0.0489306   0.37330283\n",
      "  0.86744336  0.94802139  0.40410396  0.43435716  0.13232189  0.39881985]\n",
      "epoch 233\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010295601904709115 R2: 0.93981531001513 time: 1703260089.111088\n",
      "batch_idx: 1 loss: 0.0006940610821420344 R2: 0.9398965628965612 time: 1703260095.8474638\n",
      "Training [78%] Loss: 0.000861810636306473 time: 1703260095.8474638\n",
      "weight: [ 1.04886779 -0.1696735  -0.07773317  1.20230326  0.26524867 -0.34723506\n",
      "  0.47699689  0.40944005  0.26424285  0.32404065  0.81357513  1.02241812\n",
      "  0.39587349 -0.02784754  0.45836576 -0.13269755 -0.0493788   0.3728611\n",
      "  0.86755224  0.94763015  0.40355117  0.43429768  0.13082685  0.39717944]\n",
      "epoch 234\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010269822855170062 R2: 0.9399764886225552 time: 1703260102.8521795\n",
      "batch_idx: 1 loss: 0.0006919622758959652 R2: 0.9400577147158374 time: 1703260109.5474136\n",
      "Training [78%] Loss: 0.0008594722807064856 time: 1703260109.5474136\n",
      "weight: [ 1.04911654 -0.16990885 -0.07750039  1.20257088  0.26493584 -0.34761047\n",
      "  0.47840904  0.40888866  0.2657437   0.32477214  0.81369182  1.02294415\n",
      "  0.39586383 -0.02809831  0.45813041 -0.13326683 -0.0498289   0.37241748\n",
      "  0.8676591   0.94723643  0.40299979  0.43424489  0.12933166  0.39553927]\n",
      "epoch 235\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010244073074257838 R2: 0.9401375928339041 time: 1703260116.4467897\n",
      "batch_idx: 1 loss: 0.0006898630490551091 R2: 0.9402187854770936 time: 1703260123.212201\n",
      "Training [78%] Loss: 0.0008571351782404465 time: 1703260123.212201\n",
      "weight: [ 1.04935866 -0.17014938 -0.07726881  1.20284063  0.26462142 -0.34798729\n",
      "  0.4798303   0.40833877  0.26723256  0.32551545  0.81380678  1.02347312\n",
      "  0.39585317 -0.0283546   0.45788988 -0.13383878 -0.05028092  0.37197198\n",
      "  0.86776397  0.94684031  0.4024499   0.43419884  0.12783648  0.39389953]\n",
      "epoch 236\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001021835410384455 R2: 0.9402986094875867 time: 1703260130.103066\n",
      "batch_idx: 1 loss: 0.0006877636327090952 R2: 0.9403797619708312 time: 1703260136.8573446\n",
      "Training [79%] Loss: 0.000854799521546775 time: 1703260136.8573446\n",
      "weight: [ 1.04959431 -0.17039501 -0.07703842  1.20311247  0.26430541 -0.34836551\n",
      "  0.4812606   0.40779048  0.2687096   0.3262707   0.81391993  1.02400497\n",
      "  0.39584157 -0.02861632  0.45764425 -0.13441338 -0.05073486  0.37152456\n",
      "  0.86786692  0.94644192  0.40190161  0.43415956  0.12634146  0.3922604 ]\n",
      "epoch 237\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010192667503659868 R2: 0.9404595253175547 time: 1703260143.6342204\n",
      "batch_idx: 1 loss: 0.0006856642587855947 R2: 0.9405406308890013 time: 1703260150.5521872\n",
      "Training [79%] Loss: 0.0008524655045757908 time: 1703260150.5521872\n",
      "weight: [ 1.04982363 -0.17064565 -0.07680918  1.20338637  0.26398783 -0.34874512\n",
      "  0.48269989  0.40724389  0.27017504  0.32703798  0.8140312   1.02453966\n",
      "  0.39582909 -0.02888337  0.4573936  -0.13499061 -0.05119074  0.37107521\n",
      "  0.86796797  0.94604136  0.40135501  0.43412709  0.12484674  0.39062207]\n",
      "epoch 238\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010167014852659208 R2: 0.9406203269716189 time: 1703260157.4422514\n",
      "batch_idx: 1 loss: 0.0006835651597498068 R2: 0.9407013788383504 time: 1703260164.4776244\n",
      "Training [79%] Loss: 0.0008501333225078638 time: 1703260164.4776244\n",
      "weight: [ 1.05004677 -0.17090123 -0.07658107  1.20366229  0.26366867 -0.34912612\n",
      "  0.48414812  0.40669909  0.27162907  0.32781741  0.81414051  1.02507714\n",
      "  0.39581579 -0.02915568  0.45713803 -0.13557046 -0.05164857  0.37062394\n",
      "  0.86806719  0.94563874  0.40081021  0.43410147  0.12335248  0.38898472]\n",
      "epoch 239\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00101413977450728 R2: 0.9407810010240093 time: 1703260171.6723511\n",
      "batch_idx: 1 loss: 0.0006814665687577839 R2: 0.9408619923585271 time: 1703260178.8558738\n",
      "Training [80%] Loss: 0.0008478031716325319 time: 1703260178.8558738\n",
      "weight: [ 1.05026388 -0.17116166 -0.07635407  1.2039402   0.26334797 -0.34950851\n",
      "  0.48560522  0.40615618  0.27307191  0.32860909  0.81424778  1.02561734\n",
      "  0.39580173 -0.02943314  0.45687759 -0.13615289 -0.05210837  0.37017071\n",
      "  0.86816461  0.94523417  0.40026731  0.43408272  0.12185883  0.38734854]\n",
      "epoch 240\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010115817784789411 R2: 0.9409415339858404 time: 1703260185.6822917\n",
      "batch_idx: 1 loss: 0.000679368719644039 R2: 0.9410224579385258 time: 1703260192.382222\n",
      "Training [80%] Loss: 0.00084547524906149 time: 1703260192.382222\n",
      "weight: [ 1.05047512 -0.17142686 -0.07612816  1.20422006  0.26302571 -0.34989227\n",
      "  0.48707114  0.40561526  0.27450375  0.32941311  0.81435294  1.02616021\n",
      "  0.39578698 -0.02971567  0.4566124  -0.13673788 -0.05257015  0.36971552\n",
      "  0.86826028  0.94482777  0.39972639  0.43407087  0.12036594  0.3857137 ]\n",
      "epoch 241\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010090276583725648 R2: 0.9411019123197638 time: 1703260199.3421543\n",
      "batch_idx: 1 loss: 0.0006772718464763095 R2: 0.9411827620283646 time: 1703260206.122398\n",
      "Training [80%] Loss: 0.0008431497524244372 time: 1703260206.122398\n",
      "weight: [ 1.05068062 -0.17169674 -0.07590331  1.20450184  0.26270192 -0.35027741\n",
      "  0.48854581  0.40507643  0.27592482  0.33022957  0.81445592  1.02670569\n",
      "  0.39577158 -0.03000317  0.45634252 -0.13732543 -0.05303391  0.36925837\n",
      "  0.86835427  0.94441963  0.39918755  0.43406594  0.11887396  0.38408039]\n",
      "epoch 242\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010064775762856485 R2: 0.9412621224575164 time: 1703260212.9679956\n",
      "batch_idx: 1 loss: 0.000675176183121435 R2: 0.9413428910505666 time: 1703260219.657341\n",
      "Training [81%] Loss: 0.0008408268797035418 time: 1703260219.657341\n",
      "weight: [ 1.05088053 -0.17197121 -0.07567949  1.2047855   0.26237661 -0.35066393\n",
      "  0.49002917  0.40453977  0.27733534  0.33105858  0.81455664  1.02725372\n",
      "  0.39575561 -0.03029555  0.45606804 -0.1379155  -0.05349967  0.36879923\n",
      "  0.8684466   0.94400988  0.3986509   0.43406796  0.11738305  0.38244879]\n",
      "epoch 243\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010039316950723608 R2: 0.941422150814563 time: 1703260226.4622235\n",
      "batch_idx: 1 loss: 0.0006730819631809437 R2: 0.9415028314154406 time: 1703260233.508407\n",
      "Training [81%] Loss: 0.0008385068291266522 time: 1703260233.508407\n",
      "weight: [ 1.05107499 -0.1722502  -0.07545668  1.20507101  0.26204979 -0.3510518\n",
      "  0.49152115  0.40400539  0.27873553  0.33190021  0.81465501  1.02780424\n",
      "  0.39573913 -0.03059271  0.45578906 -0.13850807 -0.05396745  0.3683381\n",
      "  0.86853733  0.94359861  0.39811651  0.43407692  0.11589335  0.38081909]\n",
      "epoch 244\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0010013901779041298 R2: 0.9415819838011388 time: 1703260240.8397245\n",
      "batch_idx: 1 loss: 0.0006709894200237468 R2: 0.9416625695373397 time: 1703260248.2235603\n",
      "Training [81%] Loss: 0.0008361897989639383 time: 1703260248.2235603\n",
      "weight: [ 1.05126414 -0.1725336  -0.07523485  1.20535832  0.26172147 -0.35144103\n",
      "  0.49302168  0.40347336  0.28012561  0.33275457  0.81475097  1.02835719\n",
      "  0.3957222  -0.03089456  0.45550565 -0.13910312 -0.05443723  0.36787498\n",
      "  0.86862651  0.94318595  0.39758448  0.43409286  0.11440501  0.37919147]\n",
      "epoch 245\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009988531879688044 R2: 0.9417416078344877 time: 1703260255.0958285\n",
      "batch_idx: 1 loss: 0.0006688987865374988 R2: 0.941822091847556 time: 1703260261.96359\n",
      "Training [82%] Loss: 0.0008338759872531516 time: 1703260261.96359\n",
      "weight: [ 1.05144812 -0.17282134 -0.07501398  1.2056474   0.26139167 -0.35183161\n",
      "  0.49453069  0.40294378  0.28150583  0.33362173  0.81484445  1.0289125\n",
      "  0.39570489 -0.031201    0.45521791 -0.13970063 -0.05490905  0.36740985\n",
      "  0.8687142   0.942772    0.39705491  0.43411577  0.11291819  0.37756611]\n",
      "epoch 246\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009963208884577132 R2: 0.9419010093541639 time: 1703260268.6612842\n",
      "batch_idx: 1 loss: 0.0006668102947294289 R2: 0.9419813848051677 time: 1703260275.3627005\n",
      "Training [82%] Loss: 0.000831565591593571 time: 1703260275.3627005\n",
      "weight: [ 1.05162706 -0.17311333 -0.07479403  1.20593821  0.26106039 -0.35222353\n",
      "  0.49604811  0.40241674  0.2828764   0.33450179  0.81493535  1.02947011\n",
      "  0.39568726 -0.03151194  0.45492593 -0.14030056 -0.05538289  0.3669427\n",
      "  0.86880043  0.94235688  0.39652787  0.43414565  0.11143303  0.37594318]\n",
      "epoch 247\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000993793442516911 R2: 0.942060174836677 time: 1703260282.3006065\n",
      "batch_idx: 1 loss: 0.0006647241755312778 R2: 0.9421404349097842 time: 1703260289.3243937\n",
      "Training [82%] Loss: 0.0008292588090240943 time: 1703260289.3243937\n",
      "weight: [ 1.0518011  -0.17340948 -0.07457497  1.2062307   0.26072766 -0.35261679\n",
      "  0.49757386  0.40189233  0.28423758  0.33539481  0.81502361  1.03002995\n",
      "  0.39566937 -0.03182727  0.45462978 -0.1409029  -0.05585877  0.36647354\n",
      "  0.86888526  0.94194069  0.39600346  0.43418252  0.10994968  0.37432287]\n",
      "epoch 248\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000991271012955971 R2: 0.942219090806929 time: 1703260296.1125174\n",
      "batch_idx: 1 loss: 0.0006626406587849098 R2: 0.9422992287160741 time: 1703260302.955241\n",
      "Training [83%] Loss: 0.0008269558358704404 time: 1703260302.955241\n",
      "weight: [ 1.05197038 -0.17370969 -0.07435678  1.20652484  0.26039348 -0.35301138\n",
      "  0.49910787  0.40137063  0.28558959  0.33630089  0.81510915  1.03059196\n",
      "  0.3956513  -0.0321469   0.45432957 -0.14150763 -0.05633668  0.36600236\n",
      "  0.86896874  0.94152355  0.39548176  0.43422636  0.10846829  0.37270535]\n",
      "epoch 249\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000988753761939029 R2: 0.9423777438489294 time: 1703260309.612224\n",
      "batch_idx: 1 loss: 0.0006605599731039655 R2: 0.9424577528465437 time: 1703260316.2465737\n",
      "Training [83%] Loss: 0.0008246568675214972 time: 1703260316.2465737\n",
      "weight: [ 1.05213501 -0.17401389 -0.07413944  1.20682059  0.26005788 -0.35340728\n",
      "  0.50065005  0.40085173  0.28693269  0.33722008  0.8151919   1.03115606\n",
      "  0.39563311 -0.03247073  0.45402537 -0.1421147  -0.05681665  0.36552915\n",
      "  0.86905091  0.94110556  0.39496285  0.43427717  0.106989    0.3710908 ]\n",
      "epoch 250\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009862418508852252 R2: 0.9425361206186154 time: 1703260323.1672819\n",
      "batch_idx: 1 loss: 0.0006584823455631679 R2: 0.9426159940018481 time: 1703260330.027481\n",
      "Training [83%] Loss: 0.0008223620982241966 time: 1703260330.027481\n",
      "weight: [ 1.05229514 -0.17432198 -0.0739229   1.20711791  0.25972086 -0.3538045\n",
      "  0.50220034  0.4003357   0.28826712  0.33815248  0.81527178  1.03172219\n",
      "  0.39561487 -0.03279867  0.45371728 -0.1427241  -0.05729865  0.36505391\n",
      "  0.86913184  0.94068684  0.39444682  0.43433494  0.10551196  0.3694794 ]\n",
      "epoch 251\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000983735440438583 R2: 0.9426942078571166 time: 1703260336.9836972\n",
      "batch_idx: 1 loss: 0.0006564080014634437 R2: 0.9427739389715015 time: 1703260343.8225586\n",
      "Training [84%] Loss: 0.0008200717209510134 time: 1703260343.8225586\n",
      "weight: [ 1.05245088 -0.17463388 -0.07370715  1.20741675  0.25938244 -0.35420302\n",
      "  0.50375864  0.39982262  0.28959312  0.33909813  0.81534872  1.03229028\n",
      "  0.39559664 -0.03313062  0.45340538 -0.14333581 -0.05778271  0.36457665\n",
      "  0.86921156  0.94026749  0.39393374  0.43439965  0.10403731  0.36787131]\n",
      "epoch 252\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009812346902866845 R2: 0.9428519924017393 time: 1703260350.792542\n",
      "batch_idx: 1 loss: 0.0006543371642645936 R2: 0.942931574646136 time: 1703260357.85403\n",
      "Training [84%] Loss: 0.000817785927275639 time: 1703260357.85403\n",
      "weight: [ 1.05260238 -0.17494949 -0.07349215  1.20771707  0.25904265 -0.35460283\n",
      "  0.50532487  0.39931258  0.29091095  0.3400571   0.81542263  1.03286026\n",
      "  0.39557849 -0.03346648  0.45308977 -0.14394979 -0.05826882  0.36409735\n",
      "  0.86929013  0.93984762  0.3934237   0.43447129  0.1025652   0.3662667 ]\n",
      "epoch 253\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009787397589028492 R2: 0.9430094611954422 time: 1703260364.7081668\n",
      "batch_idx: 1 loss: 0.0006522700554941357 R2: 0.9430888880290456 time: 1703260372.232667\n",
      "Training [84%] Loss: 0.0008155049071984924 time: 1703260372.232667\n",
      "weight: [ 1.05274973 -0.17526874 -0.07327788  1.20801882  0.25870149 -0.35500392\n",
      "  0.50689895  0.39880565  0.29222086  0.34102946  0.81549346  1.03343205\n",
      "  0.39556048 -0.03380616  0.45277052 -0.14456602 -0.05875697  0.36361602\n",
      "  0.86936759  0.93942735  0.39291677  0.43454983  0.10109576  0.36466575]\n",
      "epoch 254\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009762508034129157 R2: 0.9431666012973323 time: 1703260379.6239774\n",
      "batch_idx: 1 loss: 0.0006502068945199698 R2: 0.9432458662455806 time: 1703260386.875667\n",
      "Training [85%] Loss: 0.0008132288489664428 time: 1703260386.875667\n",
      "weight: [ 1.05289308 -0.17559153 -0.0730643   1.20832198  0.25835898 -0.35540628\n",
      "  0.50848079  0.39830191  0.2935231   0.34201526  0.81556112  1.03400557\n",
      "  0.39554269 -0.03414955  0.45244773 -0.14518446 -0.05924717  0.36313266\n",
      "  0.869444    0.93900677  0.39241303  0.43463526  0.09962913  0.36306861]\n",
      "epoch 255\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000973767979559303 R2: 0.943323399893887 time: 1703260394.7223053\n",
      "batch_idx: 1 loss: 0.0006481478983300484 R2: 0.943402496552047 time: 1703260402.4575758\n",
      "Training [85%] Loss: 0.0008109579389446757 time: 1703260402.4575758\n",
      "weight: [ 1.05303254 -0.17591778 -0.07285139  1.20862649  0.25801514 -0.3558099\n",
      "  0.5100703   0.39780142  0.29481794  0.34301454  0.81562554  1.03458077\n",
      "  0.39552518 -0.03449657  0.45212148 -0.1458051  -0.05973942  0.36264728\n",
      "  0.86951941  0.938586    0.39191254  0.43472753  0.09816545  0.36147546]\n",
      "epoch 256\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009712914415881818 R2: 0.9434798443086982 time: 1703260409.3589914\n",
      "batch_idx: 1 loss: 0.0006460932814371773 R2: 0.9435587663456241 time: 1703260416.4722886\n",
      "Training [85%] Loss: 0.0008086923615126796 time: 1703260416.4722886\n",
      "weight: [ 1.05316822 -0.1762474  -0.07263912  1.2089323   0.25766999 -0.35621478\n",
      "  0.5116674   0.39730426  0.29610561  0.34402736  0.81568665  1.03515756\n",
      "  0.39550803 -0.03484712  0.45179186 -0.1464279  -0.0602337   0.36215988\n",
      "  0.86959387  0.93816514  0.39141538  0.43482663  0.09670487  0.35988645]\n",
      "epoch 257\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00096882134205576 R2: 0.9436359220105743 time: 1703260423.3082037\n",
      "batch_idx: 1 loss: 0.0006440432558063668 R2: 0.9437146631740487 time: 1703260430.16241\n",
      "Training [86%] Loss: 0.0008064322989310634 time: 1703260430.16241\n",
      "weight: [ 1.05330024 -0.17658031 -0.07242747  1.20923938  0.25732354 -0.35662089\n",
      "  0.51327198  0.3968105   0.2973864   0.34505376  0.81574437  1.03573587\n",
      "  0.39549128 -0.0352011   0.45145895 -0.14705283 -0.06073002  0.36167046\n",
      "  0.86966742  0.9377443   0.39092162  0.43493251  0.0952475   0.35830174]\n",
      "epoch 258\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009663578317004285 R2: 0.9437916206218915 time: 1703260437.0576284\n",
      "batch_idx: 1 loss: 0.0006419980306907887 R2: 0.943870174743609 time: 1703260443.9423833\n",
      "Training [86%] Loss: 0.0008041779311956086 time: 1703260443.9423833\n",
      "weight: [ 1.05342871 -0.17691642 -0.0722164   1.20954769  0.25697582 -0.35702823\n",
      "  0.51488397  0.3963202   0.29866054  0.34609377  0.81579865  1.03631562\n",
      "  0.39547502 -0.03555843  0.45112283 -0.14767987 -0.06122837  0.36117902\n",
      "  0.86974011  0.93732358  0.39043132  0.43504515  0.09379348  0.35672149]\n",
      "epoch 259\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009639010594037746 R2: 0.9439469279275621 time: 1703260450.9756725\n",
      "batch_idx: 1 loss: 0.0006399578124485603 R2: 0.9440252889262701 time: 1703260457.9636793\n",
      "Training [86%] Loss: 0.0008019294359261674 time: 1703260457.9636793\n",
      "weight: [ 1.05355376 -0.17725566 -0.07200588  1.20985716  0.25662684 -0.35743678\n",
      "  0.51650326  0.39583342  0.29992831  0.34714744  0.8158494   1.03689674\n",
      "  0.39545931 -0.03591901  0.4507836  -0.14830898 -0.06172874  0.36068559\n",
      "  0.869812    0.93690309  0.38994455  0.43516449  0.09234294  0.35514585]\n",
      "epoch 260\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009614511721197413 R2: 0.9441018318830127 time: 1703260464.9424572\n",
      "batch_idx: 1 loss: 0.0006379228044452033 R2: 0.9441799937673258 time: 1703260471.8324986\n",
      "Training [87%] Loss: 0.0007996869882824723 time: 1703260471.8324986\n",
      "weight: [ 1.05367547 -0.17759794 -0.0717959   1.21016777  0.25627662 -0.35784654\n",
      "  0.51812976  0.39535024  0.30118995  0.34821478  0.81589656  1.03747915\n",
      "  0.39544422 -0.03628275  0.45044132 -0.14894014 -0.06223112  0.36019015\n",
      "  0.86988313  0.93648293  0.38946136  0.43529049  0.09089601  0.35357497]\n",
      "epoch 261\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009590083147385479 R2: 0.9442563206206932 time: 1703260479.0022123\n",
      "batch_idx: 1 loss: 0.000635893206992513 R2: 0.9443342774929662 time: 1703260486.0047472\n",
      "Training [87%] Loss: 0.0007974507608655304 time: 1703260486.0047472\n",
      "weight: [ 1.05379397 -0.17794317 -0.07158641  1.21047947  0.25592518 -0.35825748\n",
      "  0.51976337  0.3948707   0.30244575  0.34929584  0.81594007  1.03806278\n",
      "  0.39542981 -0.03664956  0.45009608 -0.14957332 -0.06273551  0.35969274\n",
      "  0.86995355  0.93606321  0.38898183  0.4354231   0.08945281  0.35200899]\n",
      "epoch 262\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000956572629983756 R2: 0.9444103824564014 time: 1703260493.242236\n",
      "batch_idx: 1 loss: 0.0006338692172306746 R2: 0.9444881285165281 time: 1703260500.7155209\n",
      "Training [87%] Loss: 0.0007952209236072154 time: 1703260500.7155209\n",
      "weight: [ 1.05390935 -0.17829129 -0.07137741  1.21079221  0.25557255 -0.3586696\n",
      "  0.521404    0.39439487  0.30369594  0.35039062  0.81597985  1.03864754\n",
      "  0.39541615 -0.03701935  0.44974797 -0.15020848 -0.06324189  0.35919334\n",
      "  0.8700233   0.93564402  0.388506    0.43556228  0.08801347  0.35044806]\n",
      "epoch 263\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009541442583795653 R2: 0.9445640058959841 time: 1703260507.9222116\n",
      "batch_idx: 1 loss: 0.0006318510289871222 R2: 0.9446415354438239 time: 1703260514.9755492\n",
      "Training [88%] Loss: 0.0007929976436833438 time: 1703260514.9755492\n",
      "weight: [ 1.05402172 -0.17864221 -0.07116886  1.21110595  0.25521874 -0.35908288\n",
      "  0.52305154  0.39392281  0.3049408   0.35149914  0.81601583  1.03923337\n",
      "  0.3954033  -0.03739203  0.44939705 -0.15084559 -0.06375025  0.35869198\n",
      "  0.87009245  0.93522546  0.38803393  0.43570797  0.0865781   0.34889233]\n",
      "epoch 264\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009517233382082066 R2: 0.94471717964134 time: 1703260521.8875892\n",
      "batch_idx: 1 loss: 0.0006298388326934163 R2: 0.9447944870786451 time: 1703260529.3874269\n",
      "Training [88%] Loss: 0.0007907810854508114 time: 1703260529.3874269\n",
      "weight: [ 1.05413118 -0.17899585 -0.07096074  1.21142064  0.25486376 -0.35949731\n",
      "  0.52470591  0.39345455  0.30618058  0.35262142  0.81604796  1.03982018\n",
      "  0.39539133 -0.03776752  0.44904341 -0.15148463 -0.06426058  0.35818867\n",
      "  0.87016103  0.93480764  0.38756568  0.43586011  0.08514683  0.34734192]\n",
      "epoch 265\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009493100054201941 R2: 0.9448698925951581 time: 1703260536.197576\n",
      "batch_idx: 1 loss: 0.0006278328153371017 R2: 0.9449469724281835 time: 1703260543.3622348\n",
      "Training [88%] Loss: 0.0007885714103786479 time: 1703260543.3622348\n",
      "weight: [ 1.05423783 -0.17935214 -0.07075302  1.21173624  0.25450765 -0.35991287\n",
      "  0.52636699  0.39299017  0.30741555  0.35375745  0.81607617  1.0404079\n",
      "  0.3953803  -0.03814573  0.44868712 -0.15212556 -0.06477286  0.35768342\n",
      "  0.87022909  0.93439065  0.38710129  0.43601865  0.08371977  0.34579697]\n",
      "epoch 266\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009469043935625933 R2: 0.9450221338653145 time: 1703260550.4475212\n",
      "batch_idx: 1 loss: 0.0006258331603788815 R2: 0.9450989807074018 time: 1703260557.4524534\n",
      "Training [89%] Loss: 0.0007863687769707374 time: 1703260557.4524534\n",
      "weight: [ 1.05434175 -0.179711   -0.07054568  1.21205271  0.25415043 -0.36032955\n",
      "  0.52803469  0.39252969  0.30864595  0.35490725  0.8161004   1.04099645\n",
      "  0.39537027 -0.03852659  0.44832826 -0.15276836 -0.06528708  0.35717625\n",
      "  0.87029668  0.93397458  0.38664082  0.43618352  0.08229703  0.34425761]\n",
      "epoch 267\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009445066337593034 R2: 0.9451738927694228 time: 1703260564.3824716\n",
      "batch_idx: 1 loss: 0.0006238400476513644 R2: 0.9452505013425607 time: 1703260571.3076327\n",
      "Training [89%] Loss: 0.0007841733407053339 time: 1703260571.3076327\n",
      "weight: [ 1.05444306 -0.18007236 -0.07033871  1.21236999  0.25379211 -0.36074733\n",
      "  0.52970889  0.39207318  0.30987206  0.35607081  0.81612058  1.04158575\n",
      "  0.39536132 -0.03890999  0.44796689 -0.15341299 -0.06580322  0.35666717\n",
      "  0.87036385  0.93355955  0.38618431  0.43635466  0.08087872  0.34272397]\n",
      "epoch 268\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009421168546897242 R2: 0.9453251588388316 time: 1703260578.9526823\n",
      "batch_idx: 1 loss: 0.0006218536532983487 R2: 0.945401523974738 time: 1703260586.842338\n",
      "Training [89%] Loss: 0.0007819852539940364 time: 1703260586.842338\n",
      "weight: [ 1.05454182 -0.18043616 -0.07013207  1.21268805  0.25343271 -0.3611662\n",
      "  0.53138951  0.39162068  0.31109412  0.35724813  0.81613667  1.04217573\n",
      "  0.39535349 -0.03929588  0.4476031  -0.15405942 -0.06632127  0.3561562\n",
      "  0.87043064  0.93314563  0.3857318   0.436532    0.07946495  0.34119617]\n",
      "epoch 269\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009397351825350585 R2: 0.9454759218215687 time: 1703260594.4725916\n",
      "batch_idx: 1 loss: 0.0006198741497423577 R2: 0.9455520384631979 time: 1703260601.6025488\n",
      "Training [90%] Loss: 0.000779804666138708 time: 1703260601.6025488\n",
      "weight: [ 1.05463815 -0.18080231 -0.06992574  1.21300684  0.25307226 -0.36158614\n",
      "  0.53307644  0.39117222  0.31231238  0.35843918  0.81614859  1.04276631\n",
      "  0.39534685 -0.03968416  0.44723694 -0.15470762 -0.0668412   0.35564336\n",
      "  0.87049709  0.93273293  0.38528334  0.43671547  0.07805582  0.33967434]\n",
      "epoch 270\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009373617409365386 R2: 0.9456261716849165 time: 1703260608.7582855\n",
      "batch_idx: 1 loss: 0.0006179017056303153 R2: 0.9457020348879153 time: 1703260615.397824\n",
      "Training [90%] Loss: 0.000777631723283427 time: 1703260615.397824\n",
      "weight: [ 1.05473211 -0.18117076 -0.06971971  1.21332631  0.25271078 -0.36200714\n",
      "  0.53476957  0.39072785  0.31352712  0.35964396  0.81615629  1.04335741\n",
      "  0.39534146 -0.04007476  0.4468685  -0.15535756 -0.067363    0.35512867\n",
      "  0.87056327  0.93232153  0.38483897  0.436905    0.07665145  0.33815858]\n",
      "epoch 271\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009349966509912746 R2: 0.9457758986180048 time: 1703260622.2445557\n",
      "batch_idx: 1 loss: 0.0006159364857674301 R2: 0.9458515035513819 time: 1703260629.1244533\n",
      "Training [90%] Loss: 0.0007754665683793523 time: 1703260629.1244533\n",
      "weight: [ 1.0548238  -0.18154142 -0.06951396  1.21364643  0.2523483  -0.36242917\n",
      "  0.53646879  0.3902876   0.31473856  0.36086243  0.81615972  1.04394897\n",
      "  0.39533737 -0.0404676   0.44649783 -0.15600921 -0.06788664  0.35461215\n",
      "  0.8706292   0.93191154  0.38439872  0.43710052  0.07525192  0.336649  ]\n",
      "epoch 272\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000932640031247842 R2: 0.9459250930339025 time: 1703260636.2031507\n",
      "batch_idx: 1 loss: 0.0006139786510812053 R2: 0.9460004349803246 time: 1703260643.2326937\n",
      "Training [91%] Loss: 0.0007733093411645236 time: 1703260643.2326937\n",
      "weight: [ 1.05491329 -0.18191425 -0.06930847  1.21396715  0.25198483 -0.36285223\n",
      "  0.53817401  0.38985151  0.31594697  0.36209458  0.81615882  1.0445409\n",
      "  0.39533466 -0.04086261  0.44612501 -0.15666253 -0.06841211  0.35409381\n",
      "  0.87069494  0.93150303  0.38396263  0.43730194  0.07385733  0.33514573]\n",
      "epoch 273\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009302919976801249 R2: 0.9460737455708712 time: 1703260650.7903378\n",
      "batch_idx: 1 loss: 0.0006120283586058931 R2: 0.9461488199272216 time: 1703260658.4877126\n",
      "Training [91%] Loss: 0.0007711601781430089 time: 1703260658.4877126\n",
      "weight: [ 1.05500066 -0.18228917 -0.06910322  1.21428842  0.25162039 -0.36327629\n",
      "  0.53988511  0.38941961  0.31715259  0.36334037  0.81615354  1.04513313\n",
      "  0.39533336 -0.04125972  0.44575008 -0.1573175  -0.06893938  0.35357369\n",
      "  0.87076053  0.93109609  0.38353073  0.4375092   0.07246779  0.33364886]\n",
      "epoch 274\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000927952663671265 R2: 0.9462218470932816 time: 1703260665.8372576\n",
      "batch_idx: 1 loss: 0.0006100857614521329 R2: 0.9462966493711213 time: 1703260673.1336462\n",
      "Training [91%] Loss: 0.0007690192125616989 time: 1703260673.1336462\n",
      "weight: [ 1.055086   -0.18266612 -0.06889819  1.2146102   0.25125501 -0.36370134\n",
      "  0.54160198  0.38899193  0.31835567  0.36459977  0.81614383  1.04572558\n",
      "  0.39533354 -0.04165886  0.44537313 -0.15797408 -0.06946842  0.35305181\n",
      "  0.87082602  0.93069082  0.38310306  0.4377222   0.07108337  0.33215849]\n",
      "epoch 275\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009256221400240948 R2: 0.946369388692468 time: 1703260679.9424565\n",
      "batch_idx: 1 loss: 0.0006081510087712517 R2: 0.9464439145178931 time: 1703260686.72128\n",
      "Training [92%] Loss: 0.0007668865743976732 time: 1703260686.72128\n",
      "weight: [ 1.05516937 -0.18304505 -0.06869338  1.21493246  0.25088872 -0.36412735\n",
      "  0.54332453  0.38856851  0.31955645  0.36587273  0.81612964  1.04631819\n",
      "  0.39533526 -0.04205995  0.44499421 -0.15863225 -0.06999922  0.35252818\n",
      "  0.87089145  0.9302873   0.38267963  0.43794087  0.06970416  0.33067472]\n",
      "epoch 276\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009233005349700525 R2: 0.9465163616871337 time: 1703260693.5072107\n",
      "batch_idx: 1 loss: 0.000606224245742719 R2: 0.9465906068003636 time: 1703260700.2923422\n",
      "Training [92%] Loss: 0.0007647623903563857 time: 1703260700.2923422\n",
      "weight: [ 1.05525085 -0.18342589 -0.06848876  1.21525514  0.25052153 -0.36455432\n",
      "  0.54505264  0.38814936  0.32075516  0.36715921  0.81611092  1.04691087\n",
      "  0.39533856 -0.04246293  0.44461337 -0.15929196 -0.07053174  0.35200284\n",
      "  0.87095685  0.92988561  0.38226048  0.43816513  0.06833027  0.32919765]\n",
      "epoch 277\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009209879541638274 R2: 0.9466627576230777 time: 1703260707.057297\n",
      "batch_idx: 1 loss: 0.0006043056135749706 R2: 0.9467367178782359 time: 1703260713.9293323\n",
      "Training [92%] Loss: 0.000762646783869399 time: 1703260713.9293323\n",
      "weight: [ 1.05533051 -0.18380858 -0.06828432  1.21557821  0.25015347 -0.36498222\n",
      "  0.5467862   0.3877345   0.32195206  0.36845916  0.81608762  1.04750357\n",
      "  0.39534349 -0.04286774  0.44423068 -0.1599532  -0.07106596  0.35147581\n",
      "  0.87102229  0.92948584  0.38184563  0.43839489  0.06696175  0.32772736]\n",
      "epoch 278\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009186845006876781 R2: 0.9468085682726859 time: 1703260721.1774197\n",
      "batch_idx: 1 loss: 0.000602395249495764 R2: 0.9468822396374177 time: 1703260728.2675235\n",
      "Training [93%] Loss: 0.0007605398750917211 time: 1703260728.2675235\n",
      "weight: [ 1.0554084  -0.18419307 -0.06808005  1.21590162  0.24978455 -0.36541103\n",
      "  0.54852511  0.38732397  0.32314736  0.36977252  0.81605971  1.0480962\n",
      "  0.39535011 -0.0432743   0.44384619 -0.16061593 -0.07160185  0.35094713\n",
      "  0.87108779  0.92908807  0.38143509  0.43863006  0.0655987   0.32626394]\n",
      "epoch 279\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009163902750736668 R2: 0.9469537856342993 time: 1703260735.4124885\n",
      "batch_idx: 1 loss: 0.0006004932867421412 R2: 0.9470271641889425 time: 1703260742.332416\n",
      "Training [93%] Loss: 0.000758441780907904 time: 1703260742.332416\n",
      "weight: [ 1.0554846  -0.1845793  -0.06787595  1.21622533  0.24941481 -0.36584073\n",
      "  0.55026926  0.38691778  0.32434131  0.37109923  0.81602713  1.04868869\n",
      "  0.39535847 -0.04368256  0.44345995 -0.16128011 -0.07213938  0.35041681\n",
      "  0.87115341  0.92869238  0.3810289   0.43887055  0.0642412   0.32480747]\n",
      "epoch 280\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00091410537532245 R2: 0.9470984019311863 time: 1703260749.472608\n",
      "batch_idx: 1 loss: 0.0005985998545684983 R2: 0.9471714838677914 time: 1703260756.373281\n",
      "Training [93%] Loss: 0.0007563526149454742 time: 1703260756.373281\n",
      "weight: [ 1.05555917 -0.18496723 -0.06767199  1.21654931  0.24904427 -0.36627131\n",
      "  0.55201854  0.38651595  0.32553413  0.37243923  0.81598985  1.04928099\n",
      "  0.3953686  -0.04409245  0.44307203 -0.16194572 -0.07267852  0.34988488\n",
      "  0.87121918  0.92829886  0.38062707  0.43911628  0.06288931  0.32335804]\n",
      "epoch 281\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009118298969134945 R2: 0.9472424096100063 time: 1703260763.2533965\n",
      "batch_idx: 1 loss: 0.0005967150782620814 R2: 0.9473151912314748 time: 1703260770.0566552\n",
      "Training [94%] Loss: 0.0007542724875877879 time: 1703260770.0566552\n",
      "weight: [ 1.05563217 -0.1853568  -0.06746817  1.21687352  0.24867295 -0.36670275\n",
      "  0.55377283  0.38611848  0.32672604  0.37379244  0.81594783  1.04987301\n",
      "  0.39538057 -0.04450391  0.44268246 -0.16261273 -0.07321924  0.34935139\n",
      "  0.87128514  0.92790757  0.38022961  0.43936714  0.06154311  0.32191571]\n",
      "epoch 282\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009095639328244555 R2: 0.9473858013391065 time: 1703260776.8123229\n",
      "batch_idx: 1 loss: 0.0005948390791512163 R2: 0.9474582790581534 time: 1703260783.2775683\n",
      "Training [94%] Loss: 0.0007522015059878359 time: 1703260783.2775683\n",
      "weight: [ 1.05570365 -0.18574795 -0.06726448  1.2171979   0.24830087 -0.36713501\n",
      "  0.55553204  0.3857254   0.32791727  0.3751588   0.81590102  1.0504647\n",
      "  0.39539441 -0.04491689  0.4422913  -0.16328111 -0.07376151  0.34881635\n",
      "  0.87135134  0.92751859  0.37983653  0.43962306  0.06020267  0.32048056]\n",
      "epoch 283\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009073075735617295 R2: 0.9475285700066964 time: 1703260790.004559\n",
      "batch_idx: 1 loss: 0.0005929719746166722 R2: 0.947600740344491 time: 1703260796.8022518\n",
      "Training [94%] Loss: 0.0007501397740892009 time: 1703260796.8022518\n",
      "weight: [ 1.05577366 -0.18614065 -0.06706092  1.21752244  0.24792806 -0.3675681\n",
      "  0.55729606  0.38533672  0.32910804  0.37653823  0.8158494   1.05105598\n",
      "  0.39541016 -0.04533134  0.4418986  -0.16395082 -0.0743053   0.3482798\n",
      "  0.87141782  0.927132    0.37944785  0.43988394  0.05886805  0.31905265]\n",
      "epoch 284\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009050609071862656 R2: 0.9476707087186729 time: 1703260803.927697\n",
      "batch_idx: 1 loss: 0.0005911138781167588 R2: 0.9477425683034257 time: 1703260811.2845335\n",
      "Training [95%] Loss: 0.0007480873926515121 time: 1703260811.2845335\n",
      "weight: [ 1.05584227 -0.18653485 -0.06685748  1.21784708  0.24755453 -0.36800198\n",
      "  0.55906476  0.38495244  0.33029855  0.37793064  0.81579294  1.0516468\n",
      "  0.39542787 -0.04574718  0.44150441 -0.16462184 -0.07485057  0.34774178\n",
      "  0.87148462  0.92674788  0.37906357  0.44014968  0.05753932  0.31763205]\n",
      "epoch 285\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009028240193350971 R2: 0.9478122107960913 time: 1703260818.6177483\n",
      "batch_idx: 1 loss: 0.0005892648992153586 R2: 0.9478837563617162 time: 1703260825.9075437\n",
      "Training [95%] Loss: 0.0007460444592752278 time: 1703260825.9075437\n",
      "weight: [ 1.05590952 -0.18693049 -0.06665415  1.21817179  0.24718032 -0.36843663\n",
      "  0.56083805  0.38457258  0.33148903  0.37933594  0.81573159  1.05223708\n",
      "  0.39544757 -0.04616438  0.44110877 -0.16529414 -0.07539729  0.34720231\n",
      "  0.87155177  0.9263663   0.3786837   0.44042019  0.05621654  0.31621883]\n",
      "epoch 286\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0009005969932512301 R2: 0.9479530697725524 time: 1703260832.7308009\n",
      "batch_idx: 1 loss: 0.0005874251436055181 R2: 0.9480242981571438 time: 1703260839.5249743\n",
      "Training [95%] Loss: 0.0007440110684283741 time: 1703260839.5249743\n",
      "weight: [ 1.05597545 -0.18732754 -0.06645093  1.21849654  0.24680544 -0.36887203\n",
      "  0.56261582  0.38419713  0.33267967  0.38075405  0.81566532  1.05282677\n",
      "  0.3954693  -0.04658288  0.44071172 -0.16596768 -0.07594542  0.34666144\n",
      "  0.87161931  0.92598732  0.37830825  0.44069537  0.05489976  0.31481302]\n",
      "epoch 287\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008983799098191521 R2: 0.9480932793914608 time: 1703260846.157621\n",
      "batch_idx: 1 loss: 0.0005855947131383468 R2: 0.9481641875355751 time: 1703260853.2975588\n",
      "Training [96%] Loss: 0.0007419873114787494 time: 1703260853.2975588\n",
      "weight: [ 1.05604012 -0.18772595 -0.06624781  1.21882128  0.24642993 -0.36930817\n",
      "  0.56439795  0.38382609  0.33387068  0.38218487  0.81559412  1.05341581\n",
      "  0.39549311 -0.04700262  0.44031331 -0.16664244 -0.07649493  0.34611918\n",
      "  0.87168729  0.92561102  0.37793722  0.44097513  0.05358904  0.31341471]\n",
      "epoch 288\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008961728475955003 R2: 0.9482328336030006 time: 1703260859.9455872\n",
      "batch_idx: 1 loss: 0.0005837737058614448 R2: 0.9483034185479557 time: 1703260866.6257722\n",
      "Training [96%] Loss: 0.0007399732767284725 time: 1703260866.6257722\n",
      "weight: [ 1.05610355 -0.18812567 -0.06604481  1.21914599  0.24605379 -0.36974501\n",
      "  0.56618435  0.38345948  0.33506227  0.3836283   0.81551795  1.05400412\n",
      "  0.39551901 -0.04742356  0.43991358 -0.16731839 -0.07704579  0.34557559\n",
      "  0.87175575  0.92523747  0.3775706   0.44125937  0.05228443  0.31202392]\n",
      "epoch 289\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008939758828387294 R2: 0.9483717265609075 time: 1703260873.752649\n",
      "batch_idx: 1 loss: 0.0005819622160574071 R2: 0.9484419854471084 time: 1703260880.7525125\n",
      "Training [96%] Loss: 0.0007379690494480682 time: 1703260880.7525125\n",
      "weight: [ 1.0561658  -0.18852668 -0.0658419   1.21947062  0.24567706 -0.37018255\n",
      "  0.56797489  0.38309729  0.33625461  0.38508424  0.81543678  1.05459167\n",
      "  0.39554706 -0.04784565  0.43951257 -0.1679955  -0.07759795  0.3450307\n",
      "  0.87182471  0.92486674  0.37720841  0.44154799  0.05098599  0.31064071]\n",
      "epoch 290\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008917890895454976 R2: 0.9485099526192118 time: 1703260887.367314\n",
      "batch_idx: 1 loss: 0.000580160334280559 R2: 0.9485798826843256 time: 1703260894.8423464\n",
      "Training [97%] Loss: 0.0007359747119130282 time: 1703260894.8423464\n",
      "weight: [ 1.05622691 -0.18892893 -0.06563911  1.21979516  0.24529976 -0.37062075\n",
      "  0.56976948  0.38273951  0.33744792  0.38655258  0.81535061  1.05517838\n",
      "  0.39557727 -0.04826885  0.43911033 -0.16867373 -0.07815137  0.34448454\n",
      "  0.87189421  0.92449888  0.37685063  0.4418409   0.04969376  0.30926512]\n",
      "epoch 291\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008896125394886737 R2: 0.948647506328854 time: 1703260902.4923756\n",
      "batch_idx: 1 loss: 0.0005783681473997296 R2: 0.9487171049058916 time: 1703260910.407697\n",
      "Training [97%] Loss: 0.0007339903434442016 time: 1703260910.407697\n",
      "weight: [ 1.05628689 -0.18933238 -0.06543641  1.22011955  0.24492191 -0.37105959\n",
      "  0.57156799  0.38238614  0.33864236  0.3880332   0.81525939  1.05576421\n",
      "  0.39560968 -0.0486931   0.43870688 -0.16935307 -0.07870602  0.34393715\n",
      "  0.8719643   0.92413397  0.37649726  0.442138    0.04840778  0.30789719]\n",
      "epoch 292\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008874463022513213 R2: 0.9487843824341174 time: 1703260917.7164416\n",
      "batch_idx: 1 loss: 0.0005765857386466698 R2: 0.9488536469495725 time: 1703260924.0767176\n",
      "Training [97%] Loss: 0.0007320160204489955 time: 1703260924.0767176\n",
      "weight: [ 1.0563458  -0.18973699 -0.06523383  1.22044377  0.24454353 -0.37149906\n",
      "  0.57337034  0.38203718  0.33983813  0.389526    0.81516312  1.05634909\n",
      "  0.39564431 -0.04911837  0.43830226 -0.17003348 -0.07926187  0.34338857\n",
      "  0.87203501  0.92377206  0.3761483   0.44243918  0.0471281   0.30653696]\n",
      "epoch 293\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000885290445261966 R2: 0.9489205758689743 time: 1703260930.5846934\n",
      "batch_idx: 1 loss: 0.0005748131876632931 R2: 0.9489895038409528 time: 1703260937.2245238\n",
      "Training [98%] Loss: 0.0007300518164626295 time: 1703260937.2245238\n",
      "weight: [ 1.05640366 -0.19014273 -0.06503136  1.2207678   0.24416465 -0.37193913\n",
      "  0.5751764   0.38169261  0.34103541  0.39103085  0.81506177  1.05693299\n",
      "  0.39568119 -0.0495446   0.43789652 -0.17071494 -0.07981886  0.34283884\n",
      "  0.87210637  0.92341323  0.37580373  0.44274436  0.04585476  0.30518446]\n",
      "epoch 294\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008831450338343179 R2: 0.9490560817534183 time: 1703260944.033317\n",
      "batch_idx: 1 loss: 0.0005730505705493842 R2: 0.9491246707896728 time: 1703260950.63477\n",
      "Training [98%] Loss: 0.0007280978021918511 time: 1703260950.63477\n",
      "weight: [ 1.0564605  -0.19054957 -0.064829    1.22109159  0.24378529 -0.37237978\n",
      "  0.57698608  0.38135243  0.34223436  0.39254763  0.81495533  1.05751583\n",
      "  0.39572034 -0.04997176  0.43748969 -0.17139741 -0.08037696  0.342288\n",
      "  0.87217841  0.92305752  0.37546355  0.44305343  0.0445878   0.30383973]\n",
      "epoch 295\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008810101312060808 R2: 0.9491908953897294 time: 1703260957.4965456\n",
      "batch_idx: 1 loss: 0.0005712979599158159 R2: 0.9492591431856809 time: 1703260964.9263806\n",
      "Training [98%] Loss: 0.0007261540455609484 time: 1703260964.9263806\n",
      "weight: [ 1.05651635 -0.19095746 -0.06462676  1.22141512  0.24340547 -0.37282098\n",
      "  0.57879926  0.38101663  0.34343516  0.39407622  0.81484379  1.05809759\n",
      "  0.39576179 -0.05039981  0.4370818  -0.17208087 -0.08093613  0.34173609\n",
      "  0.87225118  0.92270501  0.37512775  0.4433663   0.04332725  0.3025028 ]\n",
      "epoch 296\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008788857985752846 R2: 0.9493250122586192 time: 1703260972.3626707\n",
      "batch_idx: 1 loss: 0.0005695554249401311 R2: 0.9493929165954398 time: 1703260979.763844\n",
      "Training [99%] Loss: 0.0007242206117577079 time: 1703260979.763844\n",
      "weight: [ 1.05657122 -0.19136637 -0.06442465  1.22173836  0.24302521 -0.37326272\n",
      "  0.58061584  0.38068519  0.34463798  0.39561649  0.81472714  1.05867819\n",
      "  0.39580556 -0.0508287   0.43667288 -0.17276529 -0.08149632  0.34118314\n",
      "  0.8723247   0.92235575  0.37479631  0.44368287  0.04207314  0.30117368]\n",
      "epoch 297\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008767720951389427 R2: 0.9494584280153899 time: 1703260986.787595\n",
      "batch_idx: 1 loss: 0.0005678230314210152 R2: 0.9495259867580683 time: 1703260994.5074584\n",
      "Training [99%] Loss: 0.0007222975632799789 time: 1703260994.5074584\n",
      "weight: [ 1.05662515 -0.19177628 -0.06422267  1.22206128  0.24264454 -0.37370496\n",
      "  0.58243571  0.3803581   0.34584297  0.3971683   0.81460535  1.05925761\n",
      "  0.39585166 -0.05125839  0.43626298 -0.17345065 -0.0820575   0.34062921\n",
      "  0.87239901  0.92200979  0.37446923  0.44400304  0.04082552  0.2998524 ]\n",
      "epoch 298\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008746690781336539 R2: 0.9495911384860996 time: 1703261001.2949889\n",
      "batch_idx: 1 loss: 0.0005661008418347755 R2: 0.9496583495814692 time: 1703261007.90741\n",
      "Training [99%] Loss: 0.0007203849599842146 time: 1703261007.90741\n",
      "weight: [ 1.05667816 -0.19218715 -0.06402083  1.22238386  0.24226347 -0.37414769\n",
      "  0.58425877  0.38003535  0.34705029  0.39873151  0.81447844  1.05983579\n",
      "  0.39590012 -0.05168884  0.43585211 -0.17413692 -0.08261963  0.34007432\n",
      "  0.87247413  0.9216672   0.37414647  0.44432672  0.03958439  0.29853899]\n",
      "epoch 299\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008725768028742869 R2: 0.9497231396636987 time: 1703261014.717501\n",
      "batch_idx: 1 loss: 0.0005643889153956125 R2: 0.9497900011384999 time: 1703261022.1073895\n",
      "Training [100%] Loss: 0.0007184828591349497 time: 1703261022.1073895\n",
      "weight: [ 1.05673025 -0.19259894 -0.06381913  1.22270608  0.24188203 -0.37459089\n",
      "  0.58608491  0.37971691  0.3482601   0.400306    0.81434638  1.0604127\n",
      "  0.39595094 -0.05212002  0.43544032 -0.17482407 -0.08318265  0.33951853\n",
      "  0.8725501   0.92132802  0.37382803  0.4446538   0.0383498   0.29723345]\n",
      "epoch 300\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0008704953227918498 R2: 0.9498544277041245 time: 1703261029.677305\n",
      "batch_idx: 1 loss: 0.0005626873081162212 R2: 0.9499209376631297 time: 1703261037.1476896\n",
      "Training [100%] Loss: 0.0007165913154540354 time: 1703261037.1476896\n",
      "weight: [ 1.05678146 -0.19301163 -0.0636176   1.22302789  0.24150024 -0.37503452\n",
      "  0.58791403  0.37940277  0.34947255  0.40189162  0.81420917  1.06098828\n",
      "  0.39600415 -0.05255189  0.43502763 -0.17551207 -0.08374653  0.33896188\n",
      "  0.87262695  0.92099231  0.37351389  0.4449842   0.03712177  0.2959358 ]\n",
      "train_MSE: 0.000721160069293658\n",
      "train_RMSE: 0.02685442364478631\n",
      "train_MAE: 0.02269394130056227\n",
      "train_MAPE: 0.0494211983216808\n",
      "train_R2: 0.9499209376631297\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "weights =[0.68756473 , 1.2864305 ,  0.5411694 , -0.01524038 , 0.5852044 ,  0.6762012,\n",
    "  0.35593897 , 0.22628789,  0.38244092,  0.35140917,  0.86482936 , 0.8531242,\n",
    "  0.09241156 , 0.6720707  , 0.38071635,  0.95416117 , 0.63409   ,  0.40179932,\n",
    "  0.7345088  , 0.6243114  , 0.3178202 , -0.2618623  , 0.18122938,  1.0447433,\n",
    "  0.48699683 , 0.7739934  , 0.38703147 , 0.48046085,  0.5525667 ,  0.52838504,\n",
    "  0.28538367 , 0.30099392,  0.74503726 , 0.67772216,  0.3839896 ,  0.417687]\n",
    "weights = npp.array(weights, requires_grad=True)\n",
    "'''\n",
    "weights = params\n",
    "loss_list=[]\n",
    "r2_list=[]\n",
    "\n",
    "n_epochs=300\n",
    "\n",
    "start_time=time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss  = []\n",
    "    total_r2  = []\n",
    "    print(f\"epoch {epoch+1}\\n-------------------------------\")\n",
    "    for it, batch_index in enumerate (chain(*[X_batches])):\n",
    "        # Update the weights by one optimizer step\n",
    "        \n",
    "        X_batch = X[batch_index]\n",
    "        Y_batch = Y[batch_index]\n",
    "        weights, _, _ = opt.step(cost, weights, X_batch, Y_batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        predictions = [QNN(weights, x) for x in X]\n",
    "        r2 = R2(Y, predictions)\n",
    "        cost_t=cost(weights,X_batch,Y_batch)\n",
    "        total_loss.append(cost_t)\n",
    "        total_r2.append(r2)\n",
    "        end_timet=time.time()\n",
    "        print(\"batch_idx:\",it,\"loss:\",cost_t,\"R2:\",r2,\"time:\",end_timet)\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    r2_list.append(sum(total_r2)/len(total_r2))\n",
    "    print('Training [{:.0f}%]'.format(100. * (epoch + 1) / n_epochs),\"Loss:\", loss_list[-1], \"time:\",end_timet)\n",
    "    print(\"weight:\",weights)\n",
    "    \n",
    "    \n",
    "predictions = [QNN(weights, x) for x in X]\n",
    "\n",
    "train_R2 = R2(Y, predictions)\n",
    "train_MSE=metrics.mean_squared_error(Y,predictions)\n",
    "train_RMSE=train_MSE**(1/2)\n",
    "train_MAE=metrics.mean_absolute_error(Y,predictions)\n",
    "train_MAPE=metrics.mean_absolute_percentage_error(Y,predictions)\n",
    "\n",
    "print(\"train_MSE:\",train_MSE)\n",
    "print(\"train_RMSE:\",train_RMSE)\n",
    "print(\"train_MAE:\",train_MAE)\n",
    "print(\"train_MAPE:\",train_MAPE)\n",
    "print(\"train_R2:\",train_R2)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "plt.title(\"MSE value against epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.plot(range(len(loss_list)), np.log(loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c5609a-73ee-4deb-86d0-d6a744439104",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006811364866973042 R2: 0.9599086559770006 time: 1703172820.8441331\n",
      "batch_idx: 1 loss: 0.0004708969714715788 R2: 0.9599401679256403 time: 1703172829.2799776\n",
      "Training [1%] Loss: 0.0005760167290844415 time: 1703172829.2799776\n",
      "weight: [ 0.98045622  0.12931449  0.10444879  0.93734827  0.61615549  0.43834824\n",
      " -0.07251746  0.46293981  0.2990797  -0.37889624  0.55840489  0.33134531\n",
      "  0.57897239  0.06578474  0.62843375  0.16119853  0.19200402  0.65604726\n",
      "  0.55744941  0.53950171  0.52616863  0.90271623 -0.82927669 -0.81058041]\n",
      "epoch 2\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006800481521733737 R2: 0.9599689775965177 time: 1703172837.1959555\n",
      "batch_idx: 1 loss: 0.00047022035179802174 R2: 0.9600003298216528 time: 1703172844.9777603\n",
      "Training [2%] Loss: 0.0005751342519856976 time: 1703172844.9777603\n",
      "weight: [ 0.98073374  0.12979812  0.10458807  0.93652219  0.61509217  0.43965188\n",
      " -0.07347517  0.45969057  0.298575   -0.37882577  0.56080743  0.33008931\n",
      "  0.57802347  0.06483989  0.62935265  0.16079871  0.19227847  0.65633312\n",
      "  0.55577629  0.53830805  0.52606211  0.90260882 -0.8295292  -0.80990238]\n",
      "epoch 3\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006789689405680983 R2: 0.9600288859526664 time: 1703172852.7624233\n",
      "batch_idx: 1 loss: 0.0004695469940406565 R2: 0.9600600798029364 time: 1703172860.593613\n",
      "Training [3%] Loss: 0.0005742579673043773 time: 1703172860.593613\n",
      "weight: [ 0.98101122  0.13028038  0.10472421  0.93570193  0.61403319  0.44095254\n",
      " -0.07443649  0.45641322  0.29810903 -0.37874952  0.56322452  0.32882585\n",
      "  0.57708208  0.06390534  0.63026516  0.16040755  0.19255279  0.65661837\n",
      "  0.55410467  0.53711132  0.52595147  0.90249859 -0.82979235 -0.80921077]\n",
      "epoch 4\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006778987155880254 R2: 0.9600883843888036 time: 1703172868.5812733\n",
      "batch_idx: 1 loss: 0.0004688769398794198 R2: 0.9601194211068925 time: 1703172876.4910803\n",
      "Training [4%] Loss: 0.0005733878277337226 time: 1703172876.4910803\n",
      "weight: [ 0.98128867  0.13076116  0.1048571   0.93488745  0.61297872  0.44225012\n",
      " -0.07540109  0.45310813  0.29768239 -0.37866755  0.5656562   0.32755498\n",
      "  0.57614814  0.06298102  0.6311713   0.16002492  0.19282715  0.65690316\n",
      "  0.55243455  0.53591167  0.52583682  0.9023856  -0.83006614 -0.80850599]\n",
      "epoch 5\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006768373452695995 R2: 0.9601474760796714 time: 1703172884.2113354\n",
      "batch_idx: 1 loss: 0.00046821023043754783 R2: 0.9601783568083752 time: 1703172891.9634645\n",
      "Training [5%] Loss: 0.0005725237878535736 time: 1703172891.9634645\n",
      "weight: [ 0.98156611  0.13124032  0.10498661  0.93407874  0.6119289   0.44354451\n",
      " -0.07636866  0.44977569  0.29729564 -0.37857991  0.56810248  0.32627678\n",
      "  0.57522159  0.06206686  0.63207111  0.1596507   0.19310166  0.65718764\n",
      "  0.55076591  0.53470921  0.52571826  0.90226991 -0.8303505  -0.80778848]\n",
      "epoch 6\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006757847018986211 R2: 0.9602061640398413 time: 1703172899.9506633\n",
      "batch_idx: 1 loss: 0.00046754690618309194 R2: 0.9602368898279796 time: 1703172907.8593402\n",
      "Training [6%] Loss: 0.0005716658040408565 time: 1703172907.8593402\n",
      "weight: [ 0.98184353  0.13171774  0.10511264  0.93327577  0.61088388  0.44483558\n",
      " -0.07733886  0.44641629  0.2969493  -0.37848666  0.57056338  0.3249913\n",
      "  0.57430236  0.06116278  0.63296463  0.15928478  0.19337647  0.65747194\n",
      "  0.54909877  0.53350408  0.52559587  0.90215156 -0.83064538 -0.80705864]\n",
      "epoch 7\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006747406619331141 R2: 0.9602644511318281 time: 1703172915.627648\n",
      "batch_idx: 1 loss: 0.0004668870068385891 R2: 0.960295022939978 time: 1703172923.6161823\n",
      "Training [7%] Loss: 0.0005708138343858515 time: 1703172923.6161823\n",
      "weight: [ 0.98212095  0.13219331  0.10523506  0.9324785   0.60984378  0.44612323\n",
      " -0.07831139  0.44303036  0.29664386 -0.37838786  0.57303891  0.32369861\n",
      "  0.5733904   0.0602687   0.63385188  0.15892704  0.19365172  0.65775621\n",
      "  0.54743311  0.5322964   0.52546974  0.9020306  -0.83095072 -0.8063169 ]\n",
      "epoch 8\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006737051059288281 R2: 0.9603223400738867 time: 1703172931.3822002\n",
      "batch_idx: 1 loss: 0.00046623057129838917 R2: 0.960352758779943 time: 1703172939.1205719\n",
      "Training [8%] Loss: 0.0005699678386136087 time: 1703172939.1205719\n",
      "weight: [ 0.98239837  0.1326669   0.10535377  0.93168691  0.60880874  0.44740736\n",
      " -0.07928592  0.43961834  0.29637975 -0.37828357  0.57552906  0.32239876\n",
      "  0.57248564  0.05938454  0.63473292  0.15857737  0.19392752  0.65804058\n",
      "  0.54576896  0.5310863   0.52533997  0.90190709 -0.83126645 -0.80556366]\n",
      "epoch 9\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000672677918466742 R2: 0.9603798334475002 time: 1703172947.022623\n",
      "batch_idx: 1 loss: 0.00046557763755328805 R2: 0.9604100998520717 time: 1703172954.8442214\n",
      "Training [9%] Loss: 0.000569127778010015 time: 1703172954.8442214\n",
      "weight: [ 0.98267581  0.13313838  0.10546864  0.93090097  0.60777888  0.44868787\n",
      " -0.08026213  0.43618067  0.29615735 -0.37817386  0.57803385  0.32109181\n",
      "  0.57158803  0.0585102   0.63560777  0.15823566  0.19420402  0.65832518\n",
      "  0.54410633  0.5298739   0.52520664  0.90178109 -0.83159248 -0.80479933]\n",
      "epoch 10\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006716589880818846 R2: 0.9604369337046095 time: 1703172962.7012863\n",
      "batch_idx: 1 loss: 0.00046492824262205567 R2: 0.9604670485362281 time: 1703172970.3972769\n",
      "Training [10%] Loss: 0.0005682936153519702 time: 1703172970.3972769\n",
      "weight: [ 0.98295325  0.13360764  0.10557957  0.93012065  0.60675429  0.44996466\n",
      " -0.08123971  0.43271784  0.295977   -0.3780588   0.58055326  0.31977781\n",
      "  0.57069749  0.05764558  0.63647648  0.15790179  0.19448133  0.65861015\n",
      "  0.54244522  0.52865933  0.52506982  0.90165264 -0.83192871 -0.80402431]\n",
      "epoch 11\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006706482071928614 R2: 0.9604936431745588 time: 1703172978.2106044\n",
      "batch_idx: 1 loss: 0.0004642824224895801 R2: 0.9605236070947221 time: 1703172985.9842117\n",
      "Training [11%] Loss: 0.0005674653148412208 time: 1703172985.9842117\n",
      "weight: [ 0.98323072  0.13407456  0.10568644  0.92934592  0.60573508  0.45123764\n",
      " -0.08221834  0.42923034  0.295839   -0.37793845  0.58308729  0.31845681\n",
      "  0.56981398  0.05679059  0.6373391   0.15757568  0.19475958  0.65889561\n",
      "  0.54078567  0.5274427   0.52492959  0.9015218  -0.83227504 -0.803239  ]\n",
      "epoch 12\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000669645472031411 R2: 0.9605499640708148 time: 1703172993.8558843\n",
      "batch_idx: 1 loss: 0.0004636402120511883 R2: 0.9605797776788559 time: 1703173001.6553032\n",
      "Training [12%] Loss: 0.0005666428420412997 time: 1703173001.6553032\n",
      "weight: [ 0.98350821  0.13453901  0.10578914  0.92857674  0.60472134  0.45250673\n",
      " -0.08319771  0.42571867  0.29574361 -0.3778129   0.58563591  0.31712886\n",
      "  0.56893744  0.05594511  0.63819566  0.1572572   0.19503888  0.65918169\n",
      "  0.53912769  0.52622413  0.52478603  0.90138863 -0.83263137 -0.8024438 ]\n",
      "epoch 13\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006686506825714782 R2: 0.9606058984974524 time: 1703173009.4400542\n",
      "batch_idx: 1 loss: 0.0004630016450630203 R2: 0.9606355623352203 time: 1703173017.3948786\n",
      "Training [13%] Loss: 0.0005658261638172492 time: 1703173017.3948786\n",
      "weight: [ 0.98378574  0.13500088  0.10588755  0.9278131   0.60371315  0.45377183\n",
      " -0.08417753  0.42218337  0.29569102 -0.37768223  0.58819911  0.31579399\n",
      "  0.56806782  0.05510904  0.63904623  0.15694627  0.19531936  0.6594685\n",
      "  0.53747132  0.52500373  0.52463921  0.90125319 -0.83299756 -0.80163908]\n",
      "epoch 14\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006676637424571988 R2: 0.9606614484554186 time: 1703173025.336292\n",
      "batch_idx: 1 loss: 0.00046236675409802553 R2: 0.9606909630118073 time: 1703173033.132288\n",
      "Training [14%] Loss: 0.0005650152482776121 time: 1703173033.132288\n",
      "weight: [ 0.9840633   0.13546004  0.10598156  0.92705495  0.60271059  0.45503288\n",
      " -0.08515747  0.41862499  0.29568139 -0.3775465   0.59077687  0.31445226\n",
      "  0.56720506  0.05428225  0.63989083  0.15664277  0.19560112  0.65975617\n",
      "  0.53581658  0.52378163  0.52448919  0.90111552 -0.83337348 -0.80082523]\n",
      "epoch 15\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006666845589292618 R2: 0.9607166158486151 time: 1703173040.9101136\n",
      "batch_idx: 1 loss: 0.000461735570507397 R2: 0.9607459815639038 time: 1703173048.6089792\n",
      "Training [15%] Loss: 0.0005642100647183293 time: 1703173048.6089792\n",
      "weight: [ 0.9843409   0.13591637  0.10607106  0.92630227  0.60171373  0.4562898\n",
      " -0.08613725  0.41504408  0.29571483 -0.3774058   0.59336913  0.3131037\n",
      "  0.56634912  0.05346465  0.64072953  0.15634662  0.19588428  0.66004481\n",
      "  0.53416351  0.52255793  0.52433603  0.90097569 -0.83375899 -0.80000264]\n",
      "epoch 16\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00066571304274936 R2: 0.9607714024897783 time: 1703173056.3822527\n",
      "batch_idx: 1 loss: 0.0004611081243871388 R2: 0.9608006197598116 time: 1703173064.2383864\n",
      "Training [16%] Loss: 0.0005634105835682494 time: 1703173064.2383864\n",
      "weight: [ 0.98461854  0.13636977  0.10615594  0.92555503  0.60072262  0.45754251\n",
      " -0.08711657  0.41144124  0.29579141 -0.37726022  0.59597588  0.31174833\n",
      "  0.56549994  0.05265609  0.64156236  0.15605771  0.19616894  0.66033453\n",
      "  0.53251215  0.52133274  0.5241798   0.90083375 -0.83415395 -0.79917166]\n",
      "epoch 17\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006647491081221417 R2: 0.9608258101061959 time: 1703173071.9212325\n",
      "batch_idx: 1 loss: 0.0004604844445494962 R2: 0.9608548792863971 time: 1703173079.7621872\n",
      "Training [17%] Loss: 0.0005626167763358189 time: 1703173079.7621872\n",
      "weight: [ 0.98489622  0.1368201   0.1062361   0.92481318  0.59973732  0.45879095\n",
      " -0.08809513  0.40781706  0.29591114 -0.37710984  0.59859707  0.31038619\n",
      "  0.56465747  0.05185648  0.64238939  0.15577595  0.19645521  0.66062544\n",
      "  0.53086255  0.52010618  0.52402055  0.90068977 -0.83455819 -0.79833268]\n",
      "epoch 18\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006637926726145775 R2: 0.96087984034526 time: 1703173087.644028\n",
      "batch_idx: 1 loss: 0.0004598645584989217 R2: 0.9609087617544823 time: 1703173095.7533748\n",
      "Training [18%] Loss: 0.0005618286155567496 time: 1703173095.7533748\n",
      "weight: [ 0.98517396  0.13726726  0.10631141  0.92407671  0.59875787  0.46003505\n",
      " -0.08907264  0.40417217  0.29607398 -0.37695475  0.60123264  0.3090173\n",
      "  0.56382168  0.05106567  0.64321065  0.15550126  0.19674319  0.66091764\n",
      "  0.52921476  0.51887833  0.52385833  0.90054379 -0.83497155 -0.79748606]\n",
      "epoch 19\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006628436570724111 R2: 0.96093349477987 time: 1703173103.6390252\n",
      "batch_idx: 1 loss: 0.0004592484924123054 R2: 0.9609622687040934 time: 1703173111.3499212\n",
      "Training [19%] Loss: 0.0005610460747423583 time: 1703173111.3499212\n",
      "weight: [ 0.98545175  0.13771111  0.10638178  0.92334558  0.59778431  0.46127477\n",
      " -0.09004883  0.40050721  0.29627987 -0.37679503  0.60388254  0.30764168\n",
      "  0.56299252  0.05028354  0.6440262   0.15523353  0.19703297  0.66121123\n",
      "  0.52756882  0.51764932  0.52369319  0.90039588 -0.83539385 -0.79663215]\n",
      "epoch 20\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006619019855335877 R2: 0.9609867749136896 time: 1703173119.290713\n",
      "batch_idx: 1 loss: 0.00045863627112314954 R2: 0.9610154016095626 time: 1703173127.105089\n",
      "Training [20%] Loss: 0.0005602691283283686 time: 1703173127.105089\n",
      "weight: [ 0.98572959  0.13815156  0.10644709  0.92261975  0.59681667  0.46251003\n",
      " -0.09102341  0.39682284  0.29652866 -0.3766308   0.60654672  0.30625936\n",
      "  0.56216995  0.04950996  0.6448361   0.15497268  0.19732464  0.66150632\n",
      "  0.52592479  0.51641923  0.52352518  0.9002461  -0.83582492 -0.7957713 ]\n",
      "epoch 21\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006609675851385313 R2: 0.9610396821862885 time: 1703173135.0462801\n",
      "batch_idx: 1 loss: 0.00045802791810936735 R2: 0.961068161884526 time: 1703173143.2254763\n",
      "Training [21%] Loss: 0.0005594977516239493 time: 1703173143.2254763\n",
      "weight: [ 0.98600748  0.13858848  0.10650724  0.9218992   0.59585498  0.46374081\n",
      " -0.09199612  0.39311973  0.29682019 -0.37646212  0.60922511  0.30487033\n",
      "  0.56135392  0.04874481  0.64564038  0.15471862  0.19761831  0.661803\n",
      "  0.52428273  0.51518817  0.52335433  0.90009449 -0.83626456 -0.79490388]\n",
      "epoch 22\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006600403860373113 R2: 0.9610922179781405 time: 1703173150.966755\n",
      "batch_idx: 1 loss: 0.000457423455484422 R2: 0.9611205508867824 time: 1703173158.8092399\n",
      "Training [22%] Loss: 0.0005587319207608667 time: 1703173158.8092399\n",
      "weight: [ 0.98628543  0.13902175  0.10656212  0.92118389  0.59489925  0.46496704\n",
      " -0.09296667  0.38939858  0.29715423 -0.37628912  0.61191764  0.30347461\n",
      "  0.56054441  0.04798796  0.64643911  0.15447127  0.19791404  0.66210135\n",
      "  0.52264271  0.51395624  0.52318068  0.89994113 -0.83671258 -0.79403021]\n",
      "epoch 23\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000659120321293636 R2: 0.9611443836155267 time: 1703173166.6792774\n",
      "batch_idx: 1 loss: 0.00045682290399153854 R2: 0.9611725699230573 time: 1703173174.6273916\n",
      "Training [23%] Loss: 0.0005579716126425873 time: 1703173174.6273916\n",
      "weight: [ 0.98656343  0.13945126  0.10661162  0.92047379  0.5939495   0.46618868\n",
      " -0.09393482  0.38566011  0.29753051 -0.37611187  0.61462423  0.3020722\n",
      "  0.55974137  0.04723926  0.64723234  0.15423054  0.19821194  0.66240147\n",
      "  0.52100478  0.51272352  0.52300427  0.89978606 -0.83716877 -0.79315065]\n",
      "epoch 24\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006582073267857749 R2: 0.9611961803753288 time: 1703173182.4895504\n",
      "batch_idx: 1 loss: 0.00045622628300068734 R2: 0.9612242202536644 time: 1703173190.3317213\n",
      "Training [24%] Loss: 0.0005572168048932312 time: 1703173190.3317213\n",
      "weight: [ 0.98684149  0.1398769   0.10665565  0.91976887  0.59300574  0.4674057\n",
      " -0.0949003   0.38190504  0.29794871 -0.37593048  0.61734482  0.30066311\n",
      "  0.55894478  0.04649859  0.64802011  0.15399635  0.19851207  0.66270344\n",
      "  0.51936903  0.51149011  0.52282512  0.89962936 -0.83763294 -0.79226553]\n",
      "epoch 25\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006573013411044703 R2: 0.9612476094897058 time: 1703173198.1811185\n",
      "batch_idx: 1 loss: 0.0004556336105081565 R2: 0.961275503097068 time: 1703173206.1212225\n",
      "Training [25%] Loss: 0.0005564674758063133 time: 1703173206.1212225\n",
      "weight: [ 0.9871196   0.14029855  0.10669409  0.91906909  0.59206797  0.46861806\n",
      " -0.09586286  0.37813414  0.29840848 -0.37574505  0.6200793   0.29924731\n",
      "  0.5581546   0.04576581  0.64880248  0.15376861  0.19881451  0.66300733\n",
      "  0.51773552  0.51025609  0.52264327  0.89947107 -0.83810485 -0.79137517]\n",
      "epoch 26\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006564023054479547 R2: 0.9612986721506994 time: 1703173213.9169698\n",
      "batch_idx: 1 loss: 0.00045504490313838015 R2: 0.9613264196343655 time: 1703173221.7847757\n",
      "Training [26%] Loss: 0.0005557236042931674 time: 1703173221.7847757\n",
      "weight: [ 0.98739777  0.1407161   0.10672685  0.91837444  0.59113618  0.46982572\n",
      " -0.09682226  0.37434817  0.2989094  -0.37555569  0.62282759  0.29782482\n",
      "  0.5573708   0.04504079  0.6495795   0.15354725  0.19911934  0.66331323\n",
      "  0.51610434  0.50902156  0.52245873  0.89931125 -0.83858431 -0.79047991]\n",
      "epoch 27\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006555101635142078 R2: 0.9613493695147353 time: 1703173229.520865\n",
      "batch_idx: 1 loss: 0.00045446017614794753 R2: 0.9613769710136756 time: 1703173237.3658235\n",
      "Training [27%] Loss: 0.0005549851698310776 time: 1703173237.3658235\n",
      "weight: [ 0.98767599  0.14112944  0.10675382  0.91768486  0.59021038  0.47102867\n",
      " -0.09777825  0.37054792  0.29945101 -0.37536248  0.6255896   0.29639561\n",
      "  0.55659337  0.0443234   0.65035122  0.15333217  0.19942662  0.66362121\n",
      "  0.51447555  0.50778659  0.52227153  0.89914997 -0.83907107 -0.78958007]\n",
      "epoch 28\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006546248613906385 R2: 0.9613997027070459 time: 1703173245.1178844\n",
      "batch_idx: 1 loss: 0.0004538794434314767 R2: 0.9614271583544568 time: 1703173253.2470224\n",
      "Training [28%] Loss: 0.0005542521524110576 time: 1703173253.2470224\n",
      "weight: [ 0.98795426  0.14153845  0.10677491  0.91700034  0.58929054  0.47222688\n",
      " -0.09873061  0.3667342   0.30003281 -0.37516555  0.62836523  0.29495966\n",
      "  0.55582226  0.0436135   0.65111769  0.15312331  0.19973642  0.66393133\n",
      "  0.51284925  0.50655128  0.52208167  0.89898729 -0.8395649  -0.78867597]\n",
      "epoch 29\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006537463474414245 R2: 0.9614496728260107 time: 1703173260.979716\n",
      "batch_idx: 1 loss: 0.00045330271752922304 R2: 0.9614769827517475 time: 1703173268.7986398\n",
      "Training [29%] Loss: 0.0005535245324853237 time: 1703173268.7986398\n",
      "weight: [ 0.98823257  0.14194303  0.10679001  0.91632084  0.58837666  0.47342032\n",
      " -0.0996791   0.36290784  0.30065426 -0.374965    0.63115437  0.29351695\n",
      "  0.55505747  0.04291096  0.65187897  0.15292058  0.20004881  0.66424367\n",
      "  0.51122553  0.50531568  0.52188918  0.89882325 -0.84006559 -0.78776791]\n",
      "epoch 30\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006528745721926356 R2: 0.9614992809474139 time: 1703173276.598517\n",
      "batch_idx: 1 loss: 0.00045273000963619954 R2: 0.9615264452803276 time: 1703173284.4295661\n",
      "Training [30%] Loss: 0.0005528022909144176 time: 1703173284.4295661\n",
      "weight: [ 0.98851092  0.14234306  0.10679903  0.91564633  0.58746871  0.47460898\n",
      " -0.10062351  0.35906969  0.30131476 -0.37476093  0.63395692  0.29206745\n",
      "  0.55429897  0.04221564  0.65263511  0.1527239   0.20036384  0.66455829\n",
      "  0.50960446  0.5040799   0.52169407  0.89865792 -0.84057288 -0.78685622]\n",
      "epoch 31\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006520094882155664 R2: 0.9615485281286269 time: 1703173292.259407\n",
      "batch_idx: 1 loss: 0.0004521613296126661 R2: 0.9615755469988165 time: 1703173300.3390815\n",
      "Training [31%] Loss: 0.0005520854089141162 time: 1703173300.3390815\n",
      "weight: [ 0.98878932  0.14273844  0.10680186  0.91497677  0.58656667  0.47579284\n",
      " -0.10156362  0.35522061  0.30201366 -0.37455344  0.63677276  0.29061113\n",
      "  0.55354675  0.04152741  0.65338616  0.1525332   0.20068157  0.66487525\n",
      "  0.50798616  0.50284399  0.52149633  0.89849136 -0.84108653 -0.78594119]\n",
      "epoch 32\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006511510500084053 R2: 0.961597415412726 time: 1703173308.1090648\n",
      "batch_idx: 1 loss: 0.00045159668599573083 R2: 0.9616242889537003 time: 1703173315.9926436\n",
      "Training [32%] Loss: 0.0005513738680020681 time: 1703173315.9926436\n",
      "weight: [ 0.98906775  0.14312906  0.10679842  0.91431215  0.58567051  0.47697189\n",
      " -0.10249923  0.35136147  0.30275031 -0.37434265  0.63960179  0.28914795\n",
      "  0.55280078  0.04084614  0.65413216  0.15234838  0.20100205  0.6651946\n",
      "  0.50637071  0.50160803  0.52129597  0.89832363 -0.84160631 -0.78502313]\n",
      "epoch 33\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006502992138766691 R2: 0.961645943832522 time: 1703173323.7549558\n",
      "batch_idx: 1 loss: 0.0004510360860120007 R2: 0.9616726721832756 time: 1703173331.7269998\n",
      "Training [33%] Loss: 0.0005506676499443349 time: 1703173331.7269998\n",
      "weight: [ 0.98934621  0.14351481  0.10678861  0.91365243  0.58478021  0.47814612\n",
      " -0.10343014  0.3474932   0.30352395 -0.37412867  0.64244388  0.28767788\n",
      "  0.55206107  0.04017169  0.65487318  0.15216939  0.20132533  0.6655164\n",
      "  0.5047582   0.50037208  0.52109299  0.89815478 -0.84213195 -0.78410234]\n",
      "epoch 34\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006494539378126627 R2: 0.9616941144145137 time: 1703173339.6054103\n",
      "batch_idx: 1 loss: 0.0004504795355909739 R2: 0.9617206977215454 time: 1703173347.4209208\n",
      "Training [34%] Loss: 0.0005499667367018183 time: 1703173347.4209208\n",
      "weight: [ 0.9896247   0.14389559  0.10677234  0.91299758  0.58389573  0.47931553\n",
      " -0.10435614  0.3436167   0.30433385 -0.3739116   0.6452989   0.28620087\n",
      "  0.55132759  0.03950394  0.65560925  0.15199612  0.20165146  0.6658407\n",
      "  0.50314876  0.49913623  0.52088739  0.89798487 -0.84266322 -0.78317911]\n",
      "epoch 35\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006486151813743271 R2: 0.9617419281827939 time: 1703173355.2508006\n",
      "batch_idx: 1 loss: 0.0004499270393791523 R2: 0.9617683666020296 time: 1703173362.8773549\n",
      "Training [35%] Loss: 0.0005492711103767397 time: 1703173362.8773549\n",
      "weight: [ 0.9899032   0.14427128  0.10674951  0.91234757  0.58301703  0.48048011\n",
      " -0.10527707  0.33973291  0.30517917 -0.37369155  0.64816674  0.28471686\n",
      "  0.55060034  0.03884276  0.65634044  0.15182851  0.20198048  0.66616755\n",
      "  0.50154246  0.49790053  0.52067916  0.89781395 -0.84319986 -0.78225374]\n",
      "epoch 36\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006477829055638608 R2: 0.9617893861628393 time: 1703173370.7395406\n",
      "batch_idx: 1 loss: 0.0004493786007546003 R2: 0.9618156798615024 time: 1703173378.642711\n",
      "Training [36%] Loss: 0.0005485807531592306 time: 1703173378.642711\n",
      "weight: [ 0.99018172  0.14464179  0.10672004  0.91170237  0.58214409  0.48163986\n",
      " -0.10619272  0.3358428   0.30605908 -0.37346863  0.65104726  0.28322582\n",
      "  0.54987932  0.03818801  0.65706679  0.15166648  0.20231243  0.66649698\n",
      "  0.49993943  0.49666505  0.52046829  0.8976421  -0.84374161 -0.78132651]\n",
      "epoch 37\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006469570727063903 R2: 0.96183648938526 time: 1703173386.3079844\n",
      "batch_idx: 1 loss: 0.0004488342218419183 R2: 0.9618626385436689 time: 1703173394.7117696\n",
      "Training [37%] Loss: 0.0005478956472741543 time: 1703173394.7117696\n",
      "weight: [ 0.99046024  0.14500701  0.10668383  0.91106195  0.58127685  0.48279479\n",
      " -0.10710294  0.33194734  0.30697269 -0.37324296  0.65394033  0.28172767\n",
      "  0.54916453  0.03753957  0.65778835  0.15150994  0.20264735  0.66682906\n",
      "  0.49833978  0.49542984  0.52025477  0.89746935 -0.84428822 -0.78039771]\n",
      "epoch 38\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006461376463290913 R2: 0.9618832388894483 time: 1703173402.535576\n",
      "batch_idx: 1 loss: 0.00044829390352741255 R2: 0.9619092437027461 time: 1703173410.4279072\n",
      "Training [38%] Loss: 0.000547215774928252 time: 1703173410.4279072\n",
      "weight: [ 0.99073876  0.14536685  0.1066408   0.91042629  0.58041528  0.48394489\n",
      " -0.10800755  0.32804752  0.30791907 -0.37301464  0.65684581  0.28022236\n",
      "  0.54845595  0.03689731  0.65850517  0.15135881  0.20298527  0.6671638\n",
      "  0.49674361  0.49419497  0.52003859  0.89729578 -0.84483943 -0.77946761]\n",
      "epoch 39\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006453245910410858 R2: 0.9619296357271552 time: 1703173418.1638994\n",
      "batch_idx: 1 loss: 0.0004477576454744647 R2: 0.9619554964069834 time: 1703173425.9936032\n",
      "Training [39%] Loss: 0.0005465411182577753 time: 1703173425.9936032\n",
      "weight: [ 0.99101727  0.14572119  0.10659086  0.90979537  0.57955933  0.48509018\n",
      " -0.10890641  0.32414435  0.30889725 -0.37278377  0.65976357  0.27870983\n",
      "  0.54775361  0.0362611   0.6592173   0.15121301  0.20332623  0.66750126\n",
      "  0.49515103  0.49296049  0.51981973  0.89712143 -0.84539498 -0.7785365 ]\n",
      "epoch 40\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000644517872414424 R2: 0.9619756809659854 time: 1703173433.7644126\n",
      "batch_idx: 1 loss: 0.00044722544613889925 R2: 0.9620013977420883 time: 1703173441.8390298\n",
      "Training [40%] Loss: 0.0005458716592766615 time: 1703173441.8390298\n",
      "weight: [ 0.99129576  0.14606995  0.10653393  0.90916914  0.57870896  0.48623066\n",
      " -0.10979934  0.32023886  0.30990623 -0.37255048  0.66269347  0.27719\n",
      "  0.5470575   0.03563083  0.65992479  0.15107245  0.20367026  0.66784145\n",
      "  0.49356217  0.49172647  0.51959816  0.89694636 -0.84595461 -0.77760465]\n",
      "epoch 41\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006437174568665555 R2: 0.9620213756927989 time: 1703173449.833134\n",
      "batch_idx: 1 loss: 0.00044669730278432433 R2: 0.9620469488145786 time: 1703173457.6165876\n",
      "Training [41%] Loss: 0.0005452073798254399 time: 1703173457.6165876\n",
      "weight: [ 0.99157422  0.14641302  0.10646993  0.90854759  0.57786412  0.48736634\n",
      " -0.11068622  0.31633211  0.31094497 -0.37231487  0.66563536  0.27566281\n",
      "  0.54636762  0.03500636  0.66062768  0.15093706  0.20401738  0.66818443\n",
      "  0.49197713  0.49049294  0.51937388  0.89677062 -0.84651807 -0.77667232]\n",
      "epoch 42\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006429233115444626 R2: 0.9620667210170197 time: 1703173466.0457983\n",
      "batch_idx: 1 loss: 0.00044617321149739865 R2: 0.9620921507550262 time: 1703173474.167096\n",
      "Training [42%] Loss: 0.0005445482615209306 time: 1703173474.167096\n",
      "weight: [ 0.99185264  0.14675031  0.10639877  0.90793069  0.57702477  0.48849725\n",
      " -0.1115669   0.31242515  0.31201239 -0.37207704  0.66858909  0.27412818\n",
      "  0.545684    0.03438759  0.66132603  0.15080674  0.20436761  0.6685302\n",
      "  0.49039605  0.48925997  0.51914685  0.89659427 -0.8470851  -0.7757398 ]\n",
      "epoch 43\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006421354042108953 R2: 0.9621117180738705 time: 1703173481.8573992\n",
      "batch_idx: 1 loss: 0.0004456531672028946 R2: 0.9621370047212352 time: 1703173489.7834396\n",
      "Training [43%] Loss: 0.0005438942857068949 time: 1703173489.7834396\n",
      "weight: [ 0.99213101  0.14708172  0.10632037  0.90731842  0.57619084  0.48962339\n",
      " -0.11244125  0.30851906  0.3131074  -0.37183712  0.67155453  0.27258603\n",
      "  0.54500665  0.03377438  0.66201988  0.15068141  0.20472099  0.66887881\n",
      "  0.48881903  0.48802761  0.51891705  0.89641737 -0.84765544 -0.77480733]\n",
      "epoch 44\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006413537031328992 R2: 0.9621563680274858 time: 1703173497.7236989\n",
      "batch_idx: 1 loss: 0.000445137163678571 R2: 0.9621815119012964 time: 1703173505.601394\n",
      "Training [44%] Loss: 0.0005432454334057351 time: 1703173505.601394\n",
      "weight: [ 0.99240933  0.14740716  0.10623467  0.90671075  0.5753623   0.49074478\n",
      " -0.11330914  0.30461496  0.31422883 -0.3715952   0.67453152  0.27103629\n",
      "  0.54433557  0.03316663  0.66270929  0.15056098  0.20507752  0.66923027\n",
      "  0.48724621  0.4867959   0.51868446  0.89623996 -0.84822883 -0.77387518]\n",
      "epoch 45\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000640578176972997 R2: 0.96220067207394 time: 1703173513.399723\n",
      "batch_idx: 1 loss: 0.000444625193569769 R2: 0.9622256735165606 time: 1703173521.09481\n",
      "Training [45%] Loss: 0.000542601685271383 time: 1703173521.09481\n",
      "weight: [ 0.99268758  0.14772654  0.10614158  0.90610767  0.57453909  0.49186143\n",
      " -0.11417047  0.30071394  0.31537553 -0.37135139  0.67751992  0.26947886\n",
      "  0.5436708   0.03256421  0.66339429  0.15044536  0.20543723  0.66958461\n",
      "  0.4856777   0.48556489  0.51844904  0.8960621  -0.84880501 -0.77294361]\n",
      "epoch 46\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006398087946831714 R2: 0.9622446314441644 time: 1703173528.9540696\n",
      "batch_idx: 1 loss: 0.0004441172484037518 R2: 0.9622694908244961 time: 1703173536.8288512\n",
      "Training [46%] Loss: 0.0005419630215434616 time: 1703173536.8288512\n",
      "weight: [ 0.99296574  0.14803976  0.10604102  0.90550913  0.57372115  0.49297338\n",
      " -0.11502512  0.29681715  0.31654628 -0.3711058   0.68051956  0.26791366\n",
      "  0.54301234  0.03196701  0.66407493  0.15033445  0.20580013  0.66994185\n",
      "  0.48411364  0.48433464  0.51821076  0.89588385 -0.84938373 -0.77201287]\n",
      "epoch 47\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006390455254020221 R2: 0.9622882474067607 time: 1703173544.472253\n",
      "batch_idx: 1 loss: 0.00044361331860367397 R2: 0.9623129651214442 time: 1703173552.3513312\n",
      "Training [47%] Loss: 0.000541329422002848 time: 1703173552.3513312\n",
      "weight: [ 0.99324381  0.14834674  0.10593293  0.90491513  0.57290845  0.49408064\n",
      " -0.11587298  0.29292573  0.31773985 -0.37085854  0.68353031  0.2663406\n",
      "  0.54236024  0.03137491  0.66475127  0.15022817  0.20616624  0.67030201\n",
      "  0.48255414  0.48310517  0.51796959  0.89570525 -0.84996474 -0.77108322]\n",
      "epoch 48\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006382883383552163 R2: 0.962331521270696 time: 1703173560.2284372\n",
      "batch_idx: 1 loss: 0.0004431133935022689 R2: 0.9623560977452568 time: 1703173568.1058555\n",
      "Training [48%] Loss: 0.0005407008659287426 time: 1703173568.1058555\n",
      "weight: [ 0.99352177  0.14864739  0.10581724  0.90432565  0.57210091  0.49518324\n",
      " -0.11671396  0.28904084  0.31895498 -0.37060972  0.686552    0.26475959\n",
      "  0.5417145   0.03078781  0.66542334  0.15012642  0.20653557  0.6706651\n",
      "  0.48099934  0.48187654  0.5177255   0.89552635 -0.85054778 -0.77015488]\n",
      "epoch 49\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006375372027595193 R2: 0.9623744543878872 time: 1703173575.9514961\n",
      "batch_idx: 1 loss: 0.00044261746135516985 R2: 0.9623988900778192 time: 1703173583.6927824\n",
      "Training [49%] Loss: 0.0005400773320573446 time: 1703173583.6927824\n",
      "weight: [ 0.99379962  0.14894162  0.10569388  0.90374065  0.5712985   0.4962812\n",
      " -0.11754798  0.28516367  0.32019038 -0.37035943  0.68958449  0.26317053\n",
      "  0.54107517  0.0302056   0.66609119  0.1500291   0.20690813  0.67103115\n",
      "  0.47944936  0.48064879  0.51747845  0.89534721 -0.85113261 -0.76922812]\n",
      "epoch 50\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00063679208773054 R2: 0.9624170481556604 time: 1703173591.4604266\n",
      "batch_idx: 1 loss: 0.0004421255093538871 R2: 0.9624413435474569 time: 1703173599.2393532\n",
      "Training [50%] Loss: 0.0005394587985422135 time: 1703173599.2393532\n",
      "weight: [ 0.99407733  0.14922936  0.10556279  0.90316013  0.57050114  0.49737455\n",
      " -0.11837494  0.28129541  0.32144473 -0.37010779  0.69262762  0.26157333\n",
      "  0.54044228  0.02962816  0.66675486  0.14993612  0.20728393  0.67140016\n",
      "  0.47790434  0.47942195  0.5172284   0.89516788 -0.85171897 -0.76830316]\n",
      "epoch 51\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006360529621943868 R2: 0.962459304019094 time: 1703173607.259767\n",
      "batch_idx: 1 loss: 0.000441637523638491 R2: 0.9624834596312084 time: 1703173615.2463555\n",
      "Training [51%] Loss: 0.000538845242916439 time: 1703173615.2463555\n",
      "weight: [ 0.99435489  0.14951051  0.10542389  0.90258406  0.5697088   0.49846332\n",
      " -0.11919477  0.27743726  0.32271668 -0.36985489  0.69568123  0.25996789\n",
      "  0.53981585  0.0290554   0.6674144   0.14984737  0.20766297  0.67177214\n",
      "  0.4763644   0.47819608  0.51697533  0.8949884  -0.85230663 -0.76738024]\n",
      "epoch 52\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006353197948033567 R2: 0.9625012234732282 time: 1703173623.2182882\n",
      "batch_idx: 1 loss: 0.00044115348930995075 R2: 0.9625252398569801 time: 1703173631.047226\n",
      "Training [52%] Loss: 0.0005382366420566537 time: 1703173631.047226\n",
      "weight: [ 0.99463229  0.149785    0.10527713  0.90201242  0.56892141  0.49954754\n",
      " -0.12000741  0.27359046  0.32400488 -0.36960085  0.69874517  0.2583541\n",
      "  0.53919594  0.0284872   0.66806986  0.14976275  0.20804526  0.67214712\n",
      "  0.47482967  0.47697121  0.51671918  0.89480882 -0.85289533 -0.7664596 ]\n",
      "epoch 53\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006345925538558205 R2: 0.962542808065151 time: 1703173638.7545352\n",
      "batch_idx: 1 loss: 0.0004406733904422378 R2: 0.9625666858055666 time: 1703173646.6803176\n",
      "Training [53%] Loss: 0.0005376329721490292 time: 1703173646.6803176\n",
      "weight: [ 0.99490951  0.15005275  0.10512245  0.9014452   0.56813893  0.50062723\n",
      " -0.12081279  0.26975622  0.32530794 -0.36934575  0.70181929  0.25673187\n",
      "  0.53858258  0.02792347  0.66872128  0.14968215  0.20843082  0.6725251\n",
      "  0.4733003   0.47574737  0.51645992  0.89462919 -0.85348485 -0.76554146]\n",
      "epoch 54\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006338712072203665 R2: 0.9625840593959445 time: 1703173654.4481502\n",
      "batch_idx: 1 loss: 0.00044019721009411455 R2: 0.9626077991125375 time: 1703173662.2473404\n",
      "Training [54%] Loss: 0.0005370342086572405 time: 1703173662.2473404\n",
      "weight: [ 0.99518654  0.15031369  0.10495979  0.90088238  0.56736129  0.50170244\n",
      " -0.12161085  0.26593581  0.32662445 -0.36908971  0.70490343  0.25510109\n",
      "  0.53797582  0.02736409  0.66936869  0.14960548  0.20881963  0.67290608\n",
      "  0.4717764   0.47452461  0.51619752  0.89444956 -0.85407494 -0.76462603]\n",
      "epoch 55\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006331557222642966 R2: 0.962624979122509 time: 1703173670.2021637\n",
      "batch_idx: 1 loss: 0.00043972493032081025 R2: 0.9626485814699877 time: 1703173678.0173635\n",
      "Training [55%] Loss: 0.0005364403262925534 time: 1703173678.0173635\n",
      "weight: [ 0.99546337  0.15056774  0.10478911  0.90032394  0.56658844  0.50277319\n",
      " -0.12240155  0.26213049  0.32795298 -0.36883282  0.70799743  0.25346165\n",
      "  0.5373757   0.02680898  0.67001215  0.14953263  0.2092117   0.67329008\n",
      "  0.47025811  0.47330296  0.51593193  0.89426996 -0.85466536 -0.76371355]\n",
      "epoch 56\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000632446065786587 R2: 0.962665568959227 time: 1703173685.8850787\n",
      "batch_idx: 1 loss: 0.00043925653218546536 R2: 0.9626890346281514 time: 1703173693.7734818\n",
      "Training [56%] Loss: 0.0005358512989860262 time: 1703173693.7734818\n",
      "weight: [ 0.99573996  0.15081483  0.10461033  0.89976986  0.56582033  0.50383951\n",
      " -0.12318484  0.25834151  0.3292921  -0.36857518  0.71110116  0.25181345\n",
      "  0.53678227  0.02625804  0.67065169  0.14946347  0.20960704  0.6736771\n",
      "  0.46874558  0.47208246  0.5156631   0.89409046 -0.8552559  -0.76280422]\n",
      "epoch 57\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006317422039552678 R2: 0.9627058306795131 time: 1703173701.6035006\n",
      "batch_idx: 1 loss: 0.00043879199577048593 R2: 0.9627291603968711 time: 1703173709.325616\n",
      "Training [57%] Loss: 0.0005352670998628769 time: 1703173709.325616\n",
      "weight: [ 0.99601632  0.15105488  0.10442343  0.89922014  0.5650569   0.50490145\n",
      " -0.12396068  0.25457018  0.33064033 -0.36831689  0.71421444  0.25015638\n",
      "  0.53619559  0.02571116  0.67128736  0.14939792  0.21000564  0.67406716\n",
      "  0.46723892  0.47086314  0.51539101  0.89391108 -0.85584632 -0.76189825]\n",
      "epoch 58\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006310441022493686 R2: 0.9627457661172023 time: 1703173717.1708827\n",
      "batch_idx: 1 loss: 0.0004383313001888457 R2: 0.9627689606469267 time: 1703173725.254077\n",
      "Training [58%] Loss: 0.0005346877012191071 time: 1703173725.254077\n",
      "weight: [ 0.99629241  0.15128784  0.10422834  0.89867476  0.56429811  0.50595903\n",
      " -0.12472905  0.25081778  0.3319962  -0.36805805  0.71733714  0.24849033\n",
      "  0.53561572  0.02516826  0.6719192   0.14933584  0.21040751  0.67446025\n",
      "  0.46573827  0.46964504  0.5151156   0.89373188 -0.8564364  -0.76099585]\n",
      "epoch 59\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006303517254053251 R2: 0.9627853771678095 time: 1703173733.1623068\n",
      "batch_idx: 1 loss: 0.0004378744235953719 R2: 0.9628084373112242 time: 1703173740.9212098\n",
      "Training [59%] Loss: 0.0005341130745003485 time: 1703173740.9212098\n",
      "weight: [ 0.99656823  0.15151364  0.10402503  0.89813371  0.56354389  0.50701231\n",
      " -0.12548992  0.24708561  0.33335823 -0.36779875  0.7204691   0.24681518\n",
      "  0.53504271  0.02462924  0.67254724  0.14927713  0.21081264  0.67485638\n",
      "  0.46424378  0.4684282   0.51483684  0.8935529  -0.85702592 -0.76009722]\n",
      "epoch 60\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006296650373679555 R2: 0.9628246657896262 time: 1703173748.7774587\n",
      "batch_idx: 1 loss: 0.00043742134319808216 R2: 0.9628475923858252 time: 1703173756.701052\n",
      "Training [60%] Loss: 0.0005335431902830188 time: 1703173756.701052\n",
      "weight: [ 0.99684376  0.15173222  0.10381345  0.89759696  0.56279419  0.5080613\n",
      " -0.12624328  0.24337498  0.33472491 -0.36753909  0.72361017  0.24513084\n",
      "  0.53447663  0.024094    0.67317153  0.14922168  0.21122104  0.67525555\n",
      "  0.46275556  0.46721264  0.51455468  0.89337417 -0.85761466 -0.75920256]\n",
      "epoch 61\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006289840012458877 R2: 0.9628636340046957 time: 1703173764.4992836\n",
      "batch_idx: 1 loss: 0.0004369720352696401 R2: 0.9628864279308516 time: 1703173772.4115794\n",
      "Training [61%] Loss: 0.0005329780182577639 time: 1703173772.4115794\n",
      "weight: [ 0.99711897  0.15194351  0.10359356  0.89706452  0.56204896  0.50910605\n",
      " -0.12698911  0.23968722  0.33609472 -0.36727916  0.72676021  0.24343718\n",
      "  0.53391753  0.02356247  0.67379211  0.14916936  0.21163269  0.67565777\n",
      "  0.46127376  0.4659984   0.51426908  0.89319574 -0.85820242 -0.75831205]\n",
      "epoch 62\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006283085792715104 R2: 0.9629022838996162 time: 1703173780.2091136\n",
      "batch_idx: 1 loss: 0.00043652647515895327 R2: 0.9629249460712217 time: 1703173788.1344223\n",
      "Training [62%] Loss: 0.0005324175272152318 time: 1703173788.1344223\n",
      "weight: [ 0.99739385  0.15214745  0.10336534  0.89653637  0.56130815  0.51014661\n",
      " -0.12772741  0.23602364  0.33746615 -0.36701905  0.72991906  0.2417341\n",
      "  0.5333655   0.02303455  0.67440902  0.14912006  0.2120476   0.67606304\n",
      "  0.45979851  0.46478552  0.51397999  0.89301765 -0.85878899 -0.75742588]\n",
      "epoch 63\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006276387327652711 R2: 0.9629406176262207 time: 1703173795.9967175\n",
      "batch_idx: 1 loss: 0.0004360846373030456 R2: 0.9629631489972545 time: 1703173804.1586602\n",
      "Training [63%] Loss: 0.0005318616850341583 time: 1703173804.1586602\n",
      "weight: [ 0.99766838  0.152344    0.10312873  0.89601251  0.56057171  0.511183\n",
      " -0.12845818  0.23238557  0.33883767 -0.36675886  0.73308659  0.24002147\n",
      "  0.5328206   0.02251016  0.67502229  0.14907366  0.21246576  0.67647137\n",
      "  0.45832994  0.46357402  0.51368738  0.89283993 -0.85937417 -0.75654424]\n",
      "epoch 64\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000626974422104442 R2: 0.962978637402091 time: 1703173812.258102\n",
      "batch_idx: 1 loss: 0.0004356464952391879 R2: 0.9630010389651218 time: 1703173820.119363\n",
      "Training [64%] Loss: 0.000531310458671815 time: 1703173820.119363\n",
      "weight: [ 0.99794254  0.15253311  0.10288372  0.89549291  0.55983958  0.51221527\n",
      " -0.12918143  0.22877436  0.34020774 -0.36649867  0.73626266  0.2382992\n",
      "  0.53228291  0.0219892   0.67563197  0.14903005  0.21288718  0.67688275\n",
      "  0.45686819  0.46236394  0.5133912   0.89266263 -0.85995775 -0.75566729]\n",
      "epoch 65\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006263156066960484 R2: 0.9630163455109397 time: 1703173827.9296176\n",
      "batch_idx: 1 loss: 0.00043521202161739476 R2: 0.9630386182971454 time: 1703173835.5661886\n",
      "Training [65%] Loss: 0.0005307638141567216 time: 1703173835.5661886\n",
      "weight: [ 0.99821632  0.15271471  0.10263028  0.89497758  0.55911171  0.51324347\n",
      " -0.12989717  0.22519133  0.34157482 -0.36623857  0.73944711  0.23656716\n",
      "  0.5317525   0.0214716   0.67623808  0.14898909  0.21331184  0.67729719\n",
      "  0.45541338  0.46115532  0.51309141  0.89248577 -0.86053954 -0.75479521]\n",
      "epoch 66\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006256622449541201 R2: 0.9630537443028333 time: 1703173843.5180302\n",
      "batch_idx: 1 loss: 0.000434781188213363 R2: 0.9630758893819646 time: 1703173851.4599833\n",
      "Training [66%] Loss: 0.0005302217165837416 time: 1703173851.4599833\n",
      "weight: [ 0.99848968  0.15288878  0.10236838  0.89446651  0.55838806  0.51426762\n",
      " -0.13060542  0.22163782  0.34293738 -0.36597866  0.74263981  0.23482524\n",
      "  0.53122945  0.02095728  0.67684068  0.14895068  0.21373975  0.6777147\n",
      "  0.45396566  0.45994817  0.51278797  0.89230941 -0.86111936 -0.75392817]\n",
      "epoch 67\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006250142942809813 R2: 0.9630908361942832 time: 1703173859.258315\n",
      "batch_idx: 1 loss: 0.0004343539659418637 R2: 0.9631128546745458 time: 1703173866.9940789\n",
      "Training [67%] Loss: 0.0005296841301114225 time: 1703173866.9940789\n",
      "weight: [ 0.99876261  0.15305525  0.10209799  0.89395969  0.55766857  0.51528778\n",
      " -0.1313062   0.21811518  0.34429386 -0.36571901  0.74584064  0.23307334\n",
      "  0.53071385  0.02044615  0.6774398   0.14891469  0.2141709   0.67813526\n",
      "  0.45252515  0.45874254  0.51248084  0.89213356 -0.86169701 -0.75306633]\n",
      "epoch 68\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006243717110525542 R2: 0.9631276236681809 time: 1703173874.8084426\n",
      "batch_idx: 1 loss: 0.00043393032487069937 R2: 0.9631495166960496 time: 1703173882.6092236\n",
      "Training [68%] Loss: 0.0005291510179616268 time: 1703173882.6092236\n",
      "weight: [ 0.99903509  0.1532141   0.10181911  0.89345712  0.55695319  0.51630398\n",
      " -0.13199955  0.21462475  0.34564272 -0.36545971  0.74904944  0.23131133\n",
      "  0.53020579  0.01993814  0.67803547  0.148881    0.21460528  0.67855889\n",
      "  0.45109198  0.45753845  0.51216996  0.89195826 -0.86227233 -0.75220984]\n",
      "epoch 69\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006237344506076121 R2: 0.9631641092735983 time: 1703173890.4873292\n",
      "batch_idx: 1 loss: 0.0004335102342352501 R2: 0.9631858780335636 time: 1703173898.3196929\n",
      "Training [69%] Loss: 0.0005286223424214311 time: 1703173898.3196929\n",
      "weight: [ 0.99930711  0.15336528  0.10153171  0.89295878  0.55624188  0.51731626\n",
      " -0.13268551  0.21116787  0.34698243 -0.36520086  0.7522661   0.22953911\n",
      "  0.52970536  0.01943317  0.67862773  0.14884949  0.2150429   0.67898558\n",
      "  0.44966629  0.45633594  0.51185531  0.89178355 -0.86284513 -0.75135884]\n",
      "epoch 70\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006231024672407164 R2: 0.9632002956254417 time: 1703173906.178976\n",
      "batch_idx: 1 loss: 0.0004330936624536919 R2: 0.9632219413396849 time: 1703173914.065528\n",
      "Training [70%] Loss: 0.0005280980648472042 time: 1703173914.065528\n",
      "weight: [ 0.99957863  0.15350876  0.10123579  0.89246469  0.55553459  0.51832468\n",
      " -0.1333641   0.20774587  0.34831144 -0.36494252  0.75549048  0.22775656\n",
      "  0.52921265  0.01893115  0.67921661  0.14882004  0.21548374  0.67941535\n",
      "  0.44824821  0.45513504  0.51153683  0.89160946 -0.86341524 -0.7505135 ]\n",
      "epoch 71\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006224757141988793 R2: 0.9632361854039788 time: 1703173921.8573627\n",
      "batch_idx: 1 loss: 0.00043268057714291057 R2: 0.9632577093319673 time: 1703173929.8917196\n",
      "Training [71%] Loss: 0.000527578145670895 time: 1703173929.8917196\n",
      "weight: [ 0.99984964  0.15364451  0.10093132  0.89197483  0.55483127  0.51932927\n",
      " -0.1340354   0.20436009  0.34962823 -0.36468478  0.75872246  0.22596358\n",
      "  0.52872776  0.01843203  0.67980216  0.14879253  0.2159278   0.67984818\n",
      "  0.44683786  0.45393577  0.51121449  0.89143602 -0.8639825  -0.74967394]\n",
      "epoch 72\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006218541436816956 R2: 0.963271781354208 time: 1703173937.6688566\n",
      "batch_idx: 1 loss: 0.00043227094513518415 R2: 0.9632931847922415 time: 1703173945.7490015\n",
      "Training [72%] Loss: 0.0005270625444084399 time: 1703173945.7490015\n",
      "weight: [ 1.00012011  0.1537725   0.10061832  0.8914892   0.55413187  0.52033007\n",
      " -0.13469944  0.20101184  0.35093127 -0.36442772  0.76196191  0.22416006\n",
      "  0.52825079  0.01793572  0.6803844   0.14876684  0.21637509  0.68028408\n",
      "  0.44543537  0.45273817  0.51088825  0.89126325 -0.86454674 -0.7488403 ]\n",
      "epoch 73\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006212377068448568 R2: 0.9633070862851104 time: 1703173953.5703201\n",
      "batch_idx: 1 loss: 0.00043186473249566537 R2: 0.9633283705657826 time: 1703173961.6582541\n",
      "Training [73%] Loss: 0.000526551219670261 time: 1703173961.6582541\n",
      "weight: [ 1.00039003  0.1538927   0.10029677  0.8910078   0.55343634  0.52132713\n",
      " -0.13535628  0.19770246  0.35221905 -0.36417143  0.76520871  0.22234587\n",
      "  0.52778184  0.01744215  0.68096337  0.14874286  0.21682559  0.68072306\n",
      "  0.44404088  0.45154226  0.51055807  0.89109119 -0.86510781 -0.7480127 ]\n",
      "epoch 74\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006206263538068875 R2: 0.9633421030687754 time: 1703173969.438178\n",
      "batch_idx: 1 loss: 0.00043146190454070683 R2: 0.9633632695603728 time: 1703173977.1736956\n",
      "Training [74%] Loss: 0.0005260441291737971 time: 1703173977.1736956\n",
      "weight: [ 1.00065937  0.1540051   0.09996668  0.89053063  0.55274465  0.52232049\n",
      " -0.136006    0.19443325  0.35349006 -0.36391597  0.76846275  0.22052093\n",
      "  0.52732102  0.01695125  0.6815391   0.14872048  0.21727931  0.68116511\n",
      "  0.4426545   0.45034808  0.5102239   0.89091986 -0.86566556 -0.74719128]\n",
      "epoch 75\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.000620020033658973 R2: 0.9633768346393742 time: 1703173985.0270336\n",
      "batch_idx: 1 loss: 0.0004310624258570827 R2: 0.9633978847452156 time: 1703173993.105934\n",
      "Training [75%] Loss: 0.0005255412297580278 time: 1703173993.105934\n",
      "weight: [ 1.00092811  0.15410968  0.09962804  0.89005769  0.55205674  0.52331019\n",
      " -0.13664866  0.19120551  0.35474282 -0.36366143  0.77172391  0.21868512\n",
      "  0.52686844  0.01646296  0.68211163  0.14869957  0.21773623  0.68161023\n",
      "  0.44127637  0.44915566  0.50988571  0.89074929 -0.86621984 -0.74637615]\n",
      "epoch 76\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006194186944776983 R2: 0.9634112839920379 time: 1703174001.2944453\n",
      "batch_idx: 1 loss: 0.0004306662603220766 R2: 0.9634322191497404 time: 1703174009.1974144\n",
      "Training [76%] Loss: 0.0005250424773998875 time: 1703174009.1974144\n",
      "weight: [ 1.00119624  0.15420642  0.09928087  0.88958899  0.55137258  0.52429628\n",
      " -0.13728434  0.18802054  0.35597584 -0.36340788  0.77499208  0.21683832\n",
      "  0.52642422  0.01597719  0.682681    0.14868002  0.21819637  0.68205844\n",
      "  0.43990661  0.44796501  0.50954346  0.89057951 -0.86677051 -0.74556741]\n",
      "epoch 77\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006188222833405784 R2: 0.9634454541815931 time: 1703174017.0965436\n",
      "batch_idx: 1 loss: 0.0004302733711245842 R2: 0.9634662758622767 time: 1703174024.943117\n",
      "Training [77%] Loss: 0.0005245478272325813 time: 1703174024.943117\n",
      "weight: [ 1.00146372  0.1542953   0.09892518  0.88912452  0.55069211  0.5252788\n",
      " -0.13791312  0.18487961  0.35718767 -0.36315539  0.77826715  0.21498045\n",
      "  0.52598846  0.0154939   0.68324723  0.14866174  0.2186597   0.68250972\n",
      "  0.43854535  0.44677617  0.5091971   0.89041054 -0.86731742 -0.74476518]\n",
      "epoch 78\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006182307463441602 R2: 0.9634793483211931 time: 1703174032.8355236\n",
      "batch_idx: 1 loss: 0.00042988372078706365 R2: 0.9635000580286286 time: 1703174040.7990534\n",
      "Training [78%] Loss: 0.0005240572335656119 time: 1703174040.7990534\n",
      "weight: [ 1.00173053  0.15437633  0.09856098  0.88866429  0.5500153   0.5262578\n",
      " -0.13853508  0.18178398  0.35837686 -0.36290405  0.78154902  0.2131114\n",
      "  0.5255613   0.01501301  0.68381036  0.1486446   0.21912624  0.68296409\n",
      "  0.4371927   0.44558918  0.5088466   0.8902424  -0.86786046 -0.74396956]\n",
      "epoch 79\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006176440286246469 R2: 0.9635129695808289 time: 1703174048.657224\n",
      "batch_idx: 1 loss: 0.00042949727118854226 R2: 0.9635335688505247 time: 1703174056.5691915\n",
      "Training [79%] Loss: 0.0005235706499065946 time: 1703174056.5691915\n",
      "weight: [ 1.00199666  0.15444949  0.09818829  0.8882083   0.5493421   0.52723331\n",
      " -0.13915032  0.1787349   0.359542   -0.36265391  0.78483758  0.21123106\n",
      "  0.52514286  0.01453446  0.68437041  0.14862852  0.21959599  0.68342155\n",
      "  0.43584879  0.44440404  0.50849193  0.89007512 -0.86839949 -0.74318065]\n",
      "epoch 80\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006170620743807354 R2: 0.9635463211857431 time: 1703174064.6611066\n",
      "batch_idx: 1 loss: 0.00042911398358857946 R2: 0.9635668115839666 time: 1703174072.7899606\n",
      "Training [80%] Loss: 0.0005230880289846575 time: 1703174072.7899606\n",
      "weight: [ 1.00226208  0.15451479  0.09780712  0.88775656  0.54867247  0.52820538\n",
      " -0.13975893  0.1757336   0.36068168 -0.36240505  0.78813274  0.20933933\n",
      "  0.52473326  0.01405818  0.68492743  0.14861337  0.22006893  0.68388209\n",
      "  0.43451374  0.4432208   0.50813303  0.88990872 -0.86893439 -0.74239853]\n",
      "epoch 81\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006164848268986423 R2: 0.9635794064147258 time: 1703174080.6930676\n",
      "batch_idx: 1 loss: 0.0004287338186521374 R2: 0.9635997895374826 time: 1703174088.5529246\n",
      "Training [81%] Loss: 0.0005226093227753898 time: 1703174088.5529246\n",
      "weight: [ 1.00252677  0.15457223  0.09741751  0.88730907  0.54800637  0.52917406\n",
      " -0.14036101  0.17278129  0.36179452 -0.36215753  0.7914344   0.20743612\n",
      "  0.52433263  0.01358411  0.68548145  0.14859908  0.22054506  0.68434573\n",
      "  0.43318767  0.44203947  0.50776987  0.88974321 -0.86946504 -0.74162329]\n",
      "epoch 82\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006159122285790801 R2: 0.9636122285983288 time: 1703174096.3906667\n",
      "batch_idx: 1 loss: 0.0004283567364755078 R2: 0.9636325060702731 time: 1703174104.3153307\n",
      "Training [82%] Loss: 0.000522134482527294 time: 1703174104.3153307\n",
      "weight: [ 1.0027907   0.15462182  0.09701948  0.88686583  0.54734375  0.53013939\n",
      " -0.14095668  0.16987916  0.36287919 -0.36191144  0.79474247  0.20552133\n",
      "  0.52394111  0.0131122   0.68603249  0.14858555  0.2210244   0.68481247\n",
      "  0.43187069  0.44086009  0.50740243  0.88957863 -0.86999132 -0.74085501]\n",
      "epoch 83\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006153442209660353 R2: 0.9636447911169699 time: 1703174112.0534124\n",
      "batch_idx: 1 loss: 0.00042798269661311033 R2: 0.9636649645902816 time: 1703174119.899713\n",
      "Training [83%] Loss: 0.0005216634587895729 time: 1703174119.899713\n",
      "weight: [ 1.00305386  0.15466356  0.09661306  0.88642687  0.54668459  0.53110141\n",
      " -0.14154603  0.16702837  0.36393435 -0.36166683  0.79805686  0.20359486\n",
      "  0.52355884  0.01264238  0.68658058  0.14857268  0.22150694  0.6852823\n",
      "  0.43056293  0.43968267  0.50703065  0.88941498 -0.87051313 -0.74009377]\n",
      "epoch 84\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006147807447772072 R2: 0.9636770973989719 time: 1703174127.683151\n",
      "batch_idx: 1 loss: 0.0004276116581052437 R2: 0.9636971685521658 time: 1703174135.4840205\n",
      "Training [84%] Loss: 0.0005211962014412255 time: 1703174135.4840205\n",
      "weight: [ 1.00331623  0.15469747  0.09619828  0.88599217  0.54602883  0.53206016\n",
      " -0.14212919  0.16423006  0.36495871 -0.36142376  0.80137748  0.20165662\n",
      "  0.52318596  0.01217459  0.68712577  0.1485604   0.22199267  0.68575525\n",
      "  0.4292645   0.43850724  0.5066545   0.88925229 -0.87103037 -0.73933964]\n",
      "epoch 85\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006142217399359342 R2: 0.9637091509184963 time: 1703174143.356739\n",
      "batch_idx: 1 loss: 0.0004272435795067561 R2: 0.9637291214552024 time: 1703174151.1227205\n",
      "Training [85%] Loss: 0.0005207326597213451 time: 1703174151.1227205\n",
      "weight: [ 1.00357777  0.15472357  0.09577518  0.88556176  0.54537644  0.53301569\n",
      " -0.14270627  0.16148537  0.36595101 -0.36118231  0.80470427  0.19970651\n",
      "  0.52282261  0.01170878  0.68766807  0.14854862  0.22248161  0.6862313\n",
      "  0.42797552  0.43733383  0.50627395  0.88909057 -0.87154294 -0.73859267]\n",
      "epoch 86\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006136671456044516 R2: 0.9637409551934157 time: 1703174158.9536953\n",
      "batch_idx: 1 loss: 0.00042687841891650294 R2: 0.9637608268411142 time: 1703174166.8645291\n",
      "Training [86%] Loss: 0.0005202727822604773 time: 1703174166.8645291\n",
      "weight: [ 1.00383847  0.15474187  0.09534381  0.88513564  0.54472739  0.53396803\n",
      " -0.14327741  0.15879536  0.36691002 -0.36094254  0.80803713  0.19774445\n",
      "  0.52246895  0.01124489  0.68820752  0.14853728  0.22297375  0.68671047\n",
      "  0.42669609  0.43616246  0.50588895  0.88892984 -0.87205073 -0.73785294]\n",
      "epoch 87\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006131169002183267 R2: 0.9637725137831236 time: 1703174174.56944\n",
      "batch_idx: 1 loss: 0.0004265161340076892 R2: 0.9637922882918246 time: 1703174182.5506973\n",
      "Training [87%] Loss: 0.000519816517113008 time: 1703174182.5506973\n",
      "weight: [ 1.00409831  0.1547524   0.0949042   0.88471382  0.54408163  0.53491724\n",
      " -0.14384272  0.15616112  0.36783455 -0.3607045   0.811376    0.19577034\n",
      "  0.52212512  0.01078287  0.68874416  0.14852629  0.22346909  0.68719275\n",
      "  0.42542633  0.43499315  0.50549948  0.88877011 -0.87255366 -0.7371205 ]\n",
      "epoch 88\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006125709415219223 R2: 0.9638038302862599 time: 1703174190.3324876\n",
      "batch_idx: 1 loss: 0.00042615668205890877 R2: 0.9638235094271698 time: 1703174198.2024224\n",
      "Training [88%] Loss: 0.0005193638117904155 time: 1703174198.2024224\n",
      "weight: [ 1.00435727  0.1547552   0.0944564   0.88429632  0.54343912  0.53586336\n",
      " -0.14440235  0.15358366  0.36872344 -0.36046826  0.8147208   0.19378411\n",
      "  0.52179128  0.01032266  0.689278    0.14851561  0.22396764  0.68767817\n",
      "  0.42416636  0.43382591  0.5051055   0.8886114  -0.87305165 -0.7363954 ]\n",
      "epoch 89\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006120292066047638 R2: 0.963834908338405 time: 1703174205.9604635\n",
      "batch_idx: 1 loss: 0.00042580001998592513 R2: 0.9638544939025444 time: 1703174213.8153026\n",
      "Training [89%] Loss: 0.0005189146132953445 time: 1703174213.8153026\n",
      "weight: [ 1.00461532  0.15475028  0.09400047  0.88388314  0.54279983  0.53680642\n",
      " -0.14495642  0.15106399  0.36957558 -0.36023387  0.81807146  0.19178566\n",
      "  0.5214676   0.00986421  0.68980908  0.14850516  0.22446941  0.68816672\n",
      "  0.42291626  0.43266078  0.50470696  0.88845373 -0.8735446  -0.73567768]\n",
      "epoch 90\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006114916319385788 R2: 0.9638657516097002 time: 1703174221.6022441\n",
      "batch_idx: 1 loss: 0.0004254461043740449 R2: 0.9638852454064974 time: 1703174229.4462378\n",
      "Training [90%] Loss: 0.0005184688681563118 time: 1703174229.4462378\n",
      "weight: [ 1.00487245  0.1547377   0.09353645  0.88347429  0.54216373  0.53774646\n",
      " -0.14550509  0.14860309  0.37038988 -0.3600014   0.82142793  0.18977492\n",
      "  0.52115423  0.00940746  0.69033743  0.14849491  0.22497439  0.68865841\n",
      "  0.42167617  0.43149778  0.50430384  0.8882971  -0.87403245 -0.73496739]\n",
      "epoch 91\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006109581534149916 R2: 0.963896363802452 time: 1703174237.2434123\n",
      "batch_idx: 1 loss: 0.00042509489151110495 R2: 0.963915767658311 time: 1703174245.1553576\n",
      "Training [91%] Loss: 0.0005180265224630483 time: 1703174245.1553576\n",
      "weight: [ 1.00512863  0.15471748  0.0930644   0.8830698   0.54153077  0.53868354\n",
      " -0.14604849  0.14620187  0.37116531 -0.35977091  0.82479015  0.1877518\n",
      "  0.52085134  0.00895236  0.69086308  0.1484848   0.22548259  0.68915324\n",
      "  0.42044617  0.43033691  0.50389609  0.88814153 -0.87451512 -0.73426457]\n",
      "epoch 92\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006104287063836095 R2: 0.9639267486486768 time: 1703174252.9691234\n",
      "batch_idx: 1 loss: 0.00042474633742087514 R2: 0.9639460644055193 time: 1703174260.8474264\n",
      "Training [92%] Loss: 0.0005175875219022423 time: 1703174260.8474264\n",
      "weight: [ 1.00538383  0.15468967  0.09258438  0.88266968  0.54090093  0.53961769\n",
      " -0.14658677  0.14386125  0.37190089 -0.35954244  0.82815805  0.18571622\n",
      "  0.52055911  0.00849888  0.69138606  0.14847479  0.22599402  0.68965124\n",
      "  0.41922638  0.4291782   0.50348369  0.88798703 -0.87499255 -0.73356924]\n",
      "epoch 93\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006099032256904962 R2: 0.9639569099076303 time: 1703174268.747293\n",
      "batch_idx: 1 loss: 0.00042440039789693325 R2: 0.9639761394214256 time: 1703174277.0374894\n",
      "Training [93%] Loss: 0.0005171518117937147 time: 1703174277.0374894\n",
      "weight: [ 1.00563805  0.15465432  0.09209646  0.88227393  0.54027416  0.54054895\n",
      " -0.14712009  0.14158209  0.37259566 -0.35931605  0.83153158  0.1836681\n",
      "  0.52027771  0.00804694  0.69190639  0.14846486  0.22650869  0.69015239\n",
      "  0.41801689  0.42802167  0.5030666   0.88783362 -0.87546465 -0.73288144]\n",
      "epoch 94\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006093816457167525 R2: 0.9639868513633163 time: 1703174284.9024167\n",
      "batch_idx: 1 loss: 0.00042405702853680105 R2: 0.9640059965025858 time: 1703174292.8017337\n",
      "Training [94%] Loss: 0.0005167193371267768 time: 1703174292.8017337\n",
      "weight: [ 1.00589126  0.15461147  0.09160069  0.88188258  0.53965044  0.54147736\n",
      " -0.14764859  0.13936521  0.37324873 -0.35909179  0.8349107   0.18160738\n",
      "  0.52000731  0.00759652  0.69242411  0.14845499  0.2270266   0.69065672\n",
      "  0.41681781  0.42686733  0.50264479  0.88768129 -0.87593138 -0.73220119]\n",
      "epoch 95\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006088639004172094 R2: 0.9640165768219695 time: 1703174300.6005976\n",
      "batch_idx: 1 loss: 0.0004237161847763407 R2: 0.9640356394662936 time: 1703174308.354938\n",
      "Training [95%] Loss: 0.000516290042596775 time: 1703174308.354938\n",
      "weight: [ 1.00614345  0.15456118  0.09109714  0.88149564  0.53902973  0.54240297\n",
      " -0.14817245  0.1372114   0.37385926 -0.35886972  0.83829536  0.17953397\n",
      "  0.51974811  0.00714755  0.69293925  0.14844515  0.22754777  0.69116423\n",
      "  0.41562924  0.4257152   0.50221821  0.88753007 -0.87639268 -0.73152852]\n",
      "epoch 96\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006083499233590611 R2: 0.9640460901095486 time: 1703174316.263208\n",
      "batch_idx: 1 loss: 0.0004233778219242718 R2: 0.9640650721480533 time: 1703174324.4566429\n",
      "Training [96%] Loss: 0.0005158638726416665 time: 1703174324.4566429\n",
      "weight: [ 1.00639458  0.15450351  0.09058589  0.88111313  0.53841199  0.54332581\n",
      " -0.14869182  0.13512141  0.37442643 -0.35864989  0.84168551  0.17744781\n",
      "  0.51950028  0.00669999  0.69345183  0.14843534  0.22807219  0.69167493\n",
      "  0.41445127  0.42456529  0.50178683  0.88737995 -0.87684848 -0.73086344]\n",
      "epoch 97\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006078396477602714 R2: 0.964075395069211 time: 1703174332.238607\n",
      "batch_idx: 1 loss: 0.0004230418951967145 R2: 0.9640942983990607 time: 1703174339.989377\n",
      "Training [97%] Loss: 0.0005154407714784929 time: 1703174339.989377\n",
      "weight: [ 1.00664464  0.15443852  0.09006701  0.88073506  0.5377972   0.54424593\n",
      " -0.14920686  0.13309594  0.37494952 -0.35843235  0.84508111  0.17534883\n",
      "  0.51926403  0.00625381  0.69396188  0.14842555  0.22859989  0.69218883\n",
      "  0.413284    0.42341761  0.50135063  0.88723096 -0.87729875 -0.73020596]\n",
      "epoch 98\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006073330065277875 R2: 0.9641044955588074 time: 1703174347.9297106\n",
      "batch_idx: 1 loss: 0.00042270835975168124 R2: 0.9641233220836913 time: 1703174355.9559295\n",
      "Training [98%] Loss: 0.0005150206831397344 time: 1703174355.9559295\n",
      "weight: [ 1.00689362  0.15436627  0.08954057  0.88036146  0.53718531  0.54516335\n",
      " -0.14971774  0.13113567  0.37542781 -0.35821714  0.84848213  0.17323696\n",
      "  0.51903953  0.00580894  0.69446944  0.1484158   0.22913087  0.69270595\n",
      "  0.41212752  0.42227219  0.50090955  0.88708309 -0.87774343 -0.72955609]\n",
      "epoch 99\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006068299322952565 R2: 0.9641333954483862 time: 1703174363.8269615\n",
      "batch_idx: 1 loss: 0.00042237717072342166 R2: 0.9641521470770151 time: 1703174371.664351\n",
      "Training [99%] Loss: 0.000514603551509339 time: 1703174371.664351\n",
      "weight: [ 1.00714149  0.15428683  0.08900664  0.87999234  0.53657631  0.54607813\n",
      " -0.15022462  0.12924121  0.37586069 -0.35800431  0.85188854  0.17111213\n",
      "  0.518827    0.00536535  0.69497452  0.14840611  0.22966515  0.69322629\n",
      "  0.41098193  0.42112902  0.50046358  0.88693635 -0.87818248 -0.72891385]\n",
      "epoch 100\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0006063303574603263 R2: 0.9641620986177196 time: 1703174379.7246952\n",
      "batch_idx: 1 loss: 0.0004220482832564913 R2: 0.9641807772623203 time: 1703174387.618767\n",
      "Training [100%] Loss: 0.0005141893203584088 time: 1703174387.618767\n",
      "weight: [ 1.00738823  0.15420027  0.08846532  0.87962772  0.53597016  0.5469903\n",
      " -0.15072769  0.12741316  0.37624755 -0.35779392  0.8553003   0.16897428\n",
      "  0.51862664  0.00492299  0.69547717  0.14839648  0.23020273  0.69374987\n",
      "  0.40984732  0.41998812  0.50001267  0.88679075 -0.87861586 -0.72827923]\n",
      "train_MSE: 0.0005158122366147476\n",
      "train_RMSE: 0.022711500096091134\n",
      "train_MAE: 0.01862744687883739\n",
      "train_MAPE: 0.041242098082472194\n",
      "train_R2: 0.9641807772623203\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs=100\n",
    "\n",
    "start_time=time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss  = []\n",
    "    total_r2  = []\n",
    "    print(f\"epoch {epoch+1}\\n-------------------------------\")\n",
    "    for it, batch_index in enumerate (chain(*[X_batches])):\n",
    "        # Update the weights by one optimizer step\n",
    "        \n",
    "        X_batch = X[batch_index]\n",
    "        Y_batch = Y[batch_index]\n",
    "        weights, _, _ = opt.step(cost, weights, X_batch, Y_batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        predictions = [QNN(weights, x) for x in X]\n",
    "        r2 = R2(Y, predictions)\n",
    "        cost_t=cost(weights,X_batch,Y_batch)\n",
    "        total_loss.append(cost_t)\n",
    "        total_r2.append(r2)\n",
    "        end_timet=time.time()\n",
    "        print(\"batch_idx:\",it,\"loss:\",cost_t,\"R2:\",r2,\"time:\",end_timet)\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    r2_list.append(sum(total_r2)/len(total_r2))\n",
    "    print('Training [{:.0f}%]'.format(100. * (epoch + 1) / n_epochs),\"Loss:\", loss_list[-1], \"time:\",end_timet)\n",
    "    print(\"weight:\",weights)\n",
    "    \n",
    "    \n",
    "predictions = [QNN(weights, x) for x in X]\n",
    "\n",
    "train_R2 = R2(Y, predictions)\n",
    "train_MSE=metrics.mean_squared_error(Y,predictions)\n",
    "train_RMSE=train_MSE**(1/2)\n",
    "train_MAE=metrics.mean_absolute_error(Y,predictions)\n",
    "train_MAPE=metrics.mean_absolute_percentage_error(Y,predictions)\n",
    "\n",
    "print(\"train_MSE:\",train_MSE)\n",
    "print(\"train_RMSE:\",train_RMSE)\n",
    "print(\"train_MAE:\",train_MAE)\n",
    "print(\"train_MAPE:\",train_MAPE)\n",
    "print(\"train_R2:\",train_R2)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "plt.title(\"MSE value against epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.plot(range(len(loss_list)), np.log(loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90deb265-6d46-4ecd-882d-03a49eb3e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=xtv_test_log\n",
    "Y_test=ytv_test_log\n",
    "test_predictions = [QNN(weights, x) for x in X_test]\n",
    "\n",
    "test_R2 = R2(Y_test, test_predictions)\n",
    "test_MSE=metrics.mean_squared_error(Y_test,test_predictions)\n",
    "test_RMSE=test_MSE**(1/2)\n",
    "test_MAE=metrics.mean_absolute_error(Y_test,test_predictions)\n",
    "test_MAPE=metrics.mean_absolute_percentage_error(Y_test,test_predictions)\n",
    "\n",
    "print(\"test_MSE:\",test_MSE)\n",
    "print(\"test_RMSE:\",test_RMSE)\n",
    "print(\"test_MAE:\",test_MAE)\n",
    "print(\"test_MAPE:\",test_MAPE)\n",
    "print(\"test_R2:\",test_R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
