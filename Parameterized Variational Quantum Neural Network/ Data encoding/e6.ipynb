{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "586edb7a-4b3b-475e-8736-e85f04cf1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as npp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# set the random seed\n",
    "npp.random.seed(42)\n",
    "\n",
    "# create a device to execute the circuit on\n",
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "@qml.qnode(dev, diff_method=\"parameter-shift\", interface=\"autograd\")\n",
    "def circuit(params,inputs):\n",
    "    qml.RX(inputs[0], wires=0)\n",
    "    qml.RX(inputs[1], wires=1)\n",
    "    qml.RX(inputs[2], wires=2)\n",
    "    qml.RX(inputs[3], wires=3)\n",
    "    \n",
    "    qml.RY(0.25*np.pi, wires=0)\n",
    "    qml.RY(0.25*np.pi, wires=1)\n",
    "    qml.RY(0.25*np.pi, wires=2)\n",
    "    qml.RY(0.25*np.pi, wires=3)\n",
    "    \n",
    "    qml.RZ(0.25*np.pi, wires=0)\n",
    "    qml.RZ(0.25*np.pi, wires=1)\n",
    "    qml.RZ(0.25*np.pi, wires=2)\n",
    "    qml.RZ(0.25*np.pi, wires=3)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    qml.U3(params[0],params[1],params[2], wires=0)\n",
    "    qml.U3(params[3],params[4],params[5], wires=1)\n",
    "    qml.U3(params[6],params[7],params[8], wires=2)\n",
    "    qml.U3(params[9],params[10],params[11], wires=3)\n",
    "    \n",
    "\n",
    "    qml.broadcast(qml.CNOT, wires=[0, 1, 2,3], pattern=\"ring\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #return qml.expval(qml.PauliX(0) @ qml.PauliI(1)@ qml.PauliY(2)@ qml.PauliI(3))\n",
    "    return qml.expval(qml.PauliX(0) @  qml.PauliY(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a21f8a3e-a4ab-4c9d-bcf5-73c1b9429ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "def norminv(x):\n",
    "    return ((1.0/math.sqrt(2.0*math.pi)) * math.exp(-x*x*0.5))\n",
    "\n",
    "def d1(S0, K, r, T, sigma, q):\n",
    "    deno = (sigma * math.sqrt(T))\n",
    "    if (deno==0):\n",
    "        return 0\n",
    "    logReturns = math.log(S0/float(K)) if ((S0/float(K)) > 0.0) else 0.0\n",
    "    return (float(logReturns) + (float(r) - float(q) + float(sigma)*float(sigma)*0.5)*float(T)) / float(deno)\n",
    "    \n",
    "def d2(S0, K, r, T, sigma, q):\n",
    "        return d1(S0, K, r, T, sigma, q)-sigma*math.sqrt(T)\n",
    "        \n",
    "def bsformula(callput, S0, K, r, T, sigma, q=0):\n",
    "    N = stats.norm.cdf\n",
    "                \n",
    "    def optionValueOfCall(S0, K, r, T, sigma, q):       \n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        _d2 = d2(S0, K, r, T, sigma, q)\n",
    "        return S0*math.exp(-q*T)*N(_d1)- K*math.exp(-r*T)*N(_d2)\n",
    "      \n",
    "    def optionValueOfPut(S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        _d2 = d2(S0, K, r, T, sigma, q)\n",
    "        return float(K)*math.exp(-float(r)*float(T))*N(-_d2) - float(S0)*math.exp(-float(q)*float(T))*N(-_d1)\n",
    "        \n",
    "    def delta(callput, S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)        \n",
    "        if callput.lower() == \"call\":            \n",
    "            return N(_d1) * math.exp(-q*T)\n",
    "        else:\n",
    "            return (N(_d1)-1)* math.exp(-q*T)\n",
    "    \n",
    "    def vega(S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        return S0  * math.sqrt(T) * norminv(_d1)  * math.exp(-q*T)\n",
    "    \n",
    "    if callput.lower()==\"call\":\n",
    "        optionValue = optionValueOfCall(S0, K, r, T, sigma, q)\n",
    "    else:\n",
    "        optionValue = optionValueOfPut(S0, K, r, T, sigma, q)\n",
    "        \n",
    "    _delta = delta(callput, S0, K, r, T, sigma, q)\n",
    "    _vega = vega(S0, K, r, T, sigma, q)\n",
    "    \n",
    "    return (optionValue, _delta, _vega)\n",
    "\n",
    "def bsm_iv_generator(num_sample = 100,tao_bound=[0.01,2.0],  sigma_bound=[0.01,2.0], \n",
    "                     money_bound=[0.3,3.0], rr_bound=[0.01,0.2], callput='call', seed=42):\n",
    "    \n",
    "    # input parameters: when callput is not in 'call' or 'put', randomly generate the option price followed by root-finding methods to\n",
    "    # compute the corresponding implied vol\n",
    "    # return: X_input = [time,stock,rr, dividen, option_price]. Y_outpu  = volatility \n",
    "    np.random.seed(seed)\n",
    "    tao_min,tao_max = tao_bound[0],tao_bound[1]\n",
    "    \n",
    "    sigma_min, sigma_max = sigma_bound[0],sigma_bound[1]\n",
    "    moneyness_min,moneyness_max = money_bound[0],money_bound[1]\n",
    "    rr_min,rr_max = rr_bound[0],rr_bound[1]\n",
    "   \n",
    "    \n",
    "\n",
    "    num_sample = int(num_sample)\n",
    "    xx = np.zeros([num_sample,4],dtype='float')\n",
    "    \n",
    "   \n",
    "    xx[:,0] = np.random.uniform(sigma_min, sigma_max,xx.shape[0])\n",
    "    xx[:,1] = np.random.uniform(tao_min,tao_max,xx.shape[0])\n",
    "    xx[:,2] = np.random.uniform(moneyness_min,moneyness_max,xx.shape[0])\n",
    "    xx[:,3] = np.random.uniform(rr_min,rr_max,xx.shape[0])\n",
    "   \n",
    "    \n",
    "   \n",
    "    strike=1.0 #fixed strike\n",
    "    #callput = 'call' # call option\n",
    "    v = np.zeros(xx.shape[0]) # option value\n",
    "    k = np.ones(xx.shape[0]) # strike price, just in order to match the shape of v\n",
    "    \n",
    "    if callput in ['call','put']:        \n",
    "        for i in range(0,xx.shape[0]):        \n",
    "            sigma, T, S0, interest = xx[i,0],xx[i,1],xx[i,2],xx[i,3]\n",
    "            ## use the Black-Schole function in compfin.py\n",
    "            v[i] = bsformula(callput, S0, strike, interest, T, sigma)[0]              \n",
    "            \n",
    "  \n",
    "    v= v.reshape(xx.shape[0],1)     \n",
    "    xx_sample = np.concatenate((xx,v),axis=1) #sigma, time, s, r, v\n",
    "    \n",
    "    \n",
    "    X_input   = xx_sample[:,1:]   # time,stock,rr, option_price\n",
    "    Y_output  =  xx_sample[:,0] # sigma -implied volatility is the predictive variable.\n",
    "  \n",
    "    return X_input,Y_output\n",
    "#  log-transformation of the option value\n",
    "def logscale_vol(x_train_dat,y_train_dat,otm_lower=0.0000001):\n",
    "   # input data: x_train_dat = [time,stock,rr, option_price], y_train_dat = sigma  \n",
    "   \n",
    "    xtv_train_log=x_train_dat.copy()    \n",
    "    ytv_train_log =y_train_dat.copy()\n",
    "    \n",
    "    \n",
    "    #v_lower[v_lower<0.0]=0.0 # V=max(S-E*exp(-rt),0)  \n",
    "    xintrinsic_train=xtv_train_log[:,1]-1.0*np.exp(-1.0*xtv_train_log[:,2]*xtv_train_log[:,0])\n",
    "    xintrinsic_train[xintrinsic_train<0.0]=0.0 ## \\tilde{V} = max(S-E*exp(-rt),0)\n",
    "    xtv_train_log[:,-1] = xtv_train_log[:,-1] -xintrinsic_train\n",
    "    \n",
    "    ## remove intrisinc values below the threshold (otm_lower \\approx machine pricision)  \n",
    "   \n",
    "    ytv_train_log = ytv_train_log[~np.less(xtv_train_log[:,-1],otm_lower)]\n",
    "    xtv_train_log = xtv_train_log[~np.less(xtv_train_log[:,-1],otm_lower),:]\n",
    "    xtv_train_log[:,-1]=np.log(xtv_train_log[:,-1])\n",
    "\n",
    "    return xtv_train_log,ytv_train_log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce82ab6f-af86-47ed-9c2c-ddf97780cd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maturity time  range:\n",
      "0.500695213053119 0.59856504541106\n",
      "Stock price  range:\n",
      "0.9802024633538488 1.0196021540041706\n",
      "interest rate  range:\n",
      "0.030719674431487792 0.07952525710003366\n",
      "option value  range:\n",
      "0.09931091344863496 0.21642392770778063\n",
      "sigma range:\n",
      "0.30220884684944094 0.6947547746402069\n",
      "(100, 4)\n",
      "maturity time  range:\n",
      "0.500695213053119 0.59856504541106\n",
      "Stock price  range:\n",
      "0.9802024633538488 1.0196021540041706\n",
      "interest rate  range:\n",
      "0.030719674431487792 0.07952525710003366\n",
      "time option-value  range:\n",
      "-2.6542232063018565 -1.5996371627169406\n",
      "sigma range:\n",
      "0.30220884684944094 0.6947547746402069\n",
      "(80, 4)\n",
      "Parameters: [0.10312387 0.90255291 0.50525237 0.82645747 0.3200496  0.89552323\n",
      " 0.38920168 0.01083765 0.90538198 0.09128668 0.31931364 0.95006197]\n",
      "inputs: [0.95060715 0.57343789 0.63183721 0.44844552]\n",
      "Expectation value: -0.06522379972747203\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGAAAAIHCAYAAADQLypxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3wT9RsH8E+aNG3TJE0nbSnIEJBZEGTLkC3IENmyQfYeykZlyUYooKKACIKCVEC2/EBkyoYiUzbdbZrZpk3y+yPctUlbmrS5jPZ5v159wV0ud9/mae5799x38IxGoxGEEEIIIYQQQgghhDMezi4AIYQQQgghhBBCSHFHCRhCCCGEEEIIIYQQjlEChhBCCCGEEEIIIYRjlIAhhBBCCCGEEEII4RglYAghhBBCCCGEEEI4RgkYQgghhBBCCCGEEI5RAoYQQgghhBBCCCGEY5SAIYQQQgghhBBCCOEYJWAIIYQQQgghhBBCOEYJGEIIIYQQQgghhBCOUQKGEEIIIYQQQgghhGOUgCGEEEIIIYQQQgjhGCVgCCGEEEIIIYQQQjhGCRhCCCGEEEIIIYQQjlEChhBCCCGEEEIIIYRjlIAhhBBCCCGEEEII4RglYAghhBBCCCGEEEI4RgkYQgghhBBCCCGEEI5RAoYQQgghhBBCCCGEY5SAIYQQQgghhBBCCOEYJWAIIYQQQgghhBBCuMWjBAwhhBBCCCGEEEIIxygBQwghhBBCCCGEEMItIyVgCCGEEEIIIYQQQjhGCRhCCCGEEEIIIYQQjlEChhBCCCGEEEIIIYRjlIAhhBBCCCGEEEII4RglYAghhBBCCCGEEEI4RgkYQgghhBBCCCGEEI5RAoYQQgghhBBCCCGEY5SAIYQQQgghhBBCCOEYJWAIIYQQQgghhBBCOEYJGEIIIYQQQgghhBCOUQKGEEIIIYQQQgghhGOUgCGEEEIIIYQQQgjhGCVgCCGEEEIIIYQQQjhGCRhCCCGEEEIIIYQQjlEChhBCCCGEEEIIIYRjlIAhhBBCCCGEEEII4RglYAghhBBCCCGEEEI4RgkYQgghhBBCCCGEEI5RAoYQQgghhBBCCCGEY5SAIYQQQgghhBBCCOEYJWAIIYQQQgghhBBCOEYJGEIIIYQQQgghhBCOUQKGEEIIIYQQQgghhGOUgCGEEEIIIYQQQgjhGCVgCCGEEEIIIYQQQjhGCRhCCCGEEEIIIYQQjlEChhBCCCGEEEIIIYRjlIAhhBBCCCGEEEII4RglYAghhBBCCCGEEEI4RgkYQgghhBBCCCGEEI5RAoYQQgghhBBCCCGEY5SAIYQQQgghhBBCCOEYJWAIIYQQQgghhBBCOEYJGEIIIYQQQgghhBCOUQKGEEIIIYQQQgghhGOUgCGEEEIIIYQQQgjhGCVgCCGEEEIIIYQQQjhGCRhCCCGEEEIIIYQQjlEChhBCCCGEEEIIIYRjlIAhhBBCCCGEEEII4RglYAghhBBCCCGEEEI4RgkYQgghhBBCCCGEEI5RAoYQQgghhBBCCCGEY5SAIYQQQgghhBBCCOGYwNkFIMSR1Go1bt++jRcvXiAlJQVyuRypqalo2rQp2rVr5+zilTgUD9dC8XAtFA9CCCHE/VF9TnKiBAwp1mJiYnD48GFcunQJ165dw927d2E0GvPcdvXq1RCLxZDJZBCLxRCJRJBIJPD394efnx8kEgn4fL6Df4PiheLhWigeroXiQQghhLg/qs/J6/CM+f01EOKmEhISsG3bNvz444+4ceOG3fbL4/Hg7+8PqVQKX19f+Pj4QCgUQigUQiwWw8fHB97e3hAKheDz+fDwMPXwMxgMyMrKgk6nQ2ZmJtLT06FUKqHRaKBWq6HVatnXMjIyAABSqRQhISEICQlB6dKlERERgbp166JJkyaQSqV2+50cgeLhWigeroXiQQghhLg/qs+JtSgBQ4qN1NRUzJgxAz/88AMyMzOdXRxO8Pl8NGjQAO3atcPIkSMREhLi7CLli+LhWigeroXiQQghhLg/qs+JrSgBQ4qFvXv3YtSoUYiPjy9wWx6Pl28zQHciFosxadIkTJs2DRKJxNnFMUPxoHg4G8XDtbhyPAghhJDCoPqc6vPCoAQMcWsGgwHjx49HVFRUvtuUDiuF99u8i7cjq6JOzaqoWa0S/jp7GcdOnkN6Rga02nQoVRokpaRCpdZAnqaEWqOFVpsBhVIFg8HgwN/IdiEhIVi1ahX69u3r7KJQPEDxcDUUD9fiSvEghBBCCoPqc6rPi4ISMMStTZs2DcuXL8+13tvbCz26tMWgPl3RvEm9Qg9eZTAYoFCqoFSqkZqmQFKyHCq1BmqNFhkZOmTodMjI0EGl1iA93bSs02VCb9BDrzedOPl8D/A9+PDyEoLP94C3lxekEl+IfHwgEnlD5OMNodATAr4AXl6eAICU1DQkJcsRG5+Il3GJiLnzABev3ERmZla+ZZ0+fToWLlwIgcB5Y2tTPLJRPCgelige2VwhHoQQQkhhUH2ejepz21EChritVatWYfLkybnWd2zbDOuXz0HZiDAnlIo7arUGp89dwc+/HcRPvxzIMzPetWtX7NixAz4+Pg4vH8WD4uFMFA/X4urxIIQQQgqjONXner0eHh4e4PF4+W5D9bn9UQKGuKVjx46hXbt2Zn0pBQIBvlk5F4P7dXvtiaQ4uH3nIT77YhX2Hz6Z67XOnTsjOjraoZ8BxYPi4UooHq7F1eJBCCGEFEZxqs9j4xLx0aBJePDoKRrWi0SjdyLRvlVT1K75Vr7vofrcPniv/oAoCUPcRlZWFmrUqIG7d++ard+8bgEG9e3qnEI5yXdbd2PM9AW5mgZu3LgRI0aMcEgZKB7ZKB6uheLhWlwhHoQQQgqm0+lw7do1nD9/Hs+ePYNcLkdKSgpUKhUOHTrETnVckhSn+vzcxWv4aPBkvIxNMFv/2cShWDx3UoHvp/q8aKgFDHE7W7ZsweDBg83WLZg1DrOmlMwv/F9nL6Fz33FIUyjZdRKJBLdv30ZERATnx6d4mKN4uBaKh2txdjwIIYTklpGRgQsXLuDUqVM4ceIEzp8/j/T09Dy35fP5CAoKQqVKldC+fXu0aNECDRo0KPZjgBSH+txoNOKrNd9j9sK10Ov1uV7/dfNKfNSlrVX7ovq88CgBQ9yKXq9HzZo18e+//7Lr6tauhovHd5bIbDzj0LHTeL/XKLN1Xbp0QXR0NKfHpXjkjeLhWigersVZ8SCEEGIuNTUVa9euRVRUFBISzFtDyAL9EflOHZSrVBEeHh7YvOabfPfj6+uLhg0bomHDhujTpw+qV6/OddEdqjjU56nyNAwcPSvP7kOMR9eOoFzZ0lbvk+rzwqEEDHErBw8eRMeOHc3WHdgZhY5tmzupRK5j0JhZ2Prz72brYmJiUK1aNc6OSfHIH8XDtVA8XIsz4kEIIcRELpcjKioKK1asQGpqKgAgMDgI9d5tgAbNGqN+s0YoX7kiO55HYmw8mr/5Dng8Hg7dOAWVQoXrF6/gwl9nceHUWaSlyNl983g8fPTRR5g1axYiIyOd8evZnbvX5zdv30PXj8fjv8fP890mwN8PSQ/+tnkMF6rPbeceKTtCXjl8+LDZcs1qldCh9btOKo1rWblgOgIDZGbrNm7cyOkxKR75o3i4FoqHa3FGPAghpKRTq9X49NNPUbZsWcyePRupqal4s2plLNu8FifuX8CqbRvQe3h/VKjyptmNuDxVDgCQyKQoW6EcqtWugT6fDMDqnzbizJNriL5wFPPXLkarD0wD1P7666+oXbs2PvjgA5w7d85Jv639uGt9bjQasXn7XjRo0/e1yRcAeLtW1UINoEv1ue0oAUPcyvHjx82We3Vr7zZN/7gW4O+HTwZ+ZLbup59+yrcPrz1QPPJH8XAtFA/X4ox4EEJISfbPP/+gdu3aWLp0KZRKJSpVq4Kvvl+DvReOoGPPLvD09Mz3vapX43z4+ctyvebh4YHKNd5CzyH9sHbnd4i+cBQdPvoAHh4eOHDgABo3boyOHTsiMTGRq1+Nc+5Yn2s0WgwZOwdDxs2BVmtetwYHBeTavm7twnUbo/rcdq79l0NIDnFxcWZ9LwGgdfNGTiqNa/pkYA+z5dTUVOzbt4+TY1E8CkbxcC0UD9fiyHgQQkhJZTQasXbtWjRp0gQPHjxAaOkwrPtlE6IvHsUHvbuBz+cXuA9lmikB4ysWF7ht5RpvYcXWKBy4cgLdB/aGp6cnDh48iMjISPz5559F/n0czR3r81u376NBm77Y8nN0rtfqv10Tl0/sgsxParG+RqGPR/W5bSgBQ9zG2bNnzZalEjHq1qb+hTmVK1saLd+tb7aOq8qO4lEwiodroXi4FkfGgxBCSqK0tDT06NED48ePR2ZmJtp06YC9F47gvY5tbepuolapAABiacEJGEa5ShXw5fql2H3mICpUeROxsbFo3bo1pkyZ4latI9ytPt+55yDqt+mDW//ez/XaqCG98NcfW6HWaCFPU5i9Vv/tmoU+JtXntqEEDHEbjx8/NluuXfOtYj/lXWF0aNXUbPnGjRucHIfiYR2Kh2uheLgWR8WDEEJKmpcvX6Jhw4bYs2cPPD09MXP551i9fWOe3YgKkq4xJUy8fXxsfm+l6lXwy+kD6Dm0HwBg5cqVqFu3LmJiYmzelzO4S32u1+sx44tV6DN8eq4uR2KxCDs3LcP65XPg5SXE2YvXzF4PDwtBROnQIh2f6nPrUQKGuI0XL16YLZeNKNqJoriqUbWS2XJMTAy4mOyM4mEdiodroXi4FkfFgxBCSpJnz56hWbNmuHPnDkqFh2Lb8T34eNTgQg2yCgAatRoAIBKLCvV+ka8I879ejPW7f0BgSDBu376N1q1b486dO4XanyO5Q31uNBrx4YCJWLL6+1yv1apeGZf+3IVeH3Zg11kmYBq/U7vIZaD63HqUgCFuw/IEGFYq2EklcW3Vq75ptqxUKnN9dvZA8bAOxcO1UDxci6PiQQghJUV8fDxatmyJhw8fIqJcGfx0fA9q1atdpH0q5GkAAIlUWsCWr9eiQ2v8fvEoqtSoiri4ODRv3hy3bt0q0j655g71OY/Hg8xPkmt9ubKlceHYz6hSqbzZ+r8vXDVbbtKgTpHLQPW59SgBQ9xGbGys2XLpsBAnlcS1lSkdCl9f8yaiXDxhoHhYh+LhWkpKPHgBNcALqIH09AwAQFZWFruO0arrUAS92RTCUrURUb0Vxn26CBkZOoeW01HxIISQkkCtVqNTp05s8mXrkV9R+o0yRd4vMwivVOZX5H0FBAfihz9+RtXIGkhISED79u3x9OnTIu+XK86uz631xYyxEArNZ7J6/PQFSld/D6mvEmgAkJiUgrv3H5lt16RB7SIfn+pz61EChrgNpVJptuwvK1oWvrji8XgoV6a02bqEhAS7H4fiYR2Kh2uheGSrVa0yFs+ZiPXLZkMiFmHddzuwadseh5bBUfEghJCSYNy4cbh06RJkgf74NnobwiLC7bJf9as6zZZBeF/HPygAP/yxAxWrVsKLFy/Qrl07JCUl2WXf9uYO9TkAvFEmHKOH9M61PiU1Da26DoNGo4Ver8cZi9YvIpEPatd8q8jHp/rceq43ghAh+TAYDGbL1kybVxgn/76Ilp2H5Frv4eEBidgXFcpFoE2LRpg0agBCSwUBAB4+eorIZt2hVmsBAB1av4uDv2zIVf6WnYfgr7OXAJhGUb95Zi/KRoTZ/XewbIYol8vtfgxHxQOwLSZBgTLUb90HV2+YpgwUCAS4dGInImuYVy7PX8ShWqMuUKpM/Zojwkvh1tlo+ElzN+EsquIUj8J8PwCgXGRbPHn20urjGFO4a5JcnOJRFKsWfYqU1DTI0xTYve8Y7tx/VOjxAYrCEfEghJDi7tChQ9i8eTM8PDywZvs3KFepgt32nZqcCgCFGsA3P37+MnwbvQ393uuGO3fuYPjw4di7d6/d9m8v7lCfM2ZN+QT/+/sirt+6a7b+6o1/sXrjNuw/fApqjcbstUbvRMLT07zlTGFRfW4dagFD3IblCS8rS+/Q4xsMBqQplLh6418s/foH1GnxEZ49NzVLrFi+LFZ8OY3d9tDx09i4eZfZ+1et/5FNvgDA2q9mcJJ8ARxzAnR2PIC8YxIbl4gtUQvg6Sl4Va4sDB0/F3q9eflGT1vAJl8A4LvVn3OSfAFKRjxe9/1wNSUhHtaq/E5HVHy7A46cOIN+PTpiWP/uDi8DXbARQkjRaDQajBo1CgDQf/QQvPNuQ7vuXyk3TVlszwQMAIRFhGP97s0QCASIjo7G7t277bp/e3C1+jwlNQ237zzE2QtX8eep8zh+8hz+Pn8FT569hL9Miq/mTc7zfbMWfI3zl67j5m3z6ambN65nt7JRfW4dagFD3IblCdAyI82VXt3ao17t6lAo1Yg++Cd74oqLT8KqDduwcuF0AMCIQT2x79D/cPDYaQDA1LnL0aZFI1QsXxa37zzE7EVr2X1269QKA3p34azMIotpArVard2P4ax4ANbFZPaUEZi3JAoAcPnabaxa/yOmjhsMANi55yD2Hz7J7m/oxx+ifeumuY5jL8U5HtZ+P2ZN/gRpCmWe+/j2x924//AJuzxmWB9Oy1yc48Hg8XgwGo3sDATMv5YtXH77cTXi4pOwPGoLdv52GN06tkb3zm0cWlZHxIMQQoqzr776Ck+ePEFoRDjGzZ1q9/0XdRak13mrVjUMnzoGG5aswejRo9GsWTOEhLjOOCvOrM/1ej0uXLqBf67ewuXrt3H+0g2z6yVLpoePtrVkfbfR20UsZTaqz61DCRjiNgQC8z9XXWamQ47bvlVTDOrbFQAwZexAhFRuBp3OdOzbdx+abbtpzReo2bQbklPkUKu1GDBqJv6M/h79R81gB8MsFRKIb1bO47TMPj5eZstcnACdFQ/AupjMnDwc0QdPsF2R5i6JQrdOreAv88OEmUvYfUWEl8KKBdPApeIcD2u/H8MHfpTn+3/ec9DsYqJJgzpY9Sppw5XiHA9GRHgpPHsRh+cv41Gp4ht4+qo1UpnS5tNnNnv15Esg4KP7wEnY8nO0wxMwjogHIYQUV8+fP8fSpUsBANMXz4bI1/5JknRtOgDAy9vb7vsGgBHTx+LP/UdwL+YORo8ejV9//dUpXWLz4oz6/NGT59i8PRqbd+zF85fxVr8vMzPLpuOMGdYHzZu8Y2vx8kX1uXWoCxJxGxKJebM2hULl8DL4SSUQ56jYAgNkZq+HhQZjw/I57PLZi9fQoE0fXLl+m1333erPERwUwGk5PS0qi0wOKgtXiAeQf0wEAoFZVyStNh3DJ87HpFlfISExhd2ey65HjJISj4K+H5ZuxNzFsAnZyciw0GD8unml3foi56ckxKNbx1YAgF5Dp2LWgjXoMXgKAKD7B6bkyuHjf2PAqBn4Zssv2Lh5F+YsWgcAiKxRxaHlBBwTD0IIKa7mzJmD9PR0vN34HbTr1pGTY+h0phnyhF5CTvYv9PLCom9XQiAQYM+ePdi5cycnxykMR9bnh46dRrOOA1GhTnt8uXyjTckXa+RMak0Y8THWfjXTrokuqs+tQwkY4jZEIvOMvvZVixJHUShU+Pqbn5CSmj2VW8+u7XJt16NrO/TrkV0B3oi5x/5/6Mcf4oP2LTgtJ2B6mp2T5fgn9uDseAAFx6RW9SqYPWUEu/y/0xfx48597DLXXY8YJSEe1n4/GKnyNHTrPwEajenpiKenALs3r0RYaDDnZS0J8Vg0ZwKmjRuMVLkCK6K2IlWuwPTxQ7Bw9ngAQFCgDDdv38fUucsxadZSZOh0+GziUMybPsqh5QQcEw9CCCmOUlJSsGPHDgDAtIWzOGs1kvmqZaunkJsEDABUq10DIz4dBwCYNWuWy9QFjqjPH/z3FF36jcP7vUbh9LnLVr1HLBYhJDgAoaWCIBL5FPwGZHdHfqtSeUwaPcDufy9Un1uHuiARt+Fj0a9Q86o5JNcGj52NwWNnm60TiXzw+aej0eX99/J8z7qls3Di9EXExiWy6yLCS2HVwk85LSvD8oTKnHDtyVnxAGyLiWVXJIYjuh4xinM8CvP9MBgM6DNsOv57/Jxdt2bxZ2jcoA6nZWUU53gwfH1FWPr5FCz9fEqer9erUwNXT7nGYIeOiIer0Wg0uHfvHvz9/SGTySCVSl2muT0hxH3s2rULOp0OVWpWQ2R9+43lYSn91cMSy7rN3oZMHIlt63/Ao0eP8Mcff6Bz586cHs8aXNbnGo0Wcxatw9rvtr+2+1DVyhVQv25N1H+7JhrWq4UaVStBKMxuLXz24lU0ad/f6uPeuf8INZt0w4YVc9D3o452q39KYn1eGNQChrgNyxNgRobOSSUBunV8D6OG9Mr39ecv4s1aAgBAYnIqOw4D1xxxIe9K8QDyj4llVySGI7oeMUpaPAr6fsxasAZHTpxhlwf16YpRQ3o7omgASl48XF1JSzzExcXh66+/Rp06dVCuXDk2AdOqVSt8/vnniI11zdnDCCGu5/vvvwcAdPs473HW7IUZy8NbxM0YMAwfkQ96DDINxL98+XJOj2Utrurz/x4/Q6N2/bBy/dY8ky8yPynGDOuDKyd/xe3z+7AlaiFGD+2NtyOrmSVfDAYDJs78Ks9j1K9bE7OnjEBoqaBcrylVanw84jMMHjvbbr9TSavPC4sSMMRtWI4LkeWgZm29urXHojkT0Kldc3bd9l//QLf+E/LM7GZmZqL/qBm5TmYZGToMGD2z2PSHdFY8ANtjUqt6FTR6pza7/EaZcId0PXIkd/l+/Lb/GJas/p5drlu7GjasmJNrO3fnzO8HcU0xMTHo378/ypQpgxkzZpi9plKpcOLECcyfPx/ly5fH2LFjkZaWls+eCCEEuH79Oi5fvgyBpyc+6P0hp8fSvep2w9UgvDn1GzUYnp6eOH36NM6cOVPwGzjGRX1++VoMGrTpazZMASM4KACb1nyOuDsnsW7pLNSpVfW1+9q19zD+uXIrz/38/tNafDlrHB5ePoRFcyZAKhHn2m7rz7+jdbdhSE6RF/r3IbahBAxxG5ZZVUdNA9e+VVPMmDQc+3+OwohBPdj1x06ew/ZfD+Taft6SKFy7eYddHj00+8n+leu38cXSjdwWGI5p8ueseAC2xwQAnJmUL87xsCUW/959iIFjZrHLQYH++O3HNfD2Nh81n2vFKR6Dx8yGuMw77IXTy9gEdP14PHwj3oGsXCMMHD3ztQMGbv35d9Rs0g2C4EjwAmpgy45oTsr5OsW9iXJWVhYWLVqEOnXq4KeffkJW1utnqcjIyEBUVBRq1aqFU6dOOaiUhBB3s3nzZgDAex1bw5/DyR30ej07loeQwzFgGKGlw9C5b3cAwOrVqzk/XkHsXZ+fOvMPWnQejKTkVLP1QqEnpo4dhPuX/sDQ/t3hZcWAxzpdJmYv/DrP175dNY9t+SIS+WDGpOF4eOUQ+vf6INe2f5+/gh6DJxdYPxWkuNfn9kIJGOI2XKFZ25J5k8y6rXy+dIPZAFPnLl7D0q83s8vDB3yEqGWzMaB3dh/Wxas34cKlG5yWU683rxz4fH4+WxaeK8QDKDgmrqCkxON1sUhTKNG1/wSoVBoAps9g56ZlKBsR5vByFpd43HvwGD/u2oePe3RiZ5zqN+JT7Dv0P0wZPRD9e32AH3fuw4QZS/Ldh1qjRbPGdVG7puNnP2I4Ih7OotPp0L17d8yaNcvm1o9Pnz5F27ZtcfLkSW4KRwhxa7t3m8bx6ta/J6fHycpx7uILHHN+HjBmKADgt99+g1wud8gx82PP+vzJs5foPnASey3EqFalIq7/tQfLvphqU/f4b7b8YjaeHuPjnp3Q9dVsiDkFBfrjxw2LsXPTMvj6mnet+t/pi5g2d4XVx85Lca7P7alEJGDu3buHoUOHoly5cvDy8kJQUBDatGmDX375xdlFIzawzDg744bT1B8zu0XLg/+eYtfewwAAtVqDAaNnsjec5d+IwMoF0wEAa5fMZG809Xo9Boyeyc7+wgXLBAQXJ0BXiAfw+pi4ipISj/xiYTQa0X/kDNx78Jh9LbJGFVy98S+Wr92c588zDsdLKi7x+O7H3TAYDOj9YQcAQMy/D3Dy739Qp1ZVfDFzLL5eMgMhwQHY9sv+fFvBjB7aG1HLZuOtSuXtXj5rOSIezjJmzBjs27ev4A3zodPp0LVrV9y7l7uZOiGk5EpMTMSLFy8AAPWaNOD0WAZDdqsGR52fK1WvgrIVy8FgMODs2bMOOWZ+7FWfq1QadOs/IVdXn1bNG+L80R14q3IFm/anUKgw/rPFudaXfyMCUUtn5/GObL0+7IAzh7blmnly9cZt2PRj4QfoL871uT0V+wTMwYMHERkZiR9++AFPnjyBTqdDcnIyjh8/jl69emHQoEHUXMpNWMbJWTf8E0f2N5vubdHK72A0GjFlzjI8+O8pAMDDwwNb1y+EWGyauk4qFWPr+oVsme89eIxPP1/FWRkzLZoQWvZftQdXiQeQf0xcRUmKR16xePo8FvsPnzTb7sr125g2b0W+Pw8fP+OsjMUlHkf/dxZ8Ph8N6tYCANz/7wkAoGxEKHvMshFh0Ov1ePQ09xMyV+GIeDhDdHQ0Nm3aVOT9pKWlYdiwYQ7t5kkIcW3Xr18HAJStWA6+eYzrwRWeh+NuHZnE0l9//eWwY+bFHvW5Xq9Hn+HTcs3I2bFtM/yxcz0kEl+b97lgxTd5rv9h7ReQSgv+m4is8Rb2/rjGbEBfABg9bYHZUAq2KK71ub0V6wTMixcv0LdvX6Snm6YLq1atGr744gv07p39hHbr1q1Yv369s4pIbGB58cl3YCWQU3BQAIZ9nD3YWcydB/h5z0F8s+VXdt3k0QPwbqO6Zu9r0bQ+Jo0awC5HbfoZx0+e46SMOp15U3cu+uy6SjyAvGOy98Bxp5XHUkmKR16x2LPvmFPKkp/iEo8Hj54hMMAPPj75D4qY88mlq3JEPBxNrVZj9OjRdtvf6dOnsW3bNrvtjxDi3q5evQoAeKtWNYce1+jARHDdxvUBwOndMO1Rn3+/7TccOGI+pleVSuWx/duvrBrrxVJcfBKWrd2ca/2oIb3Qoml9q/fToF4tfLtqvtm6zMwsTJtbuBmoimN9zgVBwZu4r6+//pqdRUAikeD06dMICDANUuXh4YEdO3YAABYvXoyRI0dSMykXZ9l/XsBRP9QWTevDmJJ7NPGc1iyZgTVLzGex6PtRxwL3vWLBNKxYMK1I5bNGVpZ5E0AuMtCOigdQ+JjkdHL/FjuXynrFKR6FjcXkMQM5KU9hFKd45HwSV6nCGwCAJ89M3beMRiOePo8Fn89H+bIRAID0VzNZOHrg49dxRDwcbdeuXXafTnrDhg0YONB1vkeEEOe5du0aAOCtWtU5P5aHR3Y948iWeA1aNAYA/PPPP1Cr1fD1tb2ViD0UtT7XatPx5XLzCTgC/P2wb/tam8Z7yalb/wl5rl86f4rN+xrYpwtuxNzDyvVb2XXHT53H2QtX0bhBHZv2VRzrcy4U6xYwOftdt2jRgk2+AED37t3Z/7948QKXL192aNmI7ZiWTAwfB0yF564c0QSQ4mE9iodrKS7xqPBGBJKS5WxSpXrVN9GscT1cu3kH8xavw9jpC5GUnIqPe3ZimyP7hNeFT3hd9j1Xrt/Gph934+EjUxelv85ewqYfd7MDBPICaoAXUIPdngvFscnyDz/8YPd9XrhwgcaCIYQAMCUlAKBaZA3Oj+WZoxVDps62wcSLIrxMaYSWDoPBYGB/X2coan2+/vudeP4y3mzdTxuXoPKb5QpVnn/vPsT5S9dzrb9w7Gd26ANbfTlzLMLDQszWLVjxrc37KY71OReKbQImIyMDd+/eZZcrVDAf2Mhy+cYNbmelIUWn0+nMli37LJJsmZnmJ0CBwP6N3Sge1rM1HkajERkZGVCr1eyPRqOBTqfLd2wbiof1LOPBRetHR8SjbcvG0Ov1uHjlJrtu+zdL0KldcyyP2oqffjmAj3t2wprFn+W7j32H/ofhE+ezF3Obd0Rj+MT5SEpJZf/WeDwePDjs0uaI85Uj6XQ6XLx4kZN9//3339BoNEhPT0dmZqZLjXVVHBiNRmRmZkKr1bLnXq1Wi4yMDBqDhwMGgwEZGRnQarXQaDRmdV56ejqysrLobzwfT5+axhys+NabnB/Lw8ODrQOyshyXgAGAKjWrAoBTk89Fqc9VKg2WrPnebN17zRqgfeumhS5PtUZdcq0b2KcL6tetWeh9ikQ+mDZ2sNm6Q8dP40bM3XzekbfiVp9zpdh+KqmpqWYnbalUava6RGLe5CspKckh5Soqo9EIhUIBb29vCIVCl5h6tiBGoxHp6elQKBRISUnBy5cvER8fj6SkJCgUCqjVasjlcqSkpCAlJQVKpRIZGRnQ6XTIzMyETqeDRqNBcnKy2X49PYvtn2+R6SyaS6rVaty9exdKpRJxcXFISkpiL3KUSiVUKhW0Wi3S09Oh1WqhUqmgVCqh0WjYH51Oh4yMDGRkZLBxyYnikT/LeGzatAl79+6FUqmEUqlkb6bS09OtutD39PSEj48PJBIJpFIpxGIxHj16ZLENxSM/lvH47LPPMHfuXAiFQgiFQggEAvj4+EAsFsPX1xc+Pj7w9vaGn58f/P39IZVKIZVKERAQgNDQUPj5+UEsFkMmkyEgIABisThXk2Uu4jF8QHes3rgNv0QfQbPG9QAAEaVDsW/HunzfY9l9bP5nYzD/szF5bnvztumCd+Tgnpwm9CzjcezYMXh4eEAmkyEiIgLBwcHw8/NDYGAg/Pz8OE0G2cPdu3dtnnLaWkOHDsXQoUPN1vH5fHh5ebE/lueHgIAAiEQieHl5QSqVolSpUuxnKRaLIZFIEBQUhMDAQIjFYnh5ebnFtQVDr9cjMTERz549Q3Jyslm9lp6eDrVajcTERCQnJ0OlUrEJbaaOy8jIgEajgVarLTCp5enpCZFIZHZ+8Pb2hlgshkgkglQqRXBwMHsekEqlkMlk8PPzQ6lSpVC6dGn4+/u71edrMBjY6wKFQgG5XA6lUmn2uaampiItLY1NDjKfp1KphEKhQHp6OnQ6HXQ6HVvPZWZmWp3U8vDwgLe3N3x8fCAUCuHr6wuRSASRSASxWAw/Pz/2M5dIJPDz84NEIoFEImE/f+b/oaGhbntTqNFokJSUhBcvXiAjw9Qq0UdUuBYPtvIUeiIjPaNQLWCMRiMy0jOgUiiRlipHQmw8khOSkJqcArVSBY1aA2WaAmmpcqSlyKFWqaHL0CEzU4f4F3EAgBkzZmDAgAHwdmDr3qysLMTHxxfp/mP/kZNISk41W7do9oRCnwN+3nMwz/WW47gUxicDP8LCld+alffAkVOoVb2K1fuwrM+pBUze3PMMZAXLCrSgZXepDHU6HWQyGQBTmZlKh6lwmIsCmUwGmUwGqVSKwMBABAQEsDcSzEWaj48PfH19zS7amCy30WiEXq9nb7QzMzOhUqmgUqnYpxRM5cpUxGlpaexFT3x8PBISEhAbG4uUlBRkWTRJswchfanzJU9TmC1/8cUX+OKLLzg9JsUjf5bxuH//Pu7fv1/o/WVmZiIzMxMKhYKdhtISxSN/lvEAwN4c2ItlkoCLeLxVuQL69/oAW3f+ji9mjEWAv59d93/qzCWEh4VgydxJdt2vJct4HD9+HMeP5z2ItkAgQHh4OEJCQtgbMJFIxCZopFIpvLy84OvrC4lEwiYect4wM/WdUCg0q/uY6wCm/mNuzNVqNfsAQaFQmNV5qampbH0XHx+PxMREduw5R9Hr9Wyi3B7EYjFCQ0MhFovZ5ALz4+/vD39/f4hEIkgkEjYhyVxPeHt7w9PT0+xmWSAQmH2+BoMBBoMBer0eWVlZ7E05cz2hVCrZm3rm4UBGRga7PikpCWlpaeyDG4Ui9/eZK5mZmUhLSytSjPl8Pnx9fREYGIiwsDCUKlUKfn5+8PX1NUsg5FyWSCTsNRyTEGY+V+azzfn5Mp9tVlYWW1/kbNnDXM9ptVrI5XKkpqayyRXmb5yZ5jghIcHprX8MBoPd/sY9PDzg7+/PJsyZJKWfnx+Cg4MRHBwMf39/BAUFQSqVsn/X3t7e7Pki52ef8/M3Go3sT87Pn3momPP6mfmsmWtny6Qhc55RqVTsuSavv7sOkc0hC5BBJBZD4ieBt7c3RGIRJH5+kPhJIZaKIQvwh5+/DD6+pr8doZcXPL2Epu+prw+EXl6m76rnq++qhwfw6jyYlWn6HYTeXshIz8DV85fw7NFTaDUapGvToVGpTUkUjRaqNAXUKjU0KjWSE5KQnJiMpLgEpKXKi3wfkJKSghs3biAoKAienp7sj0AgYD9/JgZ6vZ69d2H+7pkHiGlpaeznrNVqoVAokJqaitTUVMjlcsTHx+Ply5eIi4vLlXhh2FKfH/uf+RTarZs3RIN6tQr1GWRmZqLv8Om51h/ctcEuD0lEIh/0/rAD1n23g1136swlzJz8idX7sKzP/fzse11SXBTbBExAQAD7RQQApVJp9rplhZ1zfBhXlrMfotFohFwuh1wud16BbMDj8SCVShEWFobw8HAEBgZCJpPB19eXrQCZypB5Es38iEQiDB8+HBcuXGD3R0/485cqN//75vP57IVccHAwQkJC2JsR5gKDuahjblSYmxfmaZ9QKDS7AOnduzfOncuexYnikT/LeEyYMAEtW7aERCJhb3I8PT3NkqFCoRB8Pp+9kTcYDMjKymKfHOZMgKpUKkybNg137mRPG0jxyJ9lPL7//nu0bt2aTcIwrZGYp+VM6zDmAlipVCItLQ1JSUmIj4+HQqGASqVib2KA3AMVchWPLVELsSVqISf7Hju8L8YO78vJvnOyjEeHDh0QGBiI5ORkPH/+nL0wVqlUyMrKwtOnT9nm9yXN1KlTMW/ePOj1evaHaZ2Ys2UBk9CQy+VmLRPkcjkSEhKQnJzMtkBVKBRITExk/3ZVKhUePHjg5N/UNh4eHggNDWXrNiZh4e3tzSY7goOD2XqPSSAxCTqmnmPOw8wNNpCdMMrKymK7yjAtQpiuMszDqbS0NCQkJEAul0OtVrPnhJSUFMTHxyMlJQV6vR4KhQIKhSJXy0VXxuPx2NYmTILI39+fTVjIZDI2QcRcOzDJI6bVtuV1RM56LmciI2cSifk7Z26YdTod24qJiQNzjmDqROZ8wZyrmdfkclMiIDk5GcnJyXj48KGzP1abCQQCs2SGMk0BZR4PFbgyfUjeg79ag8fjQSyVIDg0BMGhIZAF+kPqJ4WPSARfqRgyfxn8/GXwlUpMCRahJ6K378b+n38DADRo0MBev4bVmARPzlaN1tbnRqMRh0+cMVvXqV3zQpdlwKiZea7v0ObdQu/TUvPG9cwSMH9fuIqMDJ3VMzVZ1ufucn/taMX2Ct3LywuVK1dmx4GxPMlaLteqVbhspKNJpVK2v6xWq0VKSgqbRVcoFOxNGVPpp6WlsU+ScvZlZvahVquRkZHx2sw0n8+Hp6cn+wRMJBKxN+w5n8wwzfLFYjGCg4PZi6GQkBD2Jr8oTcctm3SLfR3T7NIdqTVas+VDhw6hTZs2dj0G0/yVQfHIn2U8OnbsaPd4zJs3z2yZ4pE/y3iUKVMGZcuWtcu+mdYIjRo1QkxMDLue4pE/y3hMmjQpz+9HRkYGEhIS8Pz5c6SkpLA3YcyNb1JSEtuFlXmCzHQxyXnDnLOLq16vz3WcnJiWHVKpFP7+/mxXBqZ7CXMDGhoayia3jUYjIiMj7foZMapUqQKxWMzJvrOysqBWq9kWPTmfxjM3sykpKWxCR6FQsN16mOuJnN0ptVqtVeN3MF3+mOsJiUTCPpARi8Vsy12JRILAwED24Q3TAtjf3x8BAQFu0a2EuW5juu/ExsYiISGBTYYxrR2Y1g9MgoxZZq79rG2tx+PxzFoLMH/PzPWcj48P+zkyiRWpVMp+1uHh4QgPD2eTVa7e/a8gBoMBCQkJbJd35iEm85OQkICkpCSkpKSw5xPm75pJcNraksPDw4N9uMJcPzPd1ZiW6sxnnrNLG/OZ5zzXlCpVCjKZDCqVih1a4ef/RcNgMEClUEGlVCJDmw61Sg2FPM20TqGAPEUORarpe5uhfdUdLEOHDK2pu1hmhq7A+wCDwQCj0YigUsHwC5CZkpc+3vAV+8JXLIaPrwhiiRi+UjFEvr4ICApAUKkQBAQHIjAkCGKJaRtb/4YunDK1IJFIJPDy8jKV91XLFms++5xJP29vb/azZh44MucbmUzGtnyKiIhg72ECAwNRv359XLlyhd2vtfX5zdv3EBuXaLaufavCjf1y9ca/2PnboVzr4+6cLNT+8tOi6TtmDRg0Gi0uXL7BdnMuiGV97qyZq1yd69dWRfDBBx+wCZiTJ08iOTkZgYGBAIBffvmF3S48PBz16ln3h+VsPB6PfYrg5+eH0NBQu+zXYDDkuhhlEi+uUuGmppr3ofSXSfPZMn9GoxH1W/fGpasx8Pb2wn9XDiMsNNheRSwyrTYd5eu0Q3xCMsqUDsXdiwfg42N7f1d5mnmLLy6aAFI8rEfxsA93iAefz4dEIsnVVL4w8bDF7TsPMfbThTh78RqkEjH6fdQRSz+fnGf/63MXr2H6/JW4dusOfLy90e+jjvhq/mSnDdxsbTy8vLxQpkwZlClTxm7HZrraMjcXgKmeLWr9V7FiRU6errdo0cLu+2QIBAL2Jrxy5cpF3h/TDUOv1+f5+Xp4eLBPl0sKHx8flC5dGgCK9BkzLXKYz5X5AUw3nXw+36wVDzFhWkoV5dqZ6eLCtNLJ+dkDYFvxcBmDnDe1EeXKIjAkqMj7NBgMyMrMhF6f3XqTz/eA4NV5sOe7nXDryg18EfUVWnRoXeTjWYv5bIcMGYLVq1ebvcZ087KMgb3vXwp7fXXyb/OZm8pGhBVq5iOdLhMN2vTJtb5D63dRyg6xzyko0B+1qlfG9VvZg+9ev3XX6gSMI653i4NifWaeMGECO9iuSqVCs2bN8OWXX6J3797YvXs3u92nn37KySwY7oTJ0OfsU+/l5eVSlbdlNzKpxPangNt27cOlq6an0sP6dze7ufxu624MGTsbNZt0gyA4kp1+tVxk2yKV+9j/zqJz37EoVaUZvELroHT199B76FRcunor17Y+Pt6YOmYQAODZizgsX7fF5uOZ+hubPx2zHITaHriOBwBcunoLvYdORXi1lvAKrYNSVZqhc9+xOH7yXF67K9Djpy8w4bPFqNmkGyRl60MQHAlp2QaIfPdDTJm9DM9fDfbGoHhQPArLHvGwVlZWFrp8PA5nL17Dgpnj0KpZA6zeuA2LVn6Xa9v4hCR06DkKN2LuYcncSWjeuB5Wb9yGhSu+4ax8r+OoeOSHz+ebxkx49WSaeTpd1PqvXbt2diylScWKFVGxYkW775crTOuL/D5fT0/PEpV8saecT/aZLj/M58t0GXal67fihMfjQSAQQCgU5vrsmb9vrmPg4eGB8PBwAMDT/x7bbZ9CLy/4iHzYH2GO86C3yAcAoLVo4cA1jVoNABDlMdiwQCAw+w5wdf9S2Po8Mck8cfNOnRqFOufN/yoq1+xCAPDjhkU278saFcpFmC1bDiKcH2fX5+6kWJ+dIyIisH37dnh5eQEAbt++jblz52LXrl3sNh9//DHGjh3rrCISKxkMhiI/4dfr9Zi7OIpdnjjyY7PXp81bgc07onHr3/sFNku31txF69C2+yfYf/gkEhJToNNl4mVsAnbtPYwGbfpi04+7c71n5OBeEL2q6Jau/QFpCmWubV5Hpc49SJ29mwA6Ih6bftyNBm36Ytfew4iNS4ROl4mExBTsP3wSbT4cjnmL85/pJS+Xrt5CraYf4utvt+PWv/ehUmmg1+uhVKlxI+YeVq7fippNP8TtO+ZPrSkeJhQP69kjHrY4cuIMHvz3FB3bNMPUcYPx7ar54PP5iPp+Z65tz168hjSFEi3frY8xw/rgy5mm+m/dpp85K9/rOCIezjBixAi773P8+PGUsCCEAABq164NALhz47ZDjid6dV7WqOwz2Le14p7HAgDbcszRilKf16n1Fgb16You77+HZo3roVZ121u9Xbx8E4tXbcq1fsakYQgK9Ld5f9ZoULcWOrZtht4fdsDwAR+hbu3qVr2vuNbnXCjWCRjA1A3p2rVrGDRoEMqUKQOhUAh/f3+89957+Pnnn7Ft2zZ6SuAG5HJ5rqRIsI0nngNHTuHJs5cAgMb1a6NiefMxH/h8D1R9NatI7ZpvFa3AAA4cOYkvl29kl9u3aooFs8ah0TumsQEMBgNGTV2A67fumL1PLBahc/sWAACVSoOtP/9u03GTU3KPks90vbMXruNx7eYdjJq6gB3ItGG9SCyYNQ4dWmcPNPbFso344+gpq483b0kUlCrTkxQej4f+vT7Aglnj0LFts+zfK02B5es2m72P4kHxsJU94mGL+w9NA9KWjQgDAEgkvvCXSZGYlJIrQRVWytSq6UbMPdx/+AQHj50GAKSkpiEl1bGz9wCOiYcz1KpVCx9++KHd9hcWFoYhQ4bYbX+EEPfGjDN156ZjEjDiV60+1ErbHnoUVUJsPADnJWCKUp9/+EEbbI5agOifvsapA1swd/oom46dlZWFTybNz/O1zyYMs2lftvh0wlAc2LkeP29ahm9Xz0fnDi2tel9xrc+5UKzHgGG89dZb2Lx5c8EbEpeV10xPflKJTfv4Yfte9v/dP8g9wOPzW3+y40kMGjML127eybWNLb5clt2kv0mDOjj0qykZM23cELzV4AM8evIcWVlZWLxqE3Z+v9zsvR91bssOtvX9T79h/Ajz1givk56ekWudj49PYX6FfHEdj8WrvmMHhCv/RgROHdjCjk/RtEN/nLlwFYDpM+7Y1roR5R8+fs7+//027+LHDYvZ5Qp12uPRE9PriXk0taR4UDxsYY94FFV+08Y2fCcSY4b1QdSmn1H5nY4QiXzg6SlAZmaWVQOm2psj4uEsGzZswOnTp5GYmFjwxgXYunUrZ4PvEkLcD5OAuR9zt4At7YPtgqRNL2BL+3r+2PSA4Y033nDocRnOrM9Xb9hmNhYLY+n8yZBKXa8+KM71ub1R0w/iFpKSksyWvbyEEIutn1VEr9ebDYbFtELJqTCDeeYnPiEJF6/cZJc/7JQ9YJlQ6IlO7bKf8h84eirXzVLO8t28fR+JSSlWHzvdYnYiLy8vuzdb5zIeer0efxz7i13u1K6Z2eCgOT/LC5dvICEx2apjVqtSgf3/jZh7uHX7PnS6TJz8+yJi47NvkPIaoZ7iQfGwRVHjYatKFU2tlZ48N7VgSlMoIU9TIjgoAFKJGOnpGWb9stctnYWnN47hzKFtOHt4G7Ky9ChXtjQCA2SclTE/joiHs4SEhCA6OrrITbAXLVpk91nTCCHurWrVqgCA/+49cEjynGkBo3LglNcpiclIfVW/22Ng8MJwdH3OePLsJeZ9tT7Xel9fH4wa0pvz4xdGca7P7YxHCRjiFtSvBuFiiH1FNn2pb96+D4VSxS7XqVXVbmXLy42Ye2bLlgNaVXgjexYPtVqL/3K0BgCA8LAQhAQHADCNAH/24jWrj621yEBzkX3mMh7/PX4OtTp7kLecnxWQ+7O0/Kzzs3DWeISWMo0W/+xFHGo27Qav0Dpo2XkI0tMzIBH7Yu60kRg1pFeu91I8KB62KGo8bNXuvSaoWL4MDh47jRXrtuCTifNhMBgwekgvPHn2Ej7hdfFGZPYN/OyFX+PQ8b9x7dZd9PvkMxiNRsyZahqz5PHTF+AF1EDoW9a1ZCoqR8TDmRo3boxjx46xA2bags/nY+3atZgxYwYHJSOEuLM333wTfD4fitQ0PPjXunq3KMR+plYfapW6gC3t59/rpkkBypcv77SxRBxdnwOm65rRU7+EJo8Bj6eOGeSQBFBhFPf63J4oAUPcguUAWBKxbSfiF6/6kDLv9fb2sku58pOcIjdbthwxXWJx8sxrhPGQoOx+ky9iE6w+ds4baQDsTGD2xGU8cn925vu2PJa1o7NXrVIRl0/8ggZ1a+X5evMm9fDhB63zHROK4mFC8ShYUeNhK4FAgOhtX6NhvVqYtfBr/PnXBYz/pB9mTv4kz+0fP32BafNWYOLMJQCAresXYsjHpvFKmCepAr5jeig7Ih7O1qhRI9y6dQsDBw60esy5unXr4tKlSzRJACEkTyKRCJ07dwYA7N7M/SDqzCC8aotzNpeORv8BAGjVqpXDjmnJ0fU5APwafYQdny0nP6kEE0f15/z4hVUS6nM7MZaIMWCI+3v58qXZcrjF9LgFyTkvPZfTwTIsG4NaNg+1XM4rm57zRlduQ5PPNIX5CVAmk1n9XmtxGY+CPitrPru8xPz7AB17j2YHmv2wU2tE1qiCsxev4ciJMzhw5BT+/OsCju75Fk0bvp3r/RQP65YpHkWPR2HUqFYJJ/dvybW+XNnSMKaYT3n/0zdf5bufW/8+AACMH9HPruXLjyPi4Qr8/f2xZcsWzJ8/Hxs3bsSJEydw+fJls+6nZcqUQfPmzTFw4EC0bNkSfD7fiSUmhLi6YcOGYe/evTj46z5MWzwbAgF3t3X+gaZWp8kJSQVsaR8GgwF/7j8KAOjVK3dLWEdxdH2uUKgwcVbedfRnE4dC5ue60zqXlPrcHigBQ9xCQoL5E+7goACb3i/zy87CWmZouRDo72e2rLRosqlQmi8HWGxvuY0tJ1zL34+LZptcxsNyHAqlxZSHltvn9dnlZeCYmezN/qA+XbE5agH72ntdhuB/py9Cq03HZ5+vwt+HtuV6P8XDhOJRsKLGw5lOnfkHkTWqYPLoAQ45niPi4UrKlSuHJUtMLY+6dOmCffv2Yd68eZg0aRL8/Kz77hBCCAC0adMGgYGBSE5Mwtk/T6NZO+tmqymM4NAQAECyleO8FdXNy9eRkpQMsViMZs2aFfwGjji6Pp+7eB1i43IP3B4eFoIJNkw44AwlrT4vCuqCRNyCZQY6IryUTe8Pf1VxAKZkSF4jddtTrepVzJYfPnpmvvw4e9nX1wcVy5uPqwEACUnZlVzpsJBcr+cnMcm8uWRwsP2z9VzGo2L5MvD1ze43mvOzAnJ/lrWqFzwwW5pCicvXsqdqrF+3htnr9WpXZ/9/7Vbes19RPEwoHgUrajycafmX03Dtrz2cPknNyRHxcFXKV9O5VqlShZIvhBCbeXp6ondv04Csh387wOmxAoJN3X6T4os+q5s1Du/eDwDo2LEjhEKhQ46ZF0fW59dv3cG6TXl3J5s1+RO7ThbChZJcn9uKEjDELaSkmM9yEiCz7WK1ZrVKZoNWFXWKacagMbPAC6gBXkANtPhgELs+tFQQ6tXJvoncs/8Y+//09AzsP3ySXe7YplmucQFexiYgIdH0O/N4PDSuX9vqMlm2tuHiwp7LePD5fHRo9S67vP/wSXYGF6PRiN37sj/L+m/XRKmQIHY5v3jo9eazTF26GmO2fPl6djLAxzt3BUfxoHjYoqjxKIzbdx7ivS5D4B32NkIqN8OkmV8hMzMzz23LRbZl48L8RP/xJwDg37sP4RFYE/MWr+O8zIBj4uGqVCrT00KaXpoQUlg9e/YEABzfdxhyK8dgKwwmAZOWwt0xGFlZWTjwy+8AgH79HNMdNj+Oqs+NRiPGTl8EvV6f67UypUMx9NU4ba6sJNfntqIuSMQtxMXFmS0zs6dYSyAQoFmjuuygVucv3UBDi6moF638FimpaQDMbwhT5QpMnbOMXV7+5TSrjjl7ygh0/Xg8AODcP9fRocdING1YB/sPn8KzF6bfh8/n49MJQ3O9N+esLjWrVbKpyaPaYtR0Li7uuY7HjEnDsPePP6HX6/Hk2Uu0+GAwOrVrhtPnrphN7z1rSt6DjFoK8PdDjaqVcOvf+wCAzTuioVJrUKNqJZz75zpO/HWB3bZty8a53k/xoHjYoqjxsFVWVha6fDwOz17EYcHMcbh8/TZWb9wGmZ8E8z4dned7qlaugLnTRrLL79QxtUKqWqUi2rdqihXrt2LS6AGc9zd3RDxclVZr+t1ppghCSGE1adIENWrUwK1bt7By7mJ8EbWUk+Mw01BnZWUhXZsObw5bY2zfsAXJCYkIDg5G+/btOTuONRxVn+/Y/Qf+Pn8lz9fmThsJLy/ntQKyVkmuz21FLWCIW0hKMh/0KzjQ3+Z95Mwe52yRwvh2626siNqKFVFbEXPnAbteoVSx61dEbbX6eF3efw8zJw9nlw//+TdmL1yLC5dvADA9uY9aNgtvR1bL9d7d+47mWW5rWJ4ARSL7T1fHdTzejqyGqGWz2AFdz1+6jtkL1+LIiTPsNjMnD0fnDtb3d45aNgsikelGx2g04pfoI5i7eB0OHc8eab5sRBgWz52Y670UD4qHLewRD1scOXEGD/57io5tmmHquMH4dtV88Pl8RH2/M9/3hAQHoGPb5uj1YQf07v4+SudoVt2jS1uo1Vrs2H2Q03IDjomHq8rIMHX18/LidlY+QkjxxefzsWHDBgDA7i07cf1i3jfxRSXKMfuPSqF8zZZFkxiXgHULVwIAFi5cCE9PT86OZQ1H1OcqlQbT56/M87Wa1SphcL9udj8mF0pyfW4rSsAQtxAbG2u2XJgMdJf330PZiDAAwJkLV/HoyXO7lO11Fs6egMO/foOObZshKNAfnp4ChIUGo2fXdjh/dAdGDOqZ6z1KpRr7XnVREotFGNini03HtBwESyq1/xNsR8RjxKCeOH90B3p0aYfQUkHw9BQgKNAfHds2w5Hd32Dh7Ak2Ha9Z43q4+fdvGPdJX9SoWgm+vj7g8/mQSsSoV6c65k0fheun97BlYlA8TCge1rNHPGxx/+FTAGA/K4nEF/4yKRKTUpCWz4XyX2cvQ/pGA/iE18WHAyYgMSm7mXWTBnUAwCzBxhVHxMNV6XSmrnzOHN+AEOL+mjZtikGDBgEA5o+fmWc3lqLy8PCA5FWLSIU8ze77Z6z5fBnUShXeeecdDB2au4W4ozmiPl+8+ju8jE3I87VVCz91mxnxSnJ9bivqgkRcnl6vZ/vKMwrTB5PP5+PLmWMxcPQsGI1GrFz/I9Z+NZN9/fH1o695d962RC3ElqiFr92mXasmaNeqidX73Lh5F7TadADAp+OHwk8qKeAd5iyngbP3CdBR8QCA+nVr4pfNK6zeZ0HxqFCuDL5eMjPf1/NC8chG8SiYveJRVDmnN7Y0pF83VKr4BnxFPlj//U7sPfAnRD7e7PTUzCCDlgMsc4HreLgyjcY0oxg9JSSEFNXSpUsRHR2Nuzdv48DOvejS7yO7HyOoVDCUaQrEv4xDhSpv2n3/Ny5dw95tvwAA1qxZk2t8REdzRH3+3+Nn+bau7/L+e2jVvKFdj8elklyf24pawBC35OHBK9T7+vfqzA6Ou2nbnjynenMmrTYdK9abTsRlSodiypiBNu8jOUVuthwQwP0UuBSP/FE87KekxcNalSqWBQA8eW6arSFNoYQ8TYngoABIJWKkp2ewAycDwNzpo9Cn+/vo3KElFs42jVN1I+ZejvKaLg2MRiOn5QacEw9XQQkYQoi9BAcH49NPPwUArJizGHEvYgt4h+1CQk3J+eSEpAK2tF1WVha+nGh6ANS/f380atTI7sewB3vX5/4yKbrk03172edT7HosrpXk+txW1AKGuLy8ZvIobJ9QHo+Hf/7cVdQiccbHxxtxd04VaR+JFqPgBwYGFml/ligetqF42E9Ji4e12r3XBBXLl8HBY6exYt0WXLxyEwaDAaOH9MKTZy9RvnY7lAoJRNydU7gRcxdT5yxHh9bvwk8qxvc//QYAaNrwbXZ/zCDhFcpFcFpugPt4uLL0dFNLLu88ZvoihBBbTZgwAdu2bcPt27cxsttAbDu2m+02ZA9+gTIAQGpyyus3tJHRaMSXk2Yj5upN+Pn5YdmyZQW/yQEcUZ/7y/yw8/vl+PvCVbNuSBNH9kelim/Y9VhcK8n1ua2oBQxxeQKBIFczRMt+hsQkNi4xVz/SsmXL2vUYFA/rUTxcS3GNh0AgQPS2r9GwXi3MWvg1/vzrAsZ/0g8zJ+eelSo4MADe3l746uvvMWrql3j+Mh4TR/bH8i+mstsws0zlNQOVPTkiHq5Kr9ez4zTQILyEEHvw8fHBwYMHERoainsxdzCx30joXg32bQ/SV8kctZ3rtHULV+LXH3aAx+Nhy5YtKFWqVMFvcgBH1ec8Hg99PuzALvvLpJiTY5ZCd1CS6/PCoAQMcXkCgQDh4eFm617kM1hVSWc5hZ1EIkH16tXtegyKh/UoHq6lOMejRrVKOLl/C9JjryDpwd9Ys2QGhEJPlCtbGsaUW2zLobDQYOzbsQ5xd04hI+4qntw4hlWLPmVnpAKAX6IPQyTyQb8enTgtsyPi4apyPlkVCKgxMiHEPt544w0cOHAAIpEI5/73NyYPGJNnS47C8HnVXVJrMdtNUXy3PAobFq8BAERFRaFr165223dRObI+r/5W9pg686aPQoC/48eOK4qSXJ8XBiVgiFsICjIfddyynyExuR5z12y5UaNGnIyeTvGwDsXDtVA8Cnbn3n84/OcZTB41gPMLQEfFwxXlHCS5pPzOhBDHqFu3Lvbt2wcvLy+cOHAUE/uNtMvMRWI/06D39tiX0WjE2i9XYNU80+DvCxYswKhRo4q8X3tzVH3OJGDerFAWo4b05uQYXCrJ9XlhUAKGuAXL5ohxHAwAVhxcuf6v2XJkZCQnx6F4WIfi4VooHgV7q3IF6JNu4MtZ4zg/lqPi4eqcPdMHIaT4adWqFfbu3QuhUIj//XEMXRu0w6UzF4q0T79XMwAVNQGjkKdh2qBx2LDE1PJlyZIlmDVrVpH2yRVH1efVqlQEYBp4Vyjkdtw4LlB9bhuq9YlbCA0NNVu+futuPluWXLFxiTj6v7Nm62rVqsXJsSgeBaN4uBaKh2txZDxc3eumDCeEkMLq0KEDTp06hYoVKyLu+UsMat8Lm9d8W+gZ7vz8ZQAAucVgq7a4fvEKPmryPg7u3geBQICoqCh29iZX5Kj6XCwWYWCfLujy/nuc7J9LVJ/bjhIwxC00aNDAbPmPo3+ZTatKgK07f2cHdQRMU5t26sTNGA4Uj4JRPFwLxcO1ODIerihnqxdKwBBCuNKwYUNcu3YN/fv3h8FgwLKZCzC251CkJtk+k5Gv1NQFSaPW2PzezMxMrF+8Gh+37o7nj5+hfPny+PvvvzF69Gib9+VIjqzP1301Czyefae5doSSXp8XBiVgiFvo2rWr2UlJqVLjxF9Fa0pZnBgMBmz5+Xezdb1794ZMJuPkeBSP16N4uBaKh2txdDxckVAoZP+v01FyjhDCHbFYjK1bt2LdunXw8vLC/w4eR+tqjbFw6lw8e/TE6v0w5y2dDQkIg8GAU4dPoG/Lrli3YCX0ej369OmDq1ev5kpuuCJH1udisYiT/XKJ6vPCoQQMcQthYWFo2LCh2brd+446qTSuZ/33O3H3/iOzdYMHD+bseBSP16N4uBaKh2txdDxckYeHB9sKxl4zlBBCSH54PB7GjBmD8+fPo3bt2tCqNdi+YQs61GqOif1G4PrFKwXuw/PV2CSZViSN01Ll2PL1d3i/dguM6j4IMVdvwt/fH9u3b8f27dvh5+ces/xQff56VJ8XDiVgiNvo1q2b2fKPu/bj3oPHzimMC3n46CmmzVthtq5y5cpo0qQJp8eleOSN4uFaKB6uxVnxcEXs02RqAUMIcZDatWvjypUrOHbsGNq1aweDwYCj0YfQp2VX9G/7EdYuWIEzx//Ks5uRQCAAkH+3SXmKHGeO/4VZI6eiZaX6WDrjSzx9+BhSqRSTJ09GTEwM+vbt63bdbKg+zxvV54XHMxZ2JCZCHOzZs2eoVKkSMjIy2HWd2jXH/p+jnFgq51Iq1Wjb/ROcv3TdbP3Ro0fRpk0bTo9N8ciN4uFaKB6uxZnxcEVBQUFITk7GrVu3UL16dWcXhxBSAt26dQsrVqzATz/9hKysLHa9p1CIWu/URr0mDVCtdg1IZX54/ugp5oyZjrCIcCzbshYJsfG4c+M27t68jXsxdxH77IXZvmvVqoXRo0ejX79+EIvFjv7V7Ibq89yoPi8aSsAQt/LZZ5/hq6++Mlu3d9sadO3Yykklcp7kFDna9xiBS1djzNaPHj0aUVGOqRQoHtkoHq6F4uFaXCEerqZ8+fJ4/Pgxzp07l6uJOyGEONLjx49x6NAhnDt3DidPnsSzZ88KtZ+KFSuiadOm+OSTT9CoUSO3a+2SH6rPs1F9XnSUgCFuRaFQoHLlyoiPj2fXeXt74eCuDWj5bn0nlsyxTv59ESMmf5GrCWR4eDj+/fdfSKVSh5SD4mFC8XAtFA/X4irxcDXVq1fH7du38eeff+K999xv6lFCSPFkNBrx4MEDnDp1CidPnsR///2Hy5cvQ6fTwc/PDxKJBF5eXggMDERkZCRq166NmjVrombNmsV28FWqz02oPrcPGgOGuBWpVIrFixebrUtPz0CnPmPw56nzTiqVYxiNRty+8xDdB0xEy85Dcp38goKCsHfvXoee/CgeFA9XQfFwLa4YD1cjEplmvNBobJ/SlRBCuMLj8VCpUiUMGzYMP/30E86ePYtatWoBAH766Sc8e/YMDx48wIULF/Dtt99i9OjRePfdd4tt8gWg+pzqc/uiFjDE7RgMBgwYMADbt283W8/j8fDJwI+wcPYEBAbInFM4O5OnKXD3/mPsP3ISu/cdyzXSOKNMmTI4fvw4Kleu7OASUjzyQvFwDIqHa3GHeLiS5s2b46+//sKuXbvQs2dPZxeHEELyRecrqs/zQvV54VAChrilrKws9O7dG3v27Mn1WoC/Hz6bMBR9P+qI0uGlnFA6c0ajEWq1FmqNBkqVBvI0BRKSUpCcIkeaQoWMDB3SMzKgTc+ASqWBXKHEf4+f4+6DR0hITClw/2+99RYOHTqEcuXKcf/L5IPikY3iYRuKB8WjpOrYsSMOHjyI77//HkOGDHF2cQghJF90vjKh+jwb1eeFRwkY4rYyMzPRr18//Prrr/lu0+idSHTt2AoN6tZEhTciEB4WAj6fX+C+jUYjMjOzoE1Ph0aTDqVKDbVGC7VGi5TUNMTGJyJNoYJarYFGmw61Rgt5mhJKlRqpcgUUShU02nRo0zMgT1NCo9Ha81cHYGry98UXX2DYsGHw9PS0+/5tRfGgeFA88kfxcK14uII+ffpg586dWLVqFSZOnOjs4hBCSL7ofJWN6nOqz4tK4OwCEFJYnp6e2LFjB95++218+eWXefajP/fPdZz753qO9wgQHhqCwAAZPAUC8Hg8ZGZlQqfLNGWA1RooVWpotRkwGAyO/HWsFhYWht69e2POnDnw9/d3dnFYFA+KhyugeLgWV42HK6AxYAgh7oLOV9moPqf6vMiMhBQDT548Mfbo0cMIoNj98Hg8Y8WKFY1Tpkwxnjt3zqjX6539cReI4uFaKB6uheJBjEajceLEiUYAxunTpzu7KIQQ8lp0vsob1eekMKgFDCkWypYti19++QVnzpzBN998g99//x0KhcLZxcqTQCBAcHAwgoODIZPJ4OPjAy8vL3h7e0MikUAsFqN06dKoXLkyqlSpggoVKkAoFDq72DaheLgWiodroXgQAPDz8wMAKJVKJ5eEEEJej85XeaP6nBQGJWBIsdKkSRM0adIEGRkZOHHiBH7//XecPn0ajx49glZbtH6QAoEAvr6+kEgkCAsLQ2BgIHx9feHr6wuRSAQ/Pz9IpVLIZDL2xObj4wOpVIpSpUpBIpFAIpHA29sbPB7PTr+xa6N4uBaKh2uheJRsYrEYAN3QEEJcH52vXo/qc2ILGoSXlAhGoxEJCQl48uQJnj9/DqVSiczMTBiNRgiFQgiFQnh5eUEsFkMqlcLHxwfe3t4QiUTw8fGBRCKBl5eXs3+NYoPi4VooHq6F4lEybNmyBYMHD0abNm1w9OhRZxeHEELyReerwqH6nOSFEjCEEEIIIQ525MgRtG/fHpGRkbh27Zqzi0MIIfmi8xUh9uPh7AIQQgghhJQ0ISEhAIC4uDgnl4QQQl6PzleE2A8lYAghhBBCHCw4OBgAkJyc7OSSEELI69H5ihD7oQQMIYQQQoiDSaVSAEBWVlaRB2kkhBAu0fmKEPuhBAwhhBBCiIMxs4oAcNlpSwkhBKDzFSH2RAkYQgghhBAH8/DwgJ+fHwAgNTXVyaUhhJD80fmKEPuhBAwhhBBCiBOEhoYCAF68eOHkkhBCyOvR+YoQ+6AEDCGEEEKIE4SHhwMA4uPjnVwSQgh5PTpfEWIflIAhhBBCCHGCwMBAAEBSUpKTS0IIIa9H5ytC7IMSMIQQQgghTiCTyQDQoJaEENdH5ytC7IMSMIQQQgghTuDr6wsA0Gg0Ti4JIYS8Hp2vCLEPSsAQQgghhDgBzSpCCHEXdL4ixD4oAUMIIYQQ4gT+/v4A6IaGEOL66HxFiH1QAoYQQgghxAkCAgIAAMnJyU4uCSGEvB6drwixDw8APGcXghBCCCGkpJFKpQAAlUrl5JIQQsjr0fmKEPugFjCEEEIIIU7g5eUFAMjIyHBySQgh5PXofEWIfXgAMDq7EIQQQgghJY1QKAQA6HQ6J5eEEEJej85XhNgHtYAhhBBCCHECT09PAEBmZqaTS0IIIa9H5ytC7EPg7AIQ4khqtRq3b9/GixcvkJKSArlcjtTUVDRt2hTt2rVzdvFKHIqHa6F4uBaKR/FHT5QJIe6CzleE2AclYEixFhMTg8OHD+PSpUu4du0a7t69C6Mx7153q1evhlgshkwmg1gshkgkgkQigb+/P/z8/CCRSMDn8x38GxQvFA/XQvFwLRSPkkckEgEANBqNk0tCCCGvR+crQuyDZ8zv6o4QN5WQkIBt27bhxx9/xI0bN+y2Xx6PB39/f0ilUvj6+sLHxwdCoRBCoRBisRg+Pj7w9vaGUCgEn8+Hh4eph5/BYEBWVhZ0Oh0yMzORnp4OpVIJjUYDtVoNrVbLvsYMbCaVShESEoKQkBCULl0aERERqFu3Lpo0acKOQu8uKB6uheLhWigeJdvDhw/x5ptvwtfXl2YWIYS4NDpfEWIflIAhxUZqaipmzJiBH374odj2T+Xz+WjQoAHatWuHkSNHIiQkxNlFyhfFw7VQPFwLxYMAwMuXL1G6dGl4eHggKysLPB7P2UUihJA80fmKEPugBAwpFvbu3YtRo0YhPj6+wG15PF6+zfrdiVgsxqRJkzBt2jRIJBJnF8cMxYPi4WwUD9fiyvFwpuTkZAQFBQEwDWwpEFDPcEKIa6LzFSH2QQkY4tYMBgPGjx+PqKiofLcpHVYK77d5F29HVkWdmlVRs1ol/HX2Mo6dPIf0jAxotelQqjRISkmFSq2BPE0JtUYLrTYDCqUKBoPBgb+R7UJCQrBq1Sr07dvX2UWheIDi4WooHq7FleLhCtLS0iCTyQAAWq0W3t7ezi0QIYTkg85XhNgHJWCIW5s2bRqWL1+ea723txd6dGmLQX26onmTeoUejNJgMEChVEGpVCM1TYGkZDlUag3UGi0yMnTI0OmQkaGDSq1BerppWafLhN6gh15vuhHi8z3A9+DDy0sIPt8D3l5ekEp8IfLxgUjkDZGPN4RCTwj4Anh5mab4S0lNQ1KyHLHxiXgZl4iYOw9w8cpNZGZm5VvW6dOnY+HChU59IkHxyEbxoHhYonhkc4V4uAKlUsmOk6NWq9lBLgkhxNXQ+YoQ+6AEDHFbq1atwuTJk3Ot79i2GdYvn4OyEWFOKBV31GoNTp+7gp9/O4iffjmQ55Purl27YseOHfDx8XF4+SgeFA9noni4FlePh6tQqVRslyyVSgVfX18nl4gQQvJG5ytC7IMSMMQtHTt2DO3atTMbG0EgEOCblXMxuF+3Yj8w2O07D/HZF6uw//DJXK917twZ0dHRDv0MKB4UD1dC8XAtrhYPV6JWqyEWiwHQDQ0hxLXR+YoQ+6AEDHE7WVlZqFGjBu7evWu2fvO6BRjUt6tzCuUk323djTHTF+Rq6r9x40aMGDHCIWWgeGSjeLgWiodrcYV4OJNOp8O1a9dw/vx5PHv2DHK5HImJifj9998BUJN+Qohry9kChs5XhBQeJWCI29myZQsGDx5stm7BrHGYNaX4X8Dn5a+zl9C57zikKZTsOolEgtu3byMiIoLz41M8zFE8XAvFw7U4Ox6OlJGRgQsXLuDUqVM4ceIEzp8/j/T09Hy3DwkJQeXKldG+fXu0aNECDRo0KPFj5BBCXIdCoYCfnx8AQKPRlOjuo4QUBSVgiFvR6/WoWbMm/v33X3Zd3drVcPH4Tnh4eDixZM516NhpvN9rlNm6Ll26IDo6mtPjUjzyRvFwLRQP1+KseDhKamoq1q5di6ioKCQkJJi9Jgv0R+Q7dVCuUkV4eHhg85pv8t2Pr68vGjZsiIYNG6JPnz6oXr0610UnhJB8paamIiAgAIApwSwUCp1cIkLcEyVgiFs5ePAgOnbsaLbuwM4odGzb3Eklch2DxszC1p9/N1sXExODatWqcXZMikf+KB6uheLhWpwRD67J5XJERUVhxYoVSE1NBQAEBgeh3rsN0KBZY9Rv1gjlK1dkx7tJjI1H8zffAY/Hw6Ebp6BSqHD94hVc+OssLpw6i7QUObtvHo+Hjz76CLNmzUJkZKQzfj1CSAmXmJiIkJAQAKYHDCX5QQIhRUHfHOJWDh8+bLZcs1oldGj9rpNK41pWLpiOwACZ2bqNGzdyekyKR/4oHq6F4uFanBEPrqjVanz66acoW7YsZs+ejdTUVLxZtTKWbV6LE/cvYNW2Deg9vD8qVHnTbLBheaocACCRSVG2QjlUq10DfT4ZgNU/bcSZJ9cQfeEo5q9djFYfmAZw/vXXX1G7dm188MEHOHfunJN+W0JISZWZmQkA8PDwoOQLIUVA3x7iVo4fP2623Ktbe6oEXgnw98MnAz8yW/fTTz+9dsyBoqJ45I/i4VooHq7FGfHgwj///IPatWtj6dKlUCqVqFStCr76fg32XjiCjj27wNPTM9/3ql6Ng+PnL8v1moeHByrXeAs9h/TD2p3fIfrCUXT46AN4eHjgwIEDaNy4MTp27IjExESufjVCCDGj0+kA4LXnNUJIwehKkLiNuLg4s7EUAKB180ZOKo1r+mRgD7Pl1NRU7Nu3j5NjUTwKRvFwLRQP1+LIeNib0WjE2rVr0aRJEzx48AChpcOw7pdNiL54FB/07gY+n1/gPpRppgSM76tpXV+nco23sGJrFA5cOYHuA3vD09MTBw8eRGRkJP78888i/z6EEFKQrCzTDHaUgCGkaCgBQ9zG2bNnzZalEjHq1nbf8QK4UK5sabR8t77ZOq4uzikeBaN4uBaKh2txZDzsKS0tDT169MD48eORmZmJNl06YO+FI3ivY1uzLkYFUatUAACxtOAEDKNcpQr4cv1S7D5zEBWqvInY2Fi0bt0aU6ZMcbvWQ4QQ98J0QaIEDCFFQwkY4jYeP35stly75ls0RWceOrRqarZ848YNTo5D8bAOxcO1UDxci6PiYS8vX75Ew4YNsWfPHnh6emLm8s+xevvGPLsRFSRdY0qYeBdiKtdK1avgl9MH0HNoPwDAypUrUbduXcTExNi8L0IIsQYlYAixD0rAELfx4sULs+WyEaFOKolrq1G1ktlyTEwMuJjsjOJhHYqHa6F4uBZHxcMenj17hmbNmuHOnTsoFR6Kbcf34ONRg21q9ZKTRq0GAIjEokK9X+QrwvyvF2P97h8QGBKM27dvo3Xr1rhz506h9kcIIa+j0WgAACJR4c5ZhBATSsAQt2F5QxNWKthJJXFt1au+abasVCpzfXb2QPGwDsXDtVA8XIuj4lFU8fHxaNmyJR4+fIiIcmXw0/E9qFWvdpH2qZCnAQAkUmmR9tOiQ2v8fvEoqtSoiri4ODRv3hy3bt0q0j4JIcRSSkoKAMDf39/JJSHEvVEChriN2NhYs+XSYSFOKolrK1M6FL6+5k3auXgiSvGwDsXDtZSUePACaoAXUAPp6RkATIMnMusYrboORdCbTSEsVRsR1Vth3KeLkJGhc2g5HRWPolCr1ejUqRObfNl65FeUfqNMkffLDMIrlfkVeV8BwYH44Y+fUTWyBhISEtC+fXs8ffq0yPslhBCGUvlq5ja/op+zCCnJKAFD3AZz4mf4y4r21LC44vF4KFemtNm6hIQEux+H4mEdiodroXhkq1WtMhbPmYj1y2ZDIhZh3Xc7sGnbHoeWwVHxKIpx48bh0qVLkAX649vobQiLCLfLftWv/kZsGYT3dfyDAvDDHztQsWolvHjxAu3atUNSUpJd9k0IIUy9JrZi5jZCSP5oREDiNgwGg9myNdN8FsbJvy+iZechudZ7eHhAIvZFhXIRaNOiESaNGoDQUkEAgIePniKyWXeo1VoAQIfW7+LgLxtylb9l5yH46+wlAKZZUW6e2YuyEWF2/x1kfhKzZblcbvdjOCoegG0xCQqUoX7rPrh6wzQFsEAgwKUTOxFZ4y2z9z5/EYdqjbpAqTKNwxARXgq3zkbDTyrJdZyiKk7xKMz3AwDKRbbFk2cvrT6OMYW7LhTFKR5FsWrRp0hJTYM8TYHd+47hzv1HhR7PpCgcEY/COnToEDZv3gwPDw+s2f4NylWqYLd9pyanAkChBvDNj5+/DN9Gb0O/97rhzp07GD58OPbu3Wu3/RNCSq60NFO3SZlM5tyCEOLmqAUMcRuWNzBZWXqHHt9gMCBNocTVG/9i6dc/oE6Lj/DsuambQcXyZbHiy2nstoeOn8bGzbvM3r9q/Y9s8gUA1n41g5PkC+CYGxpnxwPIOyaxcYnYErUAnp6CV+XKwtDxc6HXm5dv9LQFbPIFAL5b/TknyRegZMTjdd8PV1MS4mGtyu90RMW3O+DIiTPo16MjhvXv7vAyuGoCRqPRYNSoUQCA/qOH4J13G9p1/0q5AoB9EzAAEBYRjvW7N0MgECA6Ohq7d++26/4JISWTSqUCAPj6+jq5JIS4N2oBQ9yG5Q2N5RNmrvTq1h71aleHQqlG9ME/cfP2fQBAXHwSVm3YhpULpwMARgzqiX2H/oeDx04DAKbOXY42LRqhYvmyuH3nIWYvWsvus1unVhjQuwtnZRZZTGuq1WrtfgxnxQOwLiazp4zAvCVRAIDL125j1fofMXXcYADAzj0Hsf/wSXZ/Qz/+EO1bN811HHspzvGw9vsxa/InSFMo89zHtz/uxv2HT9jlMcP6cFrm4hwPBo/Hg9FoZGcUYv61bOHy24+rERefhOVRW7Dzt8Po1rE1undu49CyOiIehfHVV1/hyZMnCI0Ix7i5U+2+/6LOgvQ6b9WqhuFTx2DDkjUYPXo0mjVrhpAQGheKEFJ4qamvWu3RGDCEFAklYIjbEAjM/1x1mZkOOW77Vk0xqG9XAMCUsQMRUrkZdDrTsW/ffWi27aY1X6Bm025ITpFDrdZiwKiZ+DP6e/QfNYMdDLNUSCC+WTmP0zL7+HiZLXNxQ+OseADWxWTm5OGIPniC7Yo0d0kUunVqBX+ZHybMXMLuKyK8FFYsmAYuFed4WPv9GD7wozzf//Oeg2bJlyYN6mDVq6QNV4pzPBgR4aXw7EUcnr+MR6WKb+Dpq9ZIZUqbT4fdrHE9AIBAwEf3gZOw5edohydgHBEPWz1//hxLly4FAExfPBsiX/snSdK16QAAL29vu+8bAEZMH4s/9x/BvZg7GD16NH799VendDEjhBQPCoWp1R51QSKkaKgLEnEbEol5M3WFQuXwMvhJJRDnuBAPDJCZvR4WGowNy+ewy2cvXkODNn1w5fptdt13qz9HcFAAp+X0tLj5y+Tg5s8V4gHkHxOBQGDWFUmrTcfwifMxadZXSEhMYbfnsusRo6TEo6Dvh6UbMXcxbEJ2MjIsNBi/bl4JT09ProoIoGTEo1vHVgCAXkOnYtaCNegxeAoAoPsHpuTK4eN/Y8CoGfhmyy/YuHkX5ixaBwCIrFHFoeUEHBMPW82ZMwfp6el4u/E7aNetIyfH0OlMM04JvYSc7F/o5YVF366EQCDAnj17sHPnTk6OQwgpGdLTTUljb46SxoSUFJSAIW5DJDJ/Aql91aLEURQKFb7+5iekpKax63p2bZdrux5d26Ffj+wL9hsx99j/D/34Q3zQvgWn5QRMT7Nzshz/xB6cHQ+g4JjUql4Fs6eMYJf/d/oifty5j13muusRoyTEw9rvByNVnoZu/SdAozG1dvD0FGD35pUICw3mvKwlIR6L5kzAtHGDkSpXYEXUVqTKFZg+fggWzh4PAAgKlOHm7fuYOnc5Js1aigydDp9NHIp500c5tJyAY+Jhi5SUFOzYsQMAMG3hLM5ajWS+ainmKeQmAQMA1WrXwIhPxwEAZs2a5fTPlhDivigBQ4h9UBck4jZ8LMYJ0Lxqvs21wWNnY/DY2WbrRCIffP7paHR5/70837Nu6SycOH0RsXGJ7LqI8FJYtfBTTsvKsLxhYMZ/sCdnxQOwLSaWXZEYjuh6xCjO8SjM98NgMKDPsOn47/Fzdt2axZ+hcYM6nJaVUZzjwfD1FWHp51Ow9PMpeb5er04NXD3lGoOzOiIetti1axd0Oh2q1KyGyPpvc3ac9FfJR8u/FXsbMnEktq3/AY8ePcIff/yBzp07c3o8d6TRaHDv3j34+/tDJpNBKpVSdy1CLKhfjVtFg/ASUjTUAoa4DcuL1IwMnZNKAnTr+B5GDemV7+vPX8SbtQQAgMTkVHYcBq454sLRleIB5B8Ty65IDEd0PWKUtHgU9P2YtWANjpw4wy4P6tMVo4b0dkTRAJS8eLg6V7vR/f777wEA3T7Oe9wie2HGuvEWcfs02Ufkgx6DTANbL1++nNNjuaO4uDh8/fXXqFOnDsqVK8cmYFq1aoXPP/8csbGuOZsbIY7GTENNg/ASUjSUgCFuw3JciCwHNaXu1a09Fs2ZgE7tmrPrtv/6B7r1n5Dnk9rMzEz0HzUj1w1XRoYOA0bPdInxDezBWfEAbI9JrepV0Oid2uzyG2XCHdL1yJHc5fvx2/5jWLL6e3a5bu1q2LBiTq7t3J0zvx+k8K5fv47Lly9D4OmJD3p/yOmxdK+6pXE1CG9O/UYNhqenJ06fPo0zZ84U/IYSICYmBv3790eZMmUwY8YMs9dUKhVOnDiB+fPno3z58hg7dix780lISaVUmmYytBzjjBBiG0rAELdh+ZTUUdO6tm/VFDMmDcf+n6MwYlAPdv2xk+ew/dcDubaftyQK127eYZdHD81+sn/l+m18sXQjtwWGY5rwOysegO0xAQBnPmQvzvGwJRb/3n2IgWNmsctBgf747cc18PY2nwWHa8UpHoPHzIa4zDtITpEDAF7GJqDrx+PhG/EOZOUaYeDoma8dAHj/4ZOo915PiMu8A2nZBmjUth9O/n2Rk7Lmx9ldjnLavHkzAOC9jq3hz+Fg6Xq9nh2PRcjhGDCM0NJh6Ny3OwBg9erVnB/PlWVlZWHRokWoU6cOfvrpJ2RlZb12+4yMDERFRaFWrVo4deqUg0pJiOtJSTFNYODv7+/kkhDi3igBQ9yGKzRTXzJvklm3lc+XbjAb1PDcxWtY+vVmdnn4gI8QtWw2BvTO7nO/ePUmXLh0g9Ny6vXmN3t8Pj+fLQvPFeIBFBwTV1BS4vG6WKQplOjafwJUKg0A02ewc9MylI0Ic3g5i0s87j14jB937cPHPTqxM071G/Ep9h36H6aMHoj+vT7Ajzv3YcKMJXm+X6tNR4/Bk3H1xh3MnDQcIwf3xPlL19H3E8eMVcVwRDystXu3aVycbv17cnqcrBwtIfkCx/y+A8YMBQD89ttvkMvlDjmmq9HpdOjevTtmzZplc2vUp0+fom3btjh58iQ3hSPExTEJmMDAQCeXhBD3VqwTML/++itGjhyJevXqwcvLCzwej/0h7sfyCbIz4ijzk2LMsOwWLQ/+e4pdew8DANRqDQaMnsnecJZ/IwIrF0wHAKxdMpO90dTr9RgweiY7+wsXLBMQXNzQuEI8gNfHxFWUlHjkFwuj0Yj+I2fg3oPH7GuRNarg6o1/sXzt5jx/nnE4XlJxicd3P+6GwWBA7w87AABi/n2Ak3//gzq1quKLmWPx9ZIZCAkOwLZf9ufZCkavN4DH40Eo9ETr5o3w3rsNAAABMsf273dEPKyRmJiIFy9eAADqNWnA6bEMhuxWP476fStVr4KyFcvBYDDg7NmzDjmmqxkzZgz27dtX8Ib50Ol06Nq1K+7du1fwxoQUI5mZmdDpTF3rxWKxk0tDiHsr1gmYhQsX4ptvvsHly5fZkwZxX5bN1J11wz9xZH+IRNkDbC5a+R2MRiOmzFmGB/89BQB4eHhg6/qFEItNU9FKpWJsXb+QLfO9B4/x6eerOCtjpkWTasvxKOzBVeIB5B8TV1GS4pFXLJ4+j8X+wyfNtrty/TamzVuR78/Dx884K2NxicfR/50Fn89Hg7q1AAD3/3sCACgbEcoes2xEGPR6PR49fZ7r/WKxCL/8sAKeAgEatOmDDj1HokzpUPz242q7l/V1HBEPa1y/fh0AULZiOfhKHHeDwfNw3KUYk1j666+/HHZMVxEdHY1NmzYVeT9paWkYNmyYQ7vdEuJsGo2G/T/NgkRI0RTrBAyPx0PFihXRq1cvNG/evOA3EJdmebHDd+BFa07BQQEY9nH24Iwxdx7g5z0H8c2WX9l1k0cPwLuN6pq9r0XT+pg0agC7HLXpZxw/eY6TMup05k2ruRhjwFXiAeQdk70HjjutPJZKUjzyisWefcecUpb8FJd4PHj0DIEBfvDxyX8Q15wtLSxlZmbii2UbkKHTYdOaz7F60ad4/jIe/UZ86tCbS0fEwxpXr14FALxVq5pDj2t04Gddt3F9AChx3WjUajVGjx5tt/2dPn0a27Zts9v+CHF1iYmJAACRSOS0czQhxYWg4E3c19mzZ9mpQOfPn0+Dp7k5y/7aAo76zbdoWh/GlFuv3WbNkhlYs8R81oS+H3UscN8rFkzDigXTilQ+a2RlmTfp5+KJsqPiARQ+Jjmd3L/FzqWyXnGKR2FjMXnMQE7KUxjFKR45W9ZUqvAGAODJM1P3LaPRiKfPY8Hn81G+bAQAIP3VzDve3l64dvMOLl2NQa3qlTG0v2mA1kWrvsOlqzF4GZuAiNKhnJTZkiPiYY1r164BAN6qVZ3zY3l4ZMfNkcmuBi0aAwD++ecfqNXqEvMke9euXXafTnrDhg0YONB1zmuEcIkZ/yUoKIiGciCkiIp1AoZJvpDiIT093WzZxwFTd7orRzTpp3hYj+LhWopLPCq8EYF/7/2H9PQMeHt7oXrVN9GscT2cPncZ8xavQ1KKHEnJqRjYpwukUlOXGp9wU8s87cvLKP9GBIRCT8TceYiv1nwPlUqDhMQUBAbIEBYaDADgBdRgt+dqtipX6YL0zz//AACqRdbg/FieOZ4gZ+psGwy2KMLLlEZo6TDEvYjFP//8gxYtWjjs2M70ww8/2H2fFy5cwL1791C5cmW775sQV6NQKADQFNSE2EOxTsCQ4sVyHB+h0DkX6e4gM9P8hkYgsP9XneJhPVvjYTQaodPpzKZH5fF4EAgE8PT0zPPpE8XDepbx4GIQVEfEo23Lxrj1731cvHITzRrXAwBs/2YJRk9bgOVRWyHg8/Fxz05Ys/izPN8fFOiPPVtXYf5X6/Hl8o3ge/DRrHE9LJk7EXw+nx3HhsfjwYPDLm2OOF9Z4+lT0xheFd96k/NjeXh4wMPDAwaDAVlZjkvAAECVmlUR9yIW9+7dKxEJGJ1Oh4sXuZla/Z9//qEETBEYDAZkZmbCYDDAaDSajZ3F5/MhEAjA5/OpxYWdGY3GV+eerDw/ew8PD/D5fPD5fHh4eIDH4yE1NRUATUFdWMxnzvzo9Xr2M2c+Y+Zvnv7eiz9KwLgZo9EIhUIBb29vCIVCt/iSGo1GpKenQ6FQICUlBS9fvkR8fDySkpKgUCigVqshl8uRkpKClJQUKJVKZGRkQKfTsaOuazQaJCcnm+3X05P+fPOjs+j+oFarcffuXSiVSsTFxSEpKQlqtRpqtRpKpRIqlQparRbp6enQarVQqVRQKpXQaDTsj06nQ0ZGBjIyMsxGw2dQPPJnGY9NmzZh7969UCqVUCqVSE9PR2ZmJtLT05GRkVFglwRPT0/4+PhAIpFAKpVCLBbj0aNHFttQPPJjGY/PPvsMc+fOhVAohFAohEAggI+PD8RiMXx9feHj4wNvb2/4+fnB398fUqkUUqkUAQEBCA0NhZ+fH8RiMWQyGQICAiAWi3N1QeIiHsMHdMfqjdvwS/QRNgETUToU+3asy/c9lt3HOrVrgU7tWuS57a1/7wMARg7uyWlCzzIex44dg4eHB2QyGSIiIhAcHAw/Pz8EBgbCz8/P7skgo9EIuVyOjAxT9ywfkciu+8+Pp9ATGekZhWoBYzQakZGeAZVCibRUORJi45GckITU5BSolSpo1Boo0xRIS5UjLUUOtUoNXYYOmZk6xL+IAwBMmTIFoaGhCAwMRFBQEAIDAyEWi9lZI92FXq9HYmIinj17huTkZLN6LT09Hf/995/NU05ba/LkyVi7di3EYjFEIhGkUimCg4PZ84BUKoVMJoOfnx9KlSqF0qVLw9/f360+X4PBwF4XKBQKyOVyKJVKqNVqJCYmIjk5GampqUhLS4NGo0F6ejo0Gg20Wi2USiUUCgXS09Oh0+mg0+nYeo5JvFjDw8MD3t7e8PHxgVAohK+vL0QiEUQiEcRiMfz8/NjPXCKRwM/PDxKJBBKJhP38mf+HhoY6LclbVMy1sFKpRGJiIlJSUqBWq5GamoqUlBTI5XKkpaWxn7tarYZKpYJKpYJarWY/+/T0dJsmKvDyym79eOXKFURGRsLPzw++vr7w9fVFQEAAwsLCEBwczK5jYsFcp/j7+0MikbjVZ5+VlYX4+Hj2c2b+rjUaDfu3n5CQgNjYWKSlpbHXyUwMtFqt2f2Mtfh8PoRCITw9PeHp6cn+jTPXHr6+vuy1n0QiwYwZMyByUL1F7MN9vgUEgOlJjkwmA2B6KslUOkyFw9w0yGQyyGQySKVSBAYGIiAggL2R8PLygpeXF3x8fODr68sue3p6sk/ljEYj9Ho9e6OdmZnJnsQ1Gg3UajVbuTIVMXPCUalUiI+PZ09KKSkpZk/y7UXopGbq7kCepjBb/uKLL/DFF19wekyKR/4s43H//n3cv3+/0PvLzMxEZmYmFAoFO22uJYpH/izjAYC9ObAXyyQBF/F4q3IF9O/1Abbu/B1fzBiLAH/7Th996swlhIeFYMncSXbdryXLeBw/fhzHj+c9iLZAIEB4eDhCQkLYGzCRSMQmaKRSKby8vODr6wuJRAKRSMTWd0xCjanvhEIhvLy8YDAYUKpUKfYYHSKbQxYgg0gshsRPAm9vb4jEIkj8/CDxk0IsFUMW4A8/fxl8fE3JOaGXFzy9hKabRF8fCL28TMk8T4Hp6aaHB/CqXs3KzEJmZiaE3l7ISM/A1fOX8OzRU2g1GqRr06FRqU1JFI0WqjQF1Co1NCo1khOSkJyYjKS4BKSlyotcr6pUKnTp0iXXerFYjNDQUIjFYnh7e0MsFrM//v7+8Pf3h0gkgkQiYROSzPWEt7c3PD09zW6WBQIB+4QXgNkT4KysLPamnLmeUCqV7E0983AgIyODXZ+UlIS0tDT2wQ3TNcIZEhISkJCQYNN7+Hw+fH19ERgYiLCwMJQqVYq9mc2ZQLC8iWWu4ZiEMPO5Mp9tzs+X+WyzsrLY+iIzMxNardbsplyr1UIulyM1NZVNrigUCvYG/8WLF0hISHD6jE8Gg4F9GFRUHh4e8Pf3ZxPmTDLdz88PwcHBCA4Ohr+/P4KCgtibXW9vb3h7e7Pnjpyffc7Pn2lJYjQazT5/5iY85/Uz81kz1845k4ZMEpGJVVpaGpvkcgYmOQ2YkkA3btwo9L74fD6bOBOLxQgICGDvY5jEApM0Y5LCUqmUfV0kErGJCSYWzOfPxECv17P3LszfPfMAMS0tjf2ctVotFAoFUlNTkZqaCrlcjvj4eLx8+RJxcXG5Hvw6il6vh1arhVarBYACy/HZZ3m3ciUui0cJGDeTc1wB5qmdXC53XoFswOPxIJVKERYWhvDwcAQGBkImk7EnXOYkLJVK2SfRzI9IJMLw4cNx4cIFdn/0hD9/qXLzC1I+n89eyAUHByMkJIS9GWEuMJiLOuZGhbl5EYlE7IV0zguQ3r1749y57FmcKB75s4zHhAkT0LJlS0gkEvYmx9PT0ywZKhQK2ea/ANjmwsyTw5wJUJVKhWnTpuHOnTvsMSge+bOMx/fff4/WrVuzSRimNRLz1JBpHcZcACuVSqSlpSEpKQnx8fFQKBRQqVTsTQyQe2BVruKxJWohtkQt5GTfY4f3xdjhfTnZd06W8ejQoQMCAwORnJyM58+fsxfGKpUKWVlZePr0KdtdiAvKNAWUeSTpuDJ9yIRCv5fH40EslSA4NATBoSGQBfpD6ieFj0gEX6kYMn8Z/Pxl8JVKTDcsQk9Eb9+N/T//hsDAQJQpU4a92Wb+dlUqFR48eGCvX88hPDw8EBoaytZtzM2at7c3NBoNfvvtN06O26tXL/Tp04d9OJWWloaEhATI5XK2ZQLT+pd5kq7X66FQKKBQKHK1XHRlPB6PfRLPJIj8/f3ZhIVMJmMTRMy1A5M8YlptW15H5KznciYyciaR9Ho99Ho9e8Os0+nMWiMw516mZY5SqWTPF8y5mnlNLjclLpOTk5GcnIyHDx86+2O1maenJyQSCdtyzdfXFzKZjG0hyLQ0Yb4DOa/nvLy82GSSp6en2WfPXGswCQwmBsyD2EWLFuHbb79Fjx49MGzYMKSlpbEJouTkZMTGxrIt0JgfJpmnUCjY5Jler2fj5A4EAgH8/f3Z5A/z9x0QEIDg4GAEBQWhdOnSkMlkbFI/50Nxr1fJeKFQyHbtyvkv0zWJ+dyZpF3OBFLO1mdM8pS57lAqldT6xQ3RFbqbkUqlyMjIYDOjTJNDpjJnbsqYSj8tLY19ksTcSDBZYOZJSEZGxmufpPH5fLYJHNPMlrlhz3mSZ5rGicViBAcHsxdDISEh7E1+UZqOWzbfE/vSCSc/ao3WbPnQoUNo06aNXY+R84kIQPF4Hct4dOzY0e7xmDdvntkyxSN/lvEoU6YMypYta5d96/V6aDQaNGrUCDExMex6ikf+LOMxadKkPL8fGRkZSEhIwPPnz82ahDM3vklJSWwXVuYJskajYes7JqGWs0m4Xq/PdZyf/xcNg8EAlUIFlVKJDG061Co1FPI00zqFAvIUORSppi4XGdpX3SsydMjQmrpfZGboCqxXmYvuoFLB8AuQmW6QfLzhK/aFr1gMH18RxBIxfKViiHx9ERAUgKBSIQgIDkRgSBDEEtM2ttarF06dBQD069cPa9asYddnZWVBrVazLVhzPo1nLvRTUlLYriYKhQLJyclsSwqmiwOTwNRqtVZ1c2C6/DHXExKJhH0gIxaL2ZsY5qaTeXjDtAD29/dHQEBAvl0bUlJSOEvAtG7dOs9WRPlhrtuY7juxsbFISEgw6y7CJHktb2KZazgmCWENHo9n1lqAaanEXM/5+PiwnyOTWGFaGwQGBiI8PBzh4eHsDTyXY0E5gsFgQEJCAtvlnXmIyfwkJCQgKSkJKSkp7PmE+btmuu/Y2vLMw8ODfbjCXD8z3dWYluo5W3gwrc6Yz5xpAeLv749SpUo5bQwWZqy0qlWrom3btja/X6fTsecKjUZjdk5h7mOYIQmYZENKSgqbbGBiodFo2MREQTw8PMySft7e3uxnzTxwZM43MpmMbfkUERHB3sMEBgZyMk4cKdGMlIBxMzwej82k+vn5ITTUPtOEMgOh5bwYZRIvrlLhMgOAMfxlUpv3YTQaUb91b1y6GgNvby/8d+UwO9uHK9Bq01G+TjvEJySjTOlQ3L14AD4+ts+eIk8zf7Lg52ffrgkAxcMWFA/7cId48Pl8SCSSXE3lCxMPW9y+8xBjP12IsxevQSoRo99HHbH088l5zijUqutQXL91FwqlCiFBgejWqRWWfzEVXl7CPPbMPWvj4eXlhTJlyqBMmTJ2OzbzhDcrK4ud3SOiXFkEhgQVed8GgwFZmZnQ67NbQ/H5HhC8qld7vtsJt67cwBdRX6FFh9ZFPp61cg6unJNAIGBvwu0xsCzTDYN5mp7zuMzTX0cMOBkQEICKFSty0trB1kGMfXx8ULp0aQAo0mec1wCqOQf0ZAbzdJXrN1fBtJQqyrWzZQsRywFsmVY8xS0GTPenwtaXQqEQAQEB9iwS280rrwGcXen+hRBLxfovc8OGDZg6dSqmTp2Ko0ePmr3GrJ86dWquG5eSiMnQ5+xT7+Xl5VInL8vmilKJ2OZ9bNu1D5eump5KD+vfPdfN5aWrt9B76FSEV2sJr9A6KFWlGTr3HYvjJ8/ltTur7T1wHF0/Ho/wai0hLFUbgRWboGaTbhg5+XPce/CY3c7HxxtTxwwCADx7EYfl67bYfCxTf2Pzp2NSqf1v/twxHo+fvsCEzxajZpNukJStD0FwJKRlGyDy3Q8xZfYyPH81OCWD4kHxKCx7xMNaWVlZ6PLxOJy9eA0LZo5Dq2YNsHrjNixa+V2e29eqVhmL50zE+mWzIRGLsO67Hdi0bQ9n5XsdR8UjP3w+n33iHB4eDgB4+t9ju+zbw8MDQi8v+Ih82B9hjnrVW+QDANBatADimkatBgDOm60zrS+8vb3ZJ//M03+mC4qjBqNt166d3fdZsWJFVKxY0e77tUbOJ/tMlwjm82W6DLvS9VtxwsxIKBQKc332ObupFLcYMPdKXDxAKiyBQGD2HXDV+xdCLBXrv85du3ZhxYoVWLFihdlYFQDY9StWrHDaoFbEegaDochP+PV6PeYujmKXJ4782Oz1TT/uRoM2fbFr72HExiVCp8tEQmIK9h8+iTYfDse8xfnPLJIftVqDzn3H4sMBE/H7wROIjUtEZmYWUlLTcOvf+/hmy6+4eOWm2XtGDu4F0asL86Vrf0CawrZ+sip17kHqfH19bS7767hjPC5dvYVaTT/E199ux61/70Ol0pj6IqvUuBFzDyvXb0XNph/i9h3zp6QUDxOKh/XsEQ9bHDlxBg/+e4qObZph6rjB+HbVfPD5fER9vzPP7Vct+hTdO7fBe80a4I0ypqSDs2ZlcUQ8rFW7dm0AwJ0btx1yPNGr31OjKvrAoraIex4LAGxLjJJgxIgRdt/n+PHj3Wo2I0KKgnmo4EoJGELcVbFOwJDiQy6X5+qrHxxoWz/YA0dO4cmzlwCAxvVro2L57DEfrt28g1FTF7ADZzasF4kFs8ahQ+t32W2+WLYRfxw9ZdMxh4ybg/2HTwIwZeq7vP8eZk4eji9njsPY4X3xbqO6EFl0oRCLRejcvgUAQKXSYOvPv9t0zOSU3AnFwMBAm/ZREHeMx7wlUVCqTE9+eTwe+vf6AAtmjUPHts2yf680BZav22z2PooHxcNW9oiHLe4/NA1IWzYiDAAgkfjCXyZFYlJKvgmqyu90RMW3O+DIiTPo16MjhvXvzln5XscR8bBWZGQkAODOTcckYMSvWkWpHTwYZUJsPICSlYCpVasWPvzwQ7vtLywsDEOGDLHb/ghxdSqVCgDYrpqEkMIr1mPAnDx50tlFIHaS10xPflLbKoEftu9l/9/9A/MBHhev+o4dWK38GxE4dWALhELT2AlNO/THmQtXAQBfLvsGHds2t+p4J/++iF+ijwAw3TT+7/cfUK9ODave+1Hnttj52yEAwPc//YbxIz4u4B3Z0tMzcq3z8fGx+v3WcMd4PHz8nP3/+23exY8bFrPLFeq0x6MnptcTk3N3SaR4UDxsYY94FFVB08b+9uNqxMUnYXnUFuz87TC6dWyN7p3tOzC0NRwRD2sxCZj7MXcdcjy2C5I2vYAt7ev5Y1PC7o033nDocZ1tw4YNOH36NBITE4u8r61bt0Is5q5bISGuhmkB46wWioQUJ9QChriFpKQks2UvLyHEYuv7r+v1epz8+x92udE7kWav/XHsL3a5U7tm7M0lAHzYKXtwxAuXbyAhMdmqY27eEc3+/713G2Drzn2oVO99eIe9jbI1W2Pk5M/x4mV8nu/NWb6bt+8jMSnFqmMCQLrF7EReXl52bybtjvGoVqUC+/8bMfdw6/Z96HSZOPn3RcTGZ1+Qt2/VNNd7KR4UD1sUNR62qlTR1FrpyXNTC6Y0hRLyNCWCgwIglYiRnp6Ra5yVZo3roWe39vhswlDo9Xps+Tmas/K9jiPiYa2qVasCAP6798Cq2XuKimkBo3LglNcpiclIffV9scdAu+4kJCQE0dHRRb6BXLRokd1nsSPE1TEzX3p5eTm5JIS4P0rAELegfjVoIEPsK7LpIv3m7ftQKFXscp1aVdn///f4OdTq7EEQK7xhPsNGhXIRZss3Yu5ZdcyzF6+x/9936H9Y990OPPjvKTIydHj2Ig7fbPkVdVr0wN37j3K9NzwsBCHBptHijUaj2b4KorV4oszF02R3jMfCWeMRWso0s8mzF3Go2bQbvELroGXnIUhPz4BE7Iu500Zi1JBeud5L8aB42KKo8bBVu/eaoGL5Mjh47DRWrNuCTybOh8FgwOghvfDk2Uv4hNfFG5GmG8bDx//GgFEz8M2WX7Bx8y7MWWQauyeyRhUApoGReQE1EPqWdS2ZisoR8bDWm2++CT6fD0VqGh78a93fcVGI/UytotQqdQFb2s+/102DbJcvX75EPslu3Lgxjh07xg64bAs+n4+1a9dixowZHJSMENem1ZquA5x5jiakuKAEDHELlgNaSsS2XTi+iM1uaSIR+8LbOzuDn5wiN9tWKjHft+WxkvLoEpGXnE/xAaB0WCnMnDwcg/t2ZUdnT0xKweCxs/N8f0hQ9jgIL2ITrDomALMbaYCb/rruGI+qVSri8olf0KBurTxfb96kHj78oHW+I+dTPEwoHgUrajxsJRAIEL3tazSsVwuzFn6NP/+6gPGf9MPMyZ/k2jYoUIabt+9j6tzlmDRrKTJ0Onw2cSjmTR8FIHuKYgHfMT2UHREPa4lEInTu3BkAsHvzz9wf71UCRG3xGXDpaPQfAIBWrVo57JiuplGjRrh16xYGDhxo9UwpdevWxaVLlzB27FiOS0eIa0pPN3WV9Pb2LmBLQkhBivUYMKT4ePnypdlyuMX0uAWRp2UPcmg5HaxlU/OClq19kq3TZZotH/xlPWpVNz1l9pf5YeX6rQCAc/9cx6Mnz1H+DfOWBDlvdOU2NFFPU5hfzMtkMqvfay13jEfMvw/QsfdodqDZDzu1RmSNKjh78RqOnDiDA0dO4c+/LuDonm/RtOHbud5P8bBumeJR9HgURo1qlXBy/5Zc68uVLQ1jyi12uV6dGrh6ane++7n17wMAwPgR/exexrw4Ih62GDZsGPbu3YuDv+7DtMWzIRBwd5nkH2hqxZWckFTAlvZhMBjw5/6jAIBevXK3LCtJ/P39sWXLFsyfPx8bN27EiRMncPnyZbOxk8qUKYPmzZtj4MCBaNmyJfh8vhNLTIhzMePAeXp6FrAlIaQg1AKGuIWEBPMn3MFBATa9X+aX/VTV8olrYIDMbFlpMSWo5fYB/tZNwSfzy552NsDfj02+AKan+zk9fPQs1/sVyuxm6Tn3VRDL8nLRzNwd4zFwzEz2Zn9Qn67Y8+NqzJ0+Cod3f4OW79YHYBoM87PPV+X5foqHCcWjYEWNhzOdOvMPImtUweTRAxxyPEfEwxZt2rRBYGAgkhOTcPbP05weKzg0BACQbOW4SUV18/J1pCQlQywWo1mzZgW/oQQoV64clixZgosXL6JTp04AgHnz5kEul+Pp06fYtm0bWrduTckXUqIZjUbodKZxxCgBQ0jRUQKGuAXLJ8oR4aVsen/4qwtdAFCq1GYzb1QsXwa+vtl9Wh8+Nk+GWCZHalW3buDCGlXfzPc1y1YCObt8MBKSsi/KS4eF5Ho9P4lJ5t0fgoPt//Td3eKRplDi8rXsqWXr1zWfjape7ers/6/dupPnPigeJhSPghU1Hs60/MtpuPbXHk5bfuTkiHjYwtPTE7179wYAHP7tAKfHCgg2daNLii/6rDzWOLx7PwCgY8eOEAqFDjmmO2FmealSpQr8/KxLJBNSEhiNRra1KyVgCCk6SsAQt5CSYj7LSYDMtoujmtUqmc1Ccu1m9k0dn89Hh1bvssv7D59kZwwxGo3Yve8Y+1r9t2uiVEgQuzxozCzwAmqAF1ADLT4YZHbMTjmm401JTcOt2/fZ5VNnsmec8fQUoFY185vWl7EJSEg0/c48Hg+N69e2+ndVWgzoyMWFpLvFQ683n5L30tUYs+XL17OTAT559G+meFA8bFHUeBTG7TsP8V6XIfAOexshlZth0syvkJmZmee25y5ew7vvD4CkbH12W6bL5L93H8IjsCbmLV7HeZkBx8TDVj179gQAHN93GHIrxzQqDCYBk5bC3TEYWVlZOPDL7wCAfv0c073M3ahUptZYNL00Ieb0ej37f2oNRkjRUQKGuIW4uDizZWb2FGsJBAI0a1SXXT5/6YbZ6zMmDWMrlSfPXqLFB4OxcMU36NBjJC5eucluN2tK7kEt8zPk424IyzH2Q4eeIzF74dcYNn4uVm3Yxq4f1KcrpFLzC76cs7rUrFbJpi4Mao3WbJmLi0l3i0eAvx9qVK3ELm/eEY1eQ6bgy2Ub8X7PUTjx1wX2tbYtG+d6P8WD4mGLosbDVllZWejy8TicvXgNC2aOQ6tmDbB64zYsWvldrm3jE5LQoeco3Ii5hyVzJ6F543pYvXEbFq74BoBpcOT2rZpixfqtNo2tU1iOiIetmjRpgho1akClUGLl3MWcHYeZhjorKwvp2nTOjgMA2zdsQXJCIoKDg9G+fXtOj+WuaJYXQvJGCRhC7IsSMMQtJCWZD1IYHOhv8z6Gfvwh+/89+4+ZvfZ2ZDVELZvFdg06f+k6Zi9ciyMnzrDbzJw8HJ07tLT6eDI/KX79YQU7qOnzl/FYuOJbfP/Tb+xAf43eicTKBdNzvXf3vqN5ltsaljc0IpEony0Lzx3jEbVsFkQi04W10WjEL9FHMHfxOhw6nj3OQ9mIMCyeOzHXeykeFA9b2CMetjhy4gwe/PcUHds0w9Rxg/Htqvng8/mI+n5nrm3PXryGNIUSLd+tjzHD+uDLmaZZXdZtyp71p0eXtlCrtdix+yCn5QYcEw9b8fl8bNiwAQCwe8tOXL94hZPjiHLMjqVSKF+zZdEkxiVg3cKVAICFCxdSF4J8ZGSYul56eeXuEkxISZZzcGprZw4jhOSPvkXELcTGxpotF+aJcpf330PZiDAAwJkLV/HoyXOz10cM6onzR3egR5d2CC0VBE9PAYIC/dGxbTMc2f0NFs6eYPMxmzR8GzfP7MXoob1RoVwEvLyEEItFqP92Taxe9ClO7t9i1vUDAJRKNfYdPgkAEItFGNini03HtBzUUiq1foBSa7ljPJo1roebf/+GcZ/0RY2qleDr6wM+nw+pRIx6dapj3vRRuH56D1smBsXDhOJhPXvEwxb3Hz4FAPazkkh84S+TIjEpBWkWN/ZhpUyt8m7E3MP9h09w8Jgp4ZWSmoaU1DQAQJMGdQDALMHGFUfEozCaNm2KQYMGAQDmj59p9gTYXjw8PCB5NYC0Qp5m9/0z1ny+DGqlCu+88w6GDh3K2XHcHTPIKI2PQ4i5nLMdWjvTISEkfzQNNXF5er2e7ZvNKMyYCnw+H1/OHIuBo2fBaDRi5fofsfarmWbb1K9bE79sXmH1PrdELcSWqIWv3aZsRBiils22ep8bN++C9lVz9E/HD4WfVFLAO8xZTutq7xsad45HhXJl8PWSmfm+nheKRzaKR8HsFY+iyvnEMqeG70RizLA+iNr0Myq/0xEikQ88PQXIzMxiL7KZQYPzmp3N3riOR1EsXboU0dHRuHvzNg7s3Isu/T6y+zGCSgVDmaZA/Ms4VKiS/8DthXXj0jXs3fYLAGDNmjX09Po1NBrTDG+u0AqLEEJI8UU1MXFLHh6Fy8D379UZ9eqYZljZtG0PYuMcM/uEtbTadKxYvxUAUKZ0KKaMGWjzPpJT5GbLAQHcT4FL8cgfxcN+Slo8rFWpYlkAwJPnptmX0hRKyNOUCA4KgFQiRnp6BjtwMgCsWzoLT28cw5lD23D28DZkZelRrmxpdspx5iY951NPrjgjHtYKDg7Gp59+CgBYMWcx4l7EFvAO24WEmpJdyQlJBWxpu6ysLHw50ZRQ7d+/Pxo1amT3YxQnlIAhJG85E7f5JfcJIdajFjDE5eU1k0dh+7DzeDz88+euohaJMz4+3oi7c6pI+0i0mLUjMDCwSPuzRPGwDcXDfkpaPKzV7r0mqFi+DA4eO40V67bg4pWbMBgMGD2kF548e4nytduhVEgg+9nNXvg1ypYOQ5Zej/Xf74TRaMScqSPY/T17YRpEuEK5CE7LDXAfj6KaMGECtm3bhtu3b2Nkt4HYdmw3223IHvwCZQCA1OSU129oI6PRiC8nzUbM1Zvw8/PDsmXL7Lr/4ig93dSyzjuPmdcIKclyDrzLRXdMQkoaagFDXJ5AIMjVbNpy3ABiEhuXiJexCWbrypYta9djUDysR/FwLcU1HgKBANHbvkbDerUwa+HX+POvCxj/ST/MnJz3rFSPn77AtHkrMHHmEgDA1vULMSTHYMbMLFN5zUBlT46IR1H5+Pjg4MGDCA0Nxb2YO5jYbyR0rwZrtQfpq2SO2s5/I+sWrsSvP+wAj8fDli1bUKpUKbvuv7jR6/XsjSUNwkuIOYEg+3l9VlaWE0tCSPFACRji8gQCAcLDw83WvbC4aCcmf583n61DIpGgevXqdj0GxcN6FA/XUpzjUaNaJZzcvwXpsVeQ9OBvrFkyA0KhJ8qVLQ1jyi2zlkM/ffMV0p6chy7+Gm6djcaA3uYDGf8SfRgikQ/69ejEaZkdEQ97eOONN3DgwAGIRCKc+9/fmDxgTJ4tnQrD51V3F63FbFBF8d3yKGxYvAYAEBUVha5du9pt38VVznjmvNkkhJi6IDHfiww7JqAJKakoAUPcQlCQ+SwiluMGEJPrMXfNlhs1amTWdNReKB7WoXi4FopHwe7c+w+H/zyDyaMGIMCf28GDHRUPe6hbty727dsHLy8vnDhwFBP7jbTLzEViP9Mg0vbYl9FoxNovV2DVvK8AAAsWLMCoUaOKvN+SIOe4Fq76N0iIMzEtwygBQ0jRUQKGuAXL5tNxHAxYWBxcuf6v2XJkZCQnx6F4WIfi4VooHgV7q3IF6JNu4MtZ4zg/lqPiYS+tWrXC3r17IRQK8b8/jqFrg3a4dOZCkfbp92qGrKImYBTyNEwbNA4blphavixZsgSzZs0q0j5LKpopipDcmLGRmLGSCCGFR7UMcQuhoaFmy9dv3c1ny5IrNi4RR/931mxdrVq1ODkWxaNgFA/XQvFwLY6Mhz116NABp06dQsWKFRH3/CUGte+FzWu+LfSMUX7+MgCA3GIwYltcv3gFHzV5Hwd374NAIEBUVBQ7exOxHc3yQkhuQqEQAKDT6QrYkhBSEErAELfQoEEDs+U/jv5lNq0qAbbu/N1sdHqRSIROnbgZw4HiUTCKh2uheLgWR8bD3ho2bIhr166hf//+MBgMWDZzAcb2HIrUJNtnMvKVmrogadQam9+bmZmJ9YtX4+PW3fH88TOUL18ef//9N0aPHm3zvko6mmaXkNfz9fUFAKhUNMg/IUVFCRjiFrp27Qoej8cuK1VqnPiraE2/ixODwYAtP/9utq53796QyWScHI/i8XoUD9dC8XAtjo4HF8RiMbZu3Yp169bBy8sL/zt4HK2rNcbCqXPx7NETq/fDPlW2IUFnMBhw6vAJ9G3ZFesWrIRer0efPn1w9erVXMk/Yh0mDgA94SckL4GBgQCAlBTbE82EEHOUgCFuISwsDA0bNjRbt3vfUSeVxvWs/34n7t5/ZLZu8ODBnB2P4vF6FA/XQvFwLY6OB1d4PB7GjBmD8+fPo3bt2tCqNdi+YQs61GqOif1G4PrFKwXuw1PoCQDItOKmPy1Vji1ff4f3a7fAqO6DEHP1Jvz9/bF9+3Zs374dfn7cDppcnHl4eLCtYOw1wxUhxUlwcDAAID4+3sklIcT9UQKGuI1u3bqZLf+4az/uPXjsnMK4kIePnmLavBVm6ypXrowmTZpwelyKR94oHq6F4uFanBUPLtWuXRtXrlzBsWPH0K5dOxgMBhyNPoQ+Lbuif9uPsHbBCpw5/lee3YyYqV3z6/YiT5HjzPG/MGvkVLSsVB9LZ3yJpw8fQyqVYvLkyYiJiUHfvn3NWlyRwqExLgjJH9MCJjW18ONVEUJMKAFD3Ebv3r3ZafAAICsrC1PmLHNiiZxPqVTj4xEzkJ5uPi3gunXrOL8gp3jkRvFwLRQP1+LMeHCNx+OhdevWOHz4MG7evIlBgwZBIBDg8pmL2LB4DYZ3+RiNImqhf9uPsObzZTj2+yFcOHUWTx8+BgBo1RpcOfcPDv92AKvnL8Wo7oPQ6q1GaFymFoZ3+Rh7t/2CdG06atWqhY0bN+LFixdYsWIFwsLCnPuLFyPMGBdqtdrJJSHE9UilUgCAQqFwckkIcX+UgCFuo0yZMpg4caLZugNHTiH6jz+dUyAnS06R472uQ3D+0nWz9aNHj0abNm04Pz7FwxzFw7VQPFyLs+PhSDVq1MDmzZtx//59rF+/Hv3790eZMmWQqdPh8pmL+GbpWkzoOwKD3++NOWOmAwBin7/Ex627Y3L/0fh22TqcOnwCsc9eAAAqVvw/e/cd30T9xgH8k6Ztmp3uQdkCskH2kCEgIFuRKSBLZC9BGSIqSzZCGS5AFEFAKiJbfgwBQWTJHrLpTrNXR35/hLs2aUuTNrN93q9XX3CXy923eZr73j33HZUxZMgQnDp1CpcuXcKoUaMgEok8+SuWSGKxZUBktVrt4ZIQ4n0oQUmI83DMRZ07kRAPUKlUqFq1qlUf1KAgHvZtX4e2rzb2YMnc69if5zBqymd5ujTExMTgxo0b7JMKV6N4WFA8vAvFw7t4Szw8yWw24+7duzh+/DiOHTuG//77D+np6VCpVMjIyACPxwOPx0NoaCjq1q2LevXqoXbt2qhdu7ZPDU7sy2rWrInr16/jjz/+wGuvvebp4hDiVRYvXowPP/wQ77zzDrZs2eLp4hDi06gFDPEpEokECxcutFpnMBjRtf9Y/HH8Lw+Vyj3MZjOu37yHtwZPQtvuw/LczISFhWH37t1uvZmheFA8vAXFw7t4Yzw8icPhoEqVKhgxYgR++OEHnD59Gjdu3MDTp0+RnJyMx48f4+7duzh79iy++uorjBkzBq+++iolX9xIIBAAAHQ6x6cEJ6Ski4iIAACkpaV5uCSE+D5qAUN8TnZ2NgYPHowff/zRaj2Hw8F7Q3pj/uyJCA2ReaZwTqZQqnDrzgP8dvAYdu45nGfmEEbZsmVx5MgRVK1a1c0lpHjkh+LhHhQP7+IL8SCkIK1bt8aJEyewfft29OnTx9PFIcSr7NixA3369MGrr76KEydOeLo4hPg0SsAQn5SZmYl+/fph165deV4LCZbio4nDMaB3F5SJifRA6ayZzWZotXpodTqoNToolCokp8qRJldAqdLAaDTBYDRCbzBCo9FBoVLjvwdPcOvufSSnyAvd/8svv4z9+/ejQoUKrv9lCkDxyEHxcAzFg+JBiDfo0qUL9u3bh2+//RbDhg3zdHEI8Sp79+5Ft27d0LBhQ/z999+eLg4hPo0SMMRnZWRkYODAgdixY0eB2zRrVBc9u7RDkwa1Ual8LGKiI8Dlcgvdt9lsRkZGJvQGA3Q6A9QaLbQ6PbQ6PeTpSiQkpUCp0kCr1UGnN0Cr00OhVEOt0SJdoYJKrYFOb4DeYIRCqYZOp3fmrw7A0oT/s88+w4gRIxAQEOD0/TuK4kHxoHgUjOLhXfEgxFb//v2xbds2rFixIs8A2oSUdv/73//w2muv4eWXX8aNGzc8XRxCfJq/pwtASFEFBARg69ateOWVV/D555/n22/7zN+Xcebvy7ne44+YqAiEhsgQ4O8PDoeDjMwMmEwZlie6Wh3UGi30eiOys7Pd+evYLTo6Gv369cPHH3+M4OBgTxeHRfGgeHgDiod38dZ4EGKLxoAhpGDMeFQKhcKj5SCkJKAWMKREePToET744IMXPl32VRwOB5UqVULPnj3Ru3dvNG7cGH5+3j1+NsXDu1A8vAvFgxDvM3nyZKxcuRLTp0/HF1984eniEOJV7t+/j0qVKkEgENBU1IQUEyVgSIly6tQpbNiwAb/++itUKpWni5Mvf39/hIeHIzw8HDKZDHw+HzweD0FBQRCLxRCJRChTpgyqVq2KatWqoVKlSggMDPR0sYuE4uFdKB7eheJBiPeYO3cuPv30U4wePRpr1671dHEI8SpyuRyhoaEAAJPJRF1JCSkGSsCQEsloNOLo0aP49ddfcfLkSdy/fx96ffHGNfD394dQKIRYLEZ0dDRCQ0MhFAohFAohEAgglUohkUggk8nYGxU+nw+JRILIyEiIxWKIxWIEBQWBw+E46Tf1DRQP70Lx8C4UD0I8b+nSpZg2bRreeecdbNmyxdPFIcSrZGRksMn1tLQ0hISEeLhEhPguSsCQUsFsNiM5ORkPHz7EkydPoFarkZGRAbPZjMDAQAQGBoLH40EkEkEikYDP5yMoKAgCgQB8Ph9isRg8Hs/Tv0aJQfHwLhQP70LxIMT9Nm3ahKFDh6JDhw44dOiQp4tDiNcJCAhAZmYmHj9+jNjYWE8XhxCfRQkYQgghhBBSqh08eBCdOnVC3bp1cenSJU8XhxCvI5PJoFQqcevWLVStWtXTxSHEZ9HIeIQQQgghpFSLiIgAACQmJnq4JIR4J5FIBABeO2YZIb6CEjCEEEIIIaRUCw8PB2AZ34IQkhfzHUlKSvJwSQjxbX4AaHQ9QgghhBBSakkkEgBAZmZmsQfBJqQkioyMBACkpqZ6uCSE+DZqAUMIIYQQQko1pnsFQF0sCMkP8x3RaDQeLgkhvs0PAA3CSwghhBBCSi0/Pz9IpVIAQHp6uodLQ4j3EQqFAACtVuvhkhDi26gFDCGEEEIIKfWioqIAAE+fPvVwSQjxPmKxGACgVqs9XBJCfBslYAghhBBCSKkXExMDgAYZJSQ/TBckagFDSPFQAoYQQgghhJR6oaGhAGiQUULyExQUBAA0SDUhxUQJGEIIIYQQUurJZDIANAgvIfnh8/kAKAFDSHFRAoYQQgghhJR6zCCjOp3OwyUhxPswLWAMBoOHS0KIb6MEDCGEEEIIKfVoFiRCCkbTUBPiHJSAIYQQQgghpV5wcDAASsAQkh+JRAKAuugRUlyUgCGEEEIIIaVeSEgIACAtLc3DJSHE+9AYMIQ4ByVgCCGEEEJIqcc84acuFoTkJRAIANAYSYQUFyVgCCGEEEJIqcfj8QAARqPRwyUhxPtQAoYQ56AEDCGEEEIIKfUCAwMBACaTycMlIcT70PeDEOegBAwhhBBCCCn1AgICAAAZGRkeLgkh3odaiBHiHP6eLgAh7qTVanH9+nU8ffoUcrkcCoUC6enpaNmyJTp27Ojp4pU6FA/vQvHwLhQPQtyLnvATUrCgoCAAgMFg8HBJfA/V5yQ3SsCQEu3atWs4cOAAzp8/j0uXLuHWrVswm835brty5UqIRCLIZDKIRCIIBAKIxWIEBwdDKpVCLBaDy+W6+TcoWSge3oXi4V0oHoR4Fo1xQUjBqIWY/ag+Jy/CMRf010CIj0pOTsaWLVvw/fff48qVK07bL4fDQXBwMCQSCYRCIfh8PgIDAxEYGAiRSAQ+n4+goCAEBgaCy+XCz8/Swy87OxuZmZkwmUzIyMiAwWCAWq2GTqeDVquFXq9nX2OadUokEkRERCAiIgJlypRBbGwsGjRogBYtWrCzNPgKiod3oXh4F4oHId7j3r17eOmllyAUCmkmJEJsPHv2DGXKlIGfnx+ysrI8XRyvQ/U5sRclYEiJkZ6ejhkzZuC7774rsdl5LpeLJk2aoGPHjnj//fcRERHh6SIViOLhXSge3oXiQYj3yX2DmZmZCQ6H4+kiEeI1kpOTERkZCQDIyspib/RLO6rPiaMoAUNKhN27d2P06NFISkoqdFsOh1NgM0BfIhKJMHnyZEybNg1isdjTxbFC8aB4eBrFw7t4czwIYaSlpSEsLAyApZuFvz/11CeEIZfLERoaCsAyThLTJak0o/qc6vOioAQM8WnZ2dmYMGEC4uLiCtymTHQk3ujwKl6pWx31a1dH7RpVcOL0Pzh87AwMRiP0egPUGh1S5enQaHVQKNXQ6vTQ641QqTXIzs5242/kuIiICKxYsQIDBgzwdFEoHqB4eBuKh3fxpngQYkupVEImkwEA9Ho9O+goIQRQKBQIDg4GYBmIl5kVqTSi+pzq8+KgBAzxadOmTcPSpUvzrA8K4uHtHq/j3f490bpFwyIPXpWdnQ2VWgO1Wot0pQqpaQpotDpodXoYjSYYTSYYjSZotDoYDJZlkykDWdlZyMqynDi5XD9w/bjg8QLB5fohiMeDRCyEgM+HQBAEAT8IgYEB8Of6g8ezPE2QpyuRmqZAQlIKniWm4NrNuzh34V9kZGQWWNbp06dj/vz5Hn1iR/HIQfGgeNiieOTwhngQYkutVrPjHGi1WnZQXkIIoFKpIJVKAVgGqubz+R4ukedQfZ6D6nPHUQKG+KwVK1ZgypQpedZ3eb0V1i79GOVioz1QKtfRanU4eeYCfvplH374eW++mfGePXti69atHqkUKR4UD0+ieHgXb48HIfnRaDRsk3qNRgOhUOjhEhHiPXJ/P0pzgrIk1efMWD4vGu+K6nPnowQM8UmHDx9Gx44drfpS+vv7Y8PyORg6sFeJHzjv+s17+OizFfjtwLE8r3Xv3h3x8fFu/QwoHhQPb0Lx8C7eFg9CCqLVaiESiQBQAoYQW5SgLFn1eUJiCnq/Oxl37z9C04Z10axRXXRq1xL1ar9c4HuoPncOSsAQn5OZmYlatWrh1q1bVus3rpmHdwf09EyhPOTrzTsxdvq8PE0D169fj1GjRrmlDBSPHBQP70Lx8C7eEA9CGCaTCZcuXcJff/2Fx48fQ6FQICUlBb/++iuA0v2En5D8lPYueiWpPj9z7hJ6D52CZwnJVus/mjQcC+dMLvT9VJ8XDyVgiM/ZtGkThg4darVu3qzxmDW1dH7hT5w+j+4DxkOpUrPrxGIxrl+/jtjYWJcfn+JhjeLhXSge3sXT8SCll9FoxNmzZ3H8+HEcPXoUf/31FwwGQ4HbR0REoGrVqujUqRPatGmDJk2a0BgHpFQr7YNUl4T63Gw244tV32L2/NXIysrK8/qOjcvRu8frdu2L6vOiowQM8SlZWVmoXbs2bty4wa5rUK8Gzh3ZBj8/Pw+WzLP2Hz6JN/qOtlrXo0cPxMfHu/S4FI/8UTy8C8XDu3gqHqR0Sk9Px+rVqxEXF4fkZOunvbLQYNRtVB8VqlSGn58fNq7aUOB+hEIhmjZtiqZNm6J///6oWbOmq4tOiFdJTU1FeHg4AEtrkKIOMOuLSkJ9nq5QYsiYWfl2H2Lcv3QQFcqVsXufVJ8XDSVgiE/Zt28funTpYrVu77Y4dHm9tYdK5D3eHTsLm3/61WrdtWvXUKNGDZcdk+JRMIqHd6F4eBdPxIOULgqFAnFxcVi2bBnS09MBAKHhYWj4ahM0adUcjVs1Q8WqldnxClISktD6pUbgcDjYf+U4NCoNLp+7gLMnTuPs8dNQyhXsvjkcDnr37o1Zs2ahbt26nvj1CHG7x48fo1y5cggICIDJZPJ0cdzK1+vzf6/fRs93JuC/B08K3CYkWIrUu386PIYL1eeO842UHSHPHThwwGq5do0q6Nz+VQ+VxrssnzcdoSEyq3Xr16936TEpHgWjeHgXiod38UQ8SOmg1Wrx4Ycfoly5cpg9ezbS09PxUvWqWLJxNY7eOYsVW9ah38hBqFTtJasbDUW6AgAglklQrlIF1KhXC/3fG4yVP6zHqYeXEH/2EOauXoh23SwDcO7YsQP16tVDt27dcObMGQ/9toS4D9Nlr7R1PQJ8tz43m83Y+ONuNOkw4IXJFwB4pU71Ig2gS/W54ygBQ3zKkSNHrJb79urkM03/XC0kWIr3hvS2WvfDDz+8sI97cVE8Ckbx8C4UD+/iiXiQku/vv/9GvXr1sHjxYqjValSpUQ1ffLsKu88eRJc+PRAQEFDgezXPxzGQBsvyvObn54eqtV5Gn2EDsXrb14g/ewide3eDn58f9u7di+bNm6NLly5ISUlx1a9GiMeV5gSML9bnOp0ew8Z9jGHjP4Zeb123hoeF5Nm+Qb2idauk+txx3v2XQ0guiYmJVn0vAaB962YeKo13em/I21bL6enp2LNnj0uORfEoHMXDu1A8vIs740FKNrPZjNWrV6NFixa4e/cuospEY83P3yD+3CF069fLrrEq1EpLAkb4fBrqF6la62Us2xyHvReO4q0h/RAQEIB9+/ahbt26+OOPP4r9+xDijXQ6HQCUutmPfLE+v3r9Dpp0GIBNP8Xnea3xK7Xxz9HtkEklNutrFfl4VJ87hhIwxGecPn3aalkiFqFBPepfmFuFcmXQ9tXGVutcdTFI8SgcxcO7UDy8izvjQUoupVKJt99+GxMmTEBGRgY69OiM3WcP4rUurzvUnF6r0QAARJLCEzCMClUq4fO1i7Hz1D5UqvYSEhIS0L59e0ydOpWe/pISp7S2gPG1+nzbrn1o3KE/rt64k+e10cP64sTvm6HV6aFQqqxea/xK7SIfk+pzx1AChviMBw8eWC3Xq/0yTQmZj87tWlotX7lyxSXHoXjYh+LhXSge3sVd8SAl07Nnz9C0aVPs2rULAQEBmLn0U6z8cX2+3YgKY9A9v7nk8x1+b5Wa1fDzyb3oM3wgAGD58uVo0KABrl275vC+CPFWGRkZAPDCrnwlka/U51lZWZjx2Qr0Hzk9T5cjkUiAbd8swdqlH4PHC8Tpc5esXo+JjkBsmahiHZ/qc/tRAob4jKdPn1otl4st3omipKpVvYrV8rVr1+CKyc4oHvaheHgXiod3cVc8SMnz+PFjtGrVCjdv3kRkTBS2HNmFd0YPLdIgkgCg02oBAAJR0bpXCIQCzP1yIdbu/A6hEeG4fv062rdvj5s3bxZpf4R4Gw3TSsyObnoliS/U52azGW8OnoRFK7/N81qdmlVx/o/t6PtmZ3adbQKmeaN6xS4D1ef2owQM8Rm2J8DoyHAPlcS71az+ktWyWq3O89k5A8XDPhQP70Lx8C7uigcpWZKSktC2bVvcu3cPsRXK4ocju1CnYb1i7VOlUAIAxBJJIVu+WJvO7fHruUOoVqs6EhMT0bp1a1y9erVY+yTEG6hUli4rUqnUwyVxL1+ozzkcDmRScZ71FcqVwdnDP6FalYpW6/88e9FquUWT+sUuA9Xn9qMEDPEZCQkJVstloiM8VBLvVrZMFIRC6ybUrngCR/GwD8XDu5SWeHBCaoETUgsGgxEAkJmZya5jtOs5HGEvtURgZD3E1myH8R8ugNFocms53RUPUnJotVp07dqVTb5sPrgDZcqXLfZ+mUF4JbLi31yGhIfiu99/QvW6tZCcnIxOnTrh0aNHxd4vIZ6kUCgAlL4EjKfrc3t9NmMcAgOtu4c9ePQUZWq+hvTnCWYASEmV49ad+1bbtWhSr9jHp/rcfpSAIT5DrVZbLQfLiveUqqTicDioULaM1brk5GSnH4fiYR+Kh3eheOSoU6MqFn48CWuXzIZYJMCar7fimy273FoGd8WDlBzjx4/H+fPnIQsNxlfxWxAdG+OU/Wqff2cdGYT3RYLDQvDd71tRuXoVPH36FB07dkRqaqpT9k2IJzD1mqSYrcR8jS/U5wBQvmwMxgzrl2e9PF2Jdj1HQKfTIysrC6dsWr8IBHzUq/1ysY9P9bn9vG8EIUIKkJ2dbbVsz7SSRXHsz3No231YnvV+fn4Qi4SoVCEWHdo0w+TRgxEVGQYAuHf/Eeq2egtarR4A0Ln9q9j387o85W/bfRhOnD4PwDKK+r+ndqNcbLTTfwfbZojMUwtnclc8AMdiEhYqQ+P2/XHximXKQH9/f5w/ug11a1lXLk+eJqJGsx5Qayz9/mNjInH1dDykkrxNOIurJMWjKN8PAKhQ93U8fPzM7uOY5a5rsl+S4lEcKxZ8CHm6EgqlCjv3HMbNO/eLPH5GcbgjHqRk2L9/PzZu3Ag/Pz+s+nEDKlSp5LR9p6elA0CRBvAtiDRYhq/it2Dga71w8+ZNjBw5Ert373ba/glxJ6XyeTc9sfOvk7yZL9TnjFlT38P//jyHy1dvWa2/eOUGVq7fgt8OHIf2+XTijGaN6jptYGWqz+1DLWCIz7A94WVmZrn1+NnZ2VCq1Lh45QYWf/kd6rfpjcdPLM0SK1csh2WfT2O33X/kJNZv3G71/hVrv2eTLwCw+osZLkm+AO45AXo6HkD+MUlITMGmuHkICPB/Xq5MDJ8wB1lZ1uUbM20em3wBgK9XfuqS5AtQOuLxou+HtykN8bBX1UZdUPmVzjh49BQGvt0FIwa95fYy0AUbsYdOp8Po0aMBAIPGDEOjV5s6df9qxfPxLZyYgAGA6NgYrN25Ef7+/oiPj8fOnTudun9C3KW0jgHjbfW5PF2J6zfv4fTZi/jj+F84cuwM/vzrAh4+foZgmQRffDIl3/fNmvcl/jp/Gf9et56eunXzhk4rG9Xn9qEWMMRn2J4AbTPSrtK3Vyc0rFcTKrUW8fv+YE9ciUmpWLFuC5bPnw4AGPVuH+zZ/z/sO3wSAPDBnKXo0KYZKlcsh+s372H2gtXsPnt1bYfB/Xq4rMwCm2k09Xq904/hqXgA9sVk9tRR+GRRHADgn0vXsWLt9/hg/FAAwLZd+/DbgWPs/oa/8yY6tW+Z5zjOUpLjYe/3Y9aU96BUqfPdx1ff78Sdew/Z5bEj+ru0zCU5HgwOhwOz2czOQMD8a9vC5ZfvVyIxKRVL4zZh2y8H0KtLe7zVvYNby+qOeBDf98UXX+Dhw4eIio3B+DkfOH3/xZ0F6UVerlMDIz8Yi3WLVmHMmDFo1aoVIiK8cxwJQgrCtIApbV2QPFmfZ2Vl4ez5K/j74lX8c/k6/jp/xep6yZbl4aNjLVlfbfZKMUuZg+pz+1AChvgMf3/rP1dTRoZbjtupXUu8O6AnAGDquCGIqNoKJpPl2Ndv3bPa9ptVn6F2y15Ikyug1eoxePRM/BH/LQaNnsEOhhkZEYoNyz9xaZn5fJ7VsitOgJ6KB2BfTGZOGYn4fUfZrkhzFsWhV9d2CJZJMXHmInZfsTGRWDZvGlypJMfD3u/HyCG9833/T7v2WV1MtGhSHyueJ21cpSTHgxEbE4nHTxPx5FkSqlQuj0fPWyOVLWM9fWar50++/P25eGvIZGz6Kd7tCRh3xIP4tidPnmDx4sUAgOkLZ0MgdH6SxKA3AAB4QUFO3zcAjJo+Dn/8dhC3r93EmDFjsGPHDo90+SOkqBITEwGg1CUPPVGf33/4BBt/jMfGrbvx5FmS3e/LyMh06DhjR/RH6xaNHC1egag+tw91QSI+w7bPqUqlcXsZpBIxRLku/EJDZFavR0eFY93Sj9nl0+cuoUmH/rhw+Tq77uuVnyI8LMSl5QywqSwyXFBZeEM8gIJj4u/vb9UVSa83YOSkuZg86wskp8jZ7V3Z9YhRWuJR2PfD1pVrtzBiYk4yMjoqHDs2LndaX+SClIZ49OrSDgDQd/gHmDVvFd4eOhUA8FY3S3LlwJE/MXj0DGzY9DPWb9yOjxesAQDUrVXNreUE3BMP4ts+/vhjGAwGvNK8ETr26uKSY5hMlhnAAnmBLtl/II+HBV8th7+/P3bt2oVt27a55DiEuEpKSgoAIDIy0sMlcS931uf7D59Eqy5DUKl+J3y+dL1DyRd75E76Thz1DlZ/MdOpiWCqz+1DCRjiMwQC6yde+uctStxFpdLgyw0/QJ6eM5Vbn54d82z3ds+OGPh2zgXilWu32f8Pf+dNdOvUxqXlBCxPs3OzHf/EGTwdD6DwmNSpWQ2zp45il/938hy+37aHXXZ11yNGaYiHvd8PRrpCiV6DJkKnszwdCQjwx86NyxEdFe7yspaGeCz4eCKmjR+KdIUKy+I2I12hwvQJwzB/9gQAQFioDP9ev4MP5izF5FmLYTSZ8NGk4fhk+mi3lhNwTzyI75LL5di6dSsAYNr8WS5rNZLxvOVeQKBrEjAAUKNeLYz6cDwAYNasWfS3TnxKaW0B4476/O5/j9Bj4Hi80Xc0Tp75x673iEQCRISHICoyDAIBv/A3IKc78stVKmLymMFOP59SfW4f6oJEfAbfpl+h7nlzYVcbOm42ho6bbbVOIODj0w/HoMcbr+X7njWLZ+HoyXNISExh18XGRGLF/A9dWlaG7QmVOeE6k6fiATgWE9uuSAx3dD1ilOR4FOX7kZ2djf4jpuO/B0/YdasWfoTmTeq7tKyMkhwPhlAowOJPp2Lxp1Pzfb1h/Vq4eNw7BgN1RzyI79q+fTtMJhOq1a6Buo2dN1aBLcPzZLDtd9fZhk16H1vWfof79+/j999/R/fu3V16PF+k0+lw+/ZtBAcHQyaTQSKRUHctD8vOzoZcbmk9HB7u+gcl3sSV9blOp8fHC9Zg9dc/vrD7UPWqldC4QW00fqU2mjasg1rVqyAwMKe18OlzF9Gi0yC7j3vzzn3UbtEL65Z9jAG9uzjt+0X1uX2oBQzxGbYnQKPR5KGSAL26vIbRw/oW+PqTp0lWLQEAICUtnR2HwdXccaHiTfEACo6JbVckhju6HjFKWzwK+37MmrcKB4+eYpff7d8To4f1c0fRAJS+eHg7urEiL/Ltt98CAHq9k/84Us7CjFUQJHDNGDAMvoCPt9+1DDS+dOlSlx7LFyUmJuLLL79E/fr1UaFCBTYB065dO3z66adISPDO2fVKupSUFJjNZnA4HISGhnq6OG7lqvr8vweP0azjQCxfuznf5ItMKsHYEf1x4dgOXP9rDzbFzceY4f3wSt0aVsmX7OxsTJr5Rb7HaNygNmZPHYWoyLA8r6k1Wrwz6iMMHTfbab8T1ef2oQQM8Rm240JkuqlZW99enbDg44no2rE1u+7HHb+j16CJ+WZ2MzIyMGj0jDwnM6PRhMFjZpaY/pCeigfgeEzq1KyGZo3qscvly8a4peuRO/nK9+OX3w5j0cpv2eUG9Wpg3bKP82zn6zz5/SCkpLh8+TL++ecf+AcEoFu/N116LNPzbgWuGoQ3t4GjhyIgIAAnT57EqVOnCn9DKXDt2jUMGjQIZcuWxYwZM6xe02g0OHr0KObOnYuKFSti3Lhx7Iw8xD2SkixjkYSHhyPQhd30vJEr6vN/Ll1Dkw4DrIYpYISHheCbVZ8i8eYxrFk8C/XrVH/hvrbvPoC/L1zNdz+//rAan88aj3v/7MeCjydCIhbl2W7zT7+ifa8RSJMrivz7EIdwKAFDfIZtVtVd08B1atcSMyaPxG8/xWHUu2+z6w8fO4Mfd+zNs/0ni+Jw6d+b7PKY4TlP9i9cvo7PFq93bYHhniZ/nooH4HhMAMCTSfmSHA9HYnHj1j0MGTuLXQ4LDcYv369CUJD1qPmuVpLiMXTsbIjKNmIvnJ4lJKPnOxMgjG0EWYVmGDJmpl0DBk74aAE4IbXACamFm7f/c0lZC0JNlElBNm7cCAB4rUt7BLtw8PqsrCx2rAJ33FxGlYlG9wFvAQBWrlzp8uN5s8zMTCxYsAD169fHDz/8gMzMF8/iYjQaERcXhzp16uD48eNuKiVhWh6VtgF4AefX58dP/Y023YciNS3dan1gYAA+GPcu7pz/HcMHvQWeHQOCm0wZmD3/y3xf+2rFJ2zLF4GAjxmTR+Lehf0Y1Ldbnm3//OsC3h46pdDvX2GoPreLmRIwxGd4Q7O2RZ9Mtuq28unidVYDTJ05dwmLv9zILo8c3BtxS2ZjcL+cPt4LV36Ds+evuLScWVnWlQOXyy1gy6LzhngAhcfEG5SWeLwoFkqVGj0HTYRGowNg+Qy2fbME5WKj3V7OkhKP23cf4Pvte/DO213ZGacGjvoQe/b/D1PHDMGgvt3w/bY9mDhj0Qv3c+joKaz77me3J8IY7ogH8U07d1rGKeo1qI9Lj5OZq2Uq1989f3+Dxw4HAPzyyy9QKBRuOaa3MZlMeOuttzBr1iyHWwc/evQIr7/+Oo4dO+aawhErqampAErfALyAc+vzh4+f4a0hk9lrIUaNapVx+cQuLPnsA4e6x2/Y9LPVeHqMd/p0Rc/nsyHmFhYajO/XLcS2b5ZAKLTuWvW/k+cwbc4yu4+dH6rP7VOiEzBPnz7F2rVr0adPH9SqVQthYWEIDAxEZGQk3njjDezevdvTRSQOsM04e+KG09IfM6dFy93/HmH77gMAAK1Wh8FjZrI3nBXLx2L5vOkAgNWLZrI3mllZWRg8ZiY7+4sr2CYgXHEC9IZ4AC+OibcoLfEoKBZmsxmD3p+B23cfsK/VrVUNF6/cwNLVG/P9eezC8ZJKSjy+/n4nsrOz0e/NzgCAazfu4tiff6N+ner4bOY4fLloBiLCQ7Dl598KbAUjT1di6PiPMX3CUESGe6ZfvzviQXxPSkoKnj59CgBo2KKJS4+VnZ3z1NZdf39ValZDucoVkJ2djdOnT7vlmN5m7Nix2LNnT+EbFsBkMqFnz564fTtvNw7iXFqtFgAgEuXtwlLSOas+12h06DVoYp6uPu1aN8Vfh7bi5aqVHNqfSqXBhI8W5llfsXws4hbPzucdOfq+2Rmn9m/JM/PkyvVb8M33RR+gn+pz+5ToBMyWLVswduxY7NixA9euXUNaWhoyMjKQnJyM/fv3480338T777/v6WISO9k2a/PUDf+k9wdZTfe2YPnXMJvNmPrxEtz97xEAwM/PD5vXzodIZJm6TiIRYfPa+WyZb999gA8/XeGyMmbYNCG07b/qDN4SD6DgmHiL0hSP/GLx6EkCfjtwzGq7C5evY9onywr8uffgscvKWFLiceh/p8HlctGkQR0AwJ3/HgIAysVGsccsFxuNrKws3H+U9wkZAIya/CliosIx98MxTi+fvdwRD+J7Ll++DAAoV7kChPmMW+AqHD/3XRoziaUTJ0647ZjeIj4+Ht98802x96NUKjFixAi3doMujdLTLd1lpFKph0vifs6oz7OystB/5LQ8M3J2eb0Vft+2FmKx0OF9zlu2Id/1363+DBJJ4efMurVexu7vV1kN6AsAY6bNsxpKwRFUn9unRCdgGLGxsXjvvfcwb948DBo0CP7+ObOhbNiwAUeOHPFg6Yi9bCtXrhsvknILDwvBiHdyBgO8dvMuftq1Dxs27WDXTRkzGK82a2D1vjYtG2Py6MHsctw3P+HIsTMuKaPJZN2U1xV92r0lHkD+Mdm913u+16UpHvnFYteewx4pS0FKSjzu3n+M0BAp+PyCBw3N/WTfVvzvf2D373/g04/G4uHjBGRmWp5cPXqS4NIWerbcEQ/iey5evAgAeLlODbce1+zGG/kGzRsDQKnrRqPVajFmjPOSvidPnsSWLVuctj+SFzMFdWmbAQlwTn3+7ZZfsPeg9ZhF1apUxI9ffWHXWC+2EpNSsWT1xjzrRw/rizYtG9u9nyYN6+CrFXOt1mVkZGLanKLN0Eb1uX38C9/Ed5UvXx5bt25Fnz59rJpAvf766xg0KGeu9P3796N9+/aeKCJxgG3/YH8X9dNu07IxzPK8o4nntmrRDKxaZD1K/4DeXQrd97J507Bs3rRilc8ezI0UwxUZaHfFAyh6THI79tsmJ5fKfiUpHkWNxZSxQ1xSnqIoSfHI/SSuSqXyAICHjy3dt8xmMx49SQCXy0XFcrEAAMPzmV6Cgnh48OgZsrKy0KWv9Y1Qx96j8NtPa9C1YxuXlNmWO+JBfM+lS5cAAC/XqenyY/n55XyP3NmSokmb5gCAv//+G1qtFkKh40/BfdH27dudPp30unXrMGSI99QzJU1aWhoAICTEdYNhe6vi1ud6vQGfL7WegCMkWIo9P652aLyX3HoNmpjv+sVzpzq8ryH9e+DKtdtYvnYzu+7I8b9w+uxFNG9S36F9UX1unxKdgOnfv3++63v27Gm1bDI5Z+5z4loGg8Fqme+GqSJ9lTuaAFI87Efx8C4lJR6Vysfixu3/YDAYERTEQ83qL6FV84Y4eeYffLJwDVLlCqSmpWNI/x5sc2R+jKVlnv7ZP+jasTViY3JmtBgzbR5SUuVYtfAjNKxXCwDACanFbu+qQXqpyTLJz99//w0AqFG3lsuPFZDrKW2GybHBYIsjpmwZRJWJRuLTBPz9999o06aN247tSd99953T93n27Fncvn0bVatWdfq+Sc4gvGFhYR4uifsVtz5f++02PHmWZLXuh/WLUPWlCkUqz41b9/DX+ct51p89/BM79IGjPp85Dtt278ezhGR23bxlX2Hfz+sc2g/V5/YpFV2QbN26dctquVGjRh4qCXGEbaLMts8iyZGRYX0CzN3tzlkoHvZzNB5msxlGoxFarZb90el0MJlMBY5tQ/Gwn208XDFInDvi8Xrb5sjKysK5C/+y637csAhdO7bG0rjN+OHnvXinT1esWvhRvu9/qVI59O7xOvsjeN6V6fW2zREVGcb+rXE4HPi5sEubO85Xvio7OxsZGRkwGAzQ6XTsj8FgQEZGhleNdeVsjx5ZxlSr/PJLLj+Wn58f+zeemem+BAwAVKtdHQBKzUCyJpMJ586dc8m+maQdeTGz2YysrCwYjUbo9XrodDqr6w29Xg+TyYSsrCz2HKNSqQCUzjFgilOfazQ6LFr1rdW611o1Qaf2LYtcnhrNeuRZN6R/DzRuULvI+xQI+Jg2bqjVuv1HTuLKtVsFvCN/VJ/bp9R9Krb9TqtWrYo+fVw7vaEzmc1mqFQqBAUFITAw0Cumni2M2WyGwWCASqWCXC7Hs2fPkJSUhNTUVKhUKmi1WigUCsjlcsjlcqjVahiNRphMJmRkZMBkMkGn07HNHxkBAaXuz9duJpvmklqtFrdu3YJarUZiYiJSU1PZilatVkOj0UCv18NgMECv10Oj0UCtVltd8JtMJhiNRhiNRjYuuVE8CmYbj2+++Qa7d++GWq2GWq1mb6YMBgOMRmOhTeADAgLA5/MhFoshkUggEolw//59m20oHgWxjcdHH32EOXPmIDAwEIGBgfD39wefz4dIJIJQKASfz0dQUBCkUimCg4MhkUggkUgQEhKCqKgoSKVSiEQiyGQyhISEQCQS5Wmy7Ip4jBz8Flau34Kf4w+iVfOGAIDYMlHYs3VNge95UfexB5cPWS1fvXEHAPD+0D4uTejZxuPw4cPw8/ODTCZDbGwswsPDIZVKERoaCqlU6tJkkLPo9XrI5XKkp6fj2bNnePr0KZKTk6FUKqHT6djzrE6ng1KphFwut7oBYs6xtjNK5IfL5YLH47E/tueHkJAQCAQC8Hg8SCQSREZGsp+lSCSCWCxGWFgYQkNDIRKJwOPxPHptYTaboVAoYDRausvxBUV7ouuogMAAGA3GIrWAMZvNMBqM0KjUUKYrkJyQhLTkVKSnyaFVa6DT6qBWqqBMV0ApV0Cr0cJkNCEjw4Skp4kAgBkzZmDw4MEI8rLWi9nZ2ezfq0qlgkKhgFqthlarRUpKCtLS0pCens7+bTPJQr1eD7VaDZVKBYPBAJPJBJPJxP59u8KXX36J27dvQyqVQiwWQywWQyaTscsymQxRUVE+e1PIXAur1WqkpKSw54309HTI5XIoFAoolUr2c9dqtdBoNNBoNNBqtew1hsFgcCh5y+Px2JhNmTIFixYtglQqhVAohFAoREhICKKjoxEeHs6uY84tzHkoODgYYrHYpz77zMxMJCUlFev+47eDx5Calm61bsHsiUU+x/60a1++623HcSmK94b0xvzlX1mVd+/B46hTs5rd+7Ctz6kFTP5851vgBCkpKejevTubeY+MjMRvv/3mdZXdi5hMJshkMgCWp5JSqRQhISEQi8WQSqXsTYNMJoNMJoNEIkFoaChCQkLYGwnmIo3P50MoFFpdtDFPgZjsOHMRmJGRwZ7EmUw5U7kyFTFz0tdoNEhKSkJycjISEhIgl8uRadMkzRkC6UtdIIVSZbX82Wef4bPPPnPpMSkeBbONx507d3Dnzp0i7y8jIwMZGRlQqVTsNK22KB4Fs40HAPbmwFlskwSuiMfLVSthUN9u2LztV3w2YxxCgp37ZPL4qfOIiY7AojmTnbpfW7bxOHLkSIGD4/v7+yMmJgYREREQCATsD5OgkUgk4PF4EAqFEIvFbOIhd0KNqe8CAwOt6j7mgjj302GmvmMeIKhUKqs6Lz09na3vkpKSkJKSwj5EcJesrCw2Ue4MIpEIUVFREIlECAoKgkgkYn+Cg4MRHBwMgUAAsVjMJiSZ64mgoCAEBAQgKCgIfD6fTWjm/nyzs7ORnZ2NrKwsZGZmwmQywWAwsNcTcrkcb76ZM5B357qtIQuRQSASQSwVIygoCAKRAGKpFGKpBCKJCLKQYEiDZeALLcnSQB4PAbxASzmEfATyeJayBDwvi58f8DzOmRmZyMjIQGAQD0aDERf/Oo/H9x9Br9PBoDdAp9Fakig6PTRKFbQaLXQaLdKSU5GWkobUxGQo0xXFvs6Ry+WYOXMmmxyzvYllruGYhDDzuTKfbe7Pl/lsMzMz2foiIyMDer3e6qZcr9dDoVAgPT2dTa4wf+PMNODJyck+M8PQuXPnCm1d4+fnh+DgYDZhziQppVIpwsPDER4ejuDgYISFhUEikbB/10FBQez5Ivdnn/vzN5vN7E/uz595qJj7+pn5rJlrZ+b62WAwsA/HmFgx5xqlUummT9Ja7vNZYmIiEhMTi7wvLpcLgUDAnlNCQkLY+xihUAiJRMImzZiksEQiYV8XCAQICAhgf/z9/dnPn4lBVlYWe+/C/N0zDxCVSiX7Oev1eqhUKqSnpyM9PR0KhQJJSUl49uwZEhMT8yReGI7U54f/Zz3FfPvWTdGkYZ0ifXYZGRkYMHJ6nvX7tq9zykMSgYCPfm92xpqvt7Lrjp86j5lT3rN7H7b1eWlsMWWPUpOAuXPnDjp37ox79+4BAMqWLYtDhw75XF/R3P0QmadECoXCcwVyAIfDgUQiQXR0NGJiYhAaGgqZTMaecJmTsEQiYZ9EMz8CgQAjR47E2bNn2f3RE/6CpSusT4BcLpe9kAsPD0dERAR7M8JcYDAXdcyNCnPzIhAI2Avp3Bcg/fr1w5kzObM4UTwKZhuPiRMnom3bthCLxexNTkBAgFUyNDAwEFwul72Rz87ORmZmJtsCKXcCVKPRYNq0abh5M2faQIpHwWzj8e2336J9+/ZsEoZpjcQ8NWRahzEXwGq1GkqlEqmpqUhKSoJKpYJGo2FvYoC8A3m6Kh6b4uZjU9x8l+x73MgBGDdygEv2nZttPDp37ozQ0FCkpaXhyZMn7IWxRqNBZmYmHj16xHZP8WZcLpd94h4bG4vIyEgEBwezN9EikQgCgYB9UMI8ORYKhew5IPd5gPmXucFgfpjWiczTbebvV61Ws0/EmZYJCoUCycnJSEtLY5+Qq1QqpKSksH+7Go0Gd+/e9fCnl0OtVEGdT9LUVaYPy39wS3twOByIJGKER0UgPCoCstBgSKQS8AUCCCUiyIJlkAbLIJSILTeQgQGI/3EnfvvpFwDAihUrnPVrOB2Hw4FIJIJUKmUTRMHBwWzCQiaTsX/bzLUDkzxiWm0HBgbizp076N27t0vK2LRpU9SvX589XzDnaqbVjkJhSZSlpaUhLS2NvSfwJQEBARCLxQgNDUVYWBiEQiFkMhmbuGNamjAJi9zXczwej00mBQQEsOeU3F3wmPMLk8hjHsQ2btwYycnJ2LhxI2JiYqBUKtkEUVpaGhISEpCWlmbVko9J5qlUKjZBnJWVxV67+AImwZO71Za99bnZbMaBo6es1nXt2LrIZRk8ema+6zt3eLXI+7TVunlDqwTMn2cvwmg02T1Tk219XhoHbbZHqbhCP3XqFHr06MFmMuvVq4e9e/eiTJkyHi6Z4yQSCdtnk2nizGTRVSoVe1PG3AgolUq2eShzI8FkgZknIUaj8YVPbrhcLgICAthstUAgYG/Yc5/kmWb5IpEI4eHhiIqKQkREBCIiItib/OI0HbdtsioSuqdZsi/S2kwhu3//fnTo0MGpx7B9wkvxKJhtPLp06eL0eHzyySdWyxSPgtnGo2zZsihXrpxT9s20RmjWrBmuXbvGrqd4FMw2HpMnT873+2E0GpGcnIwnT56wTe+Zlh9MQoxpfcI8QdbpdGx9xyTUcndxLayLD9Oyg2lCz3RlYJ7KMjegUVFRbHKbuUGVSCQ+0U2YkZmZCa1Wy7boyf00nrmZlcvlbEJHpVIhLS2NbUnBdHFgEkB6vd6ubg5Mlz/meoK5yT969CgA4Kf/xSM7OxsalQYatRpGvQFajRYqhdKyTqWCQq6AKt1SLqP+eXcXowlGvaU7TIbRVOh1TnZ2NsxmM8IiwyENkVluWPlBEIqEEIpE4AsFEIlFEEpEEAiFCAkLQVhkBELCQxEaEQaR2LKNo9c5Z49bnpA3atQILVq0YJO8tjexzDUcMz6HPTgcjlVrAebvmbme4/P5bEvq3H+3zA1+TEwMYmJi2Bt4Z3T/i42NLfY+CjJ8+HCMGDGiwNezs7ORnJzMdnlnHmIyP8nJyUhNTYVcLmfPJ8zfNZPgdLSlk5+fH/twhbl+ZhKvTEv13C08mFZnzGee+1zDJHE9gTlXNmzYELVqOT4wtslkYs8VOp3O6pzC3McwQxIwrbHkcjnb9Y2JhU6nY1u2FMbPz8/q4WFQUBD7WTMPHMViMUJCQiCTydiWT7Gxsew9TGhoKBo3bowLFy6w+7W3Pv/3+m0kJKZYrevUrmhjv1y8cgPbftmfZ33izWNF2l9B2rRsxLYkAgCdTo+z/1xhuzkXxrY+Ly0zuzmqxCdgduzYgcGDB7MtR9544w1s374dIpHIwyUrGg6Hwz5FkEqliIqKcsp+mYH+cl+MMokXb+lvn55u3YcyWCZxeB9msxmN2/fD+YvXEBTEw38XDiA6KtxZRSw2vd6AivU7Iik5DWXLROHWub3g8x3vIqdQWj9ZcEUTQIqH/SgezuEL8eByuRCLxXm6gxQlHo64fvMexn04H6fPXYJELMLA3l2w+NMp+fa/dmRbd7A3HjweD2XLlkXZsmWddmzmCS9z8w1Y6llvq//cwd/fn70Jd0brYKYbBvM03fbz9fPzY58u28rOzmYHx46tUA6hEcWfeSU7OxuZGRnIysppncbl+sH/eZz7vNoVVy9cwWdxX6BN5/bFPp69mM+lefPmdreAYVpEMp8r8wOAbS3FdJPxNiEhIahcubJLWp8UNouUn58foqKiinXtbNtCJPdnD4DtCuPNMSgKJukXGGhfSwhbgYGBTm8NwXTzso2Bs8/fRb2+Ovan9aDQ5WKjizTzkcmUgSYd8s7s27n9q4h0wrkxt7DQYNSpWRWXr+YMvnv56i27EzDuuN4tCUrGWaEAO3bsQN++fdnkS0REBFq1aoX169dj6dKl7M/27ds9XFLPYzL0ufvU83g8r6o4bJsrSsSOJ9G2bN+D8xctT6VHDHorz83l+YtX0W/4B4ip0Ra8qPqIrNYK3QeMw5FjZ/Lbnd127z2Cnu9MQEyNtgiMrIfQyi1Qu0UvvD/lU9y++4Ddjs8Pwgdj3wUAPH6aiKVrNjl8LEt/Y+unYxKJ82/+fDEeDx49xcSPFqJ2i14Ql2sM//C6kJRrgrqvvomps5fgyVPrfs0UD4pHUTkjHvbKzMxEj3fG4/S5S5g3czzatWqCleu3YMHyr4u1rTu4Kx4F4XK5ljFFnj+ZZp5Oe1v954uY1hcFfb4BAQEFthDy8/NDTEwMAODRfw+cUh4/Pz8E8njgC/jsT2CuOAcJ+AAAvc0TXFfTabUAAIEDgw3nfrLPdPlhPl+my7A3//127NjR6fusXLkyKleu7PT92uJwOPD390dgYGCez575+/aFGDiKaXHiTYOq+vv7W30HXHX/UtT6PCXVOnHTqH6tIrWKnPtFXJ7ZhQDg+3ULHN6XPSpVsG6lZjuIcEE8XZ/7kpJzZsjHtWvXrDKiycnJ+OijjzBt2jSrn3XrHJvjnLhfdnZ2sZ/wZ2VlYc7COHZ50vvvWL3+zfc70aTDAGzffQAJiSkwmTKQnCLHbweOocObI/HJwoJnFimIVqtD9wHj8ObgSfh131EkJKYgIyMT8nQlrt64gw2bdlhNIQsA7w/tC8HzC8HFq7+DUuVYP1mNNu9AjM5uAuiL8Th/8SrqtHwTX371I67euAONRmfpi6zR4sq121i+djNqt3wT129aP5WjeFhQPOznjHg44uDRU7j73yN06dAKH4wfiq9WzAWXy0Xct9uKta07uCMexDfVq1cPAHDzynW3HE/w/O9Op3HOYMb2SnySAAA+2S2+qEaNGuX0fU6YMMGnuvz5ErPZzHY75/F4Hi6NexWnPq9f52W8278nerzxGlo1b4g6NR1vWXjun3+xcMU3edbPmDwCYaGu6Y7WpEEddHm9Ffq92RkjB/dGg3o17Xof1ef2K9EJGFJyKBSKPH31wx088ew9eBwPHz8DADRvXA+VK+aM+XDp35sY/cE8duDMpg3rYt6s8ejcPmdgq8+WrMfvh447dMxh4z/GbweOAbBk6nu88RpmThmJz2eOx7iRA/BqswYQ2HShEIkE6N6pDQBAo9Fh80+/OnTMNHneUfJDQ0Md2kdhfDEenyyKg1pjedLI4XAwqG83zJs1Hl1eb5XzeylVWLpmo9X7KB4UD0c5Ix6OuHPPMiBtudhoAIBYLESwTIKUVHmeBJUj27qDO+JBfFPdunUBADf/dU8CRvT8qbbWzYODJickAShdCZg6depYzXRVXNHR0Rg2bJjT9kesMd18gNKXgClOff5mtw7YGDcP8T98ieN7N2HO9NEOHTszMxPvTZ6b72sfTSx4rKPi+nDicOzdthY/fbMEX62ci+6d29r1PqrP7Veix4CZO3cu5s6d6+liECfIb6YnqUTs0D6++3E3+/+3ulkP8LhwxdfswGoVy8fi+N5N7JRuLTsPwqmzFwEAny/ZgC6v2zeC+bE/z+Hn+IMALDeN//v1OzSsb9/AZb27v84OtvXtD79gwqh3CnlHDoMh7/SnfD7f7vfbwxfjce/BE/b/b3R4Fd+vW8guV6rfCfcfWl5PyaepJcWD4uEIZ8SjuByZNtaTU8y6Ix7ENzEJmDvXbhWypXOwXZD0hkK2dK4nDyxJ0fLly7v1uJ62bt06nDx5EikpKYVvXIjNmzf77NiOvsB2fMjSxJP1+cp1W6zGYmEsnjsFEon3/b1TfW4/agFDfEJqaqrVMo8XCJHI/v7SWVlZVoNhNWtU1+q13w+fYJe7dmzF3lwCwJtdcwbjO/vPFSSnpNl1zI1b49n/v/ZqE2zetgdVGr6BoOhXUK52e7w/5VM8fZaU73tzl+/f63eQkiq365gAYLCZnYjH4zm9Wa4vxqNGtUrs/69cu42r1+/AZMrAsT/PISEp5wIwvxHqKR4UD0cUNx6OqlLZ0lrp4RNLCyalSg2FUo3wsBBIxCIYDEa2X/aLtnV3kghwTzyIb6pevToA4L/bd+2aTam4mBYwGjdOeS1PSUP68/OXMwY+9iURERGIj48vdheFBQsWOH1WQWItd5K+JI1rYw931+eMh4+f4ZMv1uZZLxTyMXpYP5cfvyioPrdf6foWEZ+lfT5IHUMkFDj0pf73+h2o1Bp2uX6d6uz//3vwBFptzqB7lcpbz7BhOxjVlWu37Trm6XOX2P/v2f8/rPl6K+7+9whGowmPnyZiw6YdqN/mbdy6cz/Pe2OiIxARbhkt3mw2W+2rMHqbDLQrss++GI/5syYgKtIyWvzjp4mo3bIXeFH10bb7MBgMRohFQsyZ9j5GD+ub570UD4qHI4obD0d1fK0FKlcsi32HT2LZmk14b9JcZGdnY8ywvnj4+Bn4MQ1Qvm6HQrcFLAMjc0JqIepl+1oyFZc74kF800svvQQulwtVuhJ3b9h3XikOkdSSgNRqtIVs6Tw3LlsGPa9YsWKpHCuhefPmOHz4MDvgsiO4XC5Wr16NGTNmuKBkJLfcCdDSloBxd30OWD7vMR98Dl0+A4J/MPZdtySAioLqc/uVrm8R8Vm2A2CJRY5dqDxNyGlpIhYJERSU04c1Ta6w2lYitt637bHsHQ0891N8ACgTHYmZU0Zi6ICebAWWkirH0HGz831/RFhOv8mnCcl2HROA1Y00AIjFzn+q7YvxqF6tMv45+jOaNKiT7+utWzTEm93aF3hxQfGwoHgUrrjxcJS/vz/it3yJpg3rYNb8L/HHibOY8N5AzJzynsPbMhfa/lz39FB2RzyIbxIIBOjevTsAYOfGn1x/vOcJEK3N36QrHYr/HQDQrl07tx3T2zRr1gxXr17FkCFD7L65b9CgAc6fP49x48a5uHTEVmlr0eDu+hwAdsQfxL7DJ/Osl0rEmDR6kMuPX1RUn9uvRI8BQ0qOZ8+eWS3H2EyPW5jc89LbTh9n27S5sGV7Kx+TKcNqed/Pa1GnZjUAQLBMiuVrNwMAzvx9GfcfPkHF8tYtCXLf6CocaBKtVFmfAGUymd3vtZcvxuPajbvo0m8MO9Dsm13bo26tajh97hIOHj2FvQeP448TZ3Fo11do2fSVPO+neNi3TPEofjyKolaNKjj226Y86yuUKwOz/Kpd2wLA1Rt3AQATRg10dhHz5Y54EN81YsQI7N69G/t27MG0hbPh7++6y9bgUEururTk1EK2dI7s7Gz88dshAEDfvnlb+pUmwcHB2LRpE+bOnYv169fj6NGj+Oeff6y6vpQtWxatW7fGkCFD0LZt21I3Fom38OSYYZ7g7vpcpdJg0qwv8n3to0nDIZN677TOVJ/bj1rAEJ+QnGz9hDs8LMSh98ukOVlY2wxtaIjMalltMwWl7fYhwVI7j5lzkgwJlrLJF8DydD+3e/cf53m/Sp3T7NGRE65teV3RrNkX4zFk7Ez2Zv/d/j2x6/uVmDN9NA7s3IC2rzYGYBl88aNPV+T7foqHBcWjcMWNhycdP/U36taqhiljBrvleO6IB/FdHTp0QGhoKNJSUnH6j7xPhJ0pPCoCAJBm5zhWxfXvP5chT02DSCRCq1atCn9DKVChQgUsWrQI586dQ9euXQEAn3zyCRQKBR49eoQtW7agffv2lHxxs9yft+2MQCWdu+vzOQvXICEx78DUMdERmOjAhAOeQPW5/SgBQ3yCbQY6NibSoffHPL+wAgC1Rms1UnflimUhFOb0U7z3wDoZYpscqVPTvoHyalV/qcDXbFsJ5O7ywUhOzbkILBMdkef1gqSkWjeXDA93frbe1+KhVKnxz6WcqUwbN7CejaphvZrs/y9dvZnvPigeFhSPwhU3Hp609PNpuHRil0tbGuTmjngQ3xUQEIB+/SwDTh74Za9LjxUSbunWmJqU9+bHFQ7s/A0A0KVLFwQGBrrlmL5E/Xw68GrVqkEqtS+xT1wj99+nyWTyYEncz531+eWrN7Hmm/y7W86a8h74/CCXHdsZqD63HyVgiE+Qy61nOQmROVYZ165RxWrQqkv/5tzUcblcdG73Krv824Fj7IwhZrMZO/ccZl9r/EptREaEscvvjp0FTkgtcEJqoU23d62O2TXXdLzydCWuXr/DLh8/lTPjTECAP+rUsL5pfZaQjOQUy+/M4XDQvHE9u39Xtc0Agq64cPG1eGRlWTeZPX/xmtXyP5dzkgH8oLwVHMWD4uGI4sajKK7fvIfXegxDUPQriKjaCpNnfoGMjIx8tz1z7hJefWMwxOUas9syXSZv3LoHv9Da+GThGpeXGXBPPIhv69OnDwDgyJ4DUNg5xlRRMAkYpdx1x2BkZmZi78+/AgAGDnRPdz9fo9FYnqbT9NKe5+fnBx7P8qBQr887MGxJ5q763Gw2Y9z0Bfm2MCpbJgrD33nTJcd1JqrP7UcJGOITEhMTrZaZ2VPs5e/vj1bNGrDLf52/YvX6jMkj2CaWDx8/Q5tuQzF/2QZ0fvt9nLvwL7vdrKl5B7UsyLB3eiE6V1/Rzn3ex+z5X2LEhDlYsW4Lu/7d/j0hkVhfYOSe1aV2jSoONXnU2oya7oqLF1+LR0iwFLWqV2GXN26NR99hU/H5kvV4o89oHD1xln3t9bbN87yf4kHxcERx4+GozMxM9HhnPE6fu4R5M8ejXasmWLl+CxYs/zrPtknJqejcZzSuXLuNRXMmo3Xzhli5fgvmL9sAwDI4cqd2LbFs7WaHxtYpKnfEg/i2Fi1aoFatWtCo1Fg+Z6HLjsNMQ52ZmQmD3uCy4wDAj+s2IS05BeHh4ejUqZNLj+WrmBt9mknFOzBxKG0JGHfV51t3/o4//7qQ72tzpr0PHs/7W8lRfW4/SsAQn5Caaj0oXnhosMP7yJ093vXbYavXXqlbA3FLZrFdg/46fxmz56/GwaOn2G1mThmJ7p3b2n08mVSCHd8tYwc1ffIsCfOXfYVvf/iFHcSsWaO6WD5vep737txzKN9y28P2BCgQOH+6Ol+MR9ySWRAILBcQZrMZP8cfxJyFa7D/SM64AuVio7FwzqQ876V4UDwc4Yx4OOLg0VO4+98jdOnQCh+MH4qvVswFl8tF3Lfb8mx7+twlKFVqtH21McaO6I/PZ1pmEcnd7PntHq9Dq9Vj6859Li034J54EN/G5XKxbt06AMDOTdtw+Vz+NynFJcg1u4lGpX7BlsWTkpiMNfOXAwDmz5+PgIAAlx3LlxmNlq6wTMsL4lnMjDZMy6TSwh31uUajw/S5y/N9rXaNKhg6sJfTj+kKVJ/bjxIwxCckJCRYLRclA93jjddQLjYaAHDq7EXcf/jE6vVR7/bBX4e24u0eHREVGYaAAH+EhQajy+utcHDnBsyfPdHhY7Zo+gr+PbUbY4b3Q6UKseDxAiESCdD4ldpYueBDHPttk1XXDwBQq7XYc+AYAEAkEmBI/x4OHdN2ECyJxPkjpvtiPFo1b4h///wF498bgFrVq0Ao5IPL5UIiFqFh/Zr4ZPpoXD65iy0Tg+JhQfGwnzPi4Yg79x4BAPtZicVCBMskSEmVQ2lzIxkdaWmVd+Xabdy595Cd6lKeroQ8XQkAaNGkPgBYJdhcxR3xIL6vZcuWePfddwEAcyfMdMlAoH5+fhA/H9BbpVA6ff+MVZ8ugVatQaNGjTB8+HCXHcfXMWON0Pg43oG5mdZqtYVsWbK4oz5fuPJrPEtIzve1FfM/9JlBp6k+tx9NQ028XlZWVp6Me1H6YHK5XHw+cxyGjJkFs9mM5Wu/x+ovZlpt07hBbfy8cZnd+9wUNx+b4ua/cJtysdGIWzLb7n2u37gd+ufNnz+cMBxSibiQd1iznQbO2SdAX45HpQpl8eWimQW+nh+KRw6KR+GcFY/iKmiq0KaN6mLsiP6I++YnVG3UBQIBHwEB/sjIyGSnFGcGGcxvdjZnc3U8SMmxePFixMfH49a/17F32270GNjb6ccIiwyHWqlC0rNEVKpW8ED6RXXl/CXs3vIzAGDVqlXw86PnoAXR6Swz7tFTdO9QGrsguaM+/+/BYyyL25zvaz3eeA3tWjd16vFciepz+9GZn/gkPz9O4RvlY1Df7mhY3zLDyjdbduU71Zsn6fUGLFtrORGXLROFqWOHOLyPNLnCajkkxPVT4FI8CkbxcJ7SFg97ValcDgDw8IlltgalSg2FUo3wsBBIxCIYDEZ24GQAWLN4Fh5dOYxT+7fg9IEtyMzMQoVyZdgpx5mbQiYh40qeiAfxTeHh4fjwww8BAMs+XojEpwmFvMNxEVGW5GNacmohWzouMzMTn0+yJLgHDRqEZs2aOf0YJQklYLwLEwcmLqWVs+vzYJkEPQrovr3k06lOPZarUX1uP2oBQ7xefjN5FLXPNIfDwd9/bC9ukVyGzw9C4s3jxdpHis0sEaGhocXany2Kh2MoHs5T2uJhr46vtUDlimWx7/BJLFuzCecu/Ivs7GyMGdYXDx8/Q8V6HREZEcp+drPnf4lyZaKRmZWFtd9ug9lsxscfjGL39/ipZdDBShViXVpuwPXxICXLxIkTsWXLFly/fh3v9xqCLYd3st2GnEEaKgMApKfJX7yhg8xmMz6fPBvXLv4LqVSKJUuWOHX/JZHBYGnpGJTPTHjE/YRCyxhJpakLkjvq82CZFNu+XYo/z1606oY06f1BqFK5vFOP5WpUn9uPWsAQr+fv75+nma5tP0NikZCYkqcfably5Zx6DIqH/Sge3qWkxsPf3x/xW75E04Z1MGv+l/jjxFlMeG8gZk7Jf1aqB4+eYtonyzBp5iIAwOa18zEs12DGzCxT+c1A5UzuiAcpWfh8Pvbt24eoqCjcvnYTkwa+D9PzwVqdQfI8maN18nd2zfzl2PHdVnA4HGzatAmRkZFO3X9Jk5WVxY7zQ4PweofSmIBxV33O4XDQ/83O7HKwTIKPp73v9OO4EtXnjqEEDPF6/v7+iImJsVr3tIDBqko72ynsxGIxatas6dRjUDzsR/HwLiU5HrVqVMGx3zbBkHABqXf/xKpFMxAYGIAK5crALL9q1XLohw1fQPnwL5iSLuHq6XgM7mc9kPHP8QcgEPAx8O2uLi2zO+JBSp7y5ctj7969EAgEOPO/PzFl8Nh8n1QXBf95Nwu9znnjXHy9NA7rFq4CAMTFxaFnz55O23dJlTue/v7UWN8blMYuSO6sz2u+nDPm1CfTRyMk2P1jxxUH1eeOoQQM8QlhYdajjtv2MyQWl6/dslpu1qyZS0ZPp3jYh+LhXSgehbt5+z8c+OMUpowe7PILQHfFg5Q8DRo0wJ49e8Dj8XB07yFMGvi+U2YuEkktg3o7Y19msxmrP1+GFZ98AQCYN28eRo8eXez9lga5BxGnc4J3KI0tYAD31edMAualSuUwelg/lxzDlag+dwwlYIhPsG2um+iCAfJKgguXb1gt161b1yXHoXjYh+LhXSgehXu5aiVkpV7B57PGu/xY7ooHKZnatWuH3bt3IzAwEP/7/TB6NumI86fOFmuf0ucznBQ3AaNSKDHt3fFYt8jS8mXRokWYNWtWsfZZWtFMUd5BLLYkJ5VK103R7o3cVZ/XqFYZgGXg3cBA144b5wpUnzuGzmrEJ0RFRVktX756q4AtS6+ExBQc+t9pq3V16tRxybEoHoWjeHgXiod3cWc8SMnVuXNnHD9+HJUrV0bik2d4t1NfbFz1VZFn8JIGywAACpvBJB1x+dwF9G7xBvbt3AN/f3/ExcWxszcRx+VuDUM8h2kJIpc7d4Bqb+eu+lwkEmBI/x7o8cZrLtm/K1F97jhKwBCf0KRJE6vl3w+dsJpWlQCbt/3KDloHWPrrdu3qmjEcKB6Fo3h4F4qHd3FnPEjJ1rRpU1y6dAmDBg1CdnY2lsych3F9hiM91fEbRaHE8pRfp3V8nIuMjAysXbgS77R/C08ePEbFihXx559/YsyYMQ7vq7TL3eqFEjDegWkJkpDg/OnfvZk76/M1X8wCh+Pcaa7dgepzx1EChviEnj17Wp2U1Botjp4oXlPjkiQ7OxubfvrVal2/fv0gk8lccjyKx4tRPLwLxcO7uDsepOQTiUTYvHkz1qxZAx6Ph//tO4L2NZpj/gdz8Pj+Q7v3ExgYCAAwOXCDlZ2djeMHjmJA255YM285srKy0L9/f1y8eDHPzRuxDxMHADCZKHntDaKjowEASUlJHi6Je7mzPheJBC7ZrytRfV40lIAhPiE6OhpNmza1WrdzzyEPlcb7rP12G27duW+1bujQoS47HsXjxSge3oXi4V3cHQ9SOnA4HIwdOxZ//fUX6tWrB71Whx/XbULnOq0xaeAoXD53odB9BDwfeyHDjpt+ZboCm778Gm/Ua4PRb72Laxf/RXBwMH788Uf8+OOPkEp9axYTb+Ln58e2gnHWDFekeJgWMM+ePfNwSdyL6vMXo/q8aCgBQ3xGr169rJa/3/4bbt994JnCeJF79x9h2ifLrNZVrVoVLVq0cOlxKR75o3h4F4qHd/FUPEjpUa9ePVy4cAGHDx9Gx44dkZ2djUPx+9G/bU8Mer03Vs9bhlNHTuTbzYiZ8rigbi8KuQKnjpzArPc/QNsqjbF4xud4dO8BJBIJpkyZgmvXrmHAgAE+2Y3A27CtkagFjFdgpmNOTk626m5SGlB9nj+qz4uOYy7qSGWEuNnjx49RpUoVGI1Gdl3Xjq3x209xHiyVZ6nVWrz+1nv46/xlq/WHDh1Chw4dXHpsikdeFA/vQvHwLp6MBym9rl69imXLluGHH35AZmYmuz4gMBB1GtVDwxZNUKNeLUhkUjy5/wgfj52O6NgYLNm0GskJSbh55Tpu/Xsdt6/dQsLjp1b7rlOnDsaMGYOBAwdCJBK5+1cr0cLCwpCWloarV6+iZs2ani5OqZeZmQkej4fs7Gw8e/aM7ZJUGlB9nhfV58VDCRjiUz766CN88cUXVut2b1mFnl3aeahEnpMmV6DT26Nw/uI1q/VjxoxBXJx7KgWKRw6Kh3eheHgXb4gHKd0ePHiA/fv348yZMzh27BgeP35cpP1UrlwZLVu2xHvvvYdmzZpRaxcXqVixIh48eIAzZ87k6QJCPINJil27dg01atTwdHHciurzHFSfFx8lYIhPUalUqFq1qtUgYEFBPOzbvg5tX23swZK517E/z2HUlM/yNIGMiYnBjRs3IJFI3FIOiocFxcO7UDy8i7fEgxCG2WzG3bt3cfz4cRw7dgz//fcf0tPToVKpkJGRAR6PBx6Ph9DQUNStWxf16tVD7dq1Ubt2bRpc0k1q1qyJ69ev448//sBrr/ne1LwlUZUqVdjvTatWrTxdHLei+tyC6nPnoDFgiE+RSCRYuHCh1TqDwYiu/cfij+N/eahU7mE2m3H95j28NXgS2nYflufkFxYWht27d7v15EfxoHh4C4qHd/HGeBDC4HA4qFKlCkaMGIEffvgBp0+fxo0bN/D06VMkJyfj8ePHuHv3Ls6ePYuvvvoKY8aMwauvvkrJFzcSCCwzwuh0jk8JTlyDGQemtE1FDVB9TvW5c1ELGOJzsrOzMXjwYPz4449W6zkcDt4b0hvzZ09EaIjMM4VzMoVShVt3HuC3g8ewc8/hPCONM8qWLYsjR46gatWqbi4hxSM/FA/3oHh4F1+IByHEN7Ru3RonTpzA9u3b0adPH08XhwB48803sXv3bqxduxajR4/2dHHcjurzvKg+LxpKwBCflJmZiX79+mHXrl15XgsJluKjicMxoHcXlImJ9EDprJnNZmi1emh1Oqg1OiiUKiSnypEmV0Cp0sBoNMFgNEJvMEKj0UGhUuO/B09w6+59JKfIC93/yy+/jP3796NChQqu/2UKQPHIQfFwDMWD4kEIIba6dOmCffv24dtvv8WwYcM8XRwC4J133sGPP/6IpUuXYurUqZ4ujkdQfZ6D6vOiowQM8VkZGRkYOHAgduzYUeA2zRrVRc8u7dCkQW1UKh+LmOgIcLncQvdtNpuRkZEJvcEAnc4AtUYLrU4PrU4PeboSCUkpUKo00Gp10OkN0Or0UCjVUGu0SFeooFJroNMboDcYoVCqodPpnfmrA7A0+fvss88wYsQIBAQEOH3/jqJ4UDwoHgWjeHhXPAgh3q1///7Ytm0bVqxYgUmTJnm6OATA+++/jw0bNuDTTz/FnDlzPF0cj6H6nOrz4vL3dAEIKaqAgABs3boVr7zyCj7//PN8+wmf+fsyzvx9Odd7/BETFYHQEBkC/P3B4XCQkZkBkynDkgHW6qDWaKHXG5Gdne3OX8du0dHR6NevHz7++GMEBwd7ujgsigfFwxtQPLyLt8aDEOLdaAwY78NMta7RaDxcEs+i+pzq82IzE1ICPHz40Pz222+bAZS4Hw6HY65cubJ56tSp5jNnzpizsrI8/XEXiuLhXSge3oXiQQghLzZp0iQzAPP06dM9XRTy3OzZs80AzGPHjvV0UbwG1eekKPwBcJ5/0IT4rHLlyuHnn3/GqVOnsGHDBvz6669QqVSeLla+/P39ER4ejvDwcMhkMvD5fPB4PAQFBUEsFkMkEqFMmTKoWrUqqlWrhkqVKiEwMNDTxXYIxcO7UDy8C8WDEEJeTCqVAgDUarWHS0IYYrEYAMUkN6rPSVFQFyRSorRo0QItWrSA0WjE0aNH8euvv+LkyZO4f/8+9Pri9YP09/eHUCiEWCxGdHQ0QkNDIRQKIRQKIRAIIJVKIZFIIJPJ2BMbn8+HRCJBZGQkxGIxxGIxgoKCwOFwnPQbezeKh3eheHgXigchhOSP6e5CN/veg5lm2FsTDJ5E9TlxBA3CS0oFs9mM5ORkPHz4EE+ePIFarUZGRgbMZjMCAwMRGBgIHo8HkUgEiUQCPp+PoKAgCAQC8Pl8iMVi8Hg8T/8aJQbFw7tQPLwLxYMQUtpt2rQJQ4cORYcOHXDo0CFPF4cA2LJlCwYPHkwxcQDV5yQ/lIAhhBBCCCGEeI2DBw+iU6dOqFu3Li5duuTp4hAA8fHx6NWrF5o2bYozZ854ujiE+Cw/TxeAEEIIIYQQQhgREREAgMTERA+XhDBoDBhCnIMSMIQQQgghhBCvER4eDgBIS0vzcEkIg6ahJsQ5KAFDCCGEEEII8RrMgK+ZmZnFHsSUOAefzwcAigchxUQJGEIIIYQQQojXYFpbADTrjrcICAgAAGRkZHi4JIT4NkrAEEIIIYQQQryGn58fpFIpACA9Pd3DpSEA2Nl4jEajh0tCiG+jBAwhhBBCCCHEq0RFRQEAnj596uGSEIASMIQ4CyVgCCGEEEIIIV4lJiYGAJCUlOThkhAgpwtSVlYWzGazh0tDiO+iBAwhhBBCCCHEq4SGhgIAUlNTPVwSAuQkYADAZDJ5sCSE+DZKwBBCCCGEEEK8ikwmA0CD8HoLf39/9v9ZWVkeLAkhvo0SMIQQQgghhBCvIhQKAQA6nc7DJSEAwOFw2P9TFyRCio4SMIQQQgghhBCvQrMgEUJKIkrAEEIIIYQQQrxKcHAwAErAeIvs7Gz2/35+dAtJSFHRt4cQQgghhBDiVUJCQgAAaWlpHi4JAYDMzEz2/7nHgyGEOIYSMIQQQgghhBCvIpFIAAAajcbDJSFAzsxHHA6HEjCEFAMlYAghhBBCCCFehcfjAQCMRqOHS0KAnARMQECA1YC8hBDHUAKGEEIIIYQQ4lUCAwMB5Nz4E88yGAwAgKCgIA+XhBDfRgkYQgghhBBCiFcJCAgAAGRkZHi4JAQA1Go1gJyuYYSQoqEOfKRU0Wq1uH79Op4+fQq5XA6FQoH09HS0bNkSHTt29HTxSh2Kh3eheHgXigchpDSjFjDehUnAiMViD5eEEN9GCRhSol27dg0HDhzA+fPncenSJdy6dQtmsznfbVeuXAmRSASZTAaRSASBQACxWIzg4GBIpVKIxWJwuVw3/wYlC8XDu1A8vAvFgxBCcggEAgCATqfzcEkIQAkYQpyFYy7o6o4QH5WcnIwtW7bg+++/x5UrV5y2Xw6Hg+DgYEgkEgiFQvD5fAQGBiIwMBAikQh8Ph9BQUEIDAwEl8uFn5+lh192djYyMzNhMpmQkZEBg8EAtVoNnU4HrVYLvV7PvsYMNCeRSBAREYGIiAiUKVMGsbGxaNCgAVq0aOFzTT8pHt6F4uFdKB6EEJK/e/fu4aWXXoJQKKSZkLzADz/8gEGDBqF9+/Y4fPiwp4tDiM+iFjCkxEhPT8eMGTPw3XffuaS/sNlshlwuh1wud/q+bcnlcjx48CDPei6XiyZNmqBjx454//33ERER4fKyFBXFw7tQPLwLxYMQQl6Mz+cDAPR6PcxmM82842FKpRIAIJPJPFsQQnwctYAhJcLu3bsxevRoJCUlFboth8MpsFm/LxGJRJg8eTKmTZvmdc1BKR4UD0+jeHgXb44HIcQ7paWlISwsDIBlIF5/f3pu7EmLFi3CjBkzMHToUHz33XeeLg4hPosSMMSnZWdnY8KECYiLiytwmzLRkXijw6t4pW511K9dHbVrVMGJ0//g8LEzMBiN0OsNUGt0SJWnQ6PVQaFUQ6vTQ683QqXWIDs7242/keMiIiKwYsUKDBgwwNNFoXiA4uFtKB7exZviQQjxbkqlkm1todfrafpjD/vwww+xePFiTJo0CStWrPB0cQjxWZSAIT5t2rRpWLp0aZ71QUE8vN3jdbzbvydat2hY5MEos7OzoVJroFZrka5UITVNAY1WB61OD6PRBKPJBKPRBI1WB4PBsmwyZSArOwtZWZYbIS7XD1w/Lni8QHC5fgji8SARCyHg8yEQBEHAD0JgYAD8uf7g8SxTLsrTlUhNUyAhKQXPElNw7eZdnLvwLzIyMgss6/Tp0zF//nyPPiGieOSgeFA8bFE8cnhDPAgh3k2tVrPjSGm1WnZQXuIZo0aNwldffYW5c+fik08+8XRxCPFZlIAhPmvFihWYMmVKnvVdXm+FtUs/RrnYaA+UynW0Wh1OnrmAn37Zhx9+3pvvk+6ePXti69atbL9pd6J4UDw8ieLhXbw9HoQQ76fRaNguixqNBkKh0MMlKt0GDBiAn376CStWrMCkSZM8XRxCfBYlYIhPOnz4MDp27Gg1NoK/vz82LJ+DoQN7lfiB2q7fvIePPluB3w4cy/Na9+7dER8f79bPgOJB8fAmFA/v4m3xIIT4Bq1WC5FIBIASMN6gc+fOOHDgAL777jsMHTrU08UhxGdRAob4nMzMTNSqVQu3bt2yWr9xzTy8O6CnZwrlIV9v3omx0+flaeq/fv16jBo1yi1loHjkoHh4F4qHd/GGeBBCvJPJZMKlS5fw119/4fHjx1AoFEhJScGvv/4KgLogeYOmTZvi7NmziI+PR48ePTxdHEJ8FiVgiM/ZtGlTnsz7vFnjMWtq6byAP3H6PLoPGA+lSs2uE4vFuH79OmJjY11+fIqHNYqHd6F4eBdPx4MQ4h2MRiPOnj2L48eP4+jRo/jrr79gMBgK3D4iIgJVq1ZFp06d0KZNGzRp0oTGkHKz6tWr4+bNmzh27Bhat27t6eIQ4rMoAUN8SlZWFmrXro0bN26w6xrUq4FzR7bBz8/PgyXzrP2HT+KNvqOt1vXo0QPx8fEuPS7FI38UD+9C8fAunooHIcTz0tPTsXr1asTFxSE5OdnqNVloMOo2qo8KVSrDz88PG1dtKHA/QqEQTZs2RdOmTdG/f3/UrFnT1UUv9WJjY/H06VOcP38eDRo08HRxCPFZlIAhPmXfvn3o0qWL1bq92+LQ5XXKxL87dhY2//Sr1bpr166hRo0aLjsmxaNgFA/vQvHwLp6IByHEcxQKBeLi4rBs2TKkp6cDAELDw9Dw1SZo0qo5GrdqhopVK7PjQaUkJKH1S43A4XCw/8pxaFQaXD53AWdPnMbZ46ehlCvYfXM4HPTu3RuzZs1C3bp1PfHrlQpSqRQqlQq3bt1C1apVPV0cQnxW6X0ER3zSgQMHrJZr16iCzu1f9VBpvMvyedMRGiKzWrd+/XqXHpPiUTCKh3eheHgXT8SDEOJ+Wq0WH374IcqVK4fZs2cjPT0dL1WviiUbV+PonbNYsWUd+o0chErVXrIajFuRrgAAiGUSlKtUATXq1UL/9wZj5Q/rcerhJcSfPYS5qxeiXTfLAOc7duxAvXr10K1bN5w5c8ZDv23JZTAYoFKpAADh4eEeLg0hvo0SMMSnHDlyxGq5b69Opbopf24hwVK8N6S31boffvjhhX2qi4viUTCKh3eheHgXT8SDEOJef//9N+rVq4fFixdDrVajSo1q+OLbVdh99iC69OmBgICAAt+reT5OlDRYluc1Pz8/VK31MvoMG4jV275G/NlD6Ny7G/z8/LB37140b94cXbp0QUpKiqt+tVInNTUVgGUGP5lM5tnCEOLj6EqQ+IzExESrsRQAoH3rZh4qjXd6b8jbVsvp6enYs2ePS45F8SgcxcO7UDy8izvjQQhxH7PZjNWrV6NFixa4e/cuospEY83P3yD+3CF069cLXC630H2olZYEjPD5NNQvUrXWy1i2OQ57LxzFW0P6ISAgAPv27UPdunXxxx9/FPv3IWCTWaGhoVYtlQghjqMEDPEZp0+ftlqWiEVoUI/GC8itQrkyaPtqY6t1rrr4oHgUjuLhXSge3sWd8SCEuIdSqcTbb7+NCRMmICMjAx16dMbuswfxWpfXHbpx12o0AACRpPAEDKNClUr4fO1i7Dy1D5WqvYSEhAS0b98eU6dOpdZ1xaRUKgEAwcHBHi4JIb6PEjDEZzx48MBquV7tl2kKwnx0btfSavnKlSsuOQ7Fwz4UD+9C8fAu7ooHIcT1nj17hqZNm2LXrl0ICAjAzKWfYuWP6/PtRlQYg86SMAni8x1+b5Wa1fDzyb3oM3wgAGD58uVo0KABrl275vC+iIVWqwVgmX2KEFI8lIAhPuPp06dWy+ViozxUEu9Wq3oVq+Vr167BFZOdUTzsQ/HwLhQP7+KueBBCXOvx48do1aoVbt68iciYKGw5sgvvjB5a5O4quuc3/AKRoEjvFwgFmPvlQqzd+R1CI8Jx/fp1tG/fHjdv3izS/kq7pKQkAEBYWJiHS0KI76MEDPEZtjc00ZE0Cnt+alZ/yWpZrVbn+eycgeJhH4qHd6F4eBd3xYMQ4jpJSUlo27Yt7t27h9gKZfHDkV2o07BesfapUli6vIglkmLtp03n9vj13CFUq1UdiYmJaN26Na5evVqsfZZGcrkcAM2ARIgzUAKG+IyEhASr5TLRER4qiXcrWyYKQqF1k11XPPGheNiH4uFdSks8OCG1wAmpBYPBCADIzMxk1zHa9RyOsJdaIjCyHmJrtsP4DxfAaDS5tZzuigchxDW0Wi26du3KJl82H9yBMuXLFnu/zCC8Epm02PsKCQ/Fd7//hOp1ayE5ORmdOnXCo0ePir3f0oTpgiSyY1BkQsiLUQKG+Ay1Wm21HCwr3lORkorD4aBC2TJW65KTk51+HIqHfSge3oXikaNOjapY+PEkrF0yG2KRAGu+3opvtuxyaxncFQ9CiGuMHz8e58+fhyw0GF/Fb0F0bIxT9qt9fg51ZBDeFwkOC8F3v29F5epV8PTpU3Ts2JGdWpkUjsaAIcR5aERA4jOys7Otlu2ZxrAojv15Dm27D8uz3s/PD2KREJUqxKJDm2aYPHowoiItfWHv3X+Euq3eglarBwB0bv8q9v28Lk/523YfhhOnzwOwzIry76ndKBcb7fTfQSYVWy0rFAqnH8Nd8QAci0lYqAyN2/fHxSuWKYD9/f1x/ug21K31stV7nzxNRI1mPaDWWC4qYmMicfV0PKQScZ7jFFdJikdRvh8AUKHu63j4+JndxzHLXddEvCTFozhWLPgQ8nQlFEoVdu45jJt37ntkelF3xIMQ4nz79+/Hxo0b4efnh1U/bkCFKpWctu/0tHQAKNIAvgWRBsvwVfwWDHytF27evImRI0di9+7dTtt/SZaebomHpJhdwggh1AKG+BDbG5jMzCy3Hj87OxtKlRoXr9zA4i+/Q/02vfH4iaWbQeWK5bDs82nstvuPnMT6jdut3r9i7fds8gUAVn8xwyXJF8A9NzSejgeQf0wSElOwKW4eAgL8n5crE8MnzEFWlnX5xkybxyZfAODrlZ+6JPkClI54vOj74W1KQzzsVbVRF1R+pTMOHj2FgW93wYhBb7m9DJSAIcT36HQ6jB49GgAwaMwwNHq1qVP3r1aoADg3AQMA0bExWLtzI/z9/REfH4+dO3c6df8lFXNeDgkJ8WxBCCkBqAUM8Rm2NzS2T5hdpW+vTmhYryZUai3i9/2Bf6/fAQAkJqVixbotWD5/OgBg1Lt9sGf//7Dv8EkAwAdzlqJDm2aoXLEcrt+8h9kLVrP77NW1HQb36+GyMgtspm3U6/VOP4an4gHYF5PZU0fhk0VxAIB/Ll3HirXf44PxQwEA23btw28HjrH7G/7Om+jUvmWe4zhLSY6Hvd+PWVPeg1KlzncfX32/E3fuPWSXx47o79Iyl+R4MDgcDsxmMzujEPOvbQuXX75ficSkVCyN24RtvxxAry7t8Vb3Dm4tqzviQQhxri+++AIPHz5EVGwMxs/5wOn7L+4sSC/ycp0aGPnBWKxbtApjxoxBq1atEBFB46a9CNMCRiaTebYghPg+DiVgiM/w97f+czVlZLjluJ3atcS7A3oCAKaOG4KIqq1gMlmOff3WPattv1n1GWq37IU0uQJarR6DR8/EH/HfYtDoGexgmJERodiw/BOXlpnP51ktu+KGxlPxAOyLycwpIxG/7yjbFWnOojj06toOwTIpJs5cxO4rNiYSy+ZNgyuV5HjY+/0YOaR3vu//adc+q+RLiyb1seJ50sZVSnI8GLExkXj8NBFPniWhSuXyePS8NVLZMtbTYbdq3hAA4O/PxVtDJmPTT/FuT8C4Ix6EEOd58uQJFi9eDACYvnA2BELnJ0kMegMAgBcU5PR9A8Co6ePwx28HcfvaTYwZMwY7duzwSBdMX8EkYKgFDCHFR12QiM8Qi62bqatUGreXQSoRQ5TrQiM0RGb1enRUONYt/ZhdPn3uEpp06I8Ll6+z675e+SnCw1xbgQXY3PxluODmzxviARQcE39/f6uuSHq9ASMnzcXkWV8gOUXObu/KrkeM0hKPwr4ftq5cu4URE3OSkdFR4dixcTkCAgJcVUQApSMevbq0AwD0Hf4BZs1bhbeHTgUAvNXNklw5cORPDB49Axs2/Yz1G7fj4wVrAAB1a1VzazkB98SDEOI8H3/8MQwGA15p3ggde3VxyTFMJsuMbIG8QJfsP5DHw4KvlsPf3x+7du3Ctm3bXHKckoLpgkQtYAgpNjMlYIjPEAisn7Don7cocReVSoMvN/wAebqSXdenZ8c8273dsyMGvp1zQXLl2m32/8PfeRPdOrVxaTkBy9Ps3GzHP3EGT8cDKDwmdWpWw+ypo9jl/508h++37WGXXd31iFEa4mHv94ORrlCi16CJ0OksrR0CAvyxc+NyREeFu7yspSEeCz6eiGnjhyJdocKyuM1IV6gwfcIwzJ89AQAQFirDv9fv4IM5SzF51mIYTSZ8NGk4Ppk+2q3lBNwTD0KIc8jlcmzduhUAMG3+LJe1Gsl43pIyINA1CRgAqFGvFkZ9OB4AMGvWLDr3vADNgkSI81AXJOIz+DbjBOieN091taHjZmPouNlW6wQCPj79cAx6vPFavu9Zs3gWjp48h4TEFHZdbEwkVsz/0KVlZdheEDHjPziTp+IBOBYT265IDHd0PWKU5HgU5fuRnZ2N/iOm478HT9h1qxZ+hOZN6ru0rIySHA+GUCjA4k+nYvGnU/N9vWH9Wrh43DsGn3RHPAghzrF9+3aYTCZUq10DdRu/4rLjGJ4n523Ppc42bNL72LL2O9y/fx+///47unfv7tLj+SKdTsd2DTUYDDCbzdRdi5BioBYwxGfYVsJGo8lDQKQ/vwAAMz9JREFUJQF6dXkNo4f1LfD1J0+TrFoCAEBKWjo7DoOruaNi9KZ4AAXHxLYrEsMdXY8YpS0ehX0/Zs1bhYNHT7HL7/bvidHD+rmjaABKXzy8HV3IE+I7vv32WwBAr3fyH9fLWZgb/iCBa8aAYfAFfLz9rmXg96VLl7r0WL4oMTERX375JVQqy6xUTZs2hUQiQbt27fDpp58iIcE7ZzskxJtRAob4DNtxITLd1FS0b69OWPDxRHTt2Jpd9+OO39Fr0MR8n9RmZGRg0OgZeW64jEYTBo+ZWWLGN/BUPADHY1KnZjU0a1SPXS5fNsYtXY/cyVe+H7/8dhiLVn7LLjeoVwPrln2cZztf58nvByGEuMLly5fxzz//wD8gAN36venSY5med9t01SC8uQ0cPRQBAQE4efIkTp06VfgbSoFr165h0KBBKFu2LGbMmGH1mkajwdGjRzF37lxUrFgR48aNg1KpLGBPhBBblIAhPsP2Kam7pnXt1K4lZkweid9+isOod99m1x8+dgY/7tibZ/tPFsXh0r832eUxw3Oe7F+4fB2fLV7v2gLDPU34PRUPwPGYAIAnH7KX5Hg4Eosbt+5hyNhZ7HJYaDB++X4VgoKsZ8FxtZIUj6FjZ0NUthHS5AoAwLOEZPR8ZwKEsY0gq9AMQ8bMfOEAwJt/+hW1W/SCf3hdcEJqYdPWeJeU80WoyxEhvmHjxo0AgNe6tEewCycTyMrKYsdjCXThGDCMqDLR6D7gLQDAypUrXX48b5aZmYkFCxagfv36+OGHH5CZmfnC7Y1GI+Li4lCnTh0cP37cTaUkxLdRAob4DG9opr7ok8lW3VY+XbzOatC2M+cuYfGXG9nlkYN7I27JbAzul9OneOHKb3D2/BWXljMry/pmj8vlFrBl0XlDPIDCY+INSks8XhQLpUqNnoMmQqPRAbB8Btu+WYJysdFuL2dJicftuw/w/fY9eOftruyMUwNHfYg9+/+HqWOGYFDfbvh+2x5MnLGowH1odXq0at4A9Wq7f/YjhjviQQgpvp07LeNG9RrUx6XHyczVUpjr757zweCxwwEAv/zyCzvjT2ljMpnw1ltvYdasWQ631n706BFef/11HDt2zDWFI6QEKdEJGIPBgJkzZ+L1119HhQoVIBaLERAQgLCwMLRo0QILFy5k+zQS72f7BNkTN5wyqQRjR+S0aLn73yNs330AAKDV6jB4zEz2hrNi+VgsnzcdALB60Uz2RjMrKwuDx8xkZ39xBdsEhCtuaLwhHsCLY+ItSks8CoqF2WzGoPdn4PbdB+xrdWtVw8UrN7B09cZ8fx67cLykkhKPr7/fiezsbPR7szMA4NqNuzj259+oX6c6Pps5Dl8umoGI8BBs+fm3AlvBjBneD3FLZuPlKhWdXj57uSMehJDiSUlJwdOnTwEADVs0cemxsrNzWsW563xQpWY1lKtcAdnZ2Th9+rRbjultxo4diz179hS+YQFMJhN69uyJ27dvF74xIaVYiU7AaDQaLFy4EIcPH8bDhw+h0WiQmZmJtLQ0nD59GjNnzkSjRo2Qnp7u6aISO9g2U/fUDf+k9wdBIMgZYHPB8q9hNpsx9eMluPvfIwCAn58fNq+dD5HIMhWtRCLC5rXz2TLfvvsAH366wmVlzLBpMmo7HoUzeEs8gIJj4i1KUzzyi8WjJwn47cAxq+0uXL6OaZ8sK/Dn3oPHLitjSYnHof+dBpfLRZMGdQAAd/57CAAoFxvFHrNcbDSysrJw/9GTAvfjae6IByGkeC5fvgwAKFe5AoRikduOy/Fz360Kk1g6ceKE247pLeLj4/HNN98Uez9KpRIjRoxwa7d0QnxNiU7AAECZMmXw9ttv44MPPsCCBQswZcoUlC9fnn399u3b+OqrrzxYQmIv25M5142Vcm7hYSEY8U7O4HPXbt7FT7v2YcOmHey6KWMG49VmDaze16ZlY0wePZhdjvvmJxw5dsYlZTSZrJuOuqIPtbfEA8g/Jrv3HvFYeWyVpnjkF4tdew57pCwFKSnxuHv/MUJDpODzCx6kMveTZG/ljngQQorn4sWLAICX69Rw63HNbryRb9C8MQCUum40Wq0WY8aMcdr+Tp48iS1btjhtf4SUNP6Fb+K7wsLC8ORJ3qd+U6dORZkyZdjlBw8euLFUpKhs+6P6u6hfcJuWjWGWX33hNqsWzcCqRdajwg/o3aXQfS+bNw3L5k0rVvnskZlp3aTfFU+U3RUPoOgxye3Yb5ucXCr7laR4FDUWU8YOcUl5iqIkxSN3y5oqlSwPFx4+tnTfMpvNePQkAVwuFxXLxQIADM9nFnH3wMcv4o54EEKK59KlSwCAl+vUdPmx/PxyzmvubEnRpE1zAMDff/8NrVYLoVDotmN70vbt250+nfS6deswZIj31PuEeJMS3wImt6ysLDx9+hQbNmywWl+zpusrE1J8BoPBapnvhqkJfZU7mvRTPOxH8fAuJSUelcrHIjVNwSZValZ/Ca2aN8Slf2/ik4VrMG76fKSmpeOdPl0hkVi6DPBjGoAf04B9z4XL1/HN9ztx777lYcWJ0+fxzfc72cGSOSG1wAmpxW7vCtQFiRDv9/fffwMAatSt5fJjBeRqBZdhcmww2OKIKVsGUWWikZ2dzf6+pcF3333n9H2ePXuWxoIhpAAlugUM49ixY2jbtm2+r7Vq1QojRoxwc4lIUZhMJqvlwEC6SC9IRob1DY2/v/O/6hQP+zkaD7PZDJPJZDX9I4fDgb+/PwICAvIdT4TiYT/beLhikEd3xOP1ts1x9cYdnLvwL1o1bwgA+HHDIoyZNg9L4zbDn8vFO326YtXCjwrcx579/8Oni9exyxu3xmPj1ni0b9MMQqFlLB8OhwM/F3Zpc8f5yldlZ2ezU/Lmbgng5+cHLpcLf39/r5gBraQwm83IzMxEZmYm+3n7+fnBz88PAQEBLv0eeLtHjyxj3FV++SWXH4v5zLOzs5GZ6b4EDABUq10diU8TcPv2bbRp08atx3YXs9n8/LPNhMFgwLlz51xynL///htVq1Z1yb59DfOZMz9ZWVnsWHF+fn7gcDh0Ti9FSvVVzoABA7BhwwYE+dCTYrPZDJVKhaCgIAQGBvrEl9RsNsNgMEClUkEul+PZs2dISkpCamoqVCoVtFotFAoF5HI55HI51Go1jEYjTCYTMjIyYDKZoNPpkJaWZrXfgIBS/ef7Qiab7g9arRa3bt2CWq1GYmIiUlNTodVqodVqoVarodFooNfrYTAYoNfrodFooFarodPp2B+TyQSj0Qij0cjGJTeKR8Fs4/HNN99g9+7dUKvVUKvVMBgMyMjIgMFggNFoLLTJdUBAAPh8PsRiMSQSCUQiEe7fv2+zDcWjILbx+OijjzBnzhwEBgYiMDAQ/v7+4PP5EIlEEAqF4PP5CAoKglQqRXBwMCQSCSQSCUJCQhAVFQWpVAqRSASZTIaQkBCIRKI8XZBcEY+Rg9/CyvVb8HP8QTYBE1smCnu2rinwPbbdx+Z+NBZzPxqb77b/Xrc8vXx/aB+XJvRs43H48GH4+flBJpMhNjYW4eHhkEqlCA0NhVQq9YmbYL1eD7lcjvT0dDx79gxPnz5FcnIylEoldDode57V6XRQKpWQy+XsOVmr1bLnWNsZovLD5XLB4/HYH9vzQ0hICAQCAXg8HiQSCSIjI9nPUiQSQSwWIywsDKGhoRCJRODxeD5xbcHIyspCSkoKHj9+jLS0NKt6zWAwQKvVIiUlBWlpadBoNNBqtdDpdGwdZzQa2ZhkZGS8cAD3gIAACAQCq/NDUFAQRCIRBAIBJBIJwsPD2fOARCKBTCaDVCpFZGQkypQpg+DgYJ/7fBMSEmA0WlrB8QUCtxw3IDAARoOxSC1gzGYzjAYjNCo1lOkKJCckIS05FelpcmjVGui0OqiVKijTFVDKFdBqtDAZTcjIMCHpaSIAYMaMGRg8eLBX3SMw18JqtRopKSnseSM9PR1yuRwKhQJKpRJqtZq9vtZoNOzfPXONYTAY3DJRwcGDB1GzZk1IJBIEBwdDLBb7VII9MzMTSUlJ7OfMnCd0Oh17TklOTkZCQgKUSiV7nczEQK/XW93P2IvL5SIwMBABAQEICAiASCSCVCplrz2EQiF77ScWizFjxgwI3PS9JM7hO9+CYqhcuTKWLFkCo9GIhw8f4pdffkFaWhq2bt2KCxcu4MCBA1YD83ozk8kEmUwGwPJUUiqVIiQkBGKxGFKplL0okMlkkMlkkEgkCA0NRUhICHsjwVyk8fl8CIVCq4s25qmD2WxGVlYWexGYkZHBnsR1Oh20Wi30ej17A6nVatkTjkajQVJSEntSksvlVk/ynSWQmqkXSKG0nl79s88+w2effebSY1I8CmYbjzt37uDOnTtF3l9GRgYyMjKgUqnYaUFtUTwKZhsPwHJutU0qFodtksAV8Xi5aiUM6tsNm7f9is9mjENIsNSp+z9+6jxioiOwaM5kp+7Xlm08jhw5giNH8h9E29/fHzExMYiIiIBAIGB/mASNRCIBj8eDUCiEWCxmEw+5b5iZ+i4wMNCq7mNuipn6j7kx12q17AMElUplVeelp6ez9V1SUhJSUlLYhwjukpWVxSbKnUEkEiEqKgoikYhNLjA/wcHBCA4OhkAggFgsZhOSzPVEUFAQAgICEBQUBD6fzyY0c3++uZ8AZ2ZmwmQywWAwsNcTarUaaWlpSE9PZx8OGI1Gdn1qaiqUSiX74Ealyvt9dpWMjAwolUoolcoi74PL5UIoFCI0NBTR0dGIjIyEVCqFUChkb6hsl8ViMXsNxySEmc+V+Wxzf77MZ5uZmcnWFxkZGdDr9VY35Xq9HgqFAunp6VCpVFAoFOzfODPtdFJSktXNeue6rSELkUEgEkEsFSMoKAgCkQBiqRRiqQQiiQiykGBIg2XgCy1lDeTxEMALtPxdCPkI5PEsfxsBz/82/PyA59+7zAxLmQODeDAajLj413k8vv8Iep0OBr0BOo3WkkTR6aFRqqDVaKHTaJGWnIq0lDSkJiZDma4o9nWnXC7H8ePHERYWhqCgIAQFBbHni9yffe7P32w2sz+5P3/mJjz39TPzWTPXzrZJQ+Y8o9Fo2HNNcf7uPGHLli15BuPlcrkQCATsOSUkJIS9j2ESC0zSkkkKSyQS9nWBQMAmJphYMJ8/E4OsrCz23oX5u2ceICqVSvZz1uv1UKlUSE9PR3p6OhQKBZKSkvDs2TMkJibmefDrLllZWdDr9dDr9QBQaDk++qjgVq7EO5WKBEzZsmXxwQcfsMvz5s1DvXr1kJCQgJs3b2LSpEnYvXu3B0tov9zjCpjNZigUCigUCs8VyAEcDgcSiQTR0dGIiYlBaGgoZDIZe8JlTsISiYR9Es38CAQCjBw5EmfPnmX3R0/4C5ausL4g5XK57IVceHg4IiIi2JsRJpvOXNQxNyrMzQvztC8wMNDqAqRfv344cyZnFieKR8Fs4zFx4kS0bdsWYrGYvckJCAiwSoYGBgaCy+WyN/JMc2GmBVLuBKhGo8G0adNw8+ZN9hgUj4LZxuPbb79F+/bt2SQM0xqJeWrItA5jLoDVajWUSiVSU1ORlJQElUoFjUbD3sQAeQeOdFU8NsXNx6a4+S7Z97iRAzBu5ACX7Ds323h07twZoaGhSEtLw5MnT9gLY41Gg8zMTDx69IjtDuHNuFwuZDIZoqKiEBsbi8jISAQHB7M30blbTYSGhkIoFLI/zDkg93mA+Ze5wWB+mKeuzNNt5u9XrVazT8R1Oh0MBgMUCgWSk5ORlpbGPiFXqVRISUlh/3Y1Gg3u3r3r4U/PMX5+foiKimLrNuZmLSgoiE12hIeHs/Uek0BiEnRMPcech5kbbCAnYZSZmck+/WZaMDGtCnK3ZkpOToZCoWBbJjDJO+ZJelZWFlQqFVQqVZ6Wi75ArVRBnU8S21WmD5tY5PdyOByIJGKER0UgPCoCstBgSKQS8AUCCCUiyIJlkAbLIJSILTf0gQGI/3EnfvvpFwBAp06dnPVrOE1AQADEYjFCQ0MRFhYGoVAImUzGtmpjWpow34Hc13M8Ho9NJgUEBIDL5eLy5csFDtNQXMHBweDxeFCpVGyCOCsri7128QX+/v4IDg5mzxt8Ph8CgQAhISEIDw9HWFgYypQpA5lMxib1cz8U5z1PNgYGBlqdx3Ofz7Ozs9nzOpO0y51A0mg0bIKUSZ4y1x1qtZpav/igUnmFHhERgaZNm7JJF1+abk4ikcBoNLKZUabJIVOZMzdlTKWvVCrZJ0nMjQSTBWaehBiNxhc+KeByuWwTOOaCkblhz32SZ5rGiUQihIeHsxdDERER7E1+cZqO2zbfEwnphFMQrU5vtbx//3506NDBqcewfcJL8SiYbTy6dOni9Hh88sknVssUj4LZxqNs2bIoV66cU/bNtEZo1qwZrl27xq6neBTMNh6TJ0/O9/thNBqRnJyMJ0+eWDUJZ258U1NT2dYnzBNkpotJ7hvm3E3CC+viw7TsYJrQS6VSNnHKrGPqOya5LZVK2ebivtTVJDMzE1qtlm3Rk/tpPHOhL5fL2YSOSqViu/Uw1xO5u1Pq9Xq7ujkwXf6Y6wmxWMw+kBGJROxNDHPTyTy8YVoABwcHIyQkxCe6NjDXbUy3qISEBCQnJ1t1F2GSvEx3tNytrphrP3tb63E4HKvWAszfM3M9x+fz2c8x998t81nHxMQgOjoaHA4HMTExAICf/heP7OxsaFQaaNRqGPUGaDVaqBRKyzqVCgq5Aqp0y9+JUW+wJLeNJhj1Buh0OmQYTYVedzI3pWGR4ZCGyCwJBH4QhCIhhCIR+EIBRGIRhBIRBEIhQsJCEBYZgZDwUIRGhEEktmzj6HXn2eOnAVjuFWQyGft3zSQ4HW1Z4+fnxz5cYa6fmcQr01I9dwsPptUZkzTJfa5hkrjOVKdOHafuL7fFixez42yaTCb2XKHT6azOKcx9DDMkAZNskMvlbLKB+Q7odDo2MVEYPz8/q4eHQUFB7GfNPHBkzjcymQzBwcEICwtDbGwsew8TGhrqknHiSOnm/bVVMRw+fBj16tVDeHi41frU1FSrlhS+dIHE4XDYTKpUKkVUVJRT9pudnZ3nYpRJvHhLf/v09HSr5WCZxOF9mM1mNG7fD+cvXkNQEA//XTiA6Kjwwt/oJnq9ARXrd0RSchrKlonCrXN7wec73v9YobR+siCVOrdrAkDxcATFwzl8IR5cLhdisThPd5CixMMR12/ew7gP5+P0uUuQiEUY2LsLFn86Jd8Zhdr1HI7LV29BpdYgIiwUvbq2w9LPPgCPF5jPnl3P3njweDyULVsWZcuWddqxma62zM0eAHYwRG+q/9zB39+fvQl3xsCZTDcMZgBh28/Xz8+v1A04yefzUaZMGQAo1mfMtMhhPlfmB7AeoNlZf7+5W/TFViiH0Igwp+wzMyMDWVk5++Zy/eD//HvX59WuuHrhCj6L+wJtOrcv9vHsxXyO/fv3x8qVK/N9nfmbZgZSzZ1oZLrCODsGrhISEoLKlSvj3r17Tt937kGMAwMDERIS4tT9M928bGNQGs/fxLeU6L/MuLg4xMbGolu3bpg9ezYWLFiAsWPHolatWnj27Bm7XdeuXT1YSu/AZOhz96nn8XhedfKyba4oEYsc3seW7Xtw/qLlqfSIQW/lubk8f/Eq+g3/ADE12oIXVR+R1Vqh+4BxOHLsTH67c8jDx88gKdeEndaVE1ILm7bGW23D5wfhg7HvAgAeP03E0jWbHD6Opb+x9dMxicT5N3++GI8Hj55i4kcLUbtFL4jLNYZ/eF1IyjVB3VffxNTZS/Dk+eB7DIoHxaOonBEPe2VmZqLHO+Nx+twlzJs5Hu1aNcHK9VuwYPnX+W5fp0ZVLPx4EtYumQ2xSIA1X2/FN1t2uax8L+KueBSEy+VaxrB4/mSaeTrtbfWfL2JaXxT0+RY0oxspXO4n+0yXCObzZboMO/Pv18/Pj20B8+i/B07bZyCPB76Az/4E5vreBQkss7DpbVrIuZpOqwWAArt1MDMSBgYG5vnsc3dTcXYMXKljx45O32flypVRuXJlp+83N39/f6vvgLfevxBiq8T/dZpMJuzduxfz58/HrFmzsHbtWiQlJbGv16tXD8uWLfNgCYk9srOzi/2EPysrC3MWxrHLk95/x+r1b77fiSYdBmD77gNISEyByZSB5BQ5fjtwDB3eHIlPFhY8s0hhzGYzhk+YA7VGW+i27w/tC8HzC4/Fq7+DUuVYP1mNNu9AjEKh0KF9FMYX43H+4lXUafkmvvzqR1y9cQcajc7SF1mjxZVrt7F87WbUbvkmrt+0fgpE8bCgeNjPGfFwxMGjp3D3v0fo0qEVPhg/FF+tmAsul4u4b7flu/2KBR/ire4d8FqrJihf1nJT5akbYXfEgxBSfPXq1QMA3Lxy3S3HEzw/D+g0zhlc2l6JTxIAgG2pVBqMGjXK6fucMGECJVgJKUCJTsCMHTsWo0aNQr169RAREcFmSsuXL49u3brhu+++w7lz5/J0USLeR6FQ5OmrHx7qWD/YvQeP4+FjS8un5o3roXLFnDEfLv17E6M/mMc2s23asC7mzRqPzu1fZbf5bMl6/H7oeJHKv37jdvxx/C+7thWJBOjeqQ0AQKPRYfNPvzp0rDR53lHyQ0NDHdpHYXwxHp8simMTYBwOB4P6dsO8WePR5fVWOb+XUoWlazZavY/iQfFwlDPi4Yg79ywD0paLjQYAiMVCBMskSEmVF5igqtqoCyq/0hkHj57CwLe7YMSgt1xWvhdxRzwIIcVXt25dAMDNf92TgBE9bzWodfNgrckJloe0pSkBU6dOHbz55ptO2190dDSGDRvmtP0RUtKU6DFgOnTo4PSBLoln5DfTk1Qidmgf3/2YM9PVW92s/y4WrviaHVitYvlYHN+7CYGBlrETWnYehFNnLwIAPl+yAV1eb+3QcR88eorpc5cDAHp2eQ3xvx8t9D29u7+Obb/sBwB8+8MvmDDqnULekcNgyDv9KZ/Pt/v99vDFeNx78IT9/xsdXsX36xayy5Xqd8L9h5bXU9LS87yX4kHxcIQz4lFctrMw2frl+5VITErF0rhN2PbLAfTq0h5vdXd/femOeBBCio9JwNy5dsstx2O7IOkNhWzpXE8eWBLa5cuXd+txPW3dunU4efIkUlJSir2vzZs3QyRyXbdbQnxdiW4BQ0qO1NRUq2UeLxAikf2zimRlZeHYn3+zy80a1bV67ffDJ9jlrh1bsTeXAPBm15zB387+cwXJKWl2H9dsNmPY+I+h0ehQ9aUKWDDbvukUc5fv3+t3kJIqt/uYBpvZiXg8ntObgfpiPGpUq8T+/8q127h6/Q5Mpgwc+/McEpJyLjg6tWuZ570UD4qHI4obD0dVqWxprfTwiaUFk1KlhkKpRnhYCCRiEQwGY55xVlo1b4g+vTrho4nDkZWVhU0/xbusfC/ijngQQoqvevXqAID/bt+1a3ar4mJawGjcOOW1PCUN6c/rE2cMRO1LIiIiEB8fX+wuoAsWLKCH34QUghIwxCdotdZjp4iEAocu0v+9fgcqtYZdrl+nOvv//x48gVabM8hbpfLWM2xUqhBrtXzl2m27j7v2223438lz8PPzw6Y18+yesSUmOgIR4ZbR4s1mM06fu2T3MfU2T5Rd8TTZF+Mxf9YEREVaZm54/DQRtVv2Ai+qPtp2HwaDwQixSIg5097H6GF987yX4kHxcERx4+Gojq+1QOWKZbHv8EksW7MJ702ai+zsbIwZ1hcPHz8DP6YByte1XBAfOPInBo+egQ2bfsb6jdvx8QLL2D11a1UDYGmxxwmphaiXHWvpV1TuiAchpPheeuklcLlcqNKVuHvD/uugohJJLa0GtXaMnecsNy5bBqGvWLFiqRyLqnnz5jh8+DA74LIjuFwuVq9ejRkzZrigZISULJSAIT7BdkBLscixivFpQs7Ay2KREEFBPHY5Ta6w2lYitt637bFS8+kSkZ//HjzGh59auh5NHTsEzRrXc6DEQERYzjgITxOS7X5f7htpABCLnd/1wRfjUb1aZfxz9Gc0aVAn39dbt2iIN7u1L3DkfIqHBcWjcMWNh6P8/f0Rv+VLNG1YB7Pmf4k/TpzFhPcGYuaU9/JsGxYqw7/X7+CDOUsxedZiGE0mfDRpOD6ZPhpAzhSs/lz39FB2RzwIIcUnEAjQvXt3AMDOjT+5/njPEyBam3OEKx2K/x0A0K5dO7cd09s0a9YMV69exZAhQ+yeSahBgwY4f/48xo0b5+LSEVIylOgxYEjJkXvacACIiXJs4GSFMmcQN9vpYG2b0ha2bM+TbKbrkVarR/WqlfD5zPEOlddSzpybNoUDTXCVKuuLFZlM5vCxC+Nr8QCAazfuoku/MexAs292bY+6tarh9LlLOHj0FPYePI4/TpzFoV1foWXTV/K8n+Jh3zLFo/jxKIpaNarg2G+b8qyvUK4MzPKr7HLD+rVw8fjOAvdz9cZdAMCEUQOdXsb8uCMehBDnGDFiBHbv3o19O/Zg2sLZ8Pd33W1EcKillWNacmohWzpHdnY2/vjtEACgb9+8LS9Lk+DgYGzatAlz587F+vXrcfToUVy6dAkZGRnsNmXLlkXr1q0xZMgQtG3bFlwu14MlJsS3UAKG+ITkZOsn3OFhIQ69XybNeapq+8Q1NERmtay2mfLQdvuQYGmhx9v2y34cP3UeXC4Xm9fOB48X6FB5LcfNaXYrk9o/ha1teV3RjNbX4gEAQ8bOZG/23+3fExvj5rGvvdZjGP538hz0egM++nQF/ty/Jc/7KR4WFI/CFTcennT81N+oW6sapowZ7JbjuSMehBDn6NChA0JDQ5GWkorTf5xEq45tXXas8KgIAECaA+PuFce//1yGPDUNIpEIrVq1KvwNpUCFChWwaNEiAIDRaERqair0ej3Cw8MhldpX1xNC8qIuSMQn2D5Rjo2JdOj9Mc8rcgBQa7RWM29UrlgWQmHOuAP3Hjy2eu+9+9bLdWoWPjBbUrLlgiErKwuN2/cHJ6QWOCG1ULFeR6vtho6bDU5ILWzaGp9nH8mpORcdZaIj8rxekJRU6+4Prphm3dfioVSp8c+lnKkzGzeoZfV6w3o12f9funoz331QPCwoHoUrbjw8aenn03DpxC6XPtnOzR3xIIQ4R0BAAPr16wcAOPDLXpceKyTc0s00Nan4s/LY48DO3wAAXbp0QWCg4w/NSjoej4cyZcrgpZdeouQLIcVECRjiE+Ry61lOQmSOnfxr16hiNQvJpX9zbuq4XC46t3uVXf7twDF2xhCz2Yydew6zrzV+pTYiI8LY5XfHzmKTK226vetQmV7kWUIyklMsvzOHw0FzB8aPUdsMWOeKitLX4pGVZT0l7/mL16yW/7mckwzgB+UdKJniQfFwRHHjURRfrPoWVRt1gV9obXBCauHYn+cK3Pb6zXt4rccwBEW/goiqrTB55hds0/Ibt+7BL7Q2Plm4xuVlBtwTD0KI8/Tp0wcAcGTPASjsHPOrKJgEjFLuumMwMjMzsffnXwEAAwe6p/slIaT0ogQM8QmJiYlWy8zsKfby9/dHq2YN2OW/zl+xen3G5BFs/9WHj5+hTbehmL9sAzq//T7OXfiX3W7W1LyDWuanSuVyeKtbhzw/ndu/arVdw/o18Va3DqhQznrE+dyzutSuUcWhLgxand5qWSQSFbBl0flaPEKCpahVvQq7vHFrPPoOm4rPl6zHG31G4+iJs+xrr7dtnuf9FA+KhyOKG4+i0OsN6NKhFSqWL/PC7TIzM9HjnfE4fe4S5s0cj3atmmDl+i1YsPxrAJbBkTu1a4llazc7NLZOUbkjHoQQ52nRogVq1aoFjUqN5XMWuuw4zDTUmZmZMOgNLjsOAPy4bhPSklMQHh6OTp06ufRYhBBCCRjiE1JTrQdhCw8Ndngfw995k/3/rt8OW732St0aiFsyix1A9K/zlzF7/mocPHqK3WbmlJHo3tm+/s5dXm+NnZtX5PlZu3S21XZjh/fHzs0r0KZlY6v1O/ccyrfc9rC9oREIBAVsWXS+Fg8AiFsyCwKBpSuN2WzGz/EHMWfhGuw/cpLdplxsNBbOmZTnvRQPiocjnBEPR839aCxWLPgQ0ZEv7sJz8Ogp3P3vEbp0aIUPxg/FVyvmgsvlIu7bbew2b/d4HVqtHlt37nN1sd0SD0KI83C5XKxbtw4AsHPTNlw+d8ElxxHkmj1Oo1K/YMviSUlMxpr5lhkr58+fj4CAAJcdixBCAErAEB+RkJBgtVyUJ8o93ngN5WKjAQCnzl7E/YdPrF4f9W4f/HVoK97u0RFRkWEICPBHWGgwurzeCgd3bsD82ROL/gs4QK3WYs+BYwAAkUiAIf17OPR+20EtJRL7Byi1ly/Go1Xzhvj3z18w/r0BqFW9CoRCPrhcLiRiERrWr4lPpo/G5ZO72DIxKB4WFA/7OSMernLn3iMAYD9XsViIYJkEKalyKJ/f5LRoUh8ArBJsruKOeBBCnKtly5Z49913AQBzJ8xEVlaW04/h5+cH8fMB1lUKpdP3z1j16RJo1Ro0atQIw4cPd9lxCCGEQbMgEa+XlZUFjcZmppUijKnA5XLx+cxxGDJmFsxmM5av/R6rv5hptU3jBrXx88Zldu9zU9x8bIqbb/f2tlPC5mf9xu3QP29u++GE4ZBKxC/c3pbttK7OvqHx5XhUqlAWXy6aWeDr+aF45KB4FM5Z8XCn7GzrMXmYQYNtB1h2BVfHgxDiGosXL0Z8fDxu/Xsde7ftRo+BvZ1+jLDIcKiVKiQ9S0Slai85ff9Xzl/C7i0/AwBWrVoFPz96Lk0IcT060xCf5OfHKdL7BvXtjob1LTOsfLNlFxIS3TO6vr30egOWrd0MAChbJgpTxw5xeB9pcoXVckiI66fApXgUjOLhPKUtHs5gNpthMBjZgZOrVC4HAHj4xDJTk1KlhkKpRnhYCJvMYm5CzGazy8vniXgQQoovPDwcH374IQBg2ccLkfg0oZB3OC4iypIMTktOLWRLx2VmZuLzSZYHDoMGDUKzZs2cfgxCCMkPtYAhXo+ZnSO3ovbR5XA4+PuP7cUtksvw+UFIvHm8WPtIsZmVIDQ0tFj7s0XxcAzFw3lKWzwcceL0edy++wBJKZbpuX8/dAJ3/3uE9m2aoWK9joiMCEXizePo+FoLVK5YFvsOn8SyNZtw7sK/yM7Oxphhfdl9PX5qGUS4UoVYl5fb1fEghLjOxIkTsWXLFly/fh3v9xqCLYd3st2GnEEaKgMApKfJX7yhg8xmMz6fPBvXLv4LqVSKJUuWOHX/hBDyItQChng9f3//PM1CbccNIBYJiSl4lpBsta5cuXJOPQbFw34UD+9SkuPx3Y+7MXLSXNz9zzLGy9I1mzBy0tx8yxe/5Us0bVgHs+Z/iT9OnMWE9wZi5pScGayYWabym4HKmdwRD0KI6/D5fOzbtw9RUVG4fe0mJg18Hyaj0Wn7lzxP5midfA5dM385dny3FRwOB5s2bUJkZKRT908IIS9CCRji9fz9/RETYz1N81Obi3Zi8edf1rMRiMVi1KxZ06nHoHjYj+LhXUpyPDbFzYdZfjXPDzPuVO6WQ7VqVMGx3zbBkHABqXf/xKpFMxAYmNNK5+f4AxAI+Bj4dleXltkd8SCEuFb58uWxd+9eCAQCnPnfn5gyeGy+LQGLgv98VjS9zWxpxfH10jisW7gKABAXF4eePXs6bd+EEGIPSsAQnxAWZj2LiO24AcTi8rVbVsvNmjUDl8t1+nEoHvaheHgXikfhbt7+Dwf+OIUpowcjJNi1gwe7Kx6EENdq0KAB9uzZAx6Ph6N7D2HSwPedMnORSGoZl8oZ+zKbzVj9+TKs+OQLAMC8efMwevToYu+XEEIcRQkY4hNsm4cmumBAtpLgwuUbVst169Z1yXEoHvaheHgXikfhXq5aCVmpV/D5rPEuP5a74kEIcb127dph9+7dCAwMxP9+P4yeTTri/Kmzxdqn9PkMcsVNwKgUSkx7dzzWLbK0fFm0aBFmzZpVrH0SQkhRUQKG+ISoqCir5ctXbxWwZemVkJiCQ/87bbWuTp06LjkWxaNwFA/vQvHwLu6MByHEPTp37ozjx4+jcuXKSHzyDO926ouNq74q8oxq0mAZAEBhM1i3Iy6fu4DeLd7Avp174O/vj7i4OHb2JkII8QRKwBCf0KRJE6vl3w+dYKdVJRabt/2KrKwsdlkgEKBrV9eM4UDxKBzFw7tQPLyLO+NBCHGfpk2b4tKlSxg0aBCys7OxZOY8jOszHOmpjs9kJJRYuiDptDqH35vx//buNzbOwrDj+O/A8dnxnziElDkUDYIwqFqCpa0pDCaGKGUbe2FEKoWkZYOhsJkXnVA2MW3ZJGg3sZFpG9AKVROwYXUVZVtgNF2IsvAnAlUVUVdSljZNQpwJJV0Tx3/OcWx8e0EXZiUQQvPcnZPPR8oLP3aee+5+VhR/fT5PTubLf/E3+dynb82+PYO55JJL8sorr6S/v/+UzwVwOgkwzAp9fX0plUrH3h4ZHcvml362p7aeSaanp/PE19bPOLZixYp0dXUVcnv2+GD2aCz2aCy13gOorfb29jz55JN55JFHUi6X8x/f3JRPf+KX86U1f5rB3W996PM0NzcnSY6eQsCenp7Oi9/anJXX9+WRL/513nnnndx2223Ztm3bcXEcoB4EGGaF7u7uXHXVVTOOfePZjXW6msbz5b//p+z44e4Zx+64447Cbs8eH8wejcUejaXWewC1VyqVcs899+S1115Lb29vxscqGfjKE/n1pdfl91fdne9++/WTnmPOT3872+TRkweYw4eG8sTffTW/0fur+b1bfzvbt30v8+fPz8DAQAYGBjJvXrEvKg7wYQkwzBq33HLLjLf/4evP5Qc799TnYhrIj3bvzR/82boZx3p6enLNNdcUerv2ODF7NBZ7NJZ67QHUR29vb15//fW88MILuemmmzI9PZ2N/7oht13fl89/Znke/uK6bN300gl/zKipqSnJu89qOZGhg0PZuuml/PHvrsn1ly3LX/7RA9n7oz3p7OzMvffem+3bt2flypUznpEIUG+l6kd9ZSyoscHBwVx22WWZmJg4duw3b7ouz33t0TpeVX2NjIzlM7euzmvf+e6M4xs3bsyNN95Y6G3b43j2aCz2aCz13ANoDG+88UbWrVuXp556KlNTU8eOz2luztJP9uaXrvlUPtH7C+nsmpd9u/dm7T1/mO6PL8pfPfFwDry9P//1n9/Pju99Pz/YviNvD/73jHMvXbo0/f39WbVqVdrb22t91wA+FAGGWeW+++7Lgw8+OOPYv/zj36bv5hvqdEX185ODQ/m1z96d72zbPuN4f39/Hn20Nl/k2eM99mgs9mgsjbAH0Dj27NmTDRs25NVXX82WLVsyODj4kc5z6aWX5tprr83q1atz9dVXe7YL0PAEGGaV4eHh9PT0ZP/+/ceOtbSU882vfyXX/8qyOl5ZbW155du5+977j/uRhkWLFuXNN99MZ2dnTa7DHu+yR2OxR2NplD2AxlStVrNz5868+OKL2bJlS3bt2pVDhw5leHg4k5OTKZfLKZfLWbBgQa688sr09vZmyZIlWbJkiRfvBmad0k/7iwjDrPH444/nzjvvnHFs7tzWPDvwcG647qr3+VuzX7VazZs7dmXtnz+cf/63Tce9//zzz8/zzz+fZctq+4WdPezRCOzRWBp1DwCAevIMGGad6enp3H777RkYGJhxvFQqZfVvLc+X/uQLWXBeV30u7jQbOjycHT/ck+f+fUu+8ewLx/3mkP9z0UUXZdOmTenp6anxFdrjROxRG/ZoLLNhDwCAehJgmJWmpqayYsWKPPPMM8e977z583LfF34nK5ffnAsXXVCHq5upWq1mbGw8Y5VKRkYrGTo8nAP/czA/OTiUw8OjmZg4miMTExk/MpHR0UqGhkeya8++7Ni5Owd+fPCk57/iiiuyYcOGXHzxxcXfmfdhj/fY49TYwx4AAGcLAYZZa3JyMqtWrcrTTz/9vh9z9SevTN/NN+RTv7gki3/+41nU/bGce+65Jz13tVrN5ORUxo8cSaVyJCOjYxmrjGesMp6Dhw7n7f0/zuHh0YyNVVIZP5KxyniGDo9kZHQsh4aGMzwymsr4kYwfmcjQ4ZFUKuOn864nefcp/Pfff3/uuuuuzJkz57Sf/1TZwx72eH/2aKw9AADqQYBhVpuamspDDz2UBx54IJVK5aQfP2dOUxb93Mey4LyuzGlqSqlUyuTUZI4enXz3O7pjlYyMjmV8fCLT09M1uAenrru7OytWrMjatWszf/78el/ODPawR73Zo7E08h4AALUmwHBG2Lt3b9asWfOB312erUqlUhYvXpy+vr4sX748y5YtyznnnFPvy/pA9mgs9mgs9gAAODsJMJxRtm7dmsceeyzr16/P8PBwvS/nhJqamrJw4cIsXLgwXV1daW1tTblcTktLSzo6OtLe3p4LL7wwPT09ufzyy7N48eI0NzfX+7I/Ens0Fns0FnsAAJxdBBjOSBMTE9m8eXPWr1+fl19+Obt37874+M/2ugZNTU1pa2tLR0dHuru7s2DBgrS1taWtrS1z587NvHnz0tnZma6urmNfqLS2tqazszMXXHBBOjo60tHRkZaWlpRKpdN0T2cHezQWezQWewAAnB0EGM4K1Wo1Bw4cyFtvvZV9+/ZlZGQkk5OTqVaraW5uTnNzc8rlctrb29PZ2ZnW1ta0tLRk7ty5aW1tTUdHR8rlcr3vxhnDHo3FHo3FHgAAZyYBBgAAAKBgXhkPAAAAoGACDAAAAEDBBBgAAACAggkwAAAAAAUTYAAAAAAKJsAAAAAAFEyAAQAAACiYAAMAAABQMAEGAAAAoGACDAAAAEDBBBgAAACAggkwAAAAAAUTYAAAAAAKJsAAAAAAFEyAAQAAACiYAAMAAABQMAEGAAAAoGACDAAAAEDBBBgAAACAggkwAAAAAAUTYAAAAAAKJsAAAAAAFEyAAQAAACiYAAMAAABQMAEGAAAAoGACDAAAAEDBBBgAAACAggkwAAAAAAUTYAAAAAAKJsAAAAAAFEyAAQAAACiYAAMAAABQMAEGAAAAoGACDAAAAEDBBBgAAACAYpUEGAAAAICCCTAAAAAAxaoKMAAAAAAFE2AAAAAACibAAAAAABRMgAEAAAAomAADAAAAUDABBgAAAKBgAgwAAABAwQQYAAAAgIIJMAAAAAAFE2AAAAAACibAAAAAABRMgAEAAAAomAADAAAAUDABBgAAAKBgAgwAAABAwQQYAAAAgIIJMAAAAAAFE2AAAAAACibAAAAAABRMgAEAAAAomAADAAAAUDABBgAAAKBgAgwAAABAwQQYAAAAgIIJMAAAAAAFE2AAAAAACibAAAAAABRMgAEAAAAomAADAAAAUDABBgAAAKBgAsx7Sv/vD/Vni9PPY3r6eTxrw+fu6ecxrR2Pc+35/K4f/5+uPY91bfn8Pv3Oqn83/hcgDPnYv8hGegAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1100x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xin_input,Yin_output=bsm_iv_generator(num_sample = 100,tao_bound=[0.5,0.6],  sigma_bound=[0.3,0.7], \n",
    "                                      money_bound=[0.98,1.02], rr_bound=[0.03,0.08],callput='call')\n",
    "\n",
    "#check the data value range on each dimension\n",
    "## xin = [maturity time, Stock price, interest rate, dividend, option value]\n",
    "\n",
    "xlabel =  ['maturity time', 'Stock price', 'interest rate','option value']\n",
    "for i in range(0, len(xlabel)):\n",
    "    print(xlabel[i]+'  range:')\n",
    "    print(np.min(Xin_input[:,i]),np.max(Xin_input[:,i]))\n",
    "    \n",
    "print('sigma range:')\n",
    "print(np.min(Yin_output),np.max(Yin_output))\n",
    "print(np.shape(Xin_input))\n",
    "\n",
    "# generate and shuffle the data set into training and test part\n",
    "xtv_train_log_all,ytv_train_log_all=logscale_vol(Xin_input,Yin_output,otm_lower=1e-4)\n",
    "'''\n",
    "for i in range(4):\n",
    "    xtv_train_log_all[:,i]= min_max_normalization(xtv_train_log_all[:,i])\n",
    "'''\n",
    "#ytv_train_log_all=ytv_train_log_all/2\n",
    "xtv_train_log,xtv_test_log, ytv_train_log, ytv_test_log   = train_test_split(xtv_train_log_all,ytv_train_log_all,test_size=0.2,random_state=42)\n",
    "\n",
    "xlabel =  ['maturity time', 'Stock price', 'interest rate','time option-value']\n",
    "for i in range(0, len(xlabel)):\n",
    "    print(xlabel[i]+'  range:')\n",
    "    print(np.min(xtv_train_log_all[:,i]),np.max(xtv_train_log_all[:,i]))\n",
    "    \n",
    "print('sigma range:')\n",
    "print(np.min(ytv_train_log),np.max(ytv_train_log))\n",
    "## how many samples after cleaning\n",
    "print(np.shape(xtv_train_log))\n",
    "\n",
    "\n",
    "params = npp.random.random([12], requires_grad=True)\n",
    "inputs = npp.random.random([4], requires_grad=True)\n",
    "print(\"Parameters:\", params)\n",
    "print(\"inputs:\", inputs)\n",
    "print(\"Expectation value:\", circuit(params,inputs))\n",
    "\n",
    "\n",
    "qnode = qml.QNode(circuit, dev)\n",
    "qml.draw_mpl(circuit, decimals=1, style=\"sketch\")(params,inputs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc5c5020-7fea-46b3-85c1-c67a90814673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.019345149074422252\n",
      "[-0.01934515 -0.03463214 -0.03287614 -0.00129082 -0.0392646  -0.02373663\n",
      " -0.00036328 -0.06969662 -0.05176527 -0.26545016  0.36205784  0.35254965]\n",
      "[-0.01934515 -0.03463214 -0.03287614 -0.00129082 -0.0392646  -0.02373663\n",
      " -0.00036328 -0.06969662 -0.05176527 -0.26545016  0.36205784  0.35254965]\n",
      "[-0.01934515 -0.03463214 -0.03287614 -0.00129082 -0.0392646  -0.02373663\n",
      " -0.00036328 -0.06969662 -0.05176527 -0.26545016  0.36205784  0.35254965]\n"
     ]
    }
   ],
   "source": [
    "def parameter_shift_term(qnode,params,inputs, i):\n",
    "    shifted = params.copy()\n",
    "    shifted[i] += np.pi/2\n",
    "    forward = qnode(shifted,inputs)  # forward evaluation\n",
    "\n",
    "    shifted[i] -= np.pi\n",
    "    backward = qnode(shifted,inputs) # backward evaluation\n",
    "\n",
    "    return 0.5 * (forward - backward)\n",
    "\n",
    "# gradient with respect to the first parameter\n",
    "print(parameter_shift_term(circuit,params,inputs, 0))\n",
    "\n",
    "\n",
    "def parameter_shift(qnode, params,inputs):\n",
    "    gradients = np.zeros([len(params)])\n",
    "\n",
    "    for i in range(len(params)):\n",
    "        gradients[i] = parameter_shift_term(qnode,params,inputs, i)\n",
    "\n",
    "    return gradients\n",
    "\n",
    "print(parameter_shift(circuit, params,inputs))\n",
    "\n",
    "grad_function = qml.grad(circuit)\n",
    "print(grad_function(params,inputs)[0])\n",
    "\n",
    "\n",
    "print(qml.gradients.param_shift(circuit)(params,inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9715830-fa60-4d48-bbc4-27dc40dbdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from itertools import chain\n",
    "import time\n",
    "def QNN(weights, angles):\n",
    "    return circuit(weights, angles)\n",
    "\n",
    "def cost(weights, features, labels):\n",
    "    predictions = [QNN(weights, f) for f in features]\n",
    "    \n",
    "    return square_loss(labels, predictions)\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def R2(labels, predictions):\n",
    "\n",
    "    r2 = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        r2 = r2 + metrics.r2_score(labels, predictions)\n",
    "    r2 = r2 / len(labels)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48fdbeb0-8d5d-419e-be05-d99d3936b2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=xtv_train_log\n",
    "Y=ytv_train_log\n",
    "weights_init = npp.random.random([12], requires_grad=True)\n",
    "opt = qml.AdamOptimizer(0.01)\n",
    "batch_size = 20\n",
    "batches = len (X) // batch_size\n",
    "X_batches = npp.array_split(npp.arange(len(X)) , batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2218b3c-8997-4af9-84d6-318bffadf9d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.05440605171947701 R2: -2.760435366906619 time: 1703114874.7898633\n",
      "batch_idx: 1 loss: 0.04436087944171875 R2: -2.2843803513901735 time: 1703114878.304617\n",
      "batch_idx: 2 loss: 0.03652600531318477 R2: -1.8389321658370938 time: 1703114881.773443\n",
      "batch_idx: 3 loss: 0.032116296659149425 R2: -1.4239964584545353 time: 1703114885.3056304\n",
      "Training [0%] Loss: 0.04185230828338248 time: 1703114885.3056304\n",
      "weight: [0.14295706 0.94186616 0.54375763 0.78667954 0.3598084  0.93526333\n",
      " 0.42828657 0.05075948 0.8657368  0.13099959 0.27950593 0.91026027]\n",
      "epoch 2\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.030501944509171236 R2: -1.0413514839537275 time: 1703114888.8827364\n",
      "batch_idx: 1 loss: 0.022366099469537402 R2: -0.6933601981254769 time: 1703114892.3362136\n",
      "batch_idx: 2 loss: 0.01768942976523915 R2: -0.3825312390084044 time: 1703114895.9351664\n",
      "batch_idx: 3 loss: 0.014364685491485044 R2: -0.10855439296889915 time: 1703114899.4775698\n",
      "Training [1%] Loss: 0.02123053980885821 time: 1703114899.4775698\n",
      "weight: [0.18218892 0.97662831 0.56923206 0.74781308 0.39857496 0.97393247\n",
      " 0.4677688  0.09048668 0.82684323 0.16885975 0.240898   0.87168517]\n",
      "epoch 3\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.01393328336697639 R2: 0.12923137338003396 time: 1703114903.1312644\n",
      "batch_idx: 1 loss: 0.008321298706245019 R2: 0.3297772400969559 time: 1703114906.632816\n",
      "batch_idx: 2 loss: 0.006421090746981098 R2: 0.4928827341139431 time: 1703114910.1467776\n",
      "batch_idx: 3 loss: 0.004711083432027146 R2: 0.6203553458808957 time: 1703114913.8183925\n",
      "Training [1%] Loss: 0.008346689063057414 time: 1703114913.8183925\n",
      "weight: [0.21933386 1.00240646 0.57222127 0.71173931 0.43454133 1.00966442\n",
      " 0.50858709 0.12891297 0.79044372 0.20207123 0.20556856 0.83642674]\n",
      "epoch 4\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0052572603950810344 R2: 0.7149290726325154 time: 1703114917.3037765\n",
      "batch_idx: 1 loss: 0.0022295094311944675 R2: 0.7782784731905612 time: 1703114920.7691634\n",
      "batch_idx: 2 loss: 0.0025100655819976308 R2: 0.8137555652903506 time: 1703114924.3020148\n",
      "batch_idx: 3 loss: 0.0021558890143597033 R2: 0.8260120678389378 time: 1703114927.8469665\n",
      "Training [1%] Loss: 0.0030381811056582092 time: 1703114927.8469665\n",
      "weight: [0.25142972 1.01950113 0.56290413 0.68143636 0.46486132 1.03964459\n",
      " 0.54786496 0.16304945 0.75935486 0.22646673 0.17677509 0.80770574]\n",
      "epoch 5\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0031756939375630912 R2: 0.8197820434446405 time: 1703114931.370799\n",
      "batch_idx: 1 loss: 0.0020048736941530813 R2: 0.7998444235886093 time: 1703114934.7965686\n",
      "batch_idx: 2 loss: 0.003393770603476421 R2: 0.7718242763843501 time: 1703114938.347755\n",
      "batch_idx: 3 loss: 0.003474117783764522 R2: 0.7406731578900287 time: 1703114941.9353135\n",
      "Training [2%] Loss: 0.003012114004739279 time: 1703114941.9353135\n",
      "weight: [0.27443238 1.03040226 0.5538762  0.659865   0.4864317  1.06095935\n",
      " 0.57633227 0.18747531 0.7366519  0.23836534 0.15806031 0.78896924]\n",
      "epoch 6\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.004217406778369132 R2: 0.7097051281818467 time: 1703114945.5030665\n",
      "batch_idx: 1 loss: 0.0036624122113276597 R2: 0.6832068487515238 time: 1703114948.978143\n",
      "batch_idx: 2 loss: 0.00499830088501661 R2: 0.6642500227874757 time: 1703114952.6268637\n",
      "batch_idx: 3 loss: 0.004730420848108639 R2: 0.653849984763056 time: 1703114956.2200506\n",
      "Training [2%] Loss: 0.00440213518070551 time: 1703114956.2200506\n",
      "weight: [0.28561721 1.036701   0.55297769 0.64806859 0.4977272  1.07231236\n",
      " 0.5823883  0.19728866 0.72359319 0.23705086 0.15108256 0.78180498]\n",
      "epoch 7\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.004850222300154002 R2: 0.651015218242707 time: 1703114959.6728637\n",
      "batch_idx: 1 loss: 0.004060315670141453 R2: 0.6566625728241373 time: 1703114963.218532\n",
      "batch_idx: 2 loss: 0.0048984283049026845 R2: 0.6700961863677287 time: 1703114966.6964836\n",
      "batch_idx: 3 loss: 0.004252090666338343 R2: 0.6893881778272971 time: 1703114970.0868456\n",
      "Training [2%] Loss: 0.004515264235384121 time: 1703114970.0868456\n",
      "weight: [0.28592576 1.03999884 0.56209039 0.64457079 0.49996017 1.07496556\n",
      " 0.56796275 0.19319444 0.71829902 0.224985   0.154343   0.78474551]\n",
      "epoch 8\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0041156970810461765 R2: 0.7115723009599085 time: 1703114973.6249437\n",
      "batch_idx: 1 loss: 0.002971216964800036 R2: 0.7361165443081943 time: 1703114977.2170978\n",
      "batch_idx: 2 loss: 0.0035577754691909864 R2: 0.7614283000648626 time: 1703114980.742737\n",
      "batch_idx: 3 loss: 0.0028759236486721397 R2: 0.7857608519854434 time: 1703114984.2344067\n",
      "Training [3%] Loss: 0.0033801532909273346 time: 1703114984.2344067\n",
      "weight: [0.27924393 1.04243033 0.57859551 0.64642563 0.49631786 1.07196722\n",
      " 0.54330988 0.18063726 0.71698565 0.20611375 0.16421799 0.79425102]\n",
      "epoch 9\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0030501333168490687 R2: 0.8070518211621135 time: 1703114987.7160466\n",
      "batch_idx: 1 loss: 0.0017155997958952919 R2: 0.8252677236947596 time: 1703114991.373176\n",
      "batch_idx: 2 loss: 0.002399957992124438 R2: 0.8398241837321067 time: 1703114994.981235\n",
      "batch_idx: 3 loss: 0.001875237952558952 R2: 0.8504623477903829 time: 1703114998.5665803\n",
      "Training [3%] Loss: 0.0022602322643569374 time: 1703114998.5665803\n",
      "weight: [0.27036947 1.04496967 0.59701627 0.65035334 0.49057228 1.06688579\n",
      " 0.5177833  0.16603717 0.71637606 0.18461465 0.17651475 0.8061985 ]\n",
      "epoch 10\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0026265058420837607 R2: 0.8571041813886726 time: 1703115002.0136356\n",
      "batch_idx: 1 loss: 0.0011846010415754952 R2: 0.8604411662602368 time: 1703115005.7184703\n",
      "batch_idx: 2 loss: 0.002067882520927297 R2: 0.8610303478685053 time: 1703115009.3231223\n",
      "batch_idx: 3 loss: 0.0016204840682326246 R2: 0.8595816715034422 time: 1703115013.029232\n",
      "Training [3%] Loss: 0.0018748683682047944 time: 1703115013.029232\n",
      "weight: [0.26357765 1.04606413 0.60974684 0.65349162 0.48603192 1.06285104\n",
      " 0.49866366 0.15483517 0.71541252 0.16434886 0.18747646 0.81686698]\n",
      "epoch 11\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0028081367704142694 R2: 0.8573209217371976 time: 1703115016.621727\n",
      "batch_idx: 1 loss: 0.0012249348191762607 R2: 0.8546573444377339 time: 1703115020.2552\n",
      "batch_idx: 2 loss: 0.002196006297709818 R2: 0.8522112374409468 time: 1703115023.8395987\n",
      "batch_idx: 3 loss: 0.0016572723351239785 R2: 0.8503565691250466 time: 1703115027.4518752\n",
      "Training [4%] Loss: 0.0019715875556060814 time: 1703115027.4518752\n",
      "weight: [0.26151741 1.0431725  0.61030245 0.65403849 0.48474018 1.06180524\n",
      " 0.48984806 0.15024379 0.71492156 0.14820982 0.19460269 0.82376004]\n",
      "epoch 12\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0029677662083013225 R2: 0.850198265058375 time: 1703115031.0589502\n",
      "batch_idx: 1 loss: 0.0012613214436118952 R2: 0.851138107485894 time: 1703115034.5314772\n",
      "batch_idx: 2 loss: 0.0022227234769114346 R2: 0.8531972724546988 time: 1703115038.0772486\n",
      "batch_idx: 3 loss: 0.0015594327338537427 R2: 0.8560355026785142 time: 1703115041.6049168\n",
      "Training [4%] Loss: 0.002002810965669599 time: 1703115041.6049168\n",
      "weight: [0.2645671  1.03596896 0.59866733 0.65162908 0.48706434 1.0641132\n",
      " 0.49116805 0.15256397 0.71561911 0.13729247 0.19724608 0.82621628]\n",
      "epoch 13\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0027803738579425634 R2: 0.8602115894818263 time: 1703115045.1199367\n",
      "batch_idx: 1 loss: 0.0010965340001047052 R2: 0.8646713547807332 time: 1703115048.6356823\n",
      "batch_idx: 2 loss: 0.0020465701291300827 R2: 0.8692360300536708 time: 1703115052.0386455\n",
      "batch_idx: 3 loss: 0.0013598245691237066 R2: 0.8734806445815776 time: 1703115055.7992175\n",
      "Training [4%] Loss: 0.0018208256390752644 time: 1703115055.7992175\n",
      "weight: [0.2712092  1.02686487 0.58025176 0.64712372 0.49196589 1.06881128\n",
      " 0.4996604  0.15976719 0.71694639 0.1306602  0.19649082 0.82530539]\n",
      "epoch 14\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00242212149728479 R2: 0.8777456641043232 time: 1703115059.3387432\n",
      "batch_idx: 1 loss: 0.0009141862475725328 R2: 0.8813335378808771 time: 1703115062.9012733\n",
      "batch_idx: 2 loss: 0.001868375672613531 R2: 0.8842591189715655 time: 1703115066.5254445\n",
      "batch_idx: 3 loss: 0.0012465300368838014 R2: 0.8864750893732725 time: 1703115070.1667373\n",
      "Training [5%] Loss: 0.0016128033635886638 time: 1703115070.1667373\n",
      "weight: [0.27910299 1.01849039 0.56096709 0.64194558 0.49774969 1.07431464\n",
      " 0.51125286 0.16882479 0.71785643 0.12607631 0.19434786 0.82303151]\n",
      "epoch 15\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002146499608490408 R2: 0.888216748431516 time: 1703115073.7138238\n",
      "batch_idx: 1 loss: 0.0008568260108200044 R2: 0.889377416469728 time: 1703115077.2689257\n",
      "batch_idx: 2 loss: 0.0018016428930655048 R2: 0.8900789262098476 time: 1703115080.9999726\n",
      "batch_idx: 3 loss: 0.001244669683489067 R2: 0.890583477592658 time: 1703115084.554641\n",
      "Training [5%] Loss: 0.001512409548966246 time: 1703115084.554641\n",
      "weight: [0.28612913 1.01165402 0.54435287 0.63738352 0.50284607 1.07915934\n",
      " 0.52203515 0.17694179 0.71795242 0.12119198 0.19277884 0.82135574]\n",
      "epoch 16\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020094216505915654 R2: 0.890868670138231 time: 1703115088.143625\n",
      "batch_idx: 1 loss: 0.0008711945936724739 R2: 0.8911775822212794 time: 1703115091.8449547\n",
      "batch_idx: 2 loss: 0.001793363739801866 R2: 0.8914802895599744 time: 1703115095.448393\n",
      "batch_idx: 3 loss: 0.001245512535463129 R2: 0.8920737231553286 time: 1703115098.9462047\n",
      "Training [5%] Loss: 0.0014798731298822586 time: 1703115098.9462047\n",
      "weight: [0.29107572 1.00556662 0.53117116 0.63414303 0.50635187 1.08250978\n",
      " 0.52940192 0.18243459 0.71755198 0.11456484 0.19295044 0.82144616]\n",
      "epoch 17\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019402137783375794 R2: 0.8926301232594602 time: 1703115102.7476697\n",
      "batch_idx: 1 loss: 0.000852752030431905 R2: 0.8934423363090913 time: 1703115106.3069057\n",
      "batch_idx: 2 loss: 0.001775363601809387 R2: 0.8942862298384429 time: 1703115109.734207\n",
      "batch_idx: 3 loss: 0.0011836052866664414 R2: 0.8953631154803373 time: 1703115113.2424197\n",
      "Training [6%] Loss: 0.001437983674311328 time: 1703115113.2424197\n",
      "weight: [0.29386086 0.99930223 0.52057904 0.63223675 0.50821037 1.0843202\n",
      " 0.53286622 0.18511276 0.7170442  0.10612411 0.19493405 0.82337376]\n",
      "epoch 18\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001897362425833591 R2: 0.8962756124835222 time: 1703115116.914675\n",
      "batch_idx: 1 loss: 0.0007876793151998938 R2: 0.897241668481769 time: 1703115120.4152215\n",
      "batch_idx: 2 loss: 0.0017568211557818653 R2: 0.8980462692251339 time: 1703115124.007426\n",
      "batch_idx: 3 loss: 0.00109374575849434 R2: 0.8988135543742304 time: 1703115127.5392365\n",
      "Training [6%] Loss: 0.0013839021638274223 time: 1703115127.5392365\n",
      "weight: [0.29527232 0.99283812 0.51152608 0.63116977 0.50902082 1.08515206\n",
      " 0.53386404 0.18600619 0.71648699 0.0969654  0.19790952 0.82631353]\n",
      "epoch 19\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018892132357118507 R2: 0.8993691082063864 time: 1703115131.163435\n",
      "batch_idx: 1 loss: 0.0007263700391876112 R2: 0.8998168615484173 time: 1703115134.647319\n",
      "batch_idx: 2 loss: 0.0017669151741091602 R2: 0.9001127615880906 time: 1703115138.1632423\n",
      "batch_idx: 3 loss: 0.001028020294377316 R2: 0.900291642569479 time: 1703115141.601062\n",
      "Training [6%] Loss: 0.0013526296858464846 time: 1703115141.601062\n",
      "weight: [0.29639083 0.98705884 0.50352285 0.63028577 0.50960912 1.08577427\n",
      " 0.5345935  0.18659283 0.71570512 0.08865319 0.20072352 0.82910282]\n",
      "epoch 20\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019051184093443981 R2: 0.9004636569668764 time: 1703115145.1776493\n",
      "batch_idx: 1 loss: 0.0006936814023411354 R2: 0.9005650818909967 time: 1703115148.739471\n",
      "batch_idx: 2 loss: 0.0017911804044975495 R2: 0.9006873039221406 time: 1703115152.2612853\n",
      "batch_idx: 3 loss: 0.0009944252254006872 R2: 0.9007379602160294 time: 1703115155.969248\n",
      "Training [7%] Loss: 0.0013461013603959426 time: 1703115155.969248\n",
      "weight: [0.29800683 0.98298486 0.4966056  0.62910665 0.51058488 1.08675353\n",
      " 0.53669805 0.18797265 0.71455421 0.08238627 0.20250925 0.83086492]\n",
      "epoch 21\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019058012869696116 R2: 0.9009601225999606 time: 1703115159.4897122\n",
      "batch_idx: 1 loss: 0.0006780618709186244 R2: 0.9011419560025049 time: 1703115163.0833342\n",
      "batch_idx: 2 loss: 0.0017994079770976726 R2: 0.9013994824992595 time: 1703115166.7339306\n",
      "batch_idx: 3 loss: 0.0009808566230343119 R2: 0.9015780830922309 time: 1703115170.3491297\n",
      "Training [7%] Loss: 0.0013410319395050553 time: 1703115170.3491297\n",
      "weight: [0.30030657 0.98087303 0.49080504 0.62751708 0.51209395 1.08822592\n",
      " 0.54052726 0.19040143 0.71305615 0.07843487 0.20306515 0.83139342]\n",
      "epoch 22\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018750454323484705 R2: 0.9018900725572448 time: 1703115173.847416\n",
      "batch_idx: 1 loss: 0.000671962289257263 R2: 0.902122995272663 time: 1703115177.2479327\n",
      "batch_idx: 2 loss: 0.001790856353087105 R2: 0.9023579975992156 time: 1703115180.7757766\n",
      "batch_idx: 3 loss: 0.0009830727545538395 R2: 0.9025140737357935 time: 1703115184.317024\n",
      "Training [7%] Loss: 0.0013302342073116696 time: 1703115184.317024\n",
      "weight: [0.30293264 0.97990845 0.48574291 0.6257261  0.51385893 1.08993552\n",
      " 0.54523215 0.19335346 0.71138505 0.07614935 0.20282213 0.83112153]\n",
      "epoch 23\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018337205261841425 R2: 0.9026867865802475 time: 1703115187.8344626\n",
      "batch_idx: 1 loss: 0.0006764890081859707 R2: 0.9028011929768528 time: 1703115191.4873476\n",
      "batch_idx: 2 loss: 0.0017825633779483701 R2: 0.9028766634066505 time: 1703115195.1049232\n",
      "batch_idx: 3 loss: 0.0009930538023481493 R2: 0.902957007348577 time: 1703115198.6540859\n",
      "Training [8%] Loss: 0.0013214566786666582 time: 1703115198.6540859\n",
      "weight: [0.30532109 0.97872308 0.48073231 0.62406145 0.51544062 1.09147719\n",
      " 0.54948555 0.19599236 0.70977484 0.07448971 0.20246776 0.83074307]\n",
      "epoch 24\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018044851285804 R2: 0.9029976489283401 time: 1703115202.111003\n",
      "batch_idx: 1 loss: 0.000682820087117541 R2: 0.9030606276127692 time: 1703115205.8077102\n",
      "batch_idx: 2 loss: 0.0017809748598949845 R2: 0.9030942291006454 time: 1703115209.2191436\n",
      "batch_idx: 3 loss: 0.0009943813278162651 R2: 0.9032024941617669 time: 1703115212.5955105\n",
      "Training [8%] Loss: 0.0013156653508522977 time: 1703115212.5955105\n",
      "weight: [0.30708683 0.97626827 0.47518436 0.62274211 0.5165389  1.09257478\n",
      " 0.55235307 0.19773356 0.70839276 0.07268774 0.2024943  0.83075492]\n",
      "epoch 25\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017923322526291641 R2: 0.9032539499158991 time: 1703115216.2026649\n",
      "batch_idx: 1 loss: 0.0006795530093725074 R2: 0.9033541630201253 time: 1703115219.733931\n",
      "batch_idx: 2 loss: 0.001783703107885732 R2: 0.9034260801203745 time: 1703115223.3270938\n",
      "batch_idx: 3 loss: 0.0009812316923424077 R2: 0.9035502565595124 time: 1703115226.7171679\n",
      "Training [8%] Loss: 0.0013092050155574528 time: 1703115226.7171679\n",
      "weight: [0.30822712 0.97238765 0.46893728 0.62176586 0.51715092 1.09322634\n",
      " 0.55379427 0.19855824 0.70725303 0.07061353 0.20295292 0.83120797]\n",
      "epoch 26\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017934058937437239 R2: 0.903623276441062 time: 1703115230.248235\n",
      "batch_idx: 1 loss: 0.0006687277465320652 R2: 0.9037086332620655 time: 1703115233.7008944\n",
      "batch_idx: 2 loss: 0.0017890751509591694 R2: 0.9037759303113736 time: 1703115237.1690042\n",
      "batch_idx: 3 loss: 0.0009635549902465093 R2: 0.9038393454334835 time: 1703115240.7141483\n",
      "Training [9%] Loss: 0.001303690945370367 time: 1703115240.7141483\n",
      "weight: [0.30904665 0.96776878 0.46230851 0.6209572  0.51751358 1.09365039\n",
      " 0.55451174 0.19891523 0.7062437  0.06866464 0.20353335 0.83178725]\n",
      "epoch 27\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018000595820442777 R2: 0.9039011502556823 time: 1703115244.435781\n",
      "batch_idx: 1 loss: 0.000659659531316909 R2: 0.9039431393692233 time: 1703115248.1069896\n",
      "batch_idx: 2 loss: 0.0017933192090287798 R2: 0.9040018630895 time: 1703115251.5749092\n",
      "batch_idx: 3 loss: 0.0009518905932181163 R2: 0.9040267219011054 time: 1703115255.0614688\n",
      "Training [9%] Loss: 0.0013012322289020206 time: 1703115255.0614688\n",
      "weight: [0.30989905 0.96336228 0.45583244 0.62011485 0.51790369 1.09410179\n",
      " 0.555339   0.19933658 0.70523567 0.0673306  0.203863   0.83211465]\n",
      "epoch 28\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001801697249411117 R2: 0.9041018706546724 time: 1703115258.5738986\n",
      "batch_idx: 1 loss: 0.0006566866574504231 R2: 0.9041444726863549 time: 1703115262.0104623\n",
      "batch_idx: 2 loss: 0.0017913695449831915 R2: 0.9042198604128858 time: 1703115265.510456\n",
      "batch_idx: 3 loss: 0.000948838782687729 R2: 0.9042570951388582 time: 1703115268.8990371\n",
      "Training [9%] Loss: 0.0012996480586331153 time: 1703115268.8990371\n",
      "weight: [0.31095128 0.95967458 0.44982654 0.61914419 0.51845316 1.09470184\n",
      " 0.55666935 0.20007568 0.70417013 0.0667824  0.20378745 0.83203308]\n",
      "epoch 29\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00179356214603479 R2: 0.9043437883081109 time: 1703115272.4459589\n",
      "batch_idx: 1 loss: 0.0006590921938526984 R2: 0.9043973614834199 time: 1703115275.997899\n",
      "batch_idx: 2 loss: 0.0017837433802172624 R2: 0.9044678927402858 time: 1703115279.4793234\n",
      "batch_idx: 3 loss: 0.0009514942430569019 R2: 0.9045191933832942 time: 1703115283.0072932\n",
      "Training [10%] Loss: 0.001296972990790413 time: 1703115283.0072932\n",
      "weight: [0.31213059 0.95647043 0.4441412  0.61808643 0.51910511 1.0953982\n",
      " 0.55832091 0.20101827 0.70306743 0.06677628 0.20343731 0.83167443]\n",
      "epoch 30\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017809701756387908 R2: 0.9045845500527744 time: 1703115286.5067997\n",
      "batch_idx: 1 loss: 0.0006639011948257999 R2: 0.9046352021767406 time: 1703115290.0025196\n",
      "batch_idx: 2 loss: 0.0017751388284588617 R2: 0.9046861056152833 time: 1703115293.316272\n",
      "batch_idx: 3 loss: 0.0009540925461234862 R2: 0.9047479846901464 time: 1703115296.8638573\n",
      "Training [10%] Loss: 0.0012935256862617345 time: 1703115296.8638573\n",
      "weight: [0.31325809 0.95311711 0.43834149 0.61704207 0.51971794 1.09606083\n",
      " 0.55985403 0.20188329 0.70197765 0.0668906  0.20306882 0.831298  ]\n",
      "epoch 31\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017714443232174242 R2: 0.9047963975651638 time: 1703115300.3645494\n",
      "batch_idx: 1 loss: 0.000666971278057252 R2: 0.9048499901761824 time: 1703115303.8645947\n",
      "batch_idx: 2 loss: 0.0017684038922817092 R2: 0.9048984513525179 time: 1703115307.4108443\n",
      "batch_idx: 3 loss: 0.0009521555602110231 R2: 0.9049664239440093 time: 1703115311.0419028\n",
      "Training [10%] Loss: 0.0012897437634418522 time: 1703115311.0419028\n",
      "weight: [0.31423194 0.94922004 0.43213941 0.61606788 0.52021063 1.09661537\n",
      " 0.56101636 0.20250818 0.700924   0.06685232 0.20284137 0.83106499]\n",
      "epoch 32\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017676694954324233 R2: 0.9050169759388295 time: 1703115314.5349352\n",
      "batch_idx: 1 loss: 0.0006667302896901181 R2: 0.9050710645452904 time: 1703115318.0655313\n",
      "batch_idx: 2 loss: 0.001763560546422582 R2: 0.9051232552993381 time: 1703115321.5066013\n",
      "batch_idx: 3 loss: 0.0009467403975143071 R2: 0.9051776512926658 time: 1703115325.0801399\n",
      "Training [11%] Loss: 0.0012861751822648576 time: 1703115325.0801399\n",
      "weight: [0.31510454 0.94496191 0.42565873 0.6151348  0.52062488 1.09710004\n",
      " 0.56193526 0.20297383 0.69988398 0.06667419 0.20272249 0.83094226]\n",
      "epoch 33\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017672142142707938 R2: 0.9052337568216299 time: 1703115328.5802379\n",
      "batch_idx: 1 loss: 0.0006655036821914815 R2: 0.9052794772968816 time: 1703115332.1584158\n",
      "batch_idx: 2 loss: 0.0017591115139625167 R2: 0.9053329080552764 time: 1703115335.7195294\n",
      "batch_idx: 3 loss: 0.0009420680289503821 R2: 0.9053710589786782 time: 1703115339.2137716\n",
      "Training [11%] Loss: 0.0012834743598437934 time: 1703115339.2137716\n",
      "weight: [0.31600867 0.94087798 0.4192992  0.61416971 0.52106714 1.09761231\n",
      " 0.56293855 0.20349124 0.69881634 0.06652567 0.2025757  0.83079128]\n",
      "epoch 34\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001765412715348393 R2: 0.9054333695947273 time: 1703115342.7803562\n",
      "batch_idx: 1 loss: 0.0006658801810463671 R2: 0.9054760325654614 time: 1703115346.3530269\n",
      "batch_idx: 2 loss: 0.0017534445989264044 R2: 0.9055303627128668 time: 1703115349.8107452\n",
      "batch_idx: 3 loss: 0.0009404355124458417 R2: 0.9055671318660155 time: 1703115353.379492\n",
      "Training [11%] Loss: 0.0012812932519417517 time: 1703115353.379492\n",
      "weight: [0.31702611 0.93732885 0.41334581 0.61312804 0.52160346 1.09821254\n",
      " 0.56422898 0.20419206 0.69769809 0.06650294 0.20231956 0.83052938]\n",
      "epoch 35\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017599369176511572 R2: 0.9056292383360421 time: 1703115356.8729157\n",
      "batch_idx: 1 loss: 0.0006681992797542291 R2: 0.9056730151652296 time: 1703115360.5752883\n",
      "batch_idx: 2 loss: 0.0017467380654927005 R2: 0.9057219606984624 time: 1703115364.0156918\n",
      "batch_idx: 3 loss: 0.0009407830043301587 R2: 0.9057649619293265 time: 1703115367.6530917\n",
      "Training [12%] Loss: 0.0012789143168070614 time: 1703115367.6530917\n",
      "weight: [0.31813015 0.93420999 0.40772576 0.61202479 0.5222126  1.09888125\n",
      " 0.56573987 0.20503363 0.69653458 0.06652834 0.20199838 0.83020138]\n",
      "epoch 36\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017528430890641246 R2: 0.9058176617626165 time: 1703115371.2160802\n",
      "batch_idx: 1 loss: 0.0006709293712035491 R2: 0.9058618699203912 time: 1703115374.7787802\n",
      "batch_idx: 2 loss: 0.0017405206619955141 R2: 0.905904074871289 time: 1703115378.295685\n",
      "batch_idx: 3 loss: 0.0009404428885340509 R2: 0.905952211996507 time: 1703115381.872153\n",
      "Training [12%] Loss: 0.0012761840026993096 time: 1703115381.872153\n",
      "weight: [0.31924332 0.9311713  0.40216359 0.61090227 0.52283197 1.09956116\n",
      " 0.56727713 0.20588991 0.69534218 0.06645016 0.20171324 0.82990967]\n",
      "epoch 37\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001747314579891216 R2: 0.905998917415849 time: 1703115385.5917847\n",
      "batch_idx: 1 loss: 0.0006723771674315598 R2: 0.9060435824776517 time: 1703115389.1377373\n",
      "batch_idx: 2 loss: 0.0017356690910684453 R2: 0.9060844592027879 time: 1703115392.5911126\n",
      "batch_idx: 3 loss: 0.0009381032080327669 R2: 0.9061300525287963 time: 1703115396.0836513\n",
      "Training [12%] Loss: 0.0012733660116059971 time: 1703115396.0836513\n",
      "weight: [0.3203302  0.92804798 0.39652702 0.6097796  0.52343285 1.10022603\n",
      " 0.56875172 0.20670281 0.69412818 0.06620233 0.20150945 0.82970014]\n",
      "epoch 38\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017440435119912214 R2: 0.9061781843097375 time: 1703115399.8549006\n",
      "batch_idx: 1 loss: 0.0006725282449079029 R2: 0.9062207876961837 time: 1703115403.629055\n",
      "batch_idx: 2 loss: 0.0017318394582041205 R2: 0.9062624924666745 time: 1703115407.1047785\n",
      "batch_idx: 3 loss: 0.0009349663177170549 R2: 0.9062998688230488 time: 1703115410.886904\n",
      "Training [13%] Loss: 0.0012708443832050748 time: 1703115410.886904\n",
      "weight: [0.32142228 0.92500014 0.39095213 0.60863991 0.52404083 1.10089921\n",
      " 0.57024308 0.20752455 0.69288814 0.06584464 0.20134674 0.829532  ]\n",
      "epoch 39\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001741170753825658 R2: 0.9063518298172019 time: 1703115414.4285917\n",
      "batch_idx: 1 loss: 0.0006726676419472 R2: 0.9063919864705381 time: 1703115417.958674\n",
      "batch_idx: 2 loss: 0.0017281617827646634 R2: 0.906433815505958 time: 1703115421.4282851\n",
      "batch_idx: 3 loss: 0.0009326951689443518 R2: 0.9064675179836696 time: 1703115424.9898016\n",
      "Training [13%] Loss: 0.0012686738368704682 time: 1703115424.9898016\n",
      "weight: [0.32256247 0.92225091 0.3856329  0.60746049 0.52469089 1.10161259\n",
      " 0.57185963 0.20842694 0.69161754 0.06546386 0.20116781 0.82934719]\n",
      "epoch 40\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001736922889435227 R2: 0.9065201634875264 time: 1703115428.380896\n",
      "batch_idx: 1 loss: 0.000673526869248194 R2: 0.9065597803832807 time: 1703115431.8461025\n",
      "batch_idx: 2 loss: 0.0017242997667568198 R2: 0.9065992452484576 time: 1703115435.274562\n",
      "batch_idx: 3 loss: 0.0009313848517657885 R2: 0.9066353012402144 time: 1703115438.8767564\n",
      "Training [13%] Loss: 0.0012665335943015073 time: 1703115438.8767564\n",
      "weight: [0.32374926 0.91979619 0.38057202 0.60624216 0.52538182 1.10236506\n",
      " 0.57359719 0.20940797 0.69031947 0.06507481 0.2009677  0.82914072]\n",
      "epoch 41\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001731717904626049 R2: 0.9066838309141536 time: 1703115442.2036488\n",
      "batch_idx: 1 loss: 0.0006746263810371322 R2: 0.9067234874580036 time: 1703115445.56192\n",
      "batch_idx: 2 loss: 0.0017206807493349706 R2: 0.9067598076495299 time: 1703115449.0728483\n",
      "batch_idx: 3 loss: 0.0009298941111468538 R2: 0.9067983106929584 time: 1703115452.4213042\n",
      "Training [14%] Loss: 0.0012642297865362512 time: 1703115452.4213042\n",
      "weight: [0.32494663 0.91744555 0.37560839 0.60500366 0.52608407 1.10312972\n",
      " 0.57536335 0.21040714 0.68900113 0.06463504 0.20078304 0.82894976]\n",
      "epoch 42\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017271160267050708 R2: 0.9068435709226653 time: 1703115455.6839523\n",
      "batch_idx: 1 loss: 0.0006751743609564765 R2: 0.9068828707848853 time: 1703115459.168669\n",
      "batch_idx: 2 loss: 0.0017176600643086127 R2: 0.9069182005007402 time: 1703115462.510675\n",
      "batch_idx: 3 loss: 0.000927580492417893 R2: 0.9069546076957901 time: 1703115465.8883932\n",
      "Training [14%] Loss: 0.0012618827360970132 time: 1703115465.8883932\n",
      "weight: [0.3261334  0.91508538 0.37064481 0.60375574 0.5267802  1.10389074\n",
      " 0.5771036  0.21138866 0.68766714 0.06412788 0.20063222 0.82879301]\n",
      "epoch 43\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017235583050608876 R2: 0.9070005583336795 time: 1703115469.3701186\n",
      "batch_idx: 1 loss: 0.0006751898993252488 R2: 0.9070383343336916 time: 1703115472.817291\n",
      "batch_idx: 2 loss: 0.001715027834763666 R2: 0.9070738234056487 time: 1703115476.1320257\n",
      "batch_idx: 3 loss: 0.0009250435493746856 R2: 0.9071057670217473 time: 1703115479.521121\n",
      "Training [14%] Loss: 0.0012597048971311222 time: 1703115479.521121\n",
      "weight: [0.32732167 0.91278359 0.36574463 0.60249207 0.52748008 1.10465711\n",
      " 0.57884863 0.21237329 0.6863188  0.06359221 0.20049332 0.82864827]\n",
      "epoch 44\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001720102217463631 R2: 0.9071534921011587 time: 1703115483.0709858\n",
      "batch_idx: 1 loss: 0.0006753185595554905 R2: 0.9071897216678542 time: 1703115486.52301\n",
      "batch_idx: 2 loss: 0.0017123567515962515 R2: 0.9072245844863337 time: 1703115489.9663286\n",
      "batch_idx: 3 loss: 0.0009230205862271674 R2: 0.9072549223040708 time: 1703115493.424809\n",
      "Training [15%] Loss: 0.001257699528710635 time: 1703115493.424809\n",
      "weight: [0.32852767 0.9106309  0.36099331 0.60120435 0.528197   1.10544092\n",
      " 0.5806397  0.21338901 0.68495714 0.0630711  0.20034032 0.82848923]\n",
      "epoch 45\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017160346078183917 R2: 0.9073019635543179 time: 1703115496.8718872\n",
      "batch_idx: 1 loss: 0.0006758273853609473 R2: 0.9073374794934151 time: 1703115500.3464837\n",
      "batch_idx: 2 loss: 0.0017095606646468965 R2: 0.9073704669006112 time: 1703115503.712459\n",
      "batch_idx: 3 loss: 0.0009213766973252288 R2: 0.90740179346723 time: 1703115507.1568623\n",
      "Training [15%] Loss: 0.001255699838787866 time: 1703115507.1568623\n",
      "weight: [0.32974535 0.90859202 0.35636242 0.59989546 0.52892596 1.10623762\n",
      " 0.58246069 0.21442544 0.68358405 0.06256591 0.20017604 0.82831875]\n",
      "epoch 46\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017118045520759656 R2: 0.9074463864187029 time: 1703115510.5280943\n",
      "batch_idx: 1 loss: 0.00067637517336158 R2: 0.9074814695846098 time: 1703115513.8886235\n",
      "batch_idx: 2 loss: 0.0017068602474751015 R2: 0.9075128927840549 time: 1703115517.3017523\n",
      "batch_idx: 3 loss: 0.0009195578795151982 R2: 0.9075439434579667 time: 1703115520.7063963\n",
      "Training [15%] Loss: 0.0012536494631069613 time: 1703115520.7063963\n",
      "weight: [0.33095866 0.90657436 0.35176968 0.59857317 0.52965368 1.1070352\n",
      " 0.58426962 0.21545462 0.68220092 0.06205723 0.20001717 0.82815378]\n",
      "epoch 47\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017080681839458656 R2: 0.9075876512922731 time: 1703115524.167496\n",
      "batch_idx: 1 loss: 0.0006766843965870591 R2: 0.9076218771740313 time: 1703115527.6194875\n",
      "batch_idx: 2 loss: 0.0017043312077637256 R2: 0.9076527657680579 time: 1703115530.9228477\n",
      "batch_idx: 3 loss: 0.0009175228789991372 R2: 0.9076811845775788 time: 1703115534.2901306\n",
      "Training [16%] Loss: 0.0012516516668239469 time: 1703115534.2901306\n",
      "weight: [0.33216551 0.90456608 0.34720661 0.59723833 0.5303784  1.1078321\n",
      " 0.58606076 0.21647281 0.68080845 0.06154629 0.19986443 0.82799506]\n",
      "epoch 48\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017046712216989511 R2: 0.9077257286237168 time: 1703115537.6482127\n",
      "batch_idx: 1 loss: 0.0006769519634958179 R2: 0.9077587787978404 time: 1703115541.1408362\n",
      "batch_idx: 2 loss: 0.0017018102400053272 R2: 0.9077891217327272 time: 1703115544.5206227\n",
      "batch_idx: 3 loss: 0.0009156705602296526 R2: 0.9078153962334297 time: 1703115547.9407685\n",
      "Training [16%] Loss: 0.0012497759963574374 time: 1703115547.9407685\n",
      "weight: [0.33337545 0.90262253 0.34272791 0.59588622 0.531108   1.10863544\n",
      " 0.58785857 0.21749674 0.67940731 0.0610514  0.19970518 0.82782978]\n",
      "epoch 49\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017010989554801092 R2: 0.9078600779128783 time: 1703115551.368953\n",
      "batch_idx: 1 loss: 0.0006774268032724433 R2: 0.9078923302680186 time: 1703115554.7222166\n",
      "batch_idx: 2 loss: 0.0016991968771193175 R2: 0.9079213992752667 time: 1703115558.0992267\n",
      "batch_idx: 3 loss: 0.0009141065650898223 R2: 0.9079473857094117 time: 1703115561.6972644\n",
      "Training [16%] Loss: 0.001247957300240423 time: 1703115561.6972644\n",
      "weight: [0.33459101 0.90075733 0.33834937 0.59451552 0.53184457 1.10944712\n",
      " 0.58966921 0.21853078 0.67799783 0.06057661 0.19953641 0.82765488]\n",
      "epoch 50\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016973647557154837 R2: 0.9079908298247629 time: 1703115565.1071224\n",
      "batch_idx: 1 loss: 0.0006780086897644705 R2: 0.9080226298232364 time: 1703115568.6256702\n",
      "batch_idx: 2 loss: 0.0016965930156860975 R2: 0.9080503259509382 time: 1703115572.0470836\n",
      "batch_idx: 3 loss: 0.0009125588788981554 R2: 0.908075921963359 time: 1703115575.4375966\n",
      "Training [17%] Loss: 0.0012461313350160517 time: 1703115575.4375966\n",
      "weight: [0.33580546 0.89892994 0.33403492 0.59312924 0.53258253 1.1102621\n",
      " 0.59147473 0.2195628  0.67657955 0.06010889 0.19936717 0.82747954]\n",
      "epoch 51\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016938378471298328 R2: 0.9081185729153477 time: 1703115578.8566196\n",
      "batch_idx: 1 loss: 0.0006784972933964582 R2: 0.9081497874320361 time: 1703115582.2470882\n",
      "batch_idx: 2 loss: 0.0016940916492734499 R2: 0.9081766642237609 time: 1703115585.7134378\n",
      "batch_idx: 3 loss: 0.0009109125766129207 R2: 0.9082005036090253 time: 1703115589.150476\n",
      "Training [17%] Loss: 0.0012443348416031653 time: 1703115589.150476\n",
      "weight: [0.33701614 0.89712435 0.32977147 0.59172844 0.53331968 1.11107842\n",
      " 0.59326788 0.22058792 0.67515216 0.05964157 0.1992017  0.82730806]\n",
      "epoch 52\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016905423931420586 R2: 0.908243482966441 time: 1703115592.055281\n",
      "batch_idx: 1 loss: 0.0006789353981327895 R2: 0.9082739017580653 time: 1703115594.8796792\n",
      "batch_idx: 2 loss: 0.0016916450472772176 R2: 0.9083000685885088 time: 1703115597.7043562\n",
      "batch_idx: 3 loss: 0.0009093412008348506 R2: 0.908322174598788 time: 1703115600.4828992\n",
      "Training [17%] Loss: 0.001242616009846729 time: 1703115600.4828992\n",
      "weight: [0.3382276  0.89536658 0.32558636 0.59031092 0.5340598  1.11189948\n",
      " 0.59506018 0.22161416 0.67371617 0.05918023 0.19903527 0.82713563]\n",
      "epoch 53\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016872140244278484 R2: 0.9083652745791033 time: 1703115603.2124753\n",
      "batch_idx: 1 loss: 0.0006794561909750829 R2: 0.9083950609063278 time: 1703115606.209494\n",
      "batch_idx: 2 loss: 0.001689202688525071 R2: 0.9084201543946907 time: 1703115608.9398205\n",
      "batch_idx: 3 loss: 0.000907919600977512 R2: 0.9084415542475123 time: 1703115611.6756065\n",
      "Training [18%] Loss: 0.0012409481262263785 time: 1703115611.6756065\n",
      "weight: [0.3394419  0.89366737 0.32149216 0.58887561 0.5348046  1.11272685\n",
      " 0.5968566  0.2226451  0.67227189 0.05872653 0.19886608 0.82696042]\n",
      "epoch 54\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001683826755798052 R2: 0.9084840054417354 time: 1703115614.5434756\n",
      "batch_idx: 1 loss: 0.0006800193609965935 R2: 0.9085133639037922 time: 1703115617.353001\n",
      "batch_idx: 2 loss: 0.0016868126526091085 R2: 0.9085373445203878 time: 1703115620.142146\n",
      "batch_idx: 3 loss: 0.0009065155581240693 R2: 0.9085580156501353 time: 1703115622.8758879\n",
      "Training [18%] Loss: 0.0012392935818819558 time: 1703115622.8758879\n",
      "weight: [0.34065591 0.89200679 0.31747114 0.58742369 0.53555147 1.11355817\n",
      " 0.59864846 0.22367486 0.67081882 0.05827396 0.19869864 0.826787  ]\n",
      "epoch 55\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016805660276960292 R2: 0.9086000602204173 time: 1703115625.6845024\n",
      "batch_idx: 1 loss: 0.0006805216897559034 R2: 0.9086289177280156 time: 1703115628.4161553\n",
      "batch_idx: 2 loss: 0.001684519109144355 R2: 0.9086520968488635 time: 1703115631.2726028\n",
      "batch_idx: 3 loss: 0.0009050737120239143 R2: 0.9086713173531397 time: 1703115634.0800483\n",
      "Training [18%] Loss: 0.0012376701346550503 time: 1703115634.0800483\n",
      "weight: [0.34186824 0.89037574 0.31351585 0.58595554 0.53629929 1.11439246\n",
      " 0.60043177 0.22470076 0.66935683 0.05781972 0.19853493 0.82661739]\n",
      "epoch 56\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016774384585829375 R2: 0.9087135590701733 time: 1703115636.8098397\n",
      "batch_idx: 1 loss: 0.0006809912874958237 R2: 0.9087418101293657 time: 1703115639.541557\n",
      "batch_idx: 2 loss: 0.0016822910822735474 R2: 0.908764233864915 time: 1703115642.2898793\n",
      "batch_idx: 3 loss: 0.0009036848295139645 R2: 0.9087821136538862 time: 1703115645.124477\n",
      "Training [19%] Loss: 0.0012361014144665684 time: 1703115645.124477\n",
      "weight: [0.34308105 0.88878542 0.30963874 0.58447006 0.53704984 1.11523132\n",
      " 0.60221172 0.22572659 0.6678866  0.05736764 0.19837224 0.82644882]\n",
      "epoch 57\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016743107628442318 R2: 0.9088243711892623 time: 1703115647.9693635\n",
      "batch_idx: 1 loss: 0.0006814949150587032 R2: 0.9088521196770942 time: 1703115650.7129598\n",
      "batch_idx: 2 loss: 0.0016801011253527217 R2: 0.9088736127758222 time: 1703115653.5100262\n",
      "batch_idx: 3 loss: 0.0009023740620513948 R2: 0.9088906818040808 time: 1703115656.245025\n",
      "Training [19%] Loss: 0.0012345702163267629 time: 1703115656.245025\n",
      "weight: [0.34429481 0.88723699 0.30584213 0.58296681 0.53780352 1.11607515\n",
      " 0.60398906 0.22675303 0.66640851 0.05691913 0.19820975 0.82628049]\n",
      "epoch 58\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00167119160598585 R2: 0.9089325947275974 time: 1703115658.9850075\n",
      "batch_idx: 1 loss: 0.0006820036130702546 R2: 0.9089599372982123 time: 1703115661.8947334\n",
      "batch_idx: 2 loss: 0.0016779701846421802 R2: 0.9089805463693621 time: 1703115664.634497\n",
      "batch_idx: 3 loss: 0.0009010737893402265 R2: 0.9089966624618311 time: 1703115667.3803656\n",
      "Training [19%] Loss: 0.0012330597982596278 time: 1703115667.3803656\n",
      "weight: [0.34550767 0.88571836 0.30211483 0.58144631 0.53855881 1.1169226\n",
      " 0.60575852 0.2277765  0.66492232 0.05647203 0.19804948 0.82611442]\n",
      "epoch 59\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00166816990549406 R2: 0.9090384744290109 time: 1703115670.127305\n",
      "batch_idx: 1 loss: 0.0006824767286446774 R2: 0.909065355845669 time: 1703115672.9360287\n",
      "batch_idx: 2 loss: 0.001675906389909625 R2: 0.9090852472654648 time: 1703115675.6821983\n",
      "batch_idx: 3 loss: 0.0008997787798507191 R2: 0.9091000835808816 time: 1703115678.4766085\n",
      "Training [20%] Loss: 0.0012315829509747704 time: 1703115678.4766085\n",
      "weight: [0.34671931 0.88422639 0.29845438 0.5799084  0.53931545 1.11777344\n",
      " 0.60751878 0.2287962  0.66342821 0.05602683 0.19789144 0.82595065]\n",
      "epoch 60\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016652201403768818 R2: 0.9091420510823554 time: 1703115681.3001344\n",
      "batch_idx: 1 loss: 0.000682945185620693 R2: 0.9091684495378732 time: 1703115684.0457973\n",
      "batch_idx: 2 loss: 0.001673884820286365 R2: 0.9091876008064601 time: 1703115686.7931805\n",
      "batch_idx: 3 loss: 0.000898537676111884 R2: 0.9092013580992152 time: 1703115689.6264985\n",
      "Training [20%] Loss: 0.0012301469555989558 time: 1703115689.6264985\n",
      "weight: [0.34793074 0.88276558 0.29486587 0.57835244 0.5400743  1.11862847\n",
      " 0.60927207 0.22981387 0.66192683 0.05558621 0.19773399 0.82578749]\n",
      "epoch 61\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016622829739431108 R2: 0.9092432915665208 time: 1703115692.3792202\n",
      "batch_idx: 1 loss: 0.0006834335825185192 R2: 0.9092692913763752 time: 1703115695.1892388\n",
      "batch_idx: 2 loss: 0.0016718965831903799 R2: 0.9092876353514457 time: 1703115697.9188287\n",
      "batch_idx: 3 loss: 0.0008973434800431706 R2: 0.9093005185240498 time: 1703115700.7433004\n",
      "Training [20%] Loss: 0.001228739154923795 time: 1703115700.7433004\n",
      "weight: [0.34914167 0.88133289 0.2913466  0.57677825 0.54083513 1.11948751\n",
      " 0.61101715 0.23082875 0.66041832 0.05515044 0.19757721 0.82562504]\n",
      "epoch 62\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00165938754233666 R2: 0.909342326820245 time: 1703115703.5467858\n",
      "batch_idx: 1 loss: 0.0006839170396182863 R2: 0.9093679620842895 time: 1703115706.3816264\n",
      "batch_idx: 2 loss: 0.0016699530401596465 R2: 0.9093855750488162 time: 1703115709.2668412\n",
      "batch_idx: 3 loss: 0.000896165222914105 R2: 0.9093974086353918 time: 1703115712.103114\n",
      "Training [21%] Loss: 0.0012273557112571743 time: 1703115712.103114\n",
      "weight: [0.35035123 0.87992242 0.28789076 0.57518587 0.54159724 1.12034996\n",
      " 0.61275138 0.23183906 0.6589026  0.05471865 0.197422   0.82546421]\n",
      "epoch 63\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016565636849192773 R2: 0.9094392932196765 time: 1703115714.839046\n",
      "batch_idx: 1 loss: 0.0006843876719440233 R2: 0.9094645361409464 time: 1703115717.6433513\n",
      "batch_idx: 2 loss: 0.0016680504792210519 R2: 0.9094814801925255 time: 1703115720.3862126\n",
      "batch_idx: 3 loss: 0.0008950166121384181 R2: 0.9094922007054432 time: 1703115723.1180124\n",
      "Training [21%] Loss: 0.0012260046120556927 time: 1703115723.1180124\n",
      "weight: [0.35155971 0.87853473 0.28449898 0.57357489 0.54236092 1.12121608\n",
      " 0.61447512 0.23284515 0.65738001 0.05429163 0.19726788 0.82530452]\n",
      "epoch 64\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016537792801828324 R2: 0.9095341989090379 time: 1703115725.9689054\n",
      "batch_idx: 1 loss: 0.000684866337262874 R2: 0.9095590776057646 time: 1703115728.7751708\n",
      "batch_idx: 2 loss: 0.0016661775596445677 R2: 0.9095753151237366 time: 1703115731.507158\n",
      "batch_idx: 3 loss: 0.0008939132827268138 R2: 0.9095850938353417 time: 1703115734.253369\n",
      "Training [21%] Loss: 0.001224684114954272 time: 1703115734.253369\n",
      "weight: [0.3527675  0.87717086 0.28117229 0.57194488 0.5431265  1.12208621\n",
      " 0.61618898 0.23384759 0.65585095 0.05387012 0.19711437 0.82514547]\n",
      "epoch 65\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016510216293649127 R2: 0.9096270857354651 time: 1703115737.0615654\n",
      "batch_idx: 1 loss: 0.0006853515989550715 R2: 0.9096516532586081 time: 1703115739.7870195\n",
      "batch_idx: 2 loss: 0.0016643376829399484 R2: 0.9096671900065383 time: 1703115742.6337912\n",
      "batch_idx: 3 loss: 0.0008928385942894369 R2: 0.9096760343127576 time: 1703115745.4543328\n",
      "Training [22%] Loss: 0.0012233873763873423 time: 1703115745.4543328\n",
      "weight: [0.35397422 0.87582774 0.27790736 0.57029565 0.54389371 1.12296012\n",
      " 0.61789157 0.23484547 0.65431542 0.05345344 0.196962   0.82498762]\n",
      "epoch 66\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016483146377134594 R2: 0.9097180721138317 time: 1703115748.177261\n",
      "batch_idx: 1 loss: 0.0006858290061411317 R2: 0.9097423305361205 time: 1703115750.9326546\n",
      "batch_idx: 2 loss: 0.0016625356034488733 R2: 0.90975722541387 time: 1703115753.6636374\n",
      "batch_idx: 3 loss: 0.0008917857973757472 R2: 0.909765038986165 time: 1703115756.4709837\n",
      "Training [22%] Loss: 0.0012221162611698029 time: 1703115756.4709837\n",
      "weight: [0.35517974 0.87450382 0.27470231 0.56862693 0.54466247 1.12383775\n",
      " 0.61958222 0.23583836 0.65277357 0.05304123 0.19681104 0.82483122]\n",
      "epoch 67\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001645655292696954 R2: 0.9098072177571768 time: 1703115759.2826843\n",
      "batch_idx: 1 loss: 0.0006863041139252025 R2: 0.909831169230699 time: 1703115762.0472863\n",
      "batch_idx: 2 loss: 0.0016607661802435943 R2: 0.9098454284718243 time: 1703115764.8743978\n",
      "batch_idx: 3 loss: 0.0008907662365686163 R2: 0.9098522730027414 time: 1703115767.60511\n",
      "Training [22%] Loss: 0.0012208729558585917 time: 1703115767.60511\n",
      "weight: [0.3563844  0.87320002 0.27155772 0.56693829 0.54543311 1.12471944\n",
      " 0.62126144 0.23682675 0.65122579 0.05263388 0.19666115 0.82467593]\n",
      "epoch 68\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016430260818394572 R2: 0.9098945456735331 time: 1703115770.3354676\n",
      "batch_idx: 1 loss: 0.0006867832424763844 R2: 0.9099182265778009 time: 1703115773.1729631\n",
      "batch_idx: 2 loss: 0.0016590277146232748 R2: 0.9099318412892087 time: 1703115776.0192826\n",
      "batch_idx: 3 loss: 0.0008897769434788305 R2: 0.9099377826234869 time: 1703115778.7400315\n",
      "Training [23%] Loss: 0.0012196534956044867 time: 1703115778.7400315\n",
      "weight: [0.35758819 0.87191541 0.26847218 0.56522939 0.54620566 1.12560521\n",
      " 0.62292887 0.23781043 0.64967229 0.0522312  0.19651245 0.82452189]\n",
      "epoch 69\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016404343162484936 R2: 0.9099801322083737 time: 1703115781.5592256\n",
      "batch_idx: 1 loss: 0.0006872585499989781 R2: 0.9100035612356832 time: 1703115784.2795439\n",
      "batch_idx: 2 loss: 0.0016573237635449246 R2: 0.9100165659484535 time: 1703115787.0780337\n",
      "batch_idx: 3 loss: 0.0008888089993292584 R2: 0.9100215564476033 time: 1703115790.231143\n",
      "Training [23%] Loss: 0.0012184564072804137 time: 1703115790.231143\n",
      "weight: [0.35879092 0.87064832 0.26544344 0.56349995 0.54698001 1.12649501\n",
      " 0.62458372 0.23878889 0.64811322 0.05183278 0.19636526 0.82436939]\n",
      "epoch 70\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016378863069002251 R2: 0.9100640506616365 time: 1703115793.303142\n",
      "batch_idx: 1 loss: 0.0006877283317994965 R2: 0.91008722822049 time: 1703115796.2037604\n",
      "batch_idx: 2 loss: 0.0016556527725921759 R2: 0.910099646855613 time: 1703115798.9257174\n",
      "batch_idx: 3 loss: 0.0008878663085842857 R2: 0.9101036899563782 time: 1703115801.6522026\n",
      "Training [23%] Loss: 0.0012172834299690458 time: 1703115801.6522026\n",
      "weight: [0.35999274 0.86939875 0.26247094 0.56174957 0.54775635 1.127389\n",
      " 0.62622605 0.23976226 0.64654891 0.05143878 0.19621945 0.82421833]\n",
      "epoch 71\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016353718193937473 R2: 0.9101463324389492 time: 1703115804.473704\n",
      "batch_idx: 1 loss: 0.0006881980838006022 R2: 0.9101692786780488 time: 1703115807.3327944\n",
      "batch_idx: 2 loss: 0.0016540115956504993 R2: 0.9101811093269561 time: 1703115810.057708\n",
      "batch_idx: 3 loss: 0.0008869509410714946 R2: 0.9101842615016121 time: 1703115812.8882763\n",
      "Training [24%] Loss: 0.0012161331099790856 time: 1703115812.8882763\n",
      "weight: [0.36119374 0.86816648 0.25955378 0.55997787 0.54853478 1.12828733\n",
      " 0.62785579 0.24073054 0.64497972 0.05104931 0.19607495 0.82406862]\n",
      "epoch 72\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016328894965807305 R2: 0.9102270273527905 time: 1703115815.624868\n",
      "batch_idx: 1 loss: 0.0006886657956105533 R2: 0.9102497636975058 time: 1703115818.3411233\n",
      "batch_idx: 2 loss: 0.0016524009931723344 R2: 0.9102610242227248 time: 1703115821.0899575\n",
      "batch_idx: 3 loss: 0.0008860574498476959 R2: 0.9102632777533726 time: 1703115824.0448256\n",
      "Training [24%] Loss: 0.0012150034338028284 time: 1703115824.0448256\n",
      "weight: [0.36239382 0.86695034 0.25669012 0.5581845  0.54931529 1.12918999\n",
      " 0.62947241 0.24169338 0.64340586 0.05066418 0.1959319  0.82392041]\n",
      "epoch 73\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016304448079001467 R2: 0.9103062006693593 time: 1703115826.768145\n",
      "batch_idx: 1 loss: 0.0006891286711422286 R2: 0.9103287326407651 time: 1703115829.4892673\n",
      "batch_idx: 2 loss: 0.001650820481038628 R2: 0.9103394469102414 time: 1703115832.330497\n",
      "batch_idx: 3 loss: 0.000885185832527249 R2: 0.9103407915237651 time: 1703115835.0536768\n",
      "Training [24%] Loss: 0.001213894948152063 time: 1703115835.0536768\n",
      "weight: [0.36359302 0.86574989 0.25387878 0.55636908 0.55009796 1.13009707\n",
      " 0.6310757  0.2426507  0.64182768 0.05028345 0.1957903  0.8237737 ]\n",
      "epoch 74\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016280335569015124 R2: 0.910383891489943 time: 1703115837.862902\n",
      "batch_idx: 1 loss: 0.0006895896758201392 R2: 0.9104062315825401 time: 1703115840.6760733\n",
      "batch_idx: 2 loss: 0.0016492674545846287 R2: 0.9104164049783966 time: 1703115843.3937566\n",
      "batch_idx: 3 loss: 0.0008843383402916835 R2: 0.9104168757519583 time: 1703115846.1127777\n",
      "Training [25%] Loss: 0.001212807256899491 time: 1703115846.1127777\n",
      "weight: [0.36479142 0.86456502 0.25111892 0.55453121 0.55088291 1.13100872\n",
      " 0.63266565 0.24360251 0.64024558 0.04990726 0.19565004 0.82362837]\n",
      "epoch 75\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016256523360761294 R2: 0.91046013841868 time: 1703115848.9319837\n",
      "batch_idx: 1 loss: 0.0006900491401926799 R2: 0.9104823054187976 time: 1703115851.655279\n",
      "batch_idx: 2 loss: 0.0016477413917705293 R2: 0.9104919485221155 time: 1703115854.485136\n",
      "batch_idx: 3 loss: 0.0008835123038733027 R2: 0.9104915549679491 time: 1703115857.2061458\n",
      "Training [25%] Loss: 0.0012117387929781603 time: 1703115857.2061458\n",
      "weight: [0.36598898 0.86339505 0.24840909 0.5526705  0.5516702  1.131925\n",
      " 0.63424194 0.24454862 0.63865988 0.04953552 0.19551118 0.8234845 ]\n",
      "epoch 76\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016233039623018356 R2: 0.910534994692077 time: 1703115860.0208983\n",
      "batch_idx: 1 loss: 0.0006905049682969858 R2: 0.9105569978347402 time: 1703115862.7447896\n",
      "batch_idx: 2 loss: 0.0016462421438853305 R2: 0.9105661295431334 time: 1703115865.4815497\n",
      "batch_idx: 3 loss: 0.0008827064264938881 R2: 0.9105648646051632 time: 1703115868.1988497\n",
      "Training [25%] Loss: 0.0012106893752445102 time: 1703115868.1988497\n",
      "weight: [0.36718573 0.86223954 0.24574806 0.55078656 0.55245989 1.13284599\n",
      " 0.63580435 0.24548889 0.63707096 0.04916822 0.19537375 0.82334211]\n",
      "epoch 77\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001620987102013543 R2: 0.9106085009672705 time: 1703115871.144602\n",
      "batch_idx: 1 loss: 0.0006909582676943531 R2: 0.9106303500809633 time: 1703115873.8695989\n",
      "batch_idx: 2 loss: 0.0016447681290101095 R2: 0.9106389792994575 time: 1703115876.6008723\n",
      "batch_idx: 3 loss: 0.0008819218706216929 R2: 0.9106368632932347 time: 1703115879.4073844\n",
      "Training [26%] Loss: 0.0012096588423349244 time: 1703115879.4073844\n",
      "weight: [0.36838172 0.86109836 0.24313496 0.54887896 0.5532521  1.13377183\n",
      " 0.63735286 0.24642333 0.63547927 0.0488054  0.1952377  0.82320113]\n",
      "epoch 78\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016186988452280416 R2: 0.9106806916162306 time: 1703115882.1231859\n",
      "batch_idx: 1 loss: 0.0006914097278541095 R2: 0.9107024018880076 time: 1703115884.8617253\n",
      "batch_idx: 2 loss: 0.0016433186365804736 R2: 0.9107105370818639 time: 1703115887.677028\n",
      "batch_idx: 3 loss: 0.0008811572861143757 R2: 0.9107075834653466 time: 1703115890.495285\n",
      "Training [26%] Loss: 0.0012086461239442501 time: 1703115890.495285\n",
      "weight: [0.36957696 0.85997115 0.24056863 0.5469473  0.55404692 1.13470261\n",
      " 0.63888731 0.24735183 0.63388523 0.048447   0.19510305 0.82306161]\n",
      "epoch 79\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001616440201551407 R2: 0.9107516102214832 time: 1703115893.2204273\n",
      "batch_idx: 1 loss: 0.0006918580405467588 R2: 0.9107731918638189 time: 1703115895.9496806\n",
      "batch_idx: 2 loss: 0.0016418935730721173 R2: 0.9107808477067311 time: 1703115898.673216\n",
      "batch_idx: 3 loss: 0.000880411258760709 R2: 0.9107770550039204 time: 1703115901.5553446\n",
      "Training [26%] Loss: 0.0012076507684827481 time: 1703115901.5553446\n",
      "weight: [0.37077147 0.85885757 0.23804793 0.54499115 0.55484443 1.13563842\n",
      " 0.64040752 0.24827428 0.63228927 0.04809294 0.19496985 0.82292357]\n",
      "epoch 80\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001614210789585192 R2: 0.9108212950767213 time: 1703115904.316609\n",
      "batch_idx: 1 loss: 0.0006923034470422556 R2: 0.9108427568274268 time: 1703115907.0307288\n",
      "batch_idx: 2 loss: 0.0016404919958465506 R2: 0.9108499432451692 time: 1703115909.7532544\n",
      "batch_idx: 3 loss: 0.000879684108527229 R2: 0.9108453242620131 time: 1703115912.5695527\n",
      "Training [27%] Loss: 0.0012066725852503068 time: 1703115912.5695527\n",
      "weight: [0.3719653  0.85775751 0.23557199 0.54301009 0.55564474 1.13657939\n",
      " 0.64191348 0.24919067 0.6306919  0.04774323 0.19483805 0.82278699]\n",
      "epoch 81\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016120085940408862 R2: 0.9108897781712336 time: 1703115915.3054116\n",
      "batch_idx: 1 loss: 0.0006927464818762044 R2: 0.9109111321618663 time: 1703115918.1151214\n",
      "batch_idx: 2 loss: 0.0016391132150676585 R2: 0.9109178573314681 time: 1703115920.9275794\n",
      "batch_idx: 3 loss: 0.0008789750405809614 R2: 0.9109124246003704 time: 1703115923.643114\n",
      "Training [27%] Loss: 0.0012057108328914275 time: 1703115923.643114\n",
      "weight: [0.37315846 0.85667074 0.2331398  0.54100368 0.55644796 1.13752564\n",
      " 0.6434051  0.25010091 0.62909361 0.04739781 0.19470769 0.82265189]\n",
      "epoch 82\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016098337456082498 R2: 0.910957096278073 time: 1703115926.3799984\n",
      "batch_idx: 1 loss: 0.000693186432861143 R2: 0.9109783521722361 time: 1703115929.1006327\n",
      "batch_idx: 2 loss: 0.0016377569849872343 R2: 0.9109846280420951 time: 1703115931.918637\n",
      "batch_idx: 3 loss: 0.000878282917874851 R2: 0.9109783839593335 time: 1703115934.7504025\n",
      "Training [27%] Loss: 0.0012047650203328695 time: 1703115934.7504025\n",
      "weight: [0.37435097 0.85559701 0.23075036 0.5389715  0.55725417 1.13847726\n",
      " 0.64488227 0.25100493 0.62749491 0.0470566  0.19457878 0.82251829]\n",
      "epoch 83\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016076860417274773 R2: 0.9110232839320531 time: 1703115937.4739878\n",
      "batch_idx: 1 loss: 0.0006936233082017209 R2: 0.9110444497810877 time: 1703115940.2258763\n",
      "batch_idx: 2 loss: 0.0016364225808404007 R2: 0.9110502860532627 time: 1703115943.0370967\n",
      "batch_idx: 3 loss: 0.0008776076570452054 R2: 0.9110432401144676 time: 1703115945.808865\n",
      "Training [28%] Loss: 0.001203834896953701 time: 1703115945.808865\n",
      "weight: [0.37554287 0.8545362  0.2284028  0.53691308 0.55806349 1.13943438\n",
      " 0.64634496 0.2519027  0.62589638 0.0467196  0.19445131 0.82238617]\n",
      "epoch 84\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016055641394013779 R2: 0.911088370882808 time: 1703115948.5177128\n",
      "batch_idx: 1 loss: 0.0006940574833608846 R2: 0.9111094566657334 time: 1703115951.4437444\n",
      "batch_idx: 2 loss: 0.00163510932029716 R2: 0.9111148614374274 time: 1703115954.1690388\n",
      "batch_idx: 3 loss: 0.0008769486968273595 R2: 0.9111070243133538 time: 1703115956.8869252\n",
      "Training [28%] Loss: 0.0012029199099716956 time: 1703115956.8869252\n",
      "weight: [0.37673417 0.85348817 0.22609622 0.534828   0.55887603 1.14039711\n",
      " 0.64779313 0.25279415 0.62429858 0.04638677 0.19432527 0.82225554]\n",
      "epoch 85\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016034678261110079 R2: 0.9111523890653638 time: 1703115959.6903934\n",
      "batch_idx: 1 loss: 0.0006944886173202177 R2: 0.9111734034898673 time: 1703115962.4257126\n",
      "batch_idx: 2 loss: 0.0016338168067755773 R2: 0.9111783869276862 time: 1703115965.177872\n",
      "batch_idx: 3 loss: 0.0008763051847483696 R2: 0.9111697631290889 time: 1703115968.0129862\n",
      "Training [28%] Loss: 0.001202019608738793 time: 1703115968.0129862\n",
      "weight: [0.3779249  0.85245271 0.22382972 0.53271581 0.55969188 1.14136557\n",
      " 0.64922672 0.25367922 0.6227021  0.04605804 0.19420069 0.8221264 ]\n",
      "epoch 86\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016013968696612444 R2: 0.9112153692346915 time: 1703115970.845735\n",
      "batch_idx: 1 loss: 0.0006949167022554329 R2: 0.9112363197831866 time: 1703115973.5838804\n",
      "batch_idx: 2 loss: 0.0016325444012842867 R2: 0.9112408908781765 time: 1703115976.309376\n",
      "batch_idx: 3 loss: 0.0008756768605199221 R2: 0.9112314885431717 time: 1703115979.117494\n",
      "Training [29%] Loss: 0.0012011337084302217 time: 1703115979.117494\n",
      "weight: [0.37911506 0.85142974 0.22160247 0.53057603 0.56051116 1.14233987\n",
      " 0.65064572 0.25455787 0.62110757 0.0457334  0.19407754 0.82199875]\n",
      "epoch 87\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001599350353770935 R2: 0.9112773388418466 time: 1703115981.9724379\n",
      "batch_idx: 1 loss: 0.0006953419845236706 R2: 0.9112982340113739 time: 1703115984.7288945\n",
      "batch_idx: 2 loss: 0.0016312914797764373 R2: 0.9113024006251811 time: 1703115987.554358\n",
      "batch_idx: 3 loss: 0.000875063236736554 R2: 0.9112922289008777 time: 1703115990.3035882\n",
      "Training [29%] Loss: 0.0012002617637018992 time: 1703115990.3035882\n",
      "weight: [0.38030468 0.85041914 0.21941368 0.52840824 0.56133397 1.14332013\n",
      " 0.65205012 0.25543005 0.61951562 0.0454128  0.19395584 0.82187258]\n",
      "epoch 88\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015973279730830323 R2: 0.9113383262034775 time: 1703115993.0298505\n",
      "batch_idx: 1 loss: 0.0006957643003433054 R2: 0.9113591737142868 time: 1703115995.773863\n",
      "batch_idx: 2 loss: 0.0016300576039893627 R2: 0.9113629448055969 time: 1703115998.6673753\n",
      "batch_idx: 3 loss: 0.0008744636384604317 R2: 0.911352009288998 time: 1703116001.4157403\n",
      "Training [29%] Loss: 0.001199403378969033 time: 1703116001.4157403\n",
      "weight: [0.38149377 0.84942077 0.21726252 0.52621195 0.56216042 1.14430646\n",
      " 0.6534399  0.25629571 0.61792691 0.04509621 0.19383556 0.82174788]\n",
      "epoch 89\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001595329455279813 R2: 0.911398358757267 time: 1703116004.1570852\n",
      "batch_idx: 1 loss: 0.0006961836510356927 R2: 0.9114191654732341 time: 1703116007.0760086\n",
      "batch_idx: 2 loss: 0.0016288422196218829 R2: 0.9114225493007938 time: 1703116009.816704\n",
      "batch_idx: 3 loss: 0.000873877716227638 R2: 0.9114108576075148 time: 1703116012.5383527\n",
      "Training [30%] Loss: 0.0011985582605412567 time: 1703116012.5383527\n",
      "weight: [0.38268235 0.84843455 0.21514826 0.52398672 0.56299063 1.145299\n",
      " 0.65481508 0.25715482 0.61634212 0.04478357 0.19371672 0.82162467]\n",
      "epoch 90\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015933541502293873 R2: 0.9114574617142777 time: 1703116015.4599447\n",
      "batch_idx: 1 loss: 0.0006966001814280736 R2: 0.9114782349637176 time: 1703116018.168\n",
      "batch_idx: 2 loss: 0.001627644790512307 R2: 0.9114812390962976 time: 1703116020.9021592\n",
      "batch_idx: 3 loss: 0.0008733049972892489 R2: 0.9114687994035556 time: 1703116023.6529715\n",
      "Training [30%] Loss: 0.0011977260298647542 time: 1703116023.6529715\n",
      "weight: [0.38387042 0.8474604  0.21307016 0.52173208 0.56382471 1.14629786\n",
      " 0.65617567 0.25800733 0.61476196 0.04447486 0.1935993  0.82150292]\n",
      "epoch 91\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015914017552783963 R2: 0.911515660513585 time: 1703116026.4756782\n",
      "batch_idx: 1 loss: 0.0006970138055119146 R2: 0.9115364070393793 time: 1703116029.200247\n",
      "batch_idx: 2 loss: 0.0016264648900677545 R2: 0.9115390396221553 time: 1703116032.0228324\n",
      "batch_idx: 3 loss: 0.0008727449130794497 R2: 0.9115258581435913 time: 1703116034.8364193\n",
      "Training [30%] Loss: 0.0011969063409843787 time: 1703116034.8364193\n",
      "weight: [0.385058   0.84649822 0.2110275  0.51944757 0.56466276 1.14730315\n",
      " 0.6575217  0.25885321 0.61318712 0.04417001 0.19348331 0.82138263]\n",
      "epoch 92\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015894719833410506 R2: 0.911572979785362 time: 1703116037.578523\n",
      "batch_idx: 1 loss: 0.0006974245369791699 R2: 0.9115937057373505 time: 1703116040.3144467\n",
      "batch_idx: 2 loss: 0.0016253020278803047 R2: 0.911595974445016 time: 1703116043.027851\n",
      "batch_idx: 3 loss: 0.0008721970792654246 R2: 0.9115820586407244 time: 1703116045.9273493\n",
      "Training [31%] Loss: 0.0011960989068664875 time: 1703116045.9273493\n",
      "weight: [0.38624509 0.84554795 0.20901961 0.51713274 0.56550491 1.148315\n",
      " 0.65885322 0.25969242 0.61161833 0.043869   0.19336873 0.82126381]\n",
      "epoch 93\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015875643519673633 R2: 0.9116294426448613 time: 1703116048.6666963\n",
      "batch_idx: 1 loss: 0.0006978324627427479 R2: 0.9116501543226952 time: 1703116051.4290662\n",
      "batch_idx: 2 loss: 0.0016241557296286795 R2: 0.9116520664406332 time: 1703116054.2272906\n",
      "batch_idx: 3 loss: 0.0008716610399039666 R2: 0.9116374239878633 time: 1703116056.9590588\n",
      "Training [31%] Loss: 0.0011953033960606894 time: 1703116056.9590588\n",
      "weight: [0.38743171 0.84460952 0.20704582 0.51478712 0.56635128 1.14933354\n",
      " 0.66017026 0.26052495 0.61005634 0.04357176 0.19325556 0.82114644]\n",
      "epoch 94\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001585678585003045 R2: 0.9116850721244761 time: 1703116059.7053337\n",
      "batch_idx: 1 loss: 0.0006982375445899849 R2: 0.9117057753406771 time: 1703116062.622432\n",
      "batch_idx: 2 loss: 0.0016230255782545906 R2: 0.9117073384370118 time: 1703116065.3549159\n",
      "batch_idx: 3 loss: 0.0008711363049029112 R2: 0.9116919759983423 time: 1703116068.0739508\n",
      "Training [31%] Loss: 0.0011945195031876328 time: 1703116068.0739508\n",
      "weight: [0.38861786 0.84368287 0.2051055  0.51241026 0.56720197 1.15035889\n",
      " 0.66147288 0.26135075 0.60850188 0.04327825 0.1931438  0.82103052]\n",
      "epoch 95\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001583814399181065 R2: 0.9117398904810601 time: 1703116070.8142567\n",
      "batch_idx: 1 loss: 0.0006986398133256269 R2: 0.9117605906349964 time: 1703116073.6279879\n",
      "batch_idx: 2 loss: 0.0016219111190206674 R2: 0.911761811929703 time: 1703116076.3656154\n",
      "batch_idx: 3 loss: 0.0008706224901117974 R2: 0.9117457370012401 time: 1703116079.1933908\n",
      "Training [32%] Loss: 0.0011937469554097891 time: 1703116079.1933908\n",
      "weight: [0.38980353 0.84276796 0.20319802 0.51000171 0.5680571  1.15139116\n",
      " 0.66276116 0.26216981 0.6069557  0.04298843 0.19303344 0.82091604]\n",
      "epoch 96\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015819714200062801 R2: 0.9117939189165851 time: 1703116082.0134969\n",
      "batch_idx: 1 loss: 0.000699039329451062 R2: 0.9118146213832132 time: 1703116084.7557263\n",
      "batch_idx: 2 loss: 0.0016208119144962949 R2: 0.9118155078837591 time: 1703116087.493772\n",
      "batch_idx: 3 loss: 0.000870119167449716 R2: 0.9117987279919519 time: 1703116090.3078413\n",
      "Training [32%] Loss: 0.0011929854578508383 time: 1703116090.3078413\n",
      "weight: [0.39098875 0.84186471 0.2013228  0.50756103 0.5689168  1.15243049\n",
      " 0.66403516 0.26298211 0.60541854 0.04270224 0.19292447 0.82080299]\n",
      "epoch 97\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015801493977780072 R2: 0.9118471783919789 time: 1703116093.0382483\n",
      "batch_idx: 1 loss: 0.0006994360864545795 R2: 0.9118678881301874 time: 1703116095.8510303\n",
      "batch_idx: 2 loss: 0.001619727558427541 R2: 0.9118684469541245 time: 1703116098.5794535\n",
      "batch_idx: 3 loss: 0.0008696259071065878 R2: 0.9118509691780664 time: 1703116101.3966367\n",
      "Training [32%] Loss: 0.0011922347374416788 time: 1703116101.3966367\n",
      "weight: [0.3921735  0.8409731  0.19947925 0.50508777 0.56978119 1.153477\n",
      " 0.66529496 0.26378763 0.60389117 0.04241965 0.19281688 0.82069137]\n",
      "epoch 98\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015783480639999688 R2: 0.9118996891425782 time: 1703116104.128516\n",
      "batch_idx: 1 loss: 0.0006998301238490993 R2: 0.9119204108085925 time: 1703116106.85531\n",
      "batch_idx: 2 loss: 0.0016186576272523695 R2: 0.9119206488084883 time: 1703116109.7804563\n",
      "batch_idx: 3 loss: 0.0008691423382545642 R2: 0.9119024808053384 time: 1703116112.5364232\n",
      "Training [33%] Loss: 0.0011914945383390003 time: 1703116112.5364232\n",
      "weight: [0.39335778 0.84009308 0.19766682 0.50258153 0.57065038 1.15453081\n",
      " 0.66654067 0.26458635 0.60237431 0.0421406  0.19271066 0.82058115]\n",
      "epoch 99\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015765671165143768 R2: 0.9119514706427477 time: 1703116115.2693546\n",
      "batch_idx: 1 loss: 0.0007002214844433252 R2: 0.9119722087655207 time: 1703116118.0579252\n",
      "batch_idx: 2 loss: 0.001617601717973973 R2: 0.9119721326794741 time: 1703116120.8035545\n",
      "batch_idx: 3 loss: 0.0008686680634934036 R2: 0.9119532820702292 time: 1703116123.5190845\n",
      "Training [33%] Loss: 0.0011907645956062696 time: 1703116123.5190845\n",
      "weight: [0.3945416  0.83922461 0.19588498 0.50004188 0.57152451 1.15559206\n",
      " 0.66777238 0.26537828 0.60086871 0.04186504 0.1926058  0.82047234]\n",
      "epoch 100\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015748063271651632 R2: 0.9120025420374903 time: 1703116126.3675284\n",
      "batch_idx: 1 loss: 0.0007006101755692315 R2: 0.9120233007850432 time: 1703116129.1662235\n",
      "batch_idx: 2 loss: 0.0016165594470435689 R2: 0.9120229173624553 time: 1703116131.9035494\n",
      "batch_idx: 3 loss: 0.000868202698464583 R2: 0.9120033916514105 time: 1703116134.6413498\n",
      "Training [33%] Loss: 0.0011900446620606367 time: 1703116134.6413498\n",
      "weight: [0.39572494 0.83836766 0.1941332  0.49746842 0.57240368 1.15666087\n",
      " 0.66899019 0.26616339 0.59937508 0.04159293 0.19250229 0.82036491]\n",
      "epoch 101\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015730654471903106 R2: 0.9120529218114927 time: 1703116137.4405105\n",
      "batch_idx: 1 loss: 0.0007009962322226493 R2: 0.9120737051066076 time: 1703116140.150136\n",
      "batch_idx: 2 loss: 0.0016155304275466016 R2: 0.912073020898758 time: 1703116142.9984906\n",
      "batch_idx: 3 loss: 0.0008677458910274036 R2: 0.9120528279896737 time: 1703116145.8052804\n",
      "Training [34%] Loss: 0.0011893344994967413 time: 1703116145.8052804\n",
      "weight: [0.39690782 0.83752219 0.192411   0.49486077 0.57328804 1.15773737\n",
      " 0.67019424 0.26694169 0.59789414 0.04132421 0.19240012 0.82025887]\n",
      "epoch 102\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015713442233059843 R2: 0.9121026278673698 time: 1703116148.555758\n",
      "batch_idx: 1 loss: 0.000701379680192293 R2: 0.9121234394436838 time: 1703116151.2640095\n",
      "batch_idx: 2 loss: 0.0016145142929458677 R2: 0.9121224609346245 time: 1703116153.9928992\n",
      "batch_idx: 3 loss: 0.0008672972766620247 R2: 0.9121016086981223 time: 1703116156.810088\n",
      "Training [34%] Loss: 0.0011886338682765424 time: 1703116156.810088\n",
      "weight: [0.39809022 0.8366882  0.19071789 0.49221858 0.57417771 1.15882169\n",
      " 0.67138463 0.26771319 0.59642656 0.04105883 0.19229927 0.82015419]\n",
      "epoch 103\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001569642442919688 R2: 0.9121516777224061 time: 1703116159.644684\n",
      "batch_idx: 1 loss: 0.0007017605279314683 R2: 0.9121725209990489 time: 1703116162.3606184\n",
      "batch_idx: 2 loss: 0.0016135106896283985 R2: 0.9121712546274792 time: 1703116165.1782155\n",
      "batch_idx: 3 loss: 0.0008668565099116324 R2: 0.9121497509926113 time: 1703116167.900869\n",
      "Training [34%] Loss: 0.0011879425425977968 time: 1703116167.900869\n",
      "weight: [0.39927213 0.83586564 0.1890534  0.48954151 0.57507281 1.15991396\n",
      " 0.67256152 0.26847789 0.594973   0.04079675 0.19219974 0.82005086]\n",
      "epoch 104\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001567959876576839 R2: 0.9122000883005651 time: 1703116170.6374812\n",
      "batch_idx: 1 loss: 0.0007021387980748328 R2: 0.9122209664784341 time: 1703116173.520417\n",
      "batch_idx: 2 loss: 0.0016125192684472076 R2: 0.9122194185340634 time: 1703116176.2843258\n",
      "batch_idx: 3 loss: 0.0008664232639641917 R2: 0.9121972716966352 time: 1703116179.0070994\n",
      "Training [35%] Loss: 0.0011872603017657676 time: 1703116179.0070994\n",
      "weight: [0.40045355 0.8350545  0.1874171  0.48682924 0.57597348 1.16101431\n",
      " 0.67372503 0.2692358  0.59353411 0.04053792 0.19210151 0.81994887]\n",
      "epoch 105\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015662963023997147 R2: 0.9122478760412914 time: 1703116181.7296607\n",
      "batch_idx: 1 loss: 0.0007025145004917856 R2: 0.9122687921017135 time: 1703116184.5349703\n",
      "batch_idx: 2 loss: 0.0016115396981927284 R2: 0.9122669688183149 time: 1703116187.2874503\n",
      "batch_idx: 3 loss: 0.0008659972110286 R2: 0.9122441869712661 time: 1703116190.1042666\n",
      "Training [35%] Loss: 0.0011865869280282071 time: 1703116190.1042666\n",
      "weight: [0.40163448 0.83425476 0.18580854 0.48408151 0.57687986 1.16212288\n",
      " 0.67487532 0.26998694 0.5921105  0.04028228 0.19200457 0.8198482 ]\n",
      "epoch 106\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015646515179035159 R2: 0.912295056960493 time: 1703116192.9318311\n",
      "batch_idx: 1 loss: 0.0007028876373033343 R2: 0.912316013611966 time: 1703116195.6566508\n",
      "batch_idx: 2 loss: 0.0016105716578690588 R2: 0.9123139211433939 time: 1703116198.3893774\n",
      "batch_idx: 3 loss: 0.0008655780431380576 R2: 0.9122905126079021 time: 1703116201.2056189\n",
      "Training [35%] Loss: 0.0011859222140534918 time: 1703116201.2056189\n",
      "weight: [0.4028149  0.83346642 0.18422732 0.48129808 0.57779206 1.1632398\n",
      " 0.67601255 0.27073133 0.59070272 0.04002978 0.1919089  0.81974884]\n",
      "epoch 107\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001563025309775718 R2: 0.9123416465374705 time: 1703116203.9422796\n",
      "batch_idx: 1 loss: 0.0007032582149440981 R2: 0.9123626462829657 time: 1703116206.7773705\n",
      "batch_idx: 2 loss: 0.0016096148359554144 R2: 0.9123602906629869 time: 1703116209.515364\n",
      "batch_idx: 3 loss: 0.0008651654646290606 R2: 0.9123362639269604 time: 1703116212.3180816\n",
      "Training [36%] Loss: 0.0011852659563260728 time: 1703116212.3180816\n",
      "weight: [0.40399482 0.83268946 0.18267303 0.47847875 0.57871023 1.16436522\n",
      " 0.67713687 0.27146899 0.58931133 0.03978037 0.19181448 0.81965077]\n",
      "epoch 108\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015614174751239168 R2: 0.9123876598080317 time: 1703116215.0512116\n",
      "batch_idx: 1 loss: 0.0007036262275501433 R2: 0.9124087049236781 time: 1703116217.7618694\n",
      "batch_idx: 2 loss: 0.0016086689370043 R2: 0.912406092119126 time: 1703116220.6074388\n",
      "batch_idx: 3 loss: 0.0008647591863656231 R2: 0.9123814556953155 time: 1703116223.7077081\n",
      "Training [36%] Loss: 0.0011846179565109958 time: 1703116223.7077081\n",
      "weight: [0.40517421 0.83192387 0.18114528 0.47562336 0.57963451 1.16549926\n",
      " 0.67824846 0.27219997 0.58793682 0.03953399 0.1917213  0.81955398]\n",
      "epoch 109\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015598278183222131 R2: 0.9124331113573148 time: 1703116226.6560998\n",
      "batch_idx: 1 loss: 0.0007039916652309409 R2: 0.9124542038815802 time: 1703116229.4727964\n",
      "batch_idx: 2 loss: 0.0016077336761570725 R2: 0.9124513397571276 time: 1703116232.2011783\n",
      "batch_idx: 3 loss: 0.0008643589368588537 R2: 0.9124261022869019 time: 1703116234.924696\n",
      "Training [36%] Loss: 0.00118397802414227 time: 1703116234.924696\n",
      "weight: [0.40635308 0.83116964 0.17964371 0.47273182 0.58056504 1.16664206\n",
      " 0.67934749 0.27292429 0.58657965 0.0392906  0.19162935 0.81945845]\n",
      "epoch 110\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015582561389501817 R2: 0.9124780152715806 time: 1703116237.7509434\n",
      "batch_idx: 1 loss: 0.0007043545158620781 R2: 0.9124991570440117 time: 1703116240.574876\n",
      "batch_idx: 2 loss: 0.001606808781394056 R2: 0.9124960473547363 time: 1703116243.3199565\n",
      "batch_idx: 3 loss: 0.0008639644544868382 R2: 0.912470217570411 time: 1703116246.0559366\n",
      "Training [37%] Loss: 0.0011833459726732884 time: 1703116246.0559366\n",
      "weight: [0.40753142 0.83042678 0.17816795 0.4698041  0.58150196 1.16779378\n",
      " 0.68043415 0.273642   0.58524025 0.03905014 0.1915386  0.81936416]\n",
      "epoch 111\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015567022456149091 R2: 0.9125223851967947 time: 1703116248.8646114\n",
      "batch_idx: 1 loss: 0.0007047147571825125 R2: 0.9125435778372124 time: 1703116251.5889764\n",
      "batch_idx: 2 loss: 0.0016058939957242478 R2: 0.91254022824952 time: 1703116254.440182\n",
      "batch_idx: 3 loss: 0.0008635754881894065 R2: 0.9125138149167084 time: 1703116257.2333915\n",
      "Training [37%] Loss: 0.001182721621677769 time: 1703116257.2333915\n",
      "weight: [0.40870921 0.82969527 0.17671766 0.46684022 0.5824454  1.16895454\n",
      " 0.68150863 0.27435315 0.583919   0.03881256 0.19144904 0.81927109]\n",
      "epoch 112\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015551659487000999 R2: 0.9125662343068367 time: 1703116259.9670012\n",
      "batch_idx: 1 loss: 0.0007050723637605935 R2: 0.9125874792245557 time: 1703116262.7013984\n",
      "batch_idx: 2 loss: 0.0016049890741460884 R2: 0.9125838952864974 time: 1703116265.4385724\n",
      "batch_idx: 3 loss: 0.0008631918017159479 R2: 0.9125569072594054 time: 1703116268.2313845\n",
      "Training [37%] Loss: 0.0011821047970806825 time: 1703116268.2313845\n",
      "weight: [0.40988646 0.82897513 0.1752925  0.46384028 0.58339553 1.1701245\n",
      " 0.68257111 0.27505779 0.58261623 0.0385778  0.19136065 0.81917922]\n",
      "epoch 113\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015536470584240638 R2: 0.9126095752915976 time: 1703116271.107931\n",
      "batch_idx: 1 loss: 0.0007054273049089257 R2: 0.9126308737028952 time: 1703116273.8367543\n",
      "batch_idx: 2 loss: 0.0016040937860764986 R2: 0.9126270608483082 time: 1703116276.652429\n",
      "batch_idx: 3 loss: 0.0008628131683940289 R2: 0.9125995070137142 time: 1703116279.3747847\n",
      "Training [38%] Loss: 0.0011814953294508792 time: 1703116279.3747847\n",
      "weight: [0.41106315 0.82826634 0.17389214 0.46080446 0.58435248 1.1713038\n",
      " 0.68362181 0.27575597 0.58133224 0.03834581 0.19127342 0.81908854]\n",
      "epoch 114\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015521453914940056 R2: 0.912652420381216 time: 1703116282.1085167\n",
      "batch_idx: 1 loss: 0.0007057795426622862 R2: 0.9126737732975416 time: 1703116284.9448423\n",
      "batch_idx: 2 loss: 0.0016032079152373201 R2: 0.9126697368463683 time: 1703116287.8159745\n",
      "batch_idx: 3 loss: 0.0008624393736791237 R2: 0.9126416261101585 time: 1703116290.5451677\n",
      "Training [38%] Loss: 0.001180893055768184 time: 1703116290.5451677\n",
      "weight: [0.41223928 0.82756891 0.17251627 0.45773304 0.58531639 1.17249259\n",
      " 0.68466092 0.27644777 0.58006727 0.03811654 0.19118731 0.81899902]\n",
      "epoch 115\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015506607651377996 R2: 0.9126947813141296 time: 1703116293.2767754\n",
      "batch_idx: 1 loss: 0.0007061290360285603 R2: 0.9127161895567613 time: 1703116296.08954\n",
      "batch_idx: 2 loss: 0.0016023312584994385 R2: 0.9127119346958205 time: 1703116298.8210285\n",
      "batch_idx: 3 loss: 0.0008620702155356152 R2: 0.9126832759965569 time: 1703116301.7342913\n",
      "Training [38%] Loss: 0.0011802978188003533 time: 1703116301.7342913\n",
      "weight: [0.41341485 0.82688285 0.17116459 0.45462639 0.58628743 1.17369102\n",
      " 0.68568864 0.27713325 0.57882154 0.03788993 0.19110232 0.81891064]\n",
      "epoch 116\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015491929992899223 R2: 0.91273666933955 time: 1703116304.604038\n",
      "batch_idx: 1 loss: 0.000706475738607992 R2: 0.9127581335449688 time: 1703116307.316885\n",
      "batch_idx: 2 loss: 0.001601463627445877 R2: 0.9127536653321551 time: 1703116310.0500724\n",
      "batch_idx: 3 loss: 0.0008617055019582567 R2: 0.9127244675959977 time: 1703116312.879602\n",
      "Training [39%] Loss: 0.001179709466825512 time: 1703116312.879602\n",
      "weight: [0.41458984 0.82620814 0.16983679 0.45148497 0.58726575 1.17489924\n",
      " 0.6867052  0.27781249 0.57759522 0.03766593 0.19101842 0.81882339]\n",
      "epoch 117\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015477419184262591 R2: 0.9127780952181661 time: 1703116315.6199052\n",
      "batch_idx: 1 loss: 0.0007068195995109927 R2: 0.912799615835714 time: 1703116318.4418464\n",
      "batch_idx: 2 loss: 0.0016006048475446122 R2: 0.912794939191245 time: 1703116321.172376\n",
      "batch_idx: 3 loss: 0.0008613450530234358 R2: 0.9127652113345542 time: 1703116323.9795156\n",
      "Training [39%] Loss: 0.0011791278546263249 time: 1703116323.9795156\n",
      "weight: [0.41576424 0.8255448  0.16853259 0.44830937 0.58825149 1.1761174\n",
      " 0.6877108  0.27848556 0.57638843 0.03744448 0.1909356  0.81873725]\n",
      "epoch 118\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001546307348480156 R2: 0.9128190692004947 time: 1703116326.7125807\n",
      "batch_idx: 1 loss: 0.0007071605652446653 R2: 0.9128406465047053 time: 1703116329.4415383\n",
      "batch_idx: 2 loss: 0.0015997547580582396 R2: 0.9128357662014063 time: 1703116332.2653024\n",
      "batch_idx: 3 loss: 0.00086098869978859 R2: 0.9128055171215822 time: 1703116335.102401\n",
      "Training [39%] Loss: 0.0011785528428929128 time: 1703116335.102401\n",
      "weight: [0.41693807 0.82489282 0.16725171 0.4451003  0.58924481 1.17734565\n",
      " 0.68870566 0.27915254 0.57520125 0.03722554 0.19085383 0.81865218]\n",
      "epoch 119\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015448891195438193 R2: 0.9128596010314057 time: 1703116337.8369865\n",
      "batch_idx: 1 loss: 0.0007074985784731263 R2: 0.9128812351228028 time: 1703116340.6593306\n",
      "batch_idx: 2 loss: 0.0015989132126247342 R2: 0.912876155787037 time: 1703116343.395293\n",
      "batch_idx: 3 loss: 0.0008606362836631467 R2: 0.9128453943378695 time: 1703116346.1244118\n",
      "Training [40%] Loss: 0.0011779842985762067 time: 1703116346.1244118\n",
      "weight: [0.41811129 0.8242522  0.16599387 0.4418586  0.59024587 1.17858416\n",
      " 0.68968999 0.27981352 0.57403375 0.03700904 0.19077309 0.81856819]\n",
      "epoch 120\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015434870654479481 R2: 0.9128996999414054 time: 1703116348.8477442\n",
      "batch_idx: 1 loss: 0.00070783357976419 R2: 0.9129213907500491 time: 1703116351.7638698\n",
      "batch_idx: 2 loss: 0.0015980800784686354 R2: 0.9129161168527832 time: 1703116354.5077426\n",
      "batch_idx: 3 loss: 0.0008602876573342248 R2: 0.9128848518497538 time: 1703116357.2380922\n",
      "Training [40%] Loss: 0.0011774220952537496 time: 1703116357.2380922\n",
      "weight: [0.41928392 0.82362293 0.16475879 0.43858524 0.59125482 1.17983308\n",
      " 0.69066402 0.28046858 0.57288593 0.03679493 0.19069337 0.81848523]\n",
      "epoch 121\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001542101023016064 R2: 0.912939374637522 time: 1703116360.0524838\n",
      "batch_idx: 1 loss: 0.0007081655081736621 R2: 0.9129611219308261 time: 1703116362.7761092\n",
      "batch_idx: 2 loss: 0.0015972552365503367 R2: 0.9129556577848712 time: 1703116365.5616367\n",
      "batch_idx: 3 loss: 0.0008599426836376406 R2: 0.9129238979926255 time: 1703116368.4095113\n",
      "Training [40%] Loss: 0.0011768661128444258 time: 1703116368.4095113\n",
      "weight: [0.42045594 0.82300501 0.1635462  0.43528135 0.59227181 1.18109257\n",
      " 0.69162795 0.28111782 0.57175777 0.03658316 0.19061464 0.8184033 ]\n",
      "epoch 122\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015407308337402966 R2: 0.9129786333072316 time: 1703116371.138481\n",
      "batch_idx: 1 loss: 0.0007084943012503549 R2: 0.9130004366906753 time: 1703116373.8516333\n",
      "batch_idx: 2 loss: 0.0015964385813691593 R2: 0.912994786450257 time: 1703116376.5859804\n",
      "batch_idx: 3 loss: 0.0008596012357502608 R2: 0.912962540577382 time: 1703116379.3736577\n",
      "Training [41%] Loss: 0.001176316238027518 time: 1703116379.3736577\n",
      "weight: [0.42162735 0.82239841 0.16235585 0.4319482  0.59329701 1.18236279\n",
      " 0.692582   0.28176132 0.57064921 0.03637367 0.19053689 0.81832237]\n",
      "epoch 123\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015393763428566654 R2: 0.9130174836127827 time: 1703116382.234266\n",
      "batch_idx: 1 loss: 0.0007088198965509384 R2: 0.9130393425355974 time: 1703116384.9591708\n",
      "batch_idx: 2 loss: 0.0015956300203053431 R2: 0.9130335101925402 time: 1703116387.93677\n",
      "batch_idx: 3 loss: 0.0008592631972708677 R2: 0.9130007868979815 time: 1703116390.958446\n",
      "Training [41%] Loss: 0.0011757723642459538 time: 1703116390.958446\n",
      "weight: [0.42279813 0.82180312 0.16118746 0.42858723 0.59433057 1.1836439\n",
      " 0.69352638 0.28239919 0.56956018 0.03616643 0.1904601  0.81824242]\n",
      "epoch 124\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015380373996758154 R2: 0.9130559326943622 time: 1703116393.952623\n",
      "batch_idx: 1 loss: 0.0007091422318614343 R2: 0.9130778464540524 time: 1703116396.9049644\n",
      "batch_idx: 2 loss: 0.0015948294734550845 R2: 0.9130718358403543 time: 1703116399.7241983\n",
      "batch_idx: 3 loss: 0.0008589284615849832 R2: 0.9130386437305527 time: 1703116402.4549446\n",
      "Training [41%] Loss: 0.0011752343916443294 time: 1703116402.4549446\n",
      "weight: [0.42396827 0.82121913 0.16004078 0.42520001 0.59537264 1.18493606\n",
      " 0.69446131 0.2830315  0.56849055 0.03596136 0.19038425 0.81816343]\n",
      "epoch 125\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015367138580546157 R2: 0.9130939871776024 time: 1703116405.1857328\n",
      "batch_idx: 1 loss: 0.0007094612459260157 R2: 0.9131159549224448 time: 1703116407.9805079\n",
      "batch_idx: 2 loss: 0.0015940368729058286 R2: 0.9131097697123683 time: 1703116410.7184772\n",
      "batch_idx: 3 loss: 0.0008585969321520592 R2: 0.9130761173511595 time: 1703116413.531847\n",
      "Training [42%] Loss: 0.0011747022272596299 time: 1703116413.531847\n",
      "weight: [0.42513777 0.82064639 0.15891554 0.42178832 0.59642338 1.18623944\n",
      " 0.69538698 0.28365836 0.56744019 0.03575843 0.19030931 0.81808539]\n",
      "epoch 126\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015354055756912227 R2: 0.9131316531797454 time: 1703116416.39015\n",
      "batch_idx: 1 loss: 0.0007097768794439391 R2: 0.9131536739145935 time: 1703116419.114904\n",
      "batch_idx: 2 loss: 0.0015932521620048146 R2: 0.9131473176282741 time: 1703116421.8629863\n",
      "batch_idx: 3 loss: 0.0008582685222070169 R2: 0.9131132135483506 time: 1703116424.6819172\n",
      "Training [42%] Loss: 0.0011741757848367483 time: 1703116424.6819172\n",
      "weight: [0.4263066  0.82008486 0.15781146 0.41835407 0.59748295 1.18755421\n",
      " 0.69630361 0.28427985 0.56640892 0.03555759 0.19023527 0.81800828]\n",
      "epoch 127\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015341124144817632 R2: 0.913168936325596 time: 1703116427.4053516\n",
      "batch_idx: 1 loss: 0.0007100890753813363 R2: 0.91319100891559 time: 1703116430.209346\n",
      "batch_idx: 2 loss: 0.0015924752946540853 R2: 0.9131844849268781 time: 1703116432.9309428\n",
      "batch_idx: 3 loss: 0.0008579431545187553 R2: 0.9131499376412929 time: 1703116435.7510107\n",
      "Training [42%] Loss: 0.001173654984758985 time: 1703116435.7510107\n",
      "weight: [0.42747476 0.81953451 0.1567283  0.41489934 0.59855148 1.18888052\n",
      " 0.69721138 0.28489607 0.56539655 0.03535879 0.19016212 0.81793208]\n",
      "epoch 128\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001532834240183504 R2: 0.9132058417653768 time: 1703116438.4748087\n",
      "batch_idx: 1 loss: 0.0007103977798409275 R2: 0.9132279649405748 time: 1703116441.2338145\n",
      "batch_idx: 2 loss: 0.001591706234204229 R2: 0.913221276484917 time: 1703116444.027662\n",
      "batch_idx: 3 loss: 0.0008576207614290531 R2: 0.9131862945077243 time: 1703116447.0992098\n",
      "Training [43%] Loss: 0.0011731397539144284 time: 1703116447.0992098\n",
      "weight: [0.42864221 0.81899528 0.15566577 0.41142638 0.59962915 1.19021855\n",
      " 0.69811048 0.28550709 0.56440287 0.03516198 0.19008984 0.81785677]\n",
      "epoch 129\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015315709219308978 R2: 0.9132423741973869 time: 1703116449.839684\n",
      "batch_idx: 1 loss: 0.0007107029426386051 R2: 0.913264546558698 time: 1703116452.6424146\n",
      "batch_idx: 2 loss: 0.0015909449524130932 R2: 0.9132576967443727 time: 1703116455.3707068\n",
      "batch_idx: 3 loss: 0.0008573012844527387 R2: 0.9132222886100658 time: 1703116458.1065607\n",
      "Training [43%] Loss: 0.0011726300253588338 time: 1703116458.1065607\n",
      "weight: [0.42980894 0.81846711 0.1546236  0.40793757 0.60071608 1.19156847\n",
      " 0.6990011  0.286113   0.56342764 0.03496712 0.19001841 0.81778233]\n",
      "epoch 130\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015303223321176886 R2: 0.913278537898171 time: 1703116460.848696\n",
      "batch_idx: 1 loss: 0.0007110045177337378 R2: 0.9133007579224282 time: 1703116464.0466795\n",
      "batch_idx: 2 loss: 0.0015901914282011626 R2: 0.9132937497440269 time: 1703116467.0208406\n",
      "batch_idx: 3 loss: 0.0008569846741044867 R2: 0.9132579240309152 time: 1703116469.746944\n",
      "Training [43%] Loss: 0.0011721257380392688 time: 1703116469.746944\n",
      "weight: [0.43097492 0.81794992 0.15360152 0.40443546 0.60181243 1.19293044\n",
      " 0.69988342 0.28671388 0.56247061 0.03477417 0.18994782 0.81770875]\n",
      "epoch 131\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001529088345673527 R2: 0.913314336755513 time: 1703116472.5874653\n",
      "batch_idx: 1 loss: 0.0007113024638790685 R2: 0.9133366028023178 time: 1703116475.3207436\n",
      "batch_idx: 2 loss: 0.0015894456462218123 R2: 0.9133294391553276 time: 1703116478.158752\n",
      "batch_idx: 3 loss: 0.0008566708896059391 R2: 0.913293204512191 time: 1703116480.993269\n",
      "Training [44%] Loss: 0.0011716268363450868 time: 1703116480.993269\n",
      "weight: [0.43214012 0.81744363 0.15259924 0.4009227  0.60291834 1.19430463\n",
      " 0.70075759 0.2873098  0.56153151 0.0345831  0.18987805 0.81763602]\n",
      "epoch 132\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015278688395542733 R2: 0.913349774308031 time: 1703116483.71663\n",
      "batch_idx: 1 loss: 0.0007115967449302025 R2: 0.9133720846269661 time: 1703116486.4701993\n",
      "batch_idx: 2 loss: 0.0015887075954310911 R2: 0.9133647683251102 time: 1703116489.1881356\n",
      "batch_idx: 3 loss: 0.0008563598984080163 R2: 0.9133281334966293 time: 1703116492.0138214\n",
      "Training [44%] Loss: 0.0011711332695808958 time: 1703116492.0138214\n",
      "weight: [0.43330451 0.81694815 0.15161647 0.39740208 0.60403395 1.19569122\n",
      " 0.70162377 0.28790083 0.56061005 0.03439385 0.18980909 0.81756412]\n",
      "epoch 133\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015266636921347067 R2: 0.9133848537895153 time: 1703116494.861082\n",
      "batch_idx: 1 loss: 0.0007118873302121005 R2: 0.9134072065278976 time: 1703116497.5838206\n",
      "batch_idx: 2 loss: 0.0015879772674720605 R2: 0.9133997403212957 time: 1703116500.4019797\n",
      "batch_idx: 3 loss: 0.0008560516758014187 R2: 0.9133627141758831 time: 1703116503.1388445\n",
      "Training [44%] Loss: 0.0011706449914050715 time: 1703116503.1388445\n",
      "weight: [0.43446804 0.81646338 0.15065292 0.39387648 0.6051594  1.19709038\n",
      " 0.70248212 0.28848704 0.55970592 0.0342064  0.18974092 0.81749303]\n",
      "epoch 134\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001525472782363144 R2: 0.9134195781766566 time: 1703116505.8975744\n",
      "batch_idx: 1 loss: 0.0007121741948112153 R2: 0.9134419713887633 time: 1703116508.6997619\n",
      "batch_idx: 2 loss: 0.0015872546550409477 R2: 0.9134343579831837 time: 1703116511.5590212\n",
      "batch_idx: 3 loss: 0.0008557462043011415 R2: 0.9133969495393236 time: 1703116514.300964\n",
      "Training [45%] Loss: 0.0011701619591291121 time: 1703116514.300964\n",
      "weight: [0.43563068 0.81598921 0.1497083  0.39034885 0.60629482 1.19850229\n",
      " 0.70333278 0.28906847 0.55881882 0.03402072 0.18967354 0.81742275]\n",
      "epoch 135\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00152429598909657 R2: 0.9134539502414339 time: 1703116517.0302885\n",
      "batch_idx: 1 loss: 0.0007124573196599844 R2: 0.9134763818980802 time: 1703116519.8950198\n",
      "batch_idx: 2 loss: 0.0015865397502447458 R2: 0.9134686239750639 time: 1703116522.6315732\n",
      "batch_idx: 3 loss: 0.0008554434729786365 R2: 0.9134308424257197 time: 1703116525.4159675\n",
      "Training [45%] Loss: 0.0011696841329949842 time: 1703116525.4159675\n",
      "weight: [0.43679238 0.81552552 0.1487823  0.3868222  0.60744034 1.19992711\n",
      " 0.70417587 0.28964519 0.55794843 0.03383677 0.18960692 0.81735326]\n",
      "epoch 136\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015231331902594862 R2: 0.9134879726053731 time: 1703116528.2682233\n",
      "batch_idx: 1 loss: 0.0007127366916369725 R2: 0.9135104406046031 time: 1703116531.0290334\n",
      "batch_idx: 2 loss: 0.001585832542932605 R2: 0.9135025408411648 time: 1703116533.7712119\n",
      "batch_idx: 3 loss: 0.0008551434767258269 R2: 0.9134643955765556 time: 1703116536.58549\n",
      "Training [45%] Loss: 0.0011692114753887228 time: 1703116536.58549\n",
      "weight: [0.43795307 0.81507218 0.14787462 0.38329958 0.6085961  1.20136504\n",
      " 0.70501152 0.29021723 0.55709441 0.03365453 0.18954106 0.81728455]\n",
      "epoch 137\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015219842620448963 R2: 0.9135216477955103 time: 1703116539.324404\n",
      "batch_idx: 1 loss: 0.0007130123034791199 R2: 0.9135441499741164 time: 1703116542.2460105\n",
      "batch_idx: 2 loss: 0.0015851330191336832 R2: 0.9135361110622476 time: 1703116544.9842982\n",
      "batch_idx: 3 loss: 0.0008548462153527656 R2: 0.9134976116881417 time: 1703116547.800453\n",
      "Training [46%] Loss: 0.0011687439500026162 time: 1703116547.800453\n",
      "weight: [0.43911272 0.81462905 0.14698495 0.37978402 0.60976222 1.20281625\n",
      " 0.70583985 0.29078465 0.55625643 0.03347397 0.18947596 0.8172166 ]\n",
      "epoch 138\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001520849078200826 R2: 0.9135549783010284 time: 1703116550.5514925\n",
      "batch_idx: 1 loss: 0.0007132841535896761 R2: 0.9135775124465416 time: 1703116553.2912402\n",
      "batch_idx: 2 loss: 0.0015844411595756461 R2: 0.913569337111506 time: 1703116556.110692\n",
      "batch_idx: 3 loss: 0.0008545516926604 R2: 0.9135304934636681 time: 1703116558.904003\n",
      "Training [46%] Loss: 0.0011682815210066369 time: 1703116558.904003\n",
      "weight: [0.44027126 0.814196   0.14611297 0.37627857 0.61093883 1.20428092\n",
      " 0.70666096 0.29134748 0.55543415 0.03329506 0.18941158 0.81714941]\n",
      "epoch 139\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015197275092807391 R2: 0.9135879666285136 time: 1703116561.6686199\n",
      "batch_idx: 1 loss: 0.0007135522457671101 R2: 0.9136105304919371 time: 1703116564.4854443\n",
      "batch_idx: 2 loss: 0.0015837569383506378 R2: 0.9136022215088865 time: 1703116567.2182584\n",
      "batch_idx: 3 loss: 0.0008542599154071258 R2: 0.9135630436624919 time: 1703116569.9600701\n",
      "Training [46%] Loss: 0.0011678241522014032 time: 1703116569.9600701\n",
      "weight: [0.44142862 0.81377288 0.14525839 0.37278619 0.61212605 1.20575925\n",
      " 0.70747494 0.29190575 0.55462721 0.03311779 0.18934794 0.81708297]\n",
      "epoch 140\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015186194220545895 R2: 0.9136206153554415 time: 1703116572.695188\n",
      "batch_idx: 1 loss: 0.0007138165887704171 R2: 0.9136432066642047 time: 1703116575.6004026\n",
      "batch_idx: 2 loss: 0.001583080321778944 R2: 0.9136347668728414 time: 1703116578.3365924\n",
      "batch_idx: 3 loss: 0.0008539708922166827 R2: 0.9135952651459733 time: 1703116581.068736\n",
      "Training [47%] Loss: 0.0011673718062051584 time: 1703116581.068736\n",
      "weight: [0.44258475 0.81335953 0.14442088 0.3693098  0.61332401 1.20725142\n",
      " 0.70828191 0.29245948 0.55383529 0.03294214 0.189285   0.81701726]\n",
      "epoch 141\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015175246789928543 R2: 0.9136529271801239 time: 1703116583.8990185\n",
      "batch_idx: 1 loss: 0.0007140771958211213 R2: 0.9136755436511651 time: 1703116586.6539915\n",
      "batch_idx: 2 loss: 0.0015824112674636237 R2: 0.9136669759677808 time: 1703116589.440879\n",
      "batch_idx: 3 loss: 0.0008536846324782438 R2: 0.9136271609195161 time: 1703116592.300306\n",
      "Training [47%] Loss: 0.0011669244436889607 time: 1703116592.300306\n",
      "weight: [0.44373957 0.8129558  0.14360013 0.36585222 0.61453282 1.20875764\n",
      " 0.70908194 0.29300873 0.55305803 0.03276809 0.18922278 0.81695227]\n",
      "epoch 142\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015164431378663753 R2: 0.9136849049671131 time: 1703116595.052025\n",
      "batch_idx: 1 loss: 0.0007143340839997981 R2: 0.913707544319934 time: 1703116597.7756848\n",
      "batch_idx: 2 loss: 0.0015817497235885343 R2: 0.9136988517467207 time: 1703116600.545114\n",
      "batch_idx: 3 loss: 0.0008534011452119448 R2: 0.9136587341689287 time: 1703116603.3429518\n",
      "Training [47%] Loss: 0.0011664820226666632 time: 1703116603.3429518\n",
      "weight: [0.44489301 0.81256153 0.14279584 0.36241615 0.61575262 1.2102781\n",
      " 0.70987512 0.29355349 0.55229509 0.03259562 0.18916124 0.81688799]\n",
      "epoch 143\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015153746515208393 R2: 0.9137165517873594 time: 1703116606.1999512\n",
      "batch_idx: 1 loss: 0.0007145872735600542 R2: 0.9137392117566412 time: 1703116608.9476666\n",
      "batch_idx: 2 loss: 0.0015810956284501583 R2: 0.913730397388 time: 1703116611.7740152\n",
      "batch_idx: 3 loss: 0.0008531204379750937 R2: 0.9136899882914603 time: 1703116614.4953947\n",
      "Training [48%] Loss: 0.0011660444978765364 time: 1703116614.4953947\n",
      "weight: [0.44604501 0.81217658 0.14200769 0.35900414 0.61698353 1.21181302\n",
      " 0.71066154 0.29409381 0.55154614 0.03242471 0.18910039 0.81682442]\n",
      "epoch 144\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015143190677636682 R2: 0.9137478709519596 time: 1703116617.221289\n",
      "batch_idx: 1 loss: 0.000714836787207945 R2: 0.9137705492996988 time: 1703116619.9585876\n",
      "batch_idx: 2 loss: 0.001580448910221936 R2: 0.9137616163254533 time: 1703116622.9014547\n",
      "batch_idx: 3 loss: 0.0008528425158136742 R2: 0.9137209269205029 time: 1703116625.651781\n",
      "Training [48%] Loss: 0.001165611820251806 time: 1703116625.651781\n",
      "weight: [0.44719548 0.81180077 0.1412354  0.35561861 0.61822567 1.2133626\n",
      " 0.71144126 0.29462972 0.55081085 0.03225536 0.18904022 0.81676154]\n",
      "epoch 145\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001513276229423581 R2: 0.9137788660393428 time: 1703116628.3669636\n",
      "batch_idx: 1 loss: 0.0007150826493295035 R2: 0.9138015605661648 time: 1703116631.228437\n",
      "batch_idx: 2 loss: 0.0015798094869511631 R2: 0.9137925122717881 time: 1703116633.963726\n",
      "batch_idx: 3 loss: 0.0008525673802836517 R2: 0.9137515539438347 time: 1703116636.696868\n",
      "Training [48%] Loss: 0.001165183936496975 time: 1703116636.696868\n",
      "weight: [0.44834437 0.81143397 0.14047867 0.35226181 0.61947917 1.21492707\n",
      " 0.71221438 0.29516123 0.55008891 0.03208754 0.1889807  0.81669933]\n",
      "epoch 146\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015122459745531174 R2: 0.9138095409153821 time: 1703116639.5240204\n",
      "batch_idx: 1 loss: 0.0007153248852198859 R2: 0.9138322494709141 time: 1703116642.3477948\n",
      "batch_idx: 2 loss: 0.0015791772667539897 R2: 0.9138230892348249 time: 1703116645.0859535\n",
      "batch_idx: 3 loss: 0.000852295028583355 R2: 0.9137818735156584 time: 1703116647.8026633\n",
      "Training [49%] Loss: 0.001164760788777587 time: 1703116647.8026633\n",
      "weight: [0.44949159 0.81107603 0.13973722 0.34893579 0.62074417 1.21650664\n",
      " 0.71298096 0.29568839 0.54937999 0.03192124 0.18892184 0.81663779]\n",
      "epoch 147\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001511228136757993 R2: 0.9138398997464409 time: 1703116650.642187\n",
      "batch_idx: 1 loss: 0.000715563520325221 R2: 0.9138626202386119 time: 1703116653.4120493\n",
      "batch_idx: 2 loss: 0.0015785521481929848 R2: 0.9138533515268309 time: 1703116656.240327\n",
      "batch_idx: 3 loss: 0.0008520254527947715 R2: 0.9138118900622123 time: 1703116659.0595202\n",
      "Training [49%] Loss: 0.0011643423145177426 time: 1703116659.0595202\n",
      "weight: [0.45063709 0.81072679 0.13901076 0.34564243 0.6220208  1.21810156\n",
      " 0.7137411  0.29621122 0.54868381 0.03175645 0.18886361 0.81657691]\n",
      "epoch 148\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015102225456636708 R2: 0.913869947005575 time: 1703116661.8055542\n",
      "batch_idx: 1 loss: 0.0007157985795132654 R2: 0.9138926774087108 time: 1703116664.5295951\n",
      "batch_idx: 2 loss: 0.001577934020803229 R2: 0.9138833037671704 time: 1703116667.3318334\n",
      "batch_idx: 3 loss: 0.0008517586392617127 R2: 0.9138416082816432 time: 1703116670.1854994\n",
      "Training [49%] Loss: 0.0011639284463104695 time: 1703116670.1854994\n",
      "weight: [0.45178079 0.81038613 0.13829903 0.34238343 0.62330921 1.21971207\n",
      " 0.71449487 0.29672978 0.54800008 0.03159315 0.18880601 0.81651668]\n",
      "epoch 149\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015092290274741028 R2: 0.9138996874722108 time: 1703116672.9171042\n",
      "batch_idx: 1 loss: 0.0007160300864060493 R2: 0.9139224258338944 time: 1703116675.6549065\n",
      "batch_idx: 2 loss: 0.0015773227657322145 R2: 0.9139129508787202 time: 1703116678.464645\n",
      "batch_idx: 3 loss: 0.0008514945681080945 R2: 0.9138710331384535 time: 1703116681.1973002\n",
      "Training [50%] Loss: 0.0011635191119301154 time: 1703116681.1973002\n",
      "weight: [0.45292264 0.81005393 0.13760179 0.33916027 0.62460954 1.22133841\n",
      " 0.71524236 0.2972441  0.54732852 0.03143132 0.18874903 0.81645707]\n",
      "epoch 150\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001508247405619351 R2: 0.9139291262258572 time: 1703116683.9447825\n",
      "batch_idx: 1 loss: 0.0007162580627750653 R2: 0.9139518706725399 time: 1703116686.7479115\n",
      "batch_idx: 2 loss: 0.001576718256466886 R2: 0.9139422980787465 time: 1703116689.5496325\n",
      "batch_idx: 3 loss: 0.0008512332128938113 R2: 0.9139001698531155 time: 1703116692.297699\n",
      "Training [50%] Loss: 0.0011631142344387783 time: 1703116692.297699\n",
      "weight: [0.45406257 0.80973005 0.13691878 0.33597428 0.62592193 1.22298084\n",
      " 0.71598365 0.29775424 0.54666887 0.03127095 0.18869265 0.81639808]\n",
      "epoch 151\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015072775014666607 R2: 0.9139582686345291 time: 1703116695.0350075\n",
      "batch_idx: 1 loss: 0.000716482528019016 R2: 0.9139810173759189 time: 1703116697.7626388\n",
      "batch_idx: 2 loss: 0.0015761203596124501 R2: 0.9139713508648475 time: 1703116700.564647\n",
      "batch_idx: 3 loss: 0.0008509745404123466 R2: 0.9139290238876135 time: 1703116703.393212\n",
      "Training [50%] Loss: 0.0011627137323776185 time: 1703116703.393212\n",
      "weight: [0.45520052 0.80941438 0.13624979 0.33282657 0.62724656 1.22463963\n",
      " 0.71671886 0.29826025 0.54602091 0.03111202 0.18863685 0.8163397 ]\n",
      "epoch 152\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015063191350669154 R2: 0.9139871203386033 time: 1703116706.1249232\n",
      "batch_idx: 1 loss: 0.0007167034987293918 R2: 0.9140098716709041 time: 1703116708.9314914\n",
      "batch_idx: 2 loss: 0.0015755289356987774 R2: 0.914000114996818 time: 1703116711.6521764\n",
      "batch_idx: 3 loss: 0.0008507185106139895 R2: 0.9139576009274732 time: 1703116714.392681\n",
      "Training [51%] Loss: 0.0011623175200272686 time: 1703116714.392681\n",
      "weight: [0.45633647 0.80910684 0.13559458 0.32971809 0.62858358 1.22631505\n",
      " 0.71744807 0.29876222 0.54538438 0.0309545  0.18858164 0.81628191]\n",
      "epoch 153\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015053721259270462 R2: 0.9140156872309149 time: 1703116717.2340128\n",
      "batch_idx: 1 loss: 0.0007169209883428611 R2: 0.9140384395389857 time: 1703116720.0405283\n",
      "batch_idx: 2 loss: 0.0015749438399911507 R2: 0.9140285964751771 time: 1703116722.7844374\n",
      "batch_idx: 3 loss: 0.0008504650766462471 R2: 0.9139859068610289 time: 1703116725.6127243\n",
      "Training [51%] Loss: 0.0011619255077268264 time: 1703116725.6127243\n",
      "weight: [0.45747035 0.80880733 0.13495296 0.32664961 0.62993316 1.22800738\n",
      " 0.71817139 0.29926021 0.54475909 0.03079839 0.18852698 0.81622469]\n",
      "epoch 154\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015044362937805165 R2: 0.9140439754338606 time: 1703116728.3458858\n",
      "batch_idx: 1 loss: 0.0007171350068854372 R2: 0.9140667271924423 time: 1703116731.082173\n",
      "batch_idx: 2 loss: 0.0015743649232848743 R2: 0.9140568015171355 time: 1703116733.9513905\n",
      "batch_idx: 3 loss: 0.0008502141849960568 R2: 0.9140139477566167 time: 1703116736.777899\n",
      "Training [51%] Loss: 0.0011615376022367212 time: 1703116736.777899\n",
      "weight: [0.45860213 0.80851576 0.13432473 0.32362175 0.63129549 1.22971691\n",
      " 0.71888893 0.2997543  0.54414483 0.03064365 0.18847288 0.81616804]\n",
      "epoch 155\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015035114593448691 R2: 0.9140719912742699 time: 1703116739.5110164\n",
      "batch_idx: 1 loss: 0.0007173455607995381 R2: 0.9140947410483825 time: 1703116742.3799622\n",
      "batch_idx: 2 loss: 0.0015737920326716064 R2: 0.9140847365307474 time: 1703116745.1968951\n",
      "batch_idx: 3 loss: 0.0008499657757148349 R2: 0.9140417298382223 time: 1703116747.9375057\n",
      "Training [52%] Loss: 0.001161153707132712 time: 1703116747.9375057\n",
      "weight: [0.45973178 0.80823207 0.13370973 0.32063497 0.63267074 1.23144394\n",
      " 0.71960082 0.30024459 0.54354143 0.03049025 0.1884193  0.81611193]\n",
      "epoch 156\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015025974450532304 R2: 0.9140997412567818 time: 1703116750.7787\n",
      "batch_idx: 1 loss: 0.0007175526528499965 R2: 0.9141224877014208 time: 1703116753.5068223\n",
      "batch_idx: 2 loss: 0.0015732250122651368 R2: 0.9141124080878645 time: 1703116756.3167605\n",
      "batch_idx: 3 loss: 0.0008497197827123133 R2: 0.9140692594601832 time: 1703116759.0409539\n",
      "Training [52%] Loss: 0.0011607737232201692 time: 1703116759.0409539\n",
      "weight: [0.46085928 0.80795621 0.13310779 0.31768959 0.63405912 1.23318877\n",
      " 0.72030719 0.30073118 0.54294871 0.03033819 0.18836624 0.81605636]\n",
      "epoch 157\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015016940757463359 R2: 0.9141272320362838 time: 1703116761.7736313\n",
      "batch_idx: 1 loss: 0.000717756282101379 R2: 0.9141499738955838 time: 1703116764.5043092\n",
      "batch_idx: 2 loss: 0.0015726637038806564 R2: 0.9141398228965313 time: 1703116767.4400682\n",
      "batch_idx: 3 loss: 0.0008494761341000465 R2: 0.9140965430814326 time: 1703116770.161255\n",
      "Training [52%] Loss: 0.0011603975489571045 time: 1703116770.161255\n",
      "weight: [0.46198461 0.80768812 0.13251876 0.31478582 0.63546082 1.23495171\n",
      " 0.72100816 0.30121419 0.54236654 0.03018741 0.18831369 0.8160013 ]\n",
      "epoch 158\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015008011793217941 R2: 0.9141544703900367 time: 1703116772.8785012\n",
      "batch_idx: 1 loss: 0.0007179564439557421 R2: 0.9141772064959864 time: 1703116775.6840463\n",
      "batch_idx: 2 loss: 0.0015721079476640157 R2: 0.914166987773263 time: 1703116778.4219985\n",
      "batch_idx: 3 loss: 0.0008492347525698954 R2: 0.9141235872396104 time: 1703116781.1620562\n",
      "Training [53%] Loss: 0.0011600250808778618 time: 1703116781.1620562\n",
      "weight: [0.46310776 0.80742778 0.1319425  0.31192373 0.63687605 1.23673309\n",
      " 0.72170388 0.30169372 0.54179477 0.03003791 0.18826162 0.81594673]\n",
      "epoch 159\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014999185873328295 R2: 0.9141814631898674 time: 1703116784.068662\n",
      "batch_idx: 1 loss: 0.0007181531302439165 R2: 0.9142041924607438 time: 1703116786.7959986\n",
      "batch_idx: 2 loss: 0.0015715575826690596 R2: 0.9141939096155992 time: 1703116789.5075781\n",
      "batch_idx: 3 loss: 0.0008489955557938256 R2: 0.9141503985254233 time: 1703116792.2506921\n",
      "Training [53%] Loss: 0.001159656214009908 time: 1703116792.2506921\n",
      "weight: [0.46422874 0.80717514 0.13137891 0.30910331 0.63830502 1.23853324\n",
      " 0.7223945  0.30216992 0.54123329 0.02988964 0.18821001 0.81589265]\n",
      "epoch 160\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001499046135535234 R2: 0.9142082173748148 time: 1703116795.056138\n",
      "batch_idx: 1 loss: 0.0007183463293594551 R2: 0.9142309388134324 time: 1703116797.9180427\n",
      "batch_idx: 2 loss: 0.001571012447385062 R2: 0.9142205953752691 time: 1703116800.6575267\n",
      "batch_idx: 3 loss: 0.0008487584568315696 R2: 0.9141769835574239 time: 1703116803.4103634\n",
      "Training [53%] Loss: 0.0011592908422778303 time: 1703116803.4103634\n",
      "weight: [0.46534754 0.80693022 0.13082786 0.30632445 0.63974797 1.24035247\n",
      " 0.72308017 0.30264291 0.540682   0.02974256 0.18815886 0.81583903]\n",
      "epoch 161\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014981836643827985 R2: 0.9142347399245013 time: 1703116806.2142015\n",
      "batch_idx: 1 loss: 0.0007185360264272344 R2: 0.9142574526163688 time: 1703116808.939543\n",
      "batch_idx: 2 loss: 0.0015704723802163045 R2: 0.9142470520321574 time: 1703116811.682931\n",
      "batch_idx: 3 loss: 0.000848523364537249 R2: 0.9142033489574001 time: 1703116814.5979474\n",
      "Training [54%] Loss: 0.0011589288588908966 time: 1703116814.5979474\n",
      "weight: [0.4664642  0.80669299 0.13028926 0.30358696 0.64120513 1.24219114\n",
      " 0.72376107 0.30311285 0.5401408  0.02959665 0.18810813 0.81578585]\n",
      "epoch 162\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001497331019471037 R2: 0.9142610378333605 time: 1703116817.33509\n",
      "batch_idx: 1 loss: 0.0007187222034989625 R2: 0.9142837409448733 time: 1703116820.058458\n",
      "batch_idx: 2 loss: 0.001569937219918073 R2: 0.914273286569203 time: 1703116822.7860782\n",
      "batch_idx: 3 loss: 0.0008482901839557726 R2: 0.9142295013264599 time: 1703116825.6054642\n",
      "Training [54%] Loss: 0.001158570156710961 time: 1703116825.6054642\n",
      "weight: [0.46757872 0.80646347 0.12976303 0.30089058 0.64267672 1.24404959\n",
      " 0.72443737 0.30357988 0.53960961 0.02945187 0.18805782 0.8157331 ]\n",
      "epoch 163\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001496488051933389 R2: 0.9142871180858713 time: 1703116828.3276014\n",
      "batch_idx: 1 loss: 0.0007189048397678457 R2: 0.9143098108625777 time: 1703116831.167573\n",
      "batch_idx: 2 loss: 0.001569406805994287 R2: 0.914299305948292 time: 1703116833.8988466\n",
      "batch_idx: 3 loss: 0.0008480588167029664 R2: 0.9142554472218178 time: 1703116836.7157311\n",
      "Training [54%] Loss: 0.0011582146285996219 time: 1703116836.7157311\n",
      "weight: [0.46869115 0.80624167 0.1292491  0.298235   0.644163   1.24592815\n",
      " 0.72510924 0.30404419 0.53908838 0.02930818 0.18800791 0.81568075]\n",
      "epoch 164\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014956546187924855 R2: 0.9143129876327978 time: 1703116839.4396355\n",
      "batch_idx: 1 loss: 0.0007190839117969584 R2: 0.9143356693978448 time: 1703116842.1528742\n",
      "batch_idx: 2 loss: 0.001568880979062178 R2: 0.9143251170871733 time: 1703116844.894633\n",
      "batch_idx: 3 loss: 0.0008478291613249788 R2: 0.9142811931342705 time: 1703116847.7913418\n",
      "Training [55%] Loss: 0.0011578621677441501 time: 1703116847.7913418\n",
      "weight: [0.46980153 0.80602763 0.12874741 0.29561985 0.64566422 1.24782719\n",
      " 0.72577688 0.30450593 0.53857706 0.02916554 0.18795836 0.81562879]\n",
      "epoch 165\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014948305832711778 R2: 0.9143386533684051 time: 1703116850.5337164\n",
      "batch_idx: 1 loss: 0.000719259393755831 R2: 0.9143613235211999 time: 1703116853.2538934\n",
      "batch_idx: 2 loss: 0.001568359581190747 R2: 0.9143507268372554 time: 1703116856.0616796\n",
      "batch_idx: 3 loss: 0.0008476011136334825 R2: 0.9143067454662898 time: 1703116858.784926\n",
      "Training [55%] Loss: 0.0011575126679628095 time: 1703116858.784926\n",
      "weight: [0.47090991 0.80582138 0.12825791 0.29304473 0.64718064 1.24974704\n",
      " 0.72644049 0.3049653  0.53807561 0.02902391 0.18790918 0.81557719]\n",
      "epoch 166\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001494015815068106 R2: 0.9143641221085849 time: 1703116861.6057484\n",
      "batch_idx: 1 loss: 0.000719431257661127 R2: 0.9143867801237148 time: 1703116864.3723557\n",
      "batch_idx: 2 loss: 0.0015678424562194186 R2: 0.9143761419622921 time: 1703116867.171929\n",
      "batch_idx: 3 loss: 0.000847374567015304 R2: 0.9143321105106199 time: 1703116869.9038255\n",
      "Training [55%] Loss: 0.001157166023990989 time: 1703116869.9038255\n",
      "weight: [0.47201636 0.80562297 0.12778058 0.29050922 0.64871252 1.25168806\n",
      " 0.72710027 0.30542248 0.53758399 0.02888323 0.18786032 0.81552594]\n",
      "epoch 167\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014932101906023727 R2: 0.9143894005697369 time: 1703116872.637371\n",
      "batch_idx: 1 loss: 0.0007195994736184217 R2: 0.9144120459962217 time: 1703116875.4364867\n",
      "batch_idx: 2 loss: 0.00156732945006408 R2: 0.9144013691177267 time: 1703116878.2676637\n",
      "batch_idx: 3 loss: 0.000847149412715709 R2: 0.9143572944292376 time: 1703116881.0177948\n",
      "Training [56%] Loss: 0.0011568221317501458 time: 1703116881.0177948\n",
      "weight: [0.47312094 0.80543246 0.12731538 0.28801284 0.65026012 1.2536506\n",
      " 0.72775644 0.30587768 0.53710221 0.02874348 0.18781177 0.81547501]\n",
      "epoch 168\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014924135932325002 R2: 0.9144144953482967 time: 1703116883.8214598\n",
      "batch_idx: 1 loss: 0.0007197640100624191 R2: 0.9144371278091651 time: 1703116886.557276\n",
      "batch_idx: 2 loss: 0.001566820411017585 R2: 0.9144264148305726 time: 1703116889.2918377\n",
      "batch_idx: 3 loss: 0.0008469255400956789 R2: 0.9143823032325049 time: 1703116892.1209047\n",
      "Training [56%] Loss: 0.0011564808886020458 time: 1703116892.1209047\n",
      "weight: [0.47422373 0.80524991 0.12686229 0.28555512 0.65182372 1.25563501\n",
      " 0.72840921 0.30633109 0.53663026 0.0286046  0.18776352 0.81542437]\n",
      "epoch 169\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001491625913454145 R2: 0.9144394129006816 time: 1703116895.007283\n",
      "batch_idx: 1 loss: 0.0007199248339942935 R2: 0.9144620320929041 time: 1703116897.7480402\n",
      "batch_idx: 2 loss: 0.0015663151900521418 R2: 0.9144512854796009 time: 1703116900.488106\n",
      "batch_idx: 3 loss: 0.0008467028368645858 R2: 0.9144071427583352 time: 1703116903.2955189\n",
      "Training [56%] Loss: 0.0011561421935912914 time: 1703116903.2955189\n",
      "weight: [0.47532484 0.8050754  0.12642133 0.28313558 0.6534036  1.25764161\n",
      " 0.72905882 0.30678295 0.53616813 0.02846654 0.18771552 0.81537401]\n",
      "epoch 170\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014908470490809414 R2: 0.9144641595234629 time: 1703116906.0219955\n",
      "batch_idx: 1 loss: 0.0007200819112151581 R2: 0.9144867652182935 time: 1703116908.7428193\n",
      "batch_idx: 2 loss: 0.0015658136411309943 R2: 0.914475987275671 time: 1703116911.562245\n",
      "batch_idx: 3 loss: 0.0008464811892897887 R2: 0.9144318186511871 time: 1703116914.366817\n",
      "Training [57%] Loss: 0.0011558059476792207 time: 1703116914.366817\n",
      "weight: [0.47642436 0.804909   0.12599249 0.28075373 0.65500003 1.25967076\n",
      " 0.72970551 0.30723347 0.53571587 0.02832926 0.18766778 0.8153239 ]\n",
      "epoch 171\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001490076905412584 R2: 0.9144887413335759 time: 1703116917.1101823\n",
      "batch_idx: 1 loss: 0.0007202352065553005 R2: 0.9145113333772615 time: 1703116919.8328671\n",
      "batch_idx: 2 loss: 0.0015653156215371298 R2: 0.9145005262419327 time: 1703116922.6525276\n",
      "batch_idx: 3 loss: 0.0008462604823857875 R2: 0.9144563363406549 time: 1703116925.4410386\n",
      "Training [57%] Loss: 0.0011554720539727005 time: 1703116925.4410386\n",
      "weight: [0.4775224  0.80475083 0.12557578 0.27840907 0.65661329 1.26172276\n",
      " 0.73034951 0.30768288 0.53527348 0.0281927  0.18762024 0.81527402]\n",
      "epoch 172\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014893153953934187 R2: 0.914513164248285 time: 1703116928.219766\n",
      "batch_idx: 1 loss: 0.0007203846840995999 R2: 0.9145357425631969 time: 1703116931.0164528\n",
      "batch_idx: 2 loss: 0.0015648209922265858 R2: 0.9145249081937121 time: 1703116933.8700197\n",
      "batch_idx: 3 loss: 0.0008460406000856265 R2: 0.9144807010194519 time: 1703116936.603424\n",
      "Training [57%] Loss: 0.0011551404179513077 time: 1703116936.603424\n",
      "weight: [0.47861909 0.80460096 0.12517125 0.27610112 0.65824366 1.26379793\n",
      " 0.7309911  0.30813143 0.53484101 0.02805681 0.18757291 0.81522433]\n",
      "epoch 173\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014885624397647053 R2: 0.9145374339647245 time: 1703116939.3239238\n",
      "batch_idx: 1 loss: 0.000720530307409608 R2: 0.9145599985508996 time: 1703116942.1504374\n",
      "batch_idx: 2 loss: 0.001564329618214437 R2: 0.914549138717803 time: 1703116944.9645922\n",
      "batch_idx: 3 loss: 0.000845821425397775 R2: 0.9145049176205962 time: 1703116947.6940768\n",
      "Training [58%] Loss: 0.0011548109476966313 time: 1703116947.6940768\n",
      "weight: [0.47971457 0.80445953 0.12477891 0.27382939 0.65989141 1.26589656\n",
      " 0.73163052 0.30857937 0.53441851 0.02792154 0.18752574 0.81517483]\n",
      "epoch 174\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001487817967212725 R2: 0.9145615559387469 time: 1703116950.4318461\n",
      "batch_idx: 1 loss: 0.0007206720397434014 R2: 0.9145841068758361 time: 1703116953.1549835\n",
      "batch_idx: 2 loss: 0.0015638413690012964 R2: 0.9145732231509813 time: 1703116955.9625065\n",
      "batch_idx: 3 loss: 0.0008456028405521654 R2: 0.9145289907935703 time: 1703116958.8157823\n",
      "Training [58%] Loss: 0.001154483554127397 time: 1703116958.8157823\n",
      "weight: [0.48080896 0.80432663 0.12439882 0.27159341 0.66155683 1.26801892\n",
      " 0.73226804 0.30902695 0.53400602 0.02778684 0.18747871 0.81512547]\n",
      "epoch 175\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014870819145145163 R2: 0.9145855353628697 time: 1703116961.5389292\n",
      "batch_idx: 1 loss: 0.0007208098442745238 R2: 0.914608072812497 time: 1703116964.3531284\n",
      "batch_idx: 2 loss: 0.0015633561190486565 R2: 0.9145971665574624 time: 1703116967.0801609\n",
      "batch_idx: 3 loss: 0.0008453847271392204 R2: 0.9145529248792597 time: 1703116969.8060572\n",
      "Training [58%] Loss: 0.0011541581512442293 time: 1703116969.8060572\n",
      "weight: [0.48190245 0.80420239 0.12403102 0.26939273 0.66324017 1.27016526\n",
      " 0.73290395 0.30947444 0.53360362 0.02765264 0.1874318  0.81507624]\n",
      "epoch 176\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001486354226682318 R2: 0.9146093771430659 time: 1703116972.5213666\n",
      "batch_idx: 1 loss: 0.000720943684311506 R2: 0.9146319013515894 time: 1703116975.4494777\n",
      "batch_idx: 2 loss: 0.0015628737483111186 R2: 0.9146209737051324 time: 1703116978.1744647\n",
      "batch_idx: 3 loss: 0.0008451669662463088 R2: 0.9145767238835149 time: 1703116980.9172468\n",
      "Training [59%] Loss: 0.0011538346563878129 time: 1703116980.9172468\n",
      "weight: [0.48299518 0.80408696 0.12367558 0.26722689 0.6649417  1.2723358\n",
      " 0.73353853 0.3099221  0.53321136 0.02751889 0.18738498 0.8150271 ]\n",
      "epoch 177\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014856348571068963 R2: 0.9146330858742339 time: 1703116983.6404576\n",
      "batch_idx: 1 loss: 0.0007210735235197826 R2: 0.9146555971759212 time: 1703116986.4737678\n",
      "batch_idx: 2 loss: 0.0015623941428339041 R2: 0.914644649040304 time: 1703116989.505279\n",
      "batch_idx: 3 loss: 0.0008449494385962944 R2: 0.9146003914491618 time: 1703116992.466915\n",
      "Training [59%] Loss: 0.0011535129905142192 time: 1703116992.466915\n",
      "weight: [0.48408733 0.80398046 0.12333257 0.26509548 0.66666166 1.27453072\n",
      " 0.73417207 0.31037022 0.53282933 0.02738553 0.18733823 0.81497803]\n",
      "epoch 178\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001484923767699457 R2: 0.9146566658141081 time: 1703116995.401661\n",
      "batch_idx: 1 loss: 0.0007211993261478376 R2: 0.9146791646346675 time: 1703116998.2168758\n",
      "batch_idx: 2 loss: 0.0015619171954236444 R2: 0.9146681966608551 time: 1703117000.9554288\n",
      "batch_idx: 3 loss: 0.0008447320246934587 R2: 0.9146239308263231 time: 1703117003.7005312\n",
      "Training [59%] Loss: 0.0011531930784910995 time: 1703117003.7005312\n",
      "weight: [0.48517911 0.80388304 0.12300205 0.26299808 0.6684003  1.27675017\n",
      " 0.73480487 0.31081908 0.5324576  0.02725251 0.1872915  0.81492901]\n",
      "epoch 179\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00148422092903073 R2: 0.9146801208554838 time: 1703117006.6321254\n",
      "batch_idx: 1 loss: 0.0007213210572595575 R2: 0.9147026077159726 time: 1703117009.3695168\n",
      "batch_idx: 2 loss: 0.0015614428064003284 R2: 0.9146916202875512 time: 1703117012.111876\n",
      "batch_idx: 3 loss: 0.0008445146049825415 R2: 0.9146473448410009 time: 1703117014.8296006\n",
      "Training [60%] Loss: 0.0011528748494182893 time: 1703117014.8296006\n",
      "weight: [0.4862707  0.80379485 0.12268411 0.26093431 0.67015783 1.27899423\n",
      " 0.73543725 0.31126898 0.53209627 0.02711975 0.18724479 0.81487999]\n",
      "epoch 180\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001483526320465201 R2: 0.9147034544965745 time: 1703117017.6445253\n",
      "batch_idx: 1 loss: 0.0007214386829749291 R2: 0.9147259300176479 time: 1703117020.3798778\n",
      "batch_idx: 2 loss: 0.0015609708844376582 R2: 0.9147149232334909 time: 1703117023.229675\n",
      "batch_idx: 3 loss: 0.0008442970600273816 R2: 0.9146706358618657 time: 1703117025.9484894\n",
      "Training [60%] Loss: 0.0011525582369762925 time: 1703117025.9484894\n",
      "weight: [0.48736232 0.80371605 0.12237884 0.25890381 0.67193446 1.28126295\n",
      " 0.73606951 0.31172021 0.53174541 0.0269872  0.18719805 0.81483095]\n",
      "epoch 181\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014828399302873178 R2: 0.9147266698094685 time: 1703117028.7546284\n",
      "batch_idx: 1 loss: 0.0007215521707211404 R2: 0.9147491347159097 time: 1703117031.4754565\n",
      "batch_idx: 2 loss: 0.0015605013474981736 R2: 0.9147381083715326 time: 1703117034.2099807\n",
      "batch_idx: 3 loss: 0.0008440792707163213 R2: 0.9146938057652724 time: 1703117036.9411054\n",
      "Training [60%] Loss: 0.0011522431798057383 time: 1703117036.9411054\n",
      "weight: [0.48845418 0.80364679 0.12208634 0.25690621 0.67373036 1.28355631\n",
      " 0.73670197 0.31217307 0.53140514 0.02685481 0.18715125 0.81478187]\n",
      "epoch 182\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014821617558157419 R2: 0.9147497694066036 time: 1703117039.8190887\n",
      "batch_idx: 1 loss: 0.0007216614894962457 R2: 0.9147722245321152 time: 1703117042.5530522\n",
      "batch_idx: 2 loss: 0.0015600341238681534 R2: 0.9147611780997614 time: 1703117045.291299\n",
      "batch_idx: 3 loss: 0.0008438611185024953 R2: 0.9147168558986609 time: 1703117048.08384\n",
      "Training [61%] Loss: 0.0011519296219206592 time: 1703117048.08384\n",
      "weight: [0.48954653 0.80358725 0.12180668 0.2549412  0.67554568 1.28587421\n",
      " 0.73733497 0.31262787 0.53107554 0.02672249 0.18710438 0.81473271]\n",
      "epoch 183\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014814918035004566 R2: 0.9147727554053032 time: 1703117050.820013\n",
      "batch_idx: 1 loss: 0.0007217666101476544 R2: 0.9147952016975015 time: 1703117053.620765\n",
      "batch_idx: 2 loss: 0.0015595691532953675 R2: 0.9147841343050219 time: 1703117056.3974097\n",
      "batch_idx: 3 loss: 0.0008436424856881053 R2: 0.9147397870425019 time: 1703117059.208809\n",
      "Training [61%] Loss: 0.001151617513157896 time: 1703117059.208809\n",
      "weight: [0.49063961 0.8035376  0.12153999 0.25300847 0.67738055 1.28821647\n",
      " 0.73796883 0.31308492 0.53075672 0.02659019 0.1870574  0.81468344]\n",
      "epoch 184\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014808300889965777 R2: 0.9147956293905108 time: 1703117061.9347334\n",
      "batch_idx: 1 loss: 0.0007218675056675729 R2: 0.914818067916029 time: 1703117064.6651344\n",
      "batch_idx: 2 loss: 0.0015591063882300206 R2: 0.9148069783246908 time: 1703117067.3939195\n",
      "batch_idx: 3 loss: 0.0008434232557629163 R2: 0.9147625993711636 time: 1703117070.3381965\n",
      "Training [61%] Loss: 0.0011513068096642718 time: 1703117070.3381965\n",
      "weight: [0.49173366 0.80349799 0.12128635 0.25110773 0.67923503 1.29058284\n",
      " 0.73860389 0.31354455 0.53044876 0.02645784 0.18701027 0.81463404]\n",
      "epoch 185\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001480176637207544 R2: 0.9148183923759333 time: 1703117073.0612557\n",
      "batch_idx: 1 loss: 0.000721964151507717 R2: 0.9148408243255423 time: 1703117075.7989895\n",
      "batch_idx: 2 loss: 0.0015586457951656668 R2: 0.914829710906972 time: 1703117078.6070948\n",
      "batch_idx: 3 loss: 0.000843203313808403 R2: 0.9147852924131511 time: 1703117081.349505\n",
      "Training [62%] Loss: 0.0011509974744223328 time: 1703117081.349505\n",
      "weight: [0.49282895 0.8034686  0.12104588 0.24923872 0.68110917 1.29297292\n",
      " 0.73924048 0.31400706 0.53015177 0.02632538 0.18696298 0.81458447]\n",
      "epoch 186\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001479531482289092 R2: 0.914841044763938 time: 1703117084.0749507\n",
      "batch_idx: 1 loss: 0.0007220565259156724 R2: 0.914863471457595 time: 1703117087.0305269\n",
      "batch_idx: 2 loss: 0.0015581873560722129 R2: 0.9148523321701131 time: 1703117089.752539\n",
      "batch_idx: 3 loss: 0.0008429825469804403 R2: 0.9148078650113833 time: 1703117092.473697\n",
      "Training [62%] Loss: 0.0011506894778143544 time: 1703117092.473697\n",
      "weight: [0.49392574 0.80344961 0.12081866 0.24740118 0.68300294 1.29538625\n",
      " 0.73987896 0.31447277 0.52986585 0.02619274 0.1869155  0.8145347 ]\n",
      "epoch 187\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001478894667604253 R2: 0.914863586304724 time: 1703117095.2093358\n",
      "batch_idx: 1 loss: 0.0007221446102952929 R2: 0.9148860091963671 time: 1703117098.0281043\n",
      "batch_idx: 2 loss: 0.0015577310699072318 R2: 0.9148748415611093 time: 1703117100.7663617\n",
      "batch_idx: 3 loss: 0.0008427608450844368 R2: 0.9148303152843106 time: 1703117103.535062\n",
      "Training [62%] Loss: 0.0011503827982228038 time: 1703117103.535062\n",
      "weight: [0.49502431 0.80344117 0.12060481 0.24559488 0.68491628 1.2978222\n",
      " 0.74051966 0.314942   0.52959107 0.02605985 0.18686779 0.81448472]\n",
      "epoch 188\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014782662456184138 R2: 0.9148860160554054 time: 1703117106.377448\n",
      "batch_idx: 1 loss: 0.000722228389593894 R2: 0.914908436737343 time: 1703117109.1025782\n",
      "batch_idx: 2 loss: 0.001557276954184408 R2: 0.9148972378146933 time: 1703117111.8543127\n",
      "batch_idx: 3 loss: 0.0008425381012584476 R2: 0.9148526405889376 time: 1703117114.6597443\n",
      "Training [63%] Loss: 0.001150077422663791 time: 1703117114.6597443\n",
      "weight: [0.49612495 0.80344346 0.12040441 0.24381959 0.68684905 1.30028003\n",
      " 0.74116291 0.31541505 0.52932751 0.02592665 0.18681982 0.81443448]\n",
      "epoch 189\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014776462777220984 R2: 0.9149083323399056 time: 1703117117.4438775\n",
      "batch_idx: 1 loss: 0.0007223078527191401 R2: 0.9149307525465803 time: 1703117120.2240288\n",
      "batch_idx: 2 loss: 0.001556825046569402 R2: 0.9149195189135024 time: 1703117122.952545\n",
      "batch_idx: 3 loss: 0.0008423142127804188 R2: 0.9148748374870191 time: 1703117125.7556045\n",
      "Training [63%] Loss: 0.0011497733474477648 time: 1703117125.7556045\n",
      "weight: [0.49722793 0.80345661 0.12021756 0.2420751  0.68880104 1.30275881\n",
      " 0.74180906 0.31589225 0.52907526 0.02579307 0.18677158 0.81438397]\n",
      "epoch 190\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014770348339682101 R2: 0.9149305327107179 time: 1703117128.4882467\n",
      "batch_idx: 1 loss: 0.0007223829929889696 R2: 0.9149529543216147 time: 1703117131.2174048\n",
      "batch_idx: 2 loss: 0.0015563754064628738 R2: 0.9149416820506875 time: 1703117134.1540937\n",
      "batch_idx: 3 loss: 0.0008420890820165875 R2: 0.9148969017159404 time: 1703117136.8871262\n",
      "Training [63%] Loss: 0.0011494705788591604 time: 1703117136.8871262\n",
      "weight: [0.49833355 0.80348079 0.12004432 0.24036121 0.69077195 1.30525748\n",
      " 0.74245844 0.31637388 0.52883437 0.02565905 0.18672304 0.81433316]\n",
      "epoch 191\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014764319927091877 R2: 0.9149526139138601 time: 1703117139.6229398\n",
      "batch_idx: 1 loss: 0.0007224538086183992 R2: 0.9149750389552624 time: 1703117142.3431911\n",
      "batch_idx: 2 loss: 0.0015559281165189634 R2: 0.9149637235963215 time: 1703117145.1703138\n",
      "batch_idx: 3 loss: 0.0008418626175280127 R2: 0.9149188281660432 time: 1703117147.8992076\n",
      "Training [64%] Loss: 0.0011491691338436408 time: 1703117147.8992076\n",
      "weight: [0.4994421  0.80351612 0.11988477 0.2386777  0.69276141 1.30777477\n",
      " 0.74311138 0.31686023 0.52860488 0.02552452 0.18667417 0.81428202]\n",
      "epoch 192\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001475837840118703 R2: 0.9149745718585709 time: 1703117150.7363036\n",
      "batch_idx: 1 loss: 0.0007225203032475383 R2: 0.9149970025038241 time: 1703117153.553553\n",
      "batch_idx: 2 loss: 0.001555483284034846 R2: 0.9149856390693346 time: 1703117156.2857199\n",
      "batch_idx: 3 loss: 0.0008416347353510534 R2: 0.9149406108663799 time: 1703117159.0060775\n",
      "Training [64%] Loss: 0.0011488690406880353 time: 1703117159.0060775\n",
      "weight: [0.50055386 0.80356271 0.11973895 0.23702439 0.69476894 1.31030924\n",
      " 0.74376817 0.31735159 0.52838682 0.02538942 0.18662495 0.81423053]\n",
      "epoch 193\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014752524695817984 R2: 0.9149964015935271 time: 1703117161.8246992\n",
      "batch_idx: 1 loss: 0.0007225824865157258 R2: 0.9150188401614597 time: 1703117164.548495\n",
      "batch_idx: 2 loss: 0.001555041042133647 R2: 0.9150074231168382 time: 1703117167.4021027\n",
      "batch_idx: 3 loss: 0.0008414053604655589 R2: 0.914962242981075 time: 1703117170.2153308\n",
      "Training [64%] Loss: 0.0011485703396741825 time: 1703117170.2153308\n",
      "weight: [0.50166912 0.80362068 0.11960689 0.23540105 0.69679395 1.31285923\n",
      " 0.74442913 0.31784822 0.52818019 0.02525369 0.18657537 0.81417868]\n",
      "epoch 194\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014746759809368937 R2: 0.9150180972915873 time: 1703117172.9330156\n",
      "batch_idx: 1 loss: 0.0007226403746873422 R2: 0.9150405462426802 time: 1703117175.6632304\n",
      "batch_idx: 2 loss: 0.0015546015506502347 R2: 0.9150290695029721 time: 1703117178.3897123\n",
      "batch_idx: 3 loss: 0.0008411744284602181 R2: 0.914983716818638 time: 1703117181.2026212\n",
      "Training [65%] Loss: 0.0011482730836836722 time: 1703117181.2026212\n",
      "weight: [0.50278816 0.80369009 0.1194886  0.23380749 0.69883575 1.31542287\n",
      " 0.74509453 0.31835034 0.52798499 0.02511727 0.1865254  0.81412645]\n",
      "epoch 195\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014741084795530865 R2: 0.9150396522452068 time: 1703117184.055616\n",
      "batch_idx: 1 loss: 0.0007226939913348026 R2: 0.9150621141750944 time: 1703117186.7952898\n",
      "batch_idx: 2 loss: 0.0015541649966180925 R2: 0.9150505711094892 time: 1703117189.5361688\n",
      "batch_idx: 3 loss: 0.0008409418873983508 R2: 0.915005023856551 time: 1703117192.363405\n",
      "Training [65%] Loss: 0.001147977338726083 time: 1703117192.363405\n",
      "weight: [0.50391124 0.80377099 0.11938407 0.23224345 0.7008935  1.31799808\n",
      " 0.74576464 0.3188582  0.52780115 0.02498011 0.18647504 0.81407382]\n",
      "epoch 196\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00147355007522651 R2: 0.9150610588748347 time: 1703117195.0861223\n",
      "batch_idx: 1 loss: 0.0007227433680842422 R2: 0.9150835365046662 time: 1703117197.934192\n",
      "batch_idx: 2 loss: 0.0015537315942472745 R2: 0.9150719199504355 time: 1703117200.7554083\n",
      "batch_idx: 3 loss: 0.0008407076998782576 R2: 0.9150261547834774 time: 1703117203.5347831\n",
      "Training [65%] Loss: 0.001147683184359071 time: 1703117203.5347831\n",
      "weight: [0.50503863 0.80386342 0.11929323 0.23070871 0.70296625 1.32058255\n",
      " 0.74643968 0.31937196 0.52762862 0.02484216 0.18642428 0.81402079]\n",
      "epoch 197\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014730008808808994 R2: 0.9150823087525038 time: 1703117206.3154523\n",
      "batch_idx: 1 loss: 0.0007227885454280582 R2: 0.9151048049157792 time: 1703117209.0406165\n",
      "batch_idx: 2 loss: 0.0015533015842801 R2: 0.9150931072031708 time: 1703117211.8503704\n",
      "batch_idx: 3 loss: 0.0008404718452702439 R2: 0.9150470995611297 time: 1703117214.6969514\n",
      "Training [66%] Loss: 0.0011473907139648255 time: 1703117214.6969514\n",
      "weight: [0.50617057 0.80396735 0.11921602 0.22920297 0.70505289 1.32317373\n",
      " 0.74711987 0.3198918  0.52746726 0.02470337 0.1863731  0.81396734]\n",
      "epoch 198\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014724610110593503 R2: 0.915103392642807 time: 1703117217.42961\n",
      "batch_idx: 1 loss: 0.00072282957360621 R2: 0.9151259102682671 time: 1703117220.1624773\n",
      "batch_idx: 2 loss: 0.0015528752326153987 R2: 0.9151141232578036 time: 1703117222.9799914\n",
      "batch_idx: 3 loss: 0.0008402343220967103 R2: 0.9150678475074601 time: 1703117225.699703\n",
      "Training [66%] Loss: 0.0011471000348444174 time: 1703117225.699703\n",
      "weight: [0.50730728 0.80408274 0.1191523  0.22772595 0.70715219 1.32576888\n",
      " 0.74780539 0.32041784 0.52731695 0.0245637  0.18632151 0.81391347]\n",
      "epoch 199\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014719305801978856 R2: 0.9151243005630791 time: 1703117228.4277074\n",
      "batch_idx: 1 loss: 0.0007228665135538942 R2: 0.9151468426533439 time: 1703117231.2482507\n",
      "batch_idx: 2 loss: 0.0015524528281050092 R2: 0.9151349577868 time: 1703117234.0616276\n",
      "batch_idx: 3 loss: 0.0008399951505032295 R2: 0.9150883874022794 time: 1703117236.7900057\n",
      "Training [66%] Loss: 0.0011468112680900046 time: 1703117236.7900057\n",
      "weight: [0.50844897 0.80420949 0.11910193 0.2262773  0.70926275 1.32836504\n",
      " 0.74849636 0.32095017 0.52717748 0.02442313 0.1862695  0.81385919]\n",
      "epoch 200\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014714097006761884 R2: 0.9151450218642067 time: 1703117239.5101058\n",
      "batch_idx: 1 loss: 0.0007228994379069927 R2: 0.9151675914699716 time: 1703117242.3161223\n",
      "batch_idx: 2 loss: 0.0015520346794506367 R2: 0.9151555998358974 time: 1703117245.054689\n",
      "batch_idx: 3 loss: 0.0008397543747468396 R2: 0.9151087076154308 time: 1703117247.9174752\n",
      "Training [67%] Loss: 0.0011465245481951643 time: 1703117247.9174752\n",
      "weight: [0.50959582 0.80434748 0.11906468 0.22485664 0.71138301 1.33095905\n",
      " 0.74919289 0.32148884 0.52704863 0.02428162 0.18621708 0.8138045 ]\n",
      "epoch 201\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014708984806479988 R2: 0.915165545332813 time: 1703117250.639029\n",
      "batch_idx: 1 loss: 0.0007229284320477045 R2: 0.9151881455225125 time: 1703117253.4409354\n",
      "batch_idx: 2 loss: 0.0015516211111656264 R2: 0.9151760379367586 time: 1703117256.165579\n",
      "batch_idx: 3 loss: 0.0008395120656044947 R2: 0.9151287962567964 time: 1703117258.8808548\n",
      "Training [67%] Loss: 0.001146240022366456 time: 1703117258.8808548\n",
      "weight: [0.51074797 0.80449652 0.11904032 0.22346356 0.71351128 1.33354759\n",
      " 0.74989504 0.32203385 0.52693012 0.02413916 0.18616427 0.81374941]\n",
      "epoch 202\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014703970216629115 R2: 0.9151858593146956 time: 1703117261.7120738\n",
      "batch_idx: 1 loss: 0.0007229535951614331 R2: 0.9152084931398304 time: 1703117264.536937\n",
      "batch_idx: 2 loss: 0.0015512124586147637 R2: 0.9151962602408761 time: 1703117267.267161\n",
      "batch_idx: 3 loss: 0.0008392683225818583 R2: 0.9151486413460994 time: 1703117270.024704\n",
      "Training [67%] Loss: 0.0011459578495052417 time: 1703117270.024704\n",
      "weight: [0.51190556 0.80465638 0.11902853 0.22209758 0.71564571 1.33612719\n",
      " 0.75060281 0.32258514 0.52682164 0.02399574 0.18611106 0.81369393]\n",
      "epoch 203\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014699054161030226 R2: 0.9152059518584347 time: 1703117272.8537693\n",
      "batch_idx: 1 loss: 0.0007229750412623959 R2: 0.9152286223149325 time: 1703117275.607302\n",
      "batch_idx: 2 loss: 0.0015508090622045885 R2: 0.9152162546731312 time: 1703117278.4454255\n",
      "batch_idx: 3 loss: 0.0008390232757814655 R2: 0.9151682309991432 time: 1703117281.1881962\n",
      "Training [68%] Loss: 0.001145678198837868 time: 1703117281.1881962\n",
      "weight: [0.51306867 0.80482679 0.11902898 0.22075818 0.71778431 1.33869429\n",
      " 0.75131618 0.32314264 0.52672281 0.02385136 0.18605748 0.81363808]\n",
      "epoch 204\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014694237444724569 R2: 0.9152258108769807 time: 1703117284.0097675\n",
      "batch_idx: 1 loss: 0.000722992900130496 R2: 0.9152485208632012 time: 1703117286.767093\n",
      "batch_idx: 2 loss: 0.0015504112608628888 R2: 0.9152360091022256 time: 1703117289.4921083\n",
      "batch_idx: 3 loss: 0.0008387770872746954 R2: 0.9151875536259506 time: 1703117292.2317402\n",
      "Training [68%] Loss: 0.0011454012481851342 time: 1703117292.2317402\n",
      "weight: [0.51423737 0.80500742 0.11904126 0.2194448  0.71992492 1.34124525\n",
      " 0.75203504 0.3237062  0.52663322 0.02370603 0.18600355 0.81358188]\n",
      "epoch 205\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014689520725934418 R2: 0.9152454243238125 time: 1703117295.1577783\n",
      "batch_idx: 1 loss: 0.00072300731808785 R2: 0.9152681765961527 time: 1703117297.8883169\n",
      "batch_idx: 2 loss: 0.0015500193850135561 R2: 0.915255511524123 time: 1703117300.6279268\n",
      "batch_idx: 3 loss: 0.000838529951815765 R2: 0.9152065981348741 time: 1703117303.453555\n",
      "Training [68%] Loss: 0.0011451271818776533 time: 1703117303.453555\n",
      "weight: [0.51541168 0.80519789 0.11906492 0.21815682 0.72206532 1.34377643\n",
      " 0.75275928 0.32427563 0.52655242 0.02355978 0.1859493  0.81352534]\n",
      "epoch 206\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014684904487801728 R2: 0.9152647803792238 time: 1703117306.186474\n",
      "batch_idx: 1 loss: 0.0007230184585315541 R2: 0.9152875775064807 time: 1703117308.8995388\n",
      "batch_idx: 2 loss: 0.0015496337493149546 R2: 0.9152747502534393 time: 1703117311.763089\n",
      "batch_idx: 3 loss: 0.0008382820967421038 R2: 0.9152253541359048 time: 1703117314.5762494\n",
      "Training [69%] Loss: 0.0011448561883421963 time: 1703117314.5762494\n",
      "weight: [0.5165916  0.80539777 0.11909947 0.21689355 0.72420312 1.34628422\n",
      " 0.7534887  0.32485068 0.52647991 0.02341265 0.18589473 0.81346851]\n",
      "epoch 207\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014680389010773257 R2: 0.915283867641335 time: 1703117317.3276725\n",
      "batch_idx: 1 loss: 0.000723026502133271 R2: 0.9153067119591661 time: 1703117320.0565782\n",
      "batch_idx: 2 loss: 0.0015492546454774667 R2: 0.9152937141169287 time: 1703117322.8062806\n",
      "batch_idx: 3 loss: 0.0008380337809270211 R2: 0.915243812135665 time: 1703117325.675808\n",
      "Training [69%] Loss: 0.001144588457403771 time: 1703117325.675808\n",
      "weight: [0.51777707 0.8056066  0.11914436 0.21565427 0.72633587 1.34876508\n",
      " 0.75422307 0.32543109 0.52641516 0.02326467 0.1858399  0.8134114 ]\n",
      "epoch 208\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014675974346634092 R2: 0.91530267531563 time: 1703117328.4526212\n",
      "batch_idx: 1 loss: 0.0007230316466184281 R2: 0.9153255688827298 time: 1703117331.175243\n",
      "batch_idx: 2 loss: 0.001548882335502004 R2: 0.9153123926426238 time: 1703117333.9099894\n",
      "batch_idx: 3 loss: 0.000837785292687618 R2: 0.9152619637164381 time: 1703117336.7140129\n",
      "Training [69%] Loss: 0.001144324177367865 time: 1703117336.7140129\n",
      "weight: [0.51896804 0.80582387 0.11919904 0.21443822 0.72846107 1.35121562\n",
      " 0.75496213 0.32601651 0.5263576  0.02311589 0.18578481 0.81335404]\n",
      "epoch 209\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014671660295270882 R2: 0.9153211933966586 time: 1703117339.4366398\n",
      "batch_idx: 1 loss: 0.0007230341060497247 R2: 0.9153441379541917 time: 1703117342.2913346\n",
      "batch_idx: 2 loss: 0.0015485170456791045 R2: 0.9153307762379168 time: 1703117345.078731\n",
      "batch_idx: 3 loss: 0.0008375369466042521 R2: 0.9152798016919043 time: 1703117347.8077538\n",
      "Training [70%] Loss: 0.0011440635319650424 time: 1703117347.8077538\n",
      "weight: [0.52016439 0.80604904 0.11926288 0.21324457 0.73057615 1.35363265\n",
      " 0.75570555 0.32660659 0.52630664 0.0229664  0.18572952 0.81329647]\n",
      "epoch 210\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014667446385248262 R2: 0.9153394128353372 time: 1703117350.5525556\n",
      "batch_idx: 1 loss: 0.0007230341095637408 R2: 0.9153624097712967 time: 1703117353.2711608\n",
      "batch_idx: 2 loss: 0.0015481589616554163 R2: 0.9153488563502442 time: 1703117356.0717971\n",
      "batch_idx: 3 loss: 0.0008372890792732521 R2: 0.9152973202330574 time: 1703117358.8734326\n",
      "Training [70%] Loss: 0.0011438066972543088 time: 1703117358.8734326\n",
      "weight: [0.521366   0.80628154 0.11933525 0.21207249 0.73267854 1.35601319\n",
      " 0.75645299 0.32720093 0.52626166 0.02281626 0.18567403 0.81323871]\n",
      "epoch 211\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014663331859200396 R2: 0.915357325685979 time: 1703117361.6347485\n",
      "batch_idx: 1 loss: 0.0007230318995425412 R2: 0.9153803760059279 time: 1703117364.6099236\n",
      "batch_idx: 2 loss: 0.0015478082248121488 R2: 0.9153666256045391 time: 1703117367.616654\n",
      "batch_idx: 3 loss: 0.0008370420440872769 R2: 0.915314514959235 time: 1703117370.3766124\n",
      "Training [70%] Loss: 0.0011435538385905016 time: 1703117370.3766124\n",
      "weight: [0.52257271 0.80652077 0.1194155  0.2109211  0.73476569 1.35835457\n",
      " 0.75720408 0.3277991  0.52622203 0.02266555 0.18561839 0.8131808 ]\n",
      "epoch 212\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014659315664868303 R2: 0.9153749252278741 time: 1703117373.1139386\n",
      "batch_idx: 1 loss: 0.0007230277292433779 R2: 0.9153980295333503 time: 1703117376.034254\n",
      "batch_idx: 2 loss: 0.0015474649301138112 R2: 0.9153840779127622 time: 1703117378.7756467\n",
      "batch_idx: 3 loss: 0.0008367962052107396 R2: 0.9153313829908377 time: 1703117381.505793\n",
      "Training [71%] Loss: 0.0011433051077636897 time: 1703117381.505793\n",
      "weight: [0.52378435 0.80676613 0.11950296 0.20978949 0.73683511 1.3606544\n",
      " 0.7579584  0.32840067 0.52618713 0.02251437 0.18556262 0.81312277]\n",
      "epoch 213\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014655396452360335 R2: 0.9153922060575452 time: 1703117384.3074732\n",
      "batch_idx: 1 loss: 0.0007230218599528664 R2: 0.915415364533127 time: 1703117387.0616248\n",
      "batch_idx: 2 loss: 0.0015471291254854388 R2: 0.9154012085521466 time: 1703117389.9145489\n",
      "batch_idx: 3 loss: 0.0008365519309820439 R2: 0.9153479229624238 time: 1703117392.6324215\n",
      "Training [71%] Loss: 0.0011430606404140957 time: 1703117392.6324215\n",
      "weight: [0.52500073 0.80701701 0.11959697 0.20867678 0.73888436 1.36291065\n",
      " 0.75871555 0.32900518 0.52615631 0.02236281 0.18550675 0.81306464]\n",
      "epoch 214\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014651572577914066 R2: 0.9154091641491593 time: 1703117395.4308248\n",
      "batch_idx: 1 loss: 0.0007230145577721175 R2: 0.9154323765588399 time: 1703117398.150669\n",
      "batch_idx: 2 loss: 0.0015468008126735793 R2: 0.915418014210317 time: 1703117400.8834486\n",
      "batch_idx: 3 loss: 0.0008363095870235912 R2: 0.9153641349968872 time: 1703117403.7037387\n",
      "Training [71%] Loss: 0.0011428205538151737 time: 1703117403.7037387\n",
      "weight: [0.52622165 0.8072728  0.11969687 0.20758203 0.74091114 1.36512163\n",
      " 0.75947509 0.32961216 0.52612895 0.02221097 0.18545082 0.81300644]\n",
      "epoch 215\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001464784211410561 R2: 0.9154257968822337 time: 1703117406.5550117\n",
      "batch_idx: 1 loss: 0.0007230060901708949 R2: 0.9154490625753068 time: 1703117409.278677\n",
      "batch_idx: 2 loss: 0.0015464799494529938 R2: 0.9154344929970636 time: 1703117412.087334\n",
      "batch_idx: 3 loss: 0.0008360695293672532 R2: 0.9153800206435202 time: 1703117414.8312232\n",
      "Training [72%] Loss: 0.0011425849451004257 time: 1703117414.8312232\n",
      "weight: [0.52744689 0.8075329  0.119802   0.20650435 0.74291329 1.36728602\n",
      " 0.76023659 0.33022115 0.52610445 0.02205894 0.18539484 0.81294821]\n",
      "epoch 216\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014644202866144706 R2: 0.9154421030371795 time: 1703117417.5427566\n",
      "batch_idx: 1 loss: 0.0007229967224668224 R2: 0.9154654209635046 time: 1703117420.3193226\n",
      "batch_idx: 2 loss: 0.001546166452966914 R2: 0.9154506444241027 time: 1703117423.2514608\n",
      "batch_idx: 3 loss: 0.0008358320979048597 R2: 0.9153955827844141 time: 1703117425.982532\n",
      "Training [72%] Loss: 0.0011423538899882667 time: 1703117425.982532\n",
      "weight: [0.52867625 0.80779673 0.11991174 0.20544283 0.74488879 1.36940285\n",
      " 0.76099963 0.3308317  0.52608222 0.02190683 0.18533884 0.81288996]\n",
      "epoch 217\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014640652393614292 R2: 0.9154580827607658 time: 1703117428.712032\n",
      "batch_idx: 1 loss: 0.0007229867143889158 R2: 0.9154814514947848 time: 1703117431.444005\n",
      "batch_idx: 2 loss: 0.001545860203940037 R2: 0.9154664693555074 time: 1703117434.2550473\n",
      "batch_idx: 3 loss: 0.0008355976104494924 R2: 0.9154108255151099 time: 1703117436.9824681\n",
      "Training [72%] Loss: 0.0011421274420349687 time: 1703117436.9824681\n",
      "weight: [0.52990951 0.80806372 0.12002547 0.20439661 0.74683583 1.3714715\n",
      " 0.76176377 0.33144335 0.52606169 0.02175474 0.18528285 0.81283171]\n",
      "epoch 218\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014637188036805398 R2: 0.9154737375047389 time: 1703117439.811652\n",
      "batch_idx: 1 loss: 0.0007229763168723854 R2: 0.9154971552773074 time: 1703117442.6351562\n",
      "batch_idx: 2 loss: 0.0015455610514825623 R2: 0.915481969932584 time: 1703117445.3713605\n",
      "batch_idx: 3 loss: 0.0008353663576477304 R2: 0.9154257540061794 time: 1703117448.0919988\n",
      "Training [73%] Loss: 0.0011419056324208044 time: 1703117448.0919988\n",
      "weight: [0.53114646 0.80833334 0.12014263 0.20336482 0.74875278 1.37349166\n",
      " 0.76252861 0.3320557  0.52604233 0.02160277 0.18522688 0.8127735 ]\n",
      "epoch 219\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001463380694665186 R2: 0.9154890699416661 time: 1703117450.8309004\n",
      "batch_idx: 1 loss: 0.0007229657692077482 R2: 0.9155125346783993 time: 1703117453.7295868\n",
      "batch_idx: 2 loss: 0.0015452688182081 R2: 0.9154971494777883 time: 1703117456.475774\n",
      "batch_idx: 3 loss: 0.0008351385989206157 R2: 0.9154403743528542 time: 1703117459.2160704\n",
      "Training [73%] Loss: 0.0011416884702504125 time: 1703117459.2160704\n",
      "weight: [0.5323869  0.80860508 0.12026267 0.20234665 0.75063826 1.37546335\n",
      " 0.76329376 0.33266832 0.52602365 0.021451   0.18517095 0.81271534]\n",
      "epoch 220\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014630506117195535 R2: 0.9155040838627698 time: 1703117461.9538953\n",
      "batch_idx: 1 loss: 0.0007229552966348258 R2: 0.9155275932273964 time: 1703117464.7705302\n",
      "batch_idx: 2 loss: 0.0015449833054131824 R2: 0.9155120123826906 time: 1703117467.4898293\n",
      "batch_idx: 3 loss: 0.0008349145595396651 R2: 0.9154546934195243 time: 1703117470.3239079\n",
      "Training [73%] Loss: 0.0011414759433268067 time: 1703117470.3239079\n",
      "weight: [0.53363064 0.80887848 0.12038509 0.20134132 0.75249107 1.37738686\n",
      " 0.76405884 0.33328084 0.52600519 0.02129952 0.18511509 0.81265724]\n",
      "epoch 221\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014627282419499104 R2: 0.9155187840626045 time: 1703117473.061089\n",
      "batch_idx: 1 loss: 0.0007229451084369955 R2: 0.9155423355036577 time: 1703117475.890329\n",
      "batch_idx: 2 loss: 0.001544704298105438 R2: 0.9155265639850458 time: 1703117478.6025524\n",
      "batch_idx: 3 loss: 0.0008346944288712077 R2: 0.9154687186854739 time: 1703117481.337464\n",
      "Training [74%] Loss: 0.001141268019340888 time: 1703117481.337464\n",
      "weight: [0.53487748 0.80915311 0.12050943 0.20034806 0.75431027 1.37926271\n",
      " 0.76482352 0.3338929  0.52598652 0.02114841 0.18505931 0.81259923]\n",
      "epoch 222\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001462413263595891 R2: 0.9155331762155325 time: 1703117484.1528127\n",
      "batch_idx: 1 loss: 0.0007229353965565186 R2: 0.9155567670146414 time: 1703117487.0032904\n",
      "batch_idx: 2 loss: 0.0015444315697135315 R2: 0.9155408104400117 time: 1703117489.7274613\n",
      "batch_idx: 3 loss: 0.0008344783597543044 R2: 0.9154824580971154 time: 1703117492.452664\n",
      "Training [74%] Loss: 0.0011410646474050612 time: 1703117492.452664\n",
      "weight: [0.53612726 0.80942856 0.12063526 0.19936619 0.75609513 1.38109163\n",
      " 0.76558747 0.33450418 0.52596727 0.02099775 0.18500362 0.81254133]\n",
      "epoch 223\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014621053494049204 R2: 0.9155472667484771 time: 1703117495.2631412\n",
      "batch_idx: 1 loss: 0.0007229263347217546 R2: 0.9155708940686637 time: 1703117497.9809995\n",
      "batch_idx: 2 loss: 0.0015441648863601764 R2: 0.9155547585898713 time: 1703117500.7452621\n",
      "batch_idx: 3 loss: 0.0008342664689201662 R2: 0.9154959199309614 time: 1703117503.6065977\n",
      "Training [74%] Loss: 0.0011408657598517545 time: 1703117503.6065977\n",
      "weight: [0.53737981 0.80970449 0.12076223 0.19839504 0.75784514 1.38287456\n",
      " 0.76635039 0.33511438 0.5259471  0.02084761 0.18494803 0.81248353]\n",
      "epoch 224\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014618041698639835 R2: 0.9155610627140746 time: 1703117506.4210727\n",
      "batch_idx: 1 loss: 0.000722918078053085 R2: 0.9155847236464704 time: 1703117509.1406045\n",
      "batch_idx: 2 loss: 0.0015439040106246704 R2: 0.9155684158362632 time: 1703117511.897807\n",
      "batch_idx: 3 loss: 0.0008340588383172062 R2: 0.9155091126702418 time: 1703117514.7010956\n",
      "Training [75%] Loss: 0.0011406712742147362 time: 1703117514.7010956\n",
      "weight: [0.53863501 0.80998058 0.12088997 0.19743397 0.75955999 1.38461254\n",
      " 0.76711202 0.33572323 0.52592571 0.02069804 0.18489257 0.81242587]\n",
      "epoch 225\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014615093962160575 R2: 0.9155745716675817 time: 1703117517.500518\n",
      "batch_idx: 1 loss: 0.0007229107630968243 R2: 0.9155982632753755 time: 1703117520.3257945\n",
      "batch_idx: 2 loss: 0.001543648704761236 R2: 0.9155817900180573 time: 1703117523.1231005\n",
      "batch_idx: 3 loss: 0.0008338555171775906 R2: 0.9155220448969222 time: 1703117525.8473716\n",
      "Training [75%] Loss: 0.001140481095312927 time: 1703117525.8473716\n",
      "weight: [0.5398927  0.81025655 0.1210182  0.19648243 0.76123955 1.38630675\n",
      " 0.76787212 0.3363305  0.52590282 0.02054909 0.18483725 0.81236834]\n",
      "epoch 226\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014612207032041486 R2: 0.9155878015503459 time: 1703117528.5592263\n",
      "batch_idx: 1 loss: 0.0007229045082258246 R2: 0.9156115209088458 time: 1703117531.3040855\n",
      "batch_idx: 2 loss: 0.001543398733372206 R2: 0.9155948892973017 time: 1703117534.2814045\n",
      "batch_idx: 3 loss: 0.0008336565246478328 R2: 0.915534725199764 time: 1703117537.0138164\n",
      "Training [75%] Loss: 0.001140295117362503 time: 1703117537.0138164\n",
      "weight: [0.54115278 0.81053215 0.12114667 0.19553987 0.7628839  1.38795848\n",
      " 0.76863046 0.33693599 0.52587821 0.02040082 0.18478206 0.81231096]\n",
      "epoch 227\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014609377715015786 R2: 0.9156007605817823 time: 1703117539.746445\n",
      "batch_idx: 1 loss: 0.0007228994143398294 R2: 0.9156245048139542 time: 1703117542.5604415\n",
      "batch_idx: 2 loss: 0.0015431538655603573 R2: 0.9156077220550148 time: 1703117545.273321\n",
      "batch_idx: 3 loss: 0.0008334618528058723 R2: 0.9155471620982304 time: 1703117548.0033817\n",
      "Training [76%] Loss: 0.0011401132260519095 time: 1703117548.0033817\n",
      "weight: [0.54241514 0.81080717 0.12127513 0.1946058  0.76449324 1.38956904\n",
      " 0.76938687 0.3375395  0.52585168 0.02025326 0.18472703 0.81225375]\n",
      "epoch 228\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001460660289803347 R2: 0.9156134571613007 time: 1703117550.9463978\n",
      "batch_idx: 1 loss: 0.0007228955657982673 R2: 0.9156372234682945 time: 1703117553.680636\n",
      "batch_idx: 2 loss: 0.0015429138766025782 R2: 0.9156202967978245 time: 1703117556.4127731\n",
      "batch_idx: 3 loss: 0.0008332714698982334 R2: 0.9155593639812644 time: 1703117559.1212962\n",
      "Training [76%] Loss: 0.0011399353005256065 time: 1703117559.1212962\n",
      "weight: [0.54367969 0.81108144 0.12140342 0.19367976 0.76606793 1.39113981\n",
      " 0.77014117 0.33814088 0.52582308 0.02010644 0.18467216 0.8121967 ]\n",
      "epoch 229\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001460387956568543 R2: 0.9156258997809206 time: 1703117561.9384632\n",
      "batch_idx: 1 loss: 0.0007228930315209055 R2: 0.9156496854674161 time: 1703117564.6787248\n",
      "batch_idx: 2 loss: 0.001542678549198154 R2: 0.9156326220759171 time: 1703117567.4978292\n",
      "batch_idx: 3 loss: 0.0008330853236498563 R2: 0.9155713390596405 time: 1703117570.3126218\n",
      "Training [76%] Loss: 0.0011397612152343646 time: 1703117570.3126218\n",
      "weight: [0.54494635 0.8113548  0.12153137 0.19276133 0.76760845 1.39267217\n",
      " 0.77089323 0.33874    0.52579226 0.0199604  0.18461745 0.81213982]\n",
      "epoch 230\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014601204814174546 R2: 0.915638096948862 time: 1703117573.0384731\n",
      "batch_idx: 1 loss: 0.0007228918661976667 R2: 0.915661899443322 time: 1703117575.7696848\n",
      "batch_idx: 2 loss: 0.0015424476743500274 R2: 0.9156447064123373 time: 1703117578.5946636\n",
      "batch_idx: 3 loss: 0.0008329033445233994 R2: 0.9155830953302188 time: 1703117581.3506312\n",
      "Training [77%] Loss: 0.001139590841622137 time: 1703117581.3506312\n",
      "weight: [0.54621506 0.81162713 0.12165885 0.19185014 0.76911537 1.39416754\n",
      " 0.77164291 0.33933674 0.52575912 0.01981515 0.18456293 0.81208313]\n",
      "epoch 231\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014598575861978135 R2: 0.9156500571239736 time: 1703117584.1570508\n",
      "batch_idx: 1 loss: 0.0007228921115561161 R2: 0.9156738739939815 time: 1703117586.94953\n",
      "batch_idx: 2 loss: 0.0015422210519379857 R2: 0.9156565582431997 time: 1703117589.9932613\n",
      "batch_idx: 3 loss: 0.0008327254488311638 R2: 0.9155946405503401 time: 1703117593.108804\n",
      "Training [77%] Loss: 0.0011394240496307698 time: 1703117593.108804\n",
      "weight: [0.54748576 0.81189834 0.12178576 0.19094582 0.77058937 1.3956273\n",
      " 0.77239013 0.33993102 0.52572356 0.01967071 0.18450858 0.81202663]\n",
      "epoch 232\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001459599005743958 R2: 0.9156617886605416 time: 1703117595.9759905\n",
      "batch_idx: 1 loss: 0.0007228937976437717 R2: 0.9156856176236456 time: 1703117598.8763902\n",
      "batch_idx: 2 loss: 0.0015419984910394534 R2: 0.9156681858681661 time: 1703117601.6088893\n",
      "batch_idx: 3 loss: 0.0008325515416291584 R2: 0.9156059822207598 time: 1703117604.3303475\n",
      "Training [77%] Loss: 0.0011392607090140853 time: 1703117604.3303475\n",
      "weight: [0.5487584  0.81216835 0.12191202 0.19004805 0.77203116 1.39705282\n",
      " 0.77313478 0.34052277 0.52568553 0.01952709 0.18445442 0.81197033]\n",
      "epoch 233\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014593444883578882 R2: 0.9156732997628 time: 1703117607.1453474\n",
      "batch_idx: 1 loss: 0.000722896944090919 R2: 0.9156971386932942 time: 1703117609.870831\n",
      "batch_idx: 2 loss: 0.0015417798100484802 R2: 0.9156795974103884 time: 1703117612.5835218\n",
      "batch_idx: 3 loss: 0.0008323815193471129 R2: 0.9156171275754004 time: 1703117615.466768\n",
      "Training [78%] Loss: 0.0011391006904611 time: 1703117615.466768\n",
      "weight: [0.55003294 0.81243709 0.12203757 0.18915654 0.77344154 1.39844544\n",
      " 0.77387681 0.34111191 0.52564498 0.01938431 0.18440045 0.81191422]\n",
      "epoch 234\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014590937960455136 R2: 0.9156845984483286 time: 1703117618.2840605\n",
      "batch_idx: 1 loss: 0.0007229015613279576 R2: 0.915708445380497 time: 1703117621.031174\n",
      "batch_idx: 2 loss: 0.0015415648366368015 R2: 0.9156908007849214 time: 1703117623.7584352\n",
      "batch_idx: 3 loss: 0.0008322152721295213 R2: 0.9156280835765985 time: 1703117626.554831\n",
      "Training [78%] Loss: 0.0011389438665349485 time: 1703117626.554831\n",
      "weight: [0.55130935 0.81270454 0.12216237 0.18827103 0.77482135 1.39980648\n",
      " 0.77461615 0.34169842 0.52560187 0.01924237 0.18434668 0.81185831]\n",
      "epoch 235\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014588467045422743 R2: 0.915695692519415 time: 1703117629.3095822\n",
      "batch_idx: 1 loss: 0.0007229076517387618 R2: 0.9157195456477563 time: 1703117632.1242197\n",
      "batch_idx: 2 loss: 0.0015413534075943355 R2: 0.9157018036746795 time: 1703117634.9138107\n",
      "batch_idx: 3 loss: 0.0008320526858799371 R2: 0.9156388569145971 time: 1703117637.6485765\n",
      "Training [78%] Loss: 0.0011387901124388271 time: 1703117637.6485765\n",
      "weight: [0.55258762 0.81297065 0.12228638 0.18739126 0.77617142 1.40113721\n",
      " 0.77535276 0.34228227 0.52555621 0.01910128 0.18429311 0.81180262]\n",
      "epoch 236\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014586030031624659 R2: 0.9157065895414421 time: 1703117640.384918\n",
      "batch_idx: 1 loss: 0.0007229152107379364 R2: 0.9157304472184065 time: 1703117643.1089108\n",
      "batch_idx: 2 loss: 0.0015411453685798995 R2: 0.915712613512904 time: 1703117646.042726\n",
      "batch_idx: 3 loss: 0.000831893644014315 R2: 0.915649454010199 time: 1703117648.7621515\n",
      "Training [79%] Loss: 0.001138639306623654 time: 1703117648.7621515\n",
      "weight: [0.55386772 0.81323542 0.12240961 0.186517   0.77749264 1.40243885\n",
      " 0.77608661 0.34286342 0.52550797 0.01896102 0.18423974 0.81174713]\n",
      "epoch 237\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014583624945047366 R2: 0.915717296827396 time: 1703117651.4980683\n",
      "batch_idx: 1 loss: 0.0007229242277649698 R2: 0.9157411575591029 time: 1703117654.295086\n",
      "batch_idx: 2 loss: 0.0015409405738074132 R2: 0.9157232374712464 time: 1703117657.0357533\n",
      "batch_idx: 3 loss: 0.0008317380289384323 R2: 0.9156598810198074 time: 1703117659.7736049\n",
      "Training [79%] Loss: 0.001138491331253888 time: 1703117659.7736049\n",
      "weight: [0.55514964 0.81349886 0.12253205 0.18564806 0.77878589 1.40371257\n",
      " 0.77681767 0.34344187 0.52545718 0.01882161 0.18418657 0.81169185]\n",
      "epoch 238\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014581249940441676 R2: 0.9157278214276147 time: 1703117662.6720536\n",
      "batch_idx: 1 loss: 0.0007229346871923339 R2: 0.9157516838680232 time: 1703117665.3840864\n",
      "batch_idx: 2 loss: 0.0015407388856878129 R2: 0.9157336824525826 time: 1703117668.09674\n",
      "batch_idx: 3 loss: 0.0008315857232708898 R2: 0.9156701438421292 time: 1703117670.8526895\n",
      "Training [79%] Loss: 0.001138346072548801 time: 1703117670.8526895\n",
      "weight: [0.55643339 0.81376096 0.12265371 0.18478424 0.78005206 1.40495953\n",
      " 0.77754593 0.34401762 0.52540386 0.01868303 0.18413361 0.81163679]\n",
      "epoch 239\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014578903296381333 R2: 0.9157381701239021 time: 1703117673.6562781\n",
      "batch_idx: 1 loss: 0.0007229465691476006 R2: 0.9157620330678216 time: 1703117676.3811533\n",
      "batch_idx: 2 loss: 0.0015405401744429533 R2: 0.9157439550877611 time: 1703117679.2335763\n",
      "batch_idx: 3 loss: 0.0008314366108367135 R2: 0.9156802481260099 time: 1703117682.0506701\n",
      "Training [80%] Loss: 0.0011382034210163502 time: 1703117682.0506701\n",
      "weight: [0.55771896 0.81402174 0.12277462 0.18392536 0.78129203 1.40618079\n",
      " 0.77827138 0.34459067 0.52534802 0.01854529 0.18408086 0.81158194]\n",
      "epoch 240\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014576583409698907 R2: 0.9157483494273604 time: 1703117684.7811153\n",
      "batch_idx: 1 loss: 0.0007229598502517074 R2: 0.9157722118026473 time: 1703117687.49607\n",
      "batch_idx: 2 loss: 0.001540344317704233 R2: 0.9157540617355695 time: 1703117690.3143938\n",
      "batch_idx: 3 loss: 0.0008312905774577972 R2: 0.9156901992790273 time: 1703117693.0307844\n",
      "Training [80%] Loss: 0.0011380632715959071 time: 1703117693.0307844\n",
      "weight: [0.55900635 0.81428122 0.12289478 0.18307128 0.78250666 1.4073774\n",
      " 0.77899403 0.34516105 0.5252897  0.01840837 0.18402832 0.81152731]\n",
      "epoch 241\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001457428878950815 R2: 0.9157583655791657 time: 1703117695.8384206\n",
      "batch_idx: 1 loss: 0.0007229745042772005 R2: 0.9157822264384178 time: 1703117698.5615432\n",
      "batch_idx: 2 loss: 0.0015401512001060077 R2: 0.9157640084853244 time: 1703117701.37969\n",
      "batch_idx: 3 loss: 0.0008311475115667675 R2: 0.91570000247649 time: 1703117704.1050396\n",
      "Training [80%] Loss: 0.0011379255237251977 time: 1703117704.1050396\n",
      "weight: [0.56029558 0.81453944 0.12301425 0.18222183 0.78369681 1.40855035\n",
      " 0.77971386 0.34572875 0.52522895 0.01827227 0.18397599 0.8114729 ]\n",
      "epoch 242\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014572018050984094 R2: 0.9157682245537929 time: 1703117706.822789\n",
      "batch_idx: 1 loss: 0.000722990502731099 R2: 0.9157920830657581 time: 1703117709.7100096\n",
      "batch_idx: 2 loss: 0.0015399607128814168 R2: 0.9157738011614829 time: 1703117712.463338\n",
      "batch_idx: 3 loss: 0.0008310073046692923 R2: 0.915709662670627 time: 1703117715.1979356\n",
      "Training [81%] Loss: 0.0011377900813450545 time: 1703117715.1979356\n",
      "weight: [0.56158666 0.81479643 0.12313305 0.18137688 0.78486333 1.40970059\n",
      " 0.7804309  0.3462938  0.5251658  0.01813699 0.18392387 0.8114187 ]\n",
      "epoch 243\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014569769909047222 R2: 0.9157779320641216 time: 1703117718.0040753\n",
      "batch_idx: 1 loss: 0.0007230078153677778 R2: 0.9158017875050459 time: 1703117720.7323077\n",
      "batch_idx: 2 loss: 0.0015397727534663078 R2: 0.9157834453298926 time: 1703117723.4466658\n",
      "batch_idx: 3 loss: 0.0008308698516784523 R2: 0.9157191845998179 time: 1703117726.2998679\n",
      "Training [81%] Loss: 0.001137656852854315 time: 1703117726.2998679\n",
      "weight: [0.5628796  0.81505223 0.12325124 0.18053632 0.78600702 1.41082901\n",
      " 0.78114516 0.34685623 0.52510031 0.0180025  0.18387196 0.81136473]\n",
      "epoch 244\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014567543172064822 R2: 0.9157874935680039 time: 1703117729.10012\n",
      "batch_idx: 1 loss: 0.0007230264106375154 R2: 0.9158113453130754 time: 1703117731.825003\n",
      "batch_idx: 2 loss: 0.0015395872251154554 R2: 0.915792946305211 time: 1703117734.54746\n",
      "batch_idx: 3 loss: 0.000830735051142351 R2: 0.915728572797717 time: 1703117737.3510752\n",
      "Training [81%] Loss: 0.001137525751025451 time: 1703117737.3510752\n",
      "weight: [0.56417442 0.81530687 0.12336884 0.17970001 0.78712868 1.41193647\n",
      " 0.78185665 0.34741607 0.52503252 0.01786881 0.18382026 0.81131097]\n",
      "epoch 245\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014565336735661851 R2: 0.9157969142759453 time: 1703117740.0760195\n",
      "batch_idx: 1 loss: 0.0007230462560765352 R2: 0.9158207617909413 time: 1703117742.9288564\n",
      "batch_idx: 2 loss: 0.0015394040365338609 R2: 0.9158023091592181 time: 1703117745.770831\n",
      "batch_idx: 3 loss: 0.000830602805383967 R2: 0.9157378316021865 time: 1703117748.4800618\n",
      "Training [82%] Loss: 0.0011373966928901371 time: 1703117748.4800618\n",
      "weight: [0.56547114 0.8155604  0.12348592 0.17886786 0.78822908 1.41302379\n",
      " 0.78256539 0.34797333 0.5249625  0.01773589 0.18376877 0.81125743]\n",
      "epoch 246\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014563149576708124 R2: 0.9158061991595613 time: 1703117751.2254033\n",
      "batch_idx: 1 loss: 0.0007230673186441663 R2: 0.9158300419927972 time: 1703117753.9495535\n",
      "batch_idx: 2 loss: 0.0015392231015250739 R2: 0.9158115387297212 time: 1703117756.7417786\n",
      "batch_idx: 3 loss: 0.0008304730205698002 R2: 0.9157469651640266 time: 1703117759.5782442\n",
      "Training [82%] Loss: 0.0011372695996024632 time: 1703117759.5782442\n",
      "weight: [0.56676979 0.81581287 0.12360252 0.17803975 0.78930897 1.41409174\n",
      " 0.78327141 0.34852807 0.52489029 0.01760375 0.1837175  0.81120411]\n",
      "epoch 247\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014560980747534572 R2: 0.9158153529605558 time: 1703117762.3162973\n",
      "batch_idx: 1 loss: 0.000723089565012631 R2: 0.9158391907352122 time: 1703117765.126637\n",
      "batch_idx: 2 loss: 0.0015390443386575053 R2: 0.9158206396298423 time: 1703117767.8582573\n",
      "batch_idx: 3 loss: 0.0008303456067215755 R2: 0.9157559774553844 time: 1703117770.5921035\n",
      "Training [82%] Loss: 0.0011371443962862923 time: 1703117770.5921035\n",
      "weight: [0.56807038 0.81606432 0.12371869 0.1772156  0.79036907 1.41514107\n",
      " 0.78397472 0.3490803  0.52481596 0.01747237 0.18366643 0.811151  ]\n",
      "epoch 248\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001455882937041149 R2: 0.9158243802000501 time: 1703117773.4318922\n",
      "batch_idx: 1 loss: 0.0007231129618145949 R2: 0.9158482126068985 time: 1703117776.2357728\n",
      "batch_idx: 2 loss: 0.001538867670949368 R2: 0.9158296162574973 time: 1703117778.9538083\n",
      "batch_idx: 3 loss: 0.0008302204776832203 R2: 0.9157648722779104 time: 1703117781.6902838\n",
      "Training [83%] Loss: 0.0011370210118720832 time: 1703117781.6902838\n",
      "weight: [0.56937296 0.81631481 0.12383449 0.17639532 0.79141007 1.41617246\n",
      " 0.78467535 0.34963006 0.52473956 0.01734175 0.18361558 0.81109811]\n",
      "epoch 249\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014556694632313597 R2: 0.9158332851880372 time: 1703117784.5082028\n",
      "batch_idx: 1 loss: 0.0007231374758532496 R2: 0.9158571119786261 time: 1703117787.2563102\n",
      "batch_idx: 2 loss: 0.0015386930255722549 R2: 0.915838472804937 time: 1703117790.0985088\n",
      "batch_idx: 3 loss: 0.0008300975510532365 R2: 0.9157736532705757 time: 1703117792.9080715\n",
      "Training [83%] Loss: 0.001136899378927525 time: 1703117792.9080715\n",
      "weight: [0.57067754 0.81656437 0.12394997 0.17557882 0.79243263 1.4171866\n",
      " 0.78537333 0.35017739 0.52466115 0.01721186 0.18356493 0.81104544]\n",
      "epoch 250\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014554575779982715 R2: 0.9158420720328685 time: 1703117795.6474473\n",
      "batch_idx: 1 loss: 0.0007231630742793244 R2: 0.9158658930131475 time: 1703117798.3671026\n",
      "batch_idx: 2 loss: 0.0015385203335731485 R2: 0.915847213268217 time: 1703117801.0946524\n",
      "batch_idx: 3 loss: 0.0008299767480910561 R2: 0.9157823239171788 time: 1703117803.905281\n",
      "Training [83%] Loss: 0.00113677943348545 time: 1703117803.905281\n",
      "weight: [0.57198416 0.81681306 0.12406517 0.17476603 0.79343741 1.4181841\n",
      " 0.78606868 0.35072232 0.5245808  0.01708269 0.18351449 0.81099298]\n",
      "epoch 251\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014552472115294903 R2: 0.9158507446506452 time: 1703117806.749765\n",
      "batch_idx: 1 loss: 0.0007231897247389708 R2: 0.915874559675037 time: 1703117809.490322\n",
      "batch_idx: 2 loss: 0.0015383495296143685 R2: 0.915855841456511 time: 1703117812.246044\n",
      "batch_idx: 3 loss: 0.0008298579936043052 R2: 0.9157908875535566 time: 1703117815.052642\n",
      "Training [84%] Loss: 0.0011366611148717837 time: 1703117815.052642\n",
      "weight: [0.57329285 0.81706092 0.12418017 0.17395687 0.79442502 1.41916558\n",
      " 0.78676144 0.35126489 0.52449856 0.01695425 0.18346426 0.81094073]\n",
      "epoch 252\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014550382990929206 R2: 0.9158593067744366 time: 1703117817.7567208\n",
      "batch_idx: 1 loss: 0.0007232173954961587 R2: 0.9158831157403847 time: 1703117820.5235827\n",
      "batch_idx: 2 loss: 0.0015381805517309223 R2: 0.9158643610012266 time: 1703117823.473623\n",
      "batch_idx: 3 loss: 0.0008297412158226843 R2: 0.9157993473744593 time: 1703117826.1995642\n",
      "Training [84%] Loss: 0.0011365443655356716 time: 1703117826.1995642\n",
      "weight: [0.57460364 0.81730802 0.124295   0.17315127 0.79539604 1.42013161\n",
      " 0.78745163 0.35180513 0.52441449 0.01682652 0.18341423 0.81088869]\n",
      "epoch 253\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014548307806332467 R2: 0.9158677619632826 time: 1703117828.9089801\n",
      "batch_idx: 1 loss: 0.0007232460555328067 R2: 0.9158915648061962 time: 1703117831.636119\n",
      "batch_idx: 2 loss: 0.0015380133411044012 R2: 0.9158727753648263 time: 1703117834.4295251\n",
      "batch_idx: 3 loss: 0.0008296263462630758 R2: 0.915807706440121 time: 1703117837.1734653\n",
      "Training [84%] Loss: 0.0011364291308833825 time: 1703117837.1734653\n",
      "weight: [0.57591658 0.81755439 0.12440973 0.17234917 0.79635106 1.42108273\n",
      " 0.78813928 0.35234309 0.52432866 0.01669948 0.18336441 0.81083687]\n",
      "epoch 254\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014546246003972287 R2: 0.915876113610873 time: 1703117840.0100942\n",
      "batch_idx: 1 loss: 0.0007232756746294404 R2: 0.9158999102995343 time: 1703117842.7424939\n",
      "batch_idx: 2 loss: 0.0015378478418526717 R2: 0.9158810878493565 time: 1703117845.5427172\n",
      "batch_idx: 3 loss: 0.0008295133195895954 R2: 0.9158159676825633 time: 1703117848.2541933\n",
      "Training [85%] Loss: 0.0011363153591172342 time: 1703117848.2541933\n",
      "weight: [0.57723169 0.81780008 0.1245244  0.17155051 0.79729061 1.42201946\n",
      " 0.78882442 0.35287879 0.52424112 0.01657312 0.18331479 0.81078525]\n",
      "epoch 255\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001454419706586362 R2: 0.9158843649539691 time: 1703117851.016124\n",
      "batch_idx: 1 loss: 0.0007233062234291179 R2: 0.9159081554862972 time: 1703117853.8215077\n",
      "batch_idx: 2 loss: 0.0015376840008344747 R2: 0.9158893016046413 time: 1703117856.649051\n",
      "batch_idx: 3 loss: 0.0008294020734713782 R2: 0.9158241339115701 time: 1703117859.3597283\n",
      "Training [85%] Loss: 0.0011362030010803332 time: 1703117859.3597283\n",
      "weight: [0.57854902 0.81804514 0.12463907 0.17075522 0.79821522 1.4229423\n",
      " 0.78950708 0.35341228 0.52415194 0.01644744 0.18326537 0.81073385]\n",
      "epoch 256\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014542160510359029 R2: 0.9158925190804499 time: 1703117862.1148684\n",
      "batch_idx: 1 loss: 0.0007233376734867024 R2: 0.9159163034796617 time: 1703117864.9311354\n",
      "batch_idx: 2 loss: 0.0015375217674680564 R2: 0.9158974196361372 time: 1703117867.66769\n",
      "batch_idx: 3 loss: 0.000829292548440519 R2: 0.9158322078203925 time: 1703117870.5195627\n",
      "Training [85%] Loss: 0.0011360920101077952 time: 1703117870.5195627\n",
      "weight: [0.5798686  0.81828962 0.12475379 0.16996326 0.79912539 1.42385172\n",
      " 0.79018729 0.35394358 0.52406116 0.01632243 0.18321616 0.81068264]\n",
      "epoch 257\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014540135889184683 R2: 0.9159005789370209 time: 1703117873.2617135\n",
      "batch_idx: 1 loss: 0.0007233699973056687 R2: 0.9159243572481394 time: 1703117876.0637279\n",
      "batch_idx: 2 loss: 0.0015373610935629357 R2: 0.9159054448124178 time: 1703117878.778707\n",
      "batch_idx: 3 loss: 0.0008291846877518021 R2: 0.9158401919912093 time: 1703117881.5229058\n",
      "Training [86%] Loss: 0.0011359823418847187 time: 1703117881.5229058\n",
      "weight: [0.58119048 0.81853357 0.12486861 0.16917455 0.80002159 1.42474815\n",
      " 0.79086508 0.35447274 0.52396886 0.01619807 0.18316714 0.81063165]\n",
      "epoch 258\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014538122784711074 R2: 0.9159085473365712 time: 1703117884.3304734\n",
      "batch_idx: 1 loss: 0.0007234031683640423 R2: 0.9159323196232678 time: 1703117887.1620288\n",
      "batch_idx: 2 loss: 0.0015372019331639547 R2: 0.9159133798723215 time: 1703117889.8933399\n",
      "batch_idx: 3 loss: 0.0008290784372455273 R2: 0.9158480889002906 time: 1703117892.637247\n",
      "Training [86%] Loss: 0.001135873954311158 time: 1703117892.637247\n",
      "weight: [0.5825147  0.81877702 0.12498358 0.16838907 0.80090429 1.42563204\n",
      " 0.79154048 0.35499979 0.52387508 0.01607436 0.18311832 0.81058086]\n",
      "epoch 259\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014536120807439959 R2: 0.9159164269651884 time: 1703117895.4447844\n",
      "batch_idx: 1 loss: 0.0007234371611311884 R2: 0.9159401933069186 time: 1703117898.1553495\n",
      "batch_idx: 2 loss: 0.0015370442424067858 R2: 0.9159212274317323 time: 1703117900.913081\n",
      "batch_idx: 3 loss: 0.0008289737452144572 R2: 0.915855900922929 time: 1703117903.7803185\n",
      "Training [86%] Loss: 0.0011357668073741069 time: 1703117903.7803185\n",
      "weight: [0.58384129 0.81902004 0.12509874 0.16760675 0.80177393 1.42650379\n",
      " 0.79221351 0.35552476 0.52377988 0.01595128 0.18306969 0.81053026]\n",
      "epoch 260\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001453412959369634 R2: 0.9159242203887887 time: 1703117906.5069878\n",
      "batch_idx: 1 loss: 0.0007234719510766261 R2: 0.9159479808782164 time: 1703117909.235953\n",
      "batch_idx: 2 loss: 0.0015368879793840906 R2: 0.9159289899900169 time: 1703117911.9884257\n",
      "batch_idx: 3 loss: 0.0008288705622754754 R2: 0.9158636303381227 time: 1703117914.7897594\n",
      "Training [87%] Loss: 0.0011356608630264564 time: 1703117914.7897594\n",
      "weight: [0.58517031 0.81926265 0.12521416 0.16682755 0.80263092 1.42736378\n",
      " 0.79288422 0.35604769 0.52368333 0.01582883 0.18302126 0.81047987]\n",
      "epoch 261\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014532148803508178 R2: 0.9159319300594435 time: 1703117917.5601492\n",
      "batch_idx: 1 loss: 0.0007235075146721806 R2: 0.9159556848001232 time: 1703117920.3643036\n",
      "batch_idx: 2 loss: 0.0015367331040215828 R2: 0.9159366699361284 time: 1703117923.172797\n",
      "batch_idx: 3 loss: 0.0008287688412464964 R2: 0.9158712793330327 time: 1703117925.8941798\n",
      "Training [87%] Loss: 0.0011355560850727694 time: 1703117925.8941798\n",
      "weight: [0.5865018  0.8195049  0.12532987 0.16605142 0.80347567 1.42821239\n",
      " 0.79355262 0.35656861 0.52358546 0.015707   0.18297303 0.81042968]\n",
      "epoch 262\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001453017811866265 R2: 0.9159395583213407 time: 1703117928.6191053\n",
      "batch_idx: 1 loss: 0.0007235438293883797 R2: 0.9159633074256293 time: 1703117931.3484852\n",
      "batch_idx: 2 loss: 0.0015365795779633219 R2: 0.9159442695543586 time: 1703117934.2468123\n",
      "batch_idx: 3 loss: 0.0008286685370287332 R2: 0.9158788500072189 time: 1703117936.9609544\n",
      "Training [87%] Loss: 0.001135452439061675 time: 1703117936.9609544\n",
      "weight: [0.58783581 0.81974684 0.12544592 0.16527833 0.80430857 1.42904996\n",
      " 0.79421874 0.35708754 0.52348634 0.01558577 0.18292498 0.81037968]\n",
      "epoch 263\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014528217240924934 R2: 0.915947107416429 time: 1703117939.6969047\n",
      "batch_idx: 1 loss: 0.0007235808736860439 R2: 0.9159708510036435 time: 1703117942.5369854\n",
      "batch_idx: 2 loss: 0.001536427364465457 R2: 0.9159517910298117 time: 1703117945.263071\n",
      "batch_idx: 3 loss: 0.0008285696064946936 R2: 0.9158863443766464 time: 1703117947.9851444\n",
      "Training [88%] Loss: 0.001135349892184672 time: 1703117947.9851444\n",
      "weight: [0.58917237 0.8199885  0.12556235 0.16450822 0.80512999 1.42987685\n",
      " 0.79488262 0.35760454 0.52338602 0.01546514 0.18287713 0.81032988]\n",
      "epoch 264\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014526265890407123 R2: 0.9159545794897689 time: 1703117950.8267589\n",
      "batch_idx: 1 loss: 0.000723618627003841 R2: 0.9159783176844927 time: 1703117953.6511793\n",
      "batch_idx: 2 loss: 0.0015362764282979714 R2: 0.9159592364535374 time: 1703117956.3822691\n",
      "batch_idx: 3 loss: 0.0008284720083816943 R2: 0.9158937643775088 time: 1703117959.110968\n",
      "Training [88%] Loss: 0.0011352484131810546 time: 1703117959.110968\n",
      "weight: [0.59051155 0.82022993 0.12567922 0.16374107 0.80594027 1.43069336\n",
      " 0.79554428 0.35811962 0.52328454 0.0153451  0.18282946 0.81028028]\n",
      "epoch 265\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001452432380407631 R2: 0.91596197659455 time: 1703117961.9337695\n",
      "batch_idx: 1 loss: 0.0007236570697423167 R2: 0.9159857095251788 time: 1703117964.6551728\n",
      "batch_idx: 2 loss: 0.0015361267356537123 R2: 0.915966607827394 time: 1703117967.506502\n",
      "batch_idx: 3 loss: 0.0008283757031909454 R2: 0.915901111869838 time: 1703117970.2612438\n",
      "Training [88%] Loss: 0.0011351479722486514 time: 1703117970.2612438\n",
      "weight: [0.59185338 0.82047117 0.12579656 0.16297683 0.80673977 1.43149981\n",
      " 0.79620374 0.35863281 0.52318197 0.01522564 0.18278198 0.81023086]\n",
      "epoch 266\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014522390734391425 R2: 0.9159693006968566 time: 1703117973.052553\n",
      "batch_idx: 1 loss: 0.0007236961832451493 R2: 0.9159930284942577 time: 1703117975.790443\n",
      "batch_idx: 2 loss: 0.0015359782540641975 R2: 0.9159739070686184 time: 1703117978.5067837\n",
      "batch_idx: 3 loss: 0.0008282806530921205 R2: 0.9159083886409448 time: 1703117981.4017332\n",
      "Training [89%] Loss: 0.0011350485409601524 time: 1703117981.4017332\n",
      "weight: [0.59319792 0.82071224 0.12591441 0.16221546 0.8075288  1.4322965\n",
      " 0.79686104 0.35914415 0.52307834 0.01510676 0.18273468 0.81018163]\n",
      "epoch 267\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001452046644805757 R2: 0.9159765536801329 time: 1703117984.161466\n",
      "batch_idx: 1 loss: 0.0007237359497779809 R2: 0.9160002764764966 time: 1703117986.8961308\n",
      "batch_idx: 2 loss: 0.0015358309523217414 R2: 0.915981136014152 time: 1703117989.6032228\n",
      "batch_idx: 3 loss: 0.0008281868218331144 R2: 0.9159155964086679 time: 1703117992.4440112\n",
      "Training [89%] Loss: 0.0011349500921846484 time: 1703117992.4440112\n",
      "weight: [0.59454522 0.82095321 0.12603283 0.16145694 0.80830768 1.4330837\n",
      " 0.79751621 0.35965367 0.52297371 0.01498843 0.18268757 0.8101326 ]\n",
      "epoch 268\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001451855072489118 R2: 0.9159837373494211 time: 1703117995.177778\n",
      "batch_idx: 1 loss: 0.0007237763525051842 R2: 0.9160074552772098 time: 1703117998.0295122\n",
      "batch_idx: 2 loss: 0.0015356848004074227 R2: 0.915988296424692 time: 1703118000.7788606\n",
      "batch_idx: 3 loss: 0.000828094174654958 R2: 0.9159227368244511 time: 1703118003.603161\n",
      "Training [89%] Loss: 0.0011348526000141707 time: 1703118003.603161\n",
      "weight: [0.59589533 0.82119409 0.12615184 0.16070122 0.80907671 1.43386168\n",
      " 0.79816926 0.36016138 0.52286813 0.01487067 0.18264064 0.81008375]\n",
      "epoch 269\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014516643356784213 R2: 0.9159908534353166 time: 1703118006.3425176\n",
      "batch_idx: 1 loss: 0.0007238173754650545 R2: 0.9160145666263585 time: 1703118009.084565\n",
      "batch_idx: 2 loss: 0.0015355397694244346 R2: 0.9159953899885285 time: 1703118011.8050025\n",
      "batch_idx: 3 loss: 0.0008280026782114973 R2: 0.9159298114762666 time: 1703118014.6964421\n",
      "Training [90%] Loss: 0.0011347560396948518 time: 1703118014.6964421\n",
      "weight: [0.59724829 0.82143492 0.12627148 0.15994827 0.80983616 1.43463071\n",
      " 0.79882023 0.36066734 0.52276163 0.01475345 0.18259389 0.81003508]\n",
      "epoch 270\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001451474414676345 R2: 0.9159979035977143 time: 1703118017.4349163\n",
      "batch_idx: 1 loss: 0.0007238590035434982 R2: 0.916021612182411 time: 1703118020.1619298\n",
      "batch_idx: 2 loss: 0.0015353958315365037 R2: 0.9160024183251304 time: 1703118022.983848\n",
      "batch_idx: 3 loss: 0.0008279123004937456 R2: 0.9159368218913734 time: 1703118025.7075386\n",
      "Training [90%] Loss: 0.001134660387562523 time: 1703118025.7075386\n",
      "weight: [0.59860418 0.82167575 0.12639181 0.15919806 0.81058633 1.43539103\n",
      " 0.79946914 0.36117155 0.52265427 0.01463677 0.18254732 0.8099866 ]\n",
      "epoch 271\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001451285290813454 R2: 0.9160048894293438 time: 1703118028.4315732\n",
      "batch_idx: 1 loss: 0.000723901222446618 R2: 0.9160285935359613 time: 1703118031.2766135\n",
      "batch_idx: 2 loss: 0.0015352529599109628 R2: 0.916009382988548 time: 1703118034.091232\n",
      "batch_idx: 3 loss: 0.0008278230107585844 R2: 0.9159437695389355 time: 1703118036.8261788\n",
      "Training [90%] Loss: 0.0011345656209824047 time: 1703118036.8261788\n",
      "weight: [0.59996302 0.8219166  0.12651285 0.15845056 0.81132746 1.43614287\n",
      " 0.80011601 0.36167405 0.5225461  0.01452063 0.18250092 0.8099383 ]\n",
      "epoch 272\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014510969463706611 R2: 0.9160118124590563 time: 1703118039.56527\n",
      "batch_idx: 1 loss: 0.0007239440186722401 R2: 0.9160355122131273 time: 1703118042.3870049\n",
      "batch_idx: 2 loss: 0.0015351111286661958 R2: 0.9160162854705776 time: 1703118045.1415467\n",
      "batch_idx: 3 loss: 0.0008277347794616019 R2: 0.9159506558324889 time: 1703118047.9728627\n",
      "Training [91%] Loss: 0.0011344717182926746 time: 1703118047.9728627\n",
      "weight: [0.60132489 0.82215751 0.12663463 0.15770574 0.81205982 1.43688647\n",
      " 0.80076087 0.36217486 0.52243714 0.01440501 0.18245471 0.80989018]\n",
      "epoch 273\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014509093645090545 R2: 0.9160186741549706 time: 1703118050.7911189\n",
      "batch_idx: 1 loss: 0.0007239873794805762 R2: 0.9160423696787487 time: 1703118053.520453\n",
      "batch_idx: 2 loss: 0.0015349703128231564 R2: 0.916023127203785 time: 1703118056.2487547\n",
      "batch_idx: 3 loss: 0.000827647578193796 R2: 0.9159574821322753 time: 1703118059.0402677\n",
      "Training [91%] Loss: 0.0011343786587516458 time: 1703118059.0402677\n",
      "weight: [0.60268984 0.82239851 0.12675721 0.15696357 0.81278364 1.43762205\n",
      " 0.80140375 0.36267401 0.52232744 0.01428991 0.18240866 0.80984224]\n",
      "epoch 274\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014507225292066366 R2: 0.9160254759273837 time: 1703118061.9061987\n",
      "batch_idx: 1 loss: 0.0007240312928641043 R2: 0.9160491673394008 time: 1703118064.6502967\n",
      "batch_idx: 2 loss: 0.0015348304882606694 R2: 0.9160299095642823 time: 1703118067.3674476\n",
      "batch_idx: 3 loss: 0.0008275613796219769 R2: 0.9159642497474513 time: 1703118070.1794858\n",
      "Training [91%] Loss: 0.0011342864224883468 time: 1703118070.1794858\n",
      "weight: [0.60405791 0.82263963 0.12688061 0.15622403 0.81349917 1.43834981\n",
      " 0.80204466 0.36317153 0.52221706 0.01417533 0.18236279 0.80979448]\n",
      "epoch 275\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014505364252013883 R2: 0.9160322191315291 time: 1703118072.9194982\n",
      "batch_idx: 1 loss: 0.0007240757475167393 R2: 0.9160559065462068 time: 1703118075.650898\n",
      "batch_idx: 2 loss: 0.0015346916316743302 R2: 0.9160366338744124 time: 1703118078.4696093\n",
      "batch_idx: 3 loss: 0.0008274761574325216 R2: 0.9159709599381658 time: 1703118081.3093104\n",
      "Training [92%] Loss: 0.0011341949904562448 time: 1703118081.3093104\n",
      "weight: [0.60542917 0.82288091 0.12700487 0.15548708 0.81420661 1.43906995\n",
      " 0.80268364 0.36366743 0.52210601 0.01406124 0.18231709 0.80974689]\n",
      "epoch 276\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014503510379403936 R2: 0.9160389050701807 time: 1703118084.0475569\n",
      "batch_idx: 1 loss: 0.0007241207328022898 R2: 0.9160625885974977 time: 1703118086.796304\n",
      "batch_idx: 2 loss: 0.0015345537205387523 R2: 0.916043301405202 time: 1703118089.6057327\n",
      "batch_idx: 3 loss: 0.0008273918862783709 R2: 0.9159776139175289 time: 1703118092.3196201\n",
      "Training [92%] Loss: 0.0011341043443899518 time: 1703118092.3196201\n",
      "weight: [0.60680367 0.82312237 0.12713002 0.1547527  0.8149062  1.43978267\n",
      " 0.8033207  0.36416175 0.52199436 0.01394766 0.18227155 0.80969948]\n",
      "epoch 277\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014501663535345473 R2: 0.9160455349960726 time: 1703118095.1981504\n",
      "batch_idx: 1 loss: 0.0007241662387222706 R2: 0.9160692147412833 time: 1703118097.9226851\n",
      "batch_idx: 2 loss: 0.00153441673307295 R2: 0.9160499133787144 time: 1703118100.7552104\n",
      "batch_idx: 3 loss: 0.0008273085417290094 R2: 0.9159842128534453 time: 1703118103.478019\n",
      "Training [92%] Loss: 0.0011340144667646944 time: 1703118103.478019\n",
      "weight: [0.60818147 0.82336405 0.12725609 0.15402086 0.81559813 1.44048815\n",
      " 0.80395587 0.3646545  0.52188212 0.01383456 0.18222619 0.80965223]\n",
      "epoch 278\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014499823587184912 R2: 0.9160521101141951 time: 1703118106.2763848\n",
      "batch_idx: 1 loss: 0.0007242122558829467 R2: 0.9160757861776065 time: 1703118109.0094025\n",
      "batch_idx: 2 loss: 0.0015342806482087782 R2: 0.916056470970234 time: 1703118111.940283\n",
      "batch_idx: 3 loss: 0.000827226100223164 R2: 0.9159907578703692 time: 1703118114.6647398\n",
      "Training [93%] Loss: 0.001133925340758345 time: 1703118114.6647398\n",
      "weight: [0.60956262 0.82360597 0.12738313 0.15329154 0.8162826  1.44118657\n",
      " 0.80458918 0.36514572 0.52176934 0.01372195 0.18218099 0.80960516]\n",
      "epoch 279\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014497990408156095 R2: 0.916058631583945 time: 1703118117.3767757\n",
      "batch_idx: 1 loss: 0.0007242587754616752 R2: 0.9160823040607321 time: 1703118120.098404\n",
      "batch_idx: 2 loss: 0.0015341454455621868 R2: 0.9160629753103191 time: 1703118122.9127862\n",
      "batch_idx: 3 loss: 0.0008271445390241458 R2: 0.9159972500509271 time: 1703118125.7369614\n",
      "Training [93%] Loss: 0.0011338369502159043 time: 1703118125.7369614\n",
      "weight: [0.61094718 0.82384817 0.12751115 0.15256472 0.8169598  1.4418781\n",
      " 0.80522063 0.36563541 0.52165606 0.01360982 0.18213596 0.80955826]\n",
      "epoch 280\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001449616387707703 R2: 0.916065100521133 time: 1703118128.4917574\n",
      "batch_idx: 1 loss: 0.0007243057891723674 R2: 0.9160887695011926 time: 1703118131.3091998\n",
      "batch_idx: 2 loss: 0.0015340111054072047 R2: 0.9160694274867265 time: 1703118134.0461824\n",
      "batch_idx: 3 loss: 0.0008270638361775277 R2: 0.9160036904374633 time: 1703118136.7774127\n",
      "Training [93%] Loss: 0.0011337492796162007 time: 1703118136.7774127\n",
      "weight: [0.61233521 0.82409067 0.12764019 0.15184037 0.81762992 1.44256292\n",
      " 0.80585026 0.36612362 0.52154231 0.01349816 0.18209109 0.80951152]\n",
      "epoch 281\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014494343878092143 R2: 0.9160715179998945 time: 1703118139.4988766\n",
      "batch_idx: 1 loss: 0.000724353289230047 R2: 0.9160951835677279 time: 1703118142.4294012\n",
      "batch_idx: 2 loss: 0.00153387760865257 R2: 0.9160758285462277 time: 1703118145.1642292\n",
      "batch_idx: 3 loss: 0.0008269839704710543 R2: 0.9160100800334716 time: 1703118147.872412\n",
      "Training [94%] Loss: 0.0011336623140407215 time: 1703118147.872412\n",
      "weight: [0.61372677 0.8243335  0.12777029 0.15111847 0.81829314 1.44324116\n",
      " 0.80647809 0.36661034 0.52142813 0.01338697 0.18204638 0.80946495]\n",
      "epoch 282\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014492530300458076 R2: 0.9160778850544439 time: 1703118150.610493\n",
      "batch_idx: 1 loss: 0.0007244012683143539 R2: 0.9161015472890887 time: 1703118153.4124744\n",
      "batch_idx: 2 loss: 0.0015337449368208712 R2: 0.9160821794962987 time: 1703118156.153079\n",
      "batch_idx: 3 loss: 0.0008269049213966062 R2: 0.9160164198049345 time: 1703118158.9721751\n",
      "Training [94%] Loss: 0.0011335760391444098 time: 1703118158.9721751\n",
      "weight: [0.61512191 0.82457669 0.12790147 0.15039899 0.81894962 1.44391299\n",
      " 0.80710413 0.36709562 0.52131354 0.01327624 0.18200183 0.80941855]\n",
      "epoch 283\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014490723038371289 R2: 0.9160842026807641 time: 1703118161.7819955\n",
      "batch_idx: 1 loss: 0.0007244497195318308 R2: 0.9161078616557369 time: 1703118164.516955\n",
      "batch_idx: 2 loss: 0.0015336130720301517 R2: 0.9160884813066874 time: 1703118167.2470975\n",
      "batch_idx: 3 loss: 0.0008268266691139907 R2: 0.9160227106816038 time: 1703118170.0311275\n",
      "Training [94%] Loss: 0.0011334904411282756 time: 1703118170.0311275\n",
      "weight: [0.61652068 0.82482026 0.12803376 0.14968193 0.81959953 1.44457856\n",
      " 0.80772841 0.36757947 0.52119859 0.01316596 0.18195744 0.80937231]\n",
      "epoch 284\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014488921990836788 R2: 0.9160904718381463 time: 1703118172.777963\n",
      "batch_idx: 1 loss: 0.000724498636376872 R2: 0.9161141276214207 time: 1703118175.6101737\n",
      "batch_idx: 2 loss: 0.001533481996977955 R2: 0.9160947349109184 time: 1703118178.3331828\n",
      "batch_idx: 3 loss: 0.0008267491944165194 R2: 0.9160289535581404 time: 1703118181.1769753\n",
      "Training [95%] Loss: 0.0011334055067137563 time: 1703118181.1769753\n",
      "weight: [0.61792314 0.82506424 0.1281672  0.14896724 0.82024302 1.44523801\n",
      " 0.80835095 0.3680619  0.5210833  0.01305613 0.1819132  0.80932623]\n",
      "epoch 285\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014487127061577354 R2: 0.9160966934506686 time: 1703118183.8863285\n",
      "batch_idx: 1 loss: 0.0007245480126910822 R2: 0.916120346104672 time: 1703118186.662873\n",
      "batch_idx: 2 loss: 0.0015333516949277092 R2: 0.9161009412076535 time: 1703118189.900003\n",
      "batch_idx: 3 loss: 0.0008266724786981158 R2: 0.9160351492952212 time: 1703118193.0034873\n",
      "Training [95%] Loss: 0.0011333212231186606 time: 1703118193.0034873\n",
      "weight: [0.61932936 0.82530865 0.12830181 0.14825493 0.82088024 1.44589146\n",
      " 0.80897177 0.36854295 0.5209677  0.01294674 0.18186913 0.80928031]\n",
      "epoch 286\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001448533815898191 R2: 0.9161028684085378 time: 1703118195.9089403\n",
      "batch_idx: 1 loss: 0.000724597842620916 R2: 0.9161265179901882 time: 1703118198.7317355\n",
      "batch_idx: 2 loss: 0.001533222149697486 R2: 0.9161071010619913 time: 1703118201.4989264\n",
      "batch_idx: 3 loss: 0.000826596503921893 R2: 0.9160412987205419 time: 1703118204.222758\n",
      "Training [95%] Loss: 0.0011332375780346215 time: 1703118204.222758\n",
      "weight: [0.62073937 0.82555353 0.12843761 0.14754496 0.82151135 1.44653906\n",
      " 0.80959089 0.36902262 0.52085183 0.0128378  0.1818252  0.80923454]\n",
      "epoch 287\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001448355519609436 R2: 0.9161089975693939 time: 1703118207.125434\n",
      "batch_idx: 1 loss: 0.0007246481205732226 R2: 0.9161326441301284 time: 1703118209.9307914\n",
      "batch_idx: 2 loss: 0.0015330933456511428 R2: 0.9161132153066655 time: 1703118212.6531556\n",
      "batch_idx: 3 loss: 0.0008265212525900227 R2: 0.9160474026297344 time: 1703118215.3775673\n",
      "Training [96%] Loss: 0.001133154559605956 time: 1703118215.3775673\n",
      "weight: [0.62215324 0.82579889 0.12857465 0.14683732 0.82213648 1.44718093\n",
      " 0.81020833 0.36950095 0.52073571 0.01272928 0.18178143 0.80918894]\n",
      "epoch 288\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014481778090641635 R2: 0.9161150817594713 time: 1703118218.1876144\n",
      "batch_idx: 1 loss: 0.0007246988411685544 R2: 0.9161387253453197 time: 1703118220.9369452\n",
      "batch_idx: 2 loss: 0.0015329652676917909 R2: 0.9161192847431515 time: 1703118223.7968094\n",
      "batch_idx: 3 loss: 0.0008264467077148098 R2: 0.9160534617872415 time: 1703118226.601232\n",
      "Training [96%] Loss: 0.0011330721564098297 time: 1703118226.601232\n",
      "weight: [0.62357102 0.82604476 0.12871294 0.14613199 0.82275577 1.44781719\n",
      " 0.81082411 0.36997794 0.52061938 0.01262119 0.18173781 0.80914349]\n",
      "epoch 289\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014480006765102283 R2: 0.9161211217747273 time: 1703118229.3232741\n",
      "batch_idx: 1 loss: 0.000724749999191879 R2: 0.916144762426397 time: 1703118232.062059\n",
      "batch_idx: 2 loss: 0.0015328379012577217 R2: 0.9161253101427128 time: 1703118234.7876992\n",
      "batch_idx: 3 loss: 0.0008263728527907936 R2: 0.9160594769270685 time: 1703118237.7122886\n",
      "Training [96%] Loss: 0.0011329903574376556 time: 1703118237.7122886\n",
      "weight: [0.62499275 0.82629117 0.12885251 0.14542895 0.82336934 1.44844796\n",
      " 0.81143825 0.37045362 0.52050285 0.01251352 0.18169435 0.80909819]\n",
      "epoch 290\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014478241146816404 R2: 0.9161271183818606 time: 1703118240.4823964\n",
      "batch_idx: 1 loss: 0.0007248015895403077 R2: 0.9161507561348261 time: 1703118243.2269604\n",
      "batch_idx: 2 loss: 0.0015327112323207752 R2: 0.9161312922473426 time: 1703118246.0223932\n",
      "batch_idx: 3 loss: 0.0008262996717678394 R2: 0.9160654487535126 time: 1703118248.7493098\n",
      "Training [97%] Loss: 0.0011329091520776407 time: 1703118248.7493098\n",
      "weight: [0.62641849 0.82653813 0.12899339 0.14472819 0.82397733 1.44907335\n",
      " 0.81205076 0.370928   0.52038617 0.01240627 0.18165103 0.80905304]\n",
      "epoch 291\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014476481168137398 R2: 0.9161330723192677 time: 1703118251.504823\n",
      "batch_idx: 1 loss: 0.0007248536071676274 R2: 0.9161567072039046 time: 1703118254.3878326\n",
      "batch_idx: 2 loss: 0.0015325852473872337 R2: 0.9161372317706526 time: 1703118257.2062626\n",
      "batch_idx: 3 loss: 0.0008262271490250359 R2: 0.9160713779417765 time: 1703118259.9273245\n",
      "Training [97%] Loss: 0.0011328285300984092 time: 1703118259.9273245\n",
      "weight: [0.62784828 0.82678568 0.1291356  0.14402968 0.82457985 1.44969347\n",
      " 0.81266168 0.37140111 0.52026935 0.01229943 0.18160785 0.80900805]\n",
      "epoch 292\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014474726766628295 R2: 0.9161389842979164 time: 1703118262.7902143\n",
      "batch_idx: 1 loss: 0.0007249060470250334 R2: 0.9161626163396347 time: 1703118265.8392954\n",
      "batch_idx: 2 loss: 0.0015324599335013703 R2: 0.9161431293986751 time: 1703118268.7656806\n",
      "batch_idx: 3 loss: 0.0008261552693453595 R2: 0.9160772651385558 time: 1703118271.6332524\n",
      "Training [97%] Loss: 0.0011327484816336482 time: 1703118271.6332524\n",
      "weight: [0.62928217 0.82703382 0.12927918 0.14333342 0.82517703 1.45030843\n",
      " 0.813271   0.37187295 0.52015241 0.012193   0.18156482 0.80896321]\n",
      "epoch 293\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014472977885301957 R2: 0.9161448550021744 time: 1703118274.3537507\n",
      "batch_idx: 1 loss: 0.0007249589039977916 R2: 0.9161684842215708 time: 1703118277.0924535\n",
      "batch_idx: 2 loss: 0.0015323352782516929 R2: 0.9161489857906041 time: 1703118279.8972857\n",
      "batch_idx: 3 loss: 0.0008260840178909502 R2: 0.9160831109625193 time: 1703118282.6280837\n",
      "Training [98%] Loss: 0.0011326689971676576 time: 1703118282.6280837\n",
      "weight: [0.6307202  0.8272826  0.12942414 0.14263939 0.82576898 1.45091833\n",
      " 0.81387877 0.37234356 0.5200354  0.01208697 0.18152194 0.80891851]\n",
      "epoch 294\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014471234472910764 R2: 0.9161506850905378 time: 1703118285.371885\n",
      "batch_idx: 1 loss: 0.0007250121728372548 R2: 0.916174311503568 time: 1703118288.1856549\n",
      "batch_idx: 2 loss: 0.0015322112697800793 R2: 0.9161548015794712 time: 1703118290.9961734\n",
      "batch_idx: 3 loss: 0.0008260133801789351 R2: 0.9160889160047482 time: 1703118293.742303\n",
      "Training [98%] Loss: 0.0011325900675218364 time: 1703118293.742303\n",
      "weight: [0.63216239 0.82753202 0.12957052 0.14194757 0.82635579 1.45152327\n",
      " 0.81448498 0.37281295 0.51991832 0.01198134 0.1814792  0.80887396]\n",
      "epoch 295\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014469496484284616 R2: 0.9161564751963173 time: 1703118296.4755056\n",
      "batch_idx: 1 loss: 0.0007250658480877426 R2: 0.9161800988145016 time: 1703118299.2788808\n",
      "batch_idx: 2 loss: 0.0015320878967938858 R2: 0.9161605773727407 time: 1703118302.1336563\n",
      "batch_idx: 3 loss: 0.0008259433420577184 R2: 0.9160946808290987 time: 1703118304.8705902\n",
      "Training [98%] Loss: 0.0011325116838419521 time: 1703118304.8705902\n",
      "weight: [0.6336088  0.82778212 0.12971834 0.14125795 0.82693759 1.45212335\n",
      " 0.81508966 0.37328112 0.51980121 0.01187609 0.1814366  0.80882955]\n",
      "epoch 296\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014467763880722812 R2: 0.9161622259282594 time: 1703118307.6007147\n",
      "batch_idx: 1 loss: 0.0007251199240076937 R2: 0.91618584675888 time: 1703118310.4313173\n",
      "batch_idx: 2 loss: 0.0015319651485812917 R2: 0.9161663137528663 time: 1703118313.161532\n",
      "batch_idx: 3 loss: 0.0008258738896836272 R2: 0.9161004059725085 time: 1703118315.8922048\n",
      "Training [99%] Loss: 0.0011324338375862236 time: 1703118315.8922048\n",
      "weight: [0.63505945 0.8280329  0.12986761 0.14057051 0.82751447 1.45271864\n",
      " 0.81569283 0.37374811 0.51968408 0.01177124 0.18139414 0.80878529]\n",
      "epoch 297\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014466036630440843 R2: 0.9161679378710884 time: 1703118318.7082841\n",
      "batch_idx: 1 loss: 0.0007251743944845138 R2: 0.9161915559174499 time: 1703118321.5854247\n",
      "batch_idx: 2 loss: 0.0015318430150299397 R2: 0.9161720112777599 time: 1703118324.3257701\n",
      "batch_idx: 3 loss: 0.0008258050094978143 R2: 0.9161060919452299 time: 1703118327.0678234\n",
      "Training [99%] Loss: 0.0011323565205140882 time: 1703118327.0678234\n",
      "weight: [0.63651435 0.8282844  0.13001838 0.13988524 0.82808653 1.45330926\n",
      " 0.81629451 0.37421392 0.51956696 0.01166677 0.18135182 0.80874117]\n",
      "epoch 298\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014464314709077483 R2: 0.9161736115860262 time: 1703118329.885327\n",
      "batch_idx: 1 loss: 0.0007252292529423735 R2: 0.9161972268476862 time: 1703118332.6157696\n",
      "batch_idx: 2 loss: 0.0015317214866492179 R2: 0.9161776704812322 time: 1703118335.4564188\n",
      "batch_idx: 3 loss: 0.0008257366882034545 R2: 0.9161117392310117 time: 1703118338.2729013\n",
      "Training [99%] Loss: 0.0011322797246756987 time: 1703118338.2729013\n",
      "weight: [0.63797354 0.82853663 0.13017065 0.13920213 0.82865386 1.45389527\n",
      " 0.81689471 0.37467858 0.51944987 0.01156268 0.18130964 0.8086972 ]\n",
      "epoch 299\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001446259810026379 R2: 0.916179247611211 time: 1703118341.0139208\n",
      "batch_idx: 1 loss: 0.0007252844922423365 R2: 0.9162028600842891 time: 1703118343.740485\n",
      "batch_idx: 2 loss: 0.0015316005545963135 R2: 0.9161832918733384 time: 1703118346.4786506\n",
      "batch_idx: 3 loss: 0.0008256689127429915 R2: 0.916117348287203 time: 1703118349.3029995\n",
      "Training [100%] Loss: 0.001132203442402005 time: 1703118349.3029995\n",
      "weight: [0.63943702 0.82878962 0.13032446 0.13852116 0.82921655 1.45447676\n",
      " 0.81749345 0.3751421  0.51933284 0.01145896 0.18126759 0.80865336]\n",
      "epoch 300\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014460886796260576 R2: 0.9161848464620933 time: 1703118352.1285803\n",
      "batch_idx: 1 loss: 0.000725340104573957 R2: 0.9162084561395712 time: 1703118354.8811586\n",
      "batch_idx: 2 loss: 0.0015314802107063495 R2: 0.9161888759407099 time: 1703118357.698482\n",
      "batch_idx: 3 loss: 0.0008256016702755569 R2: 0.9161229195448376 time: 1703118360.4688632\n",
      "Training [100%] Loss: 0.0011321276662954803 time: 1703118360.4688632\n",
      "weight: [0.64090481 0.82904338 0.13047983 0.13784232 0.82977471 1.45505382\n",
      " 0.81809075 0.37560449 0.51921587 0.01135562 0.18122568 0.80860966]\n",
      "train_MSE: 0.0011382723061279314\n",
      "train_RMSE: 0.03373829139313269\n",
      "train_MAE: 0.027538388032413937\n",
      "train_MAPE: 0.060309390129189164\n",
      "train_R2: 0.9161229195448376\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "weights =[0.68756473 , 1.2864305 ,  0.5411694 , -0.01524038 , 0.5852044 ,  0.6762012,\n",
    "  0.35593897 , 0.22628789,  0.38244092,  0.35140917,  0.86482936 , 0.8531242,\n",
    "  0.09241156 , 0.6720707  , 0.38071635,  0.95416117 , 0.63409   ,  0.40179932,\n",
    "  0.7345088  , 0.6243114  , 0.3178202 , -0.2618623  , 0.18122938,  1.0447433,\n",
    "  0.48699683 , 0.7739934  , 0.38703147 , 0.48046085,  0.5525667 ,  0.52838504,\n",
    "  0.28538367 , 0.30099392,  0.74503726 , 0.67772216,  0.3839896 ,  0.417687]\n",
    "weights = npp.array(weights, requires_grad=True)\n",
    "'''\n",
    "weights = params\n",
    "loss_list=[]\n",
    "r2_list=[]\n",
    "\n",
    "n_epochs=300\n",
    "\n",
    "start_time=time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss  = []\n",
    "    total_r2  = []\n",
    "    print(f\"epoch {epoch+1}\\n-------------------------------\")\n",
    "    for it, batch_index in enumerate (chain(*[X_batches])):\n",
    "        # Update the weights by one optimizer step\n",
    "        \n",
    "        X_batch = X[batch_index]\n",
    "        Y_batch = Y[batch_index]\n",
    "        weights, _, _ = opt.step(cost, weights, X_batch, Y_batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        predictions = [QNN(weights, x) for x in X]\n",
    "        r2 = R2(Y, predictions)\n",
    "        cost_t=cost(weights,X_batch,Y_batch)\n",
    "        total_loss.append(cost_t)\n",
    "        total_r2.append(r2)\n",
    "        end_timet=time.time()\n",
    "        print(\"batch_idx:\",it,\"loss:\",cost_t,\"R2:\",r2,\"time:\",end_timet)\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    r2_list.append(sum(total_r2)/len(total_r2))\n",
    "    print('Training [{:.0f}%]'.format(100. * (epoch + 1) / n_epochs),\"Loss:\", loss_list[-1], \"time:\",end_timet)\n",
    "    print(\"weight:\",weights)\n",
    "    \n",
    "    \n",
    "predictions = [QNN(weights, x) for x in X]\n",
    "\n",
    "train_R2 = R2(Y, predictions)\n",
    "train_MSE=metrics.mean_squared_error(Y,predictions)\n",
    "train_RMSE=train_MSE**(1/2)\n",
    "train_MAE=metrics.mean_absolute_error(Y,predictions)\n",
    "train_MAPE=metrics.mean_absolute_percentage_error(Y,predictions)\n",
    "\n",
    "print(\"train_MSE:\",train_MSE)\n",
    "print(\"train_RMSE:\",train_RMSE)\n",
    "print(\"train_MAE:\",train_MAE)\n",
    "print(\"train_MAPE:\",train_MAPE)\n",
    "print(\"train_R2:\",train_R2)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "plt.title(\"MSE value against epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.plot(range(len(loss_list)), np.log(loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd9d36c3-7a70-48e7-b5ca-23249f259d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001445918079866624 R2: 0.9161904086317575 time: 1703119490.612783\n",
      "batch_idx: 1 loss: 0.0007253960813375589 R2: 0.9162140155038243 time: 1703119494.0189047\n",
      "batch_idx: 2 loss: 0.0015313604475268607 R2: 0.9161944231467917 time: 1703119497.3729036\n",
      "batch_idx: 3 loss: 0.0008255349481543526 R2: 0.9161284534085979 time: 1703119500.6765785\n",
      "Training [0%] Loss: 0.001132052389221349 time: 1703119500.6765785\n",
      "weight: [0.64237689 0.82929794 0.13063677 0.1371656  0.8303284  1.45562652\n",
      " 0.81868663 0.37606577 0.519099   0.01125264 0.1811839  0.80856609]\n",
      "epoch 2\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001445748011920272 R2: 0.9161959345912024 time: 1703119504.0136495\n",
      "batch_idx: 1 loss: 0.0007254524130163476 R2: 0.9162195386456288 time: 1703119507.3408687\n",
      "batch_idx: 2 loss: 0.0015312412583569006 R2: 0.9161999339320633 time: 1703119510.6882226\n",
      "batch_idx: 3 loss: 0.0008254687339041341 R2: 0.9161339502567939 time: 1703119514.079026\n",
      "Training [1%] Loss: 0.0011319776042994136 time: 1703119514.079026\n",
      "weight: [0.64385326 0.8295533  0.13079533 0.136491   0.83087771 1.45619494\n",
      " 0.81928109 0.37652596 0.51898225 0.01115002 0.18114225 0.80852266]\n",
      "epoch 3\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014455784780581233 R2: 0.9162014247895639 time: 1703119517.6042066\n",
      "batch_idx: 1 loss: 0.0007255090890373588 R2: 0.9162250260121155 time: 1703119520.9216838\n",
      "batch_idx: 2 loss: 0.0015311226372910726 R2: 0.9162054087141829 time: 1703119524.3069067\n",
      "batch_idx: 3 loss: 0.000825403015198565 R2: 0.9161394104412419 time: 1703119527.6172266\n",
      "Training [2%] Loss: 0.00113190330489628 time: 1703119527.6172266\n",
      "weight: [0.64533389 0.8298095  0.1309555  0.13581849 0.83142273 1.45675914\n",
      " 0.81987417 0.37698507 0.51886562 0.01104775 0.18110073 0.80847937]\n",
      "epoch 4\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001445409481745653 R2: 0.9162068796542876 time: 1703119531.0899138\n",
      "batch_idx: 1 loss: 0.0007255660976203439 R2: 0.9162304780291779 time: 1703119534.3955657\n",
      "batch_idx: 2 loss: 0.0015310045792688112 R2: 0.9162108478881 time: 1703119537.8792593\n",
      "batch_idx: 3 loss: 0.0008253377798376644 R2: 0.9161448342871179 time: 1703119541.2864525\n",
      "Training [2%] Loss: 0.0011318294846181182 time: 1703119541.2864525\n",
      "weight: [0.64681876 0.83006656 0.13111733 0.13514806 0.83196352 1.45731921\n",
      " 0.82046587 0.37744312 0.51874915 0.01094585 0.18105935 0.8084362 ]\n",
      "epoch 5\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00144524102774718 R2: 0.9162122995912508 time: 1703119544.6110775\n",
      "batch_idx: 1 loss: 0.0007256234256135558 R2: 0.9162358951016298 time: 1703119547.9386728\n",
      "batch_idx: 2 loss: 0.0015308870801293063 R2: 0.9162162518261143 time: 1703119551.2808642\n",
      "batch_idx: 3 loss: 0.0008252730157251701 R2: 0.9161502220927581 time: 1703119554.6864288\n",
      "Training [2%] Loss: 0.0011317561373038031 time: 1703119554.6864288\n",
      "weight: [0.64830783 0.83032448 0.13128082 0.13447971 0.83250017 1.4578752\n",
      " 0.82105621 0.37790012 0.51863284 0.01084429 0.18101809 0.80839317]\n",
      "epoch 6\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014450731222403217 R2: 0.9162176849848438 time: 1703119557.9528363\n",
      "batch_idx: 1 loss: 0.0007256810583153913 R2: 0.916241277613343 time: 1703119561.335563\n",
      "batch_idx: 2 loss: 0.0015307701366722528 R2: 0.916221620877906 time: 1703119564.823472\n",
      "batch_idx: 3 loss: 0.0008252087108459871 R2: 0.9161555741294383 time: 1703119568.2190557\n",
      "Training [3%] Loss: 0.0011316832570184882 time: 1703119568.2190557\n",
      "weight: [0.64980102 0.83058329 0.131446   0.13381343 0.83303275 1.45842718\n",
      " 0.82164521 0.37835609 0.51851672 0.01074307 0.18097695 0.80835027]\n",
      "epoch 7\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014449057729406278 R2: 0.9162230361980097 time: 1703119571.4466631\n",
      "batch_idx: 1 loss: 0.0007257389792809396 R2: 0.9162466259273285 time: 1703119574.8052738\n",
      "batch_idx: 2 loss: 0.001530653746724885 R2: 0.9162269553705104 time: 1703119578.2558317\n",
      "batch_idx: 3 loss: 0.0008251448532437847 R2: 0.9161608906411007 time: 1703119581.645348\n",
      "Training [4%] Loss: 0.0011316108380475592 time: 1703119581.645348\n",
      "weight: [0.65129828 0.830843   0.13161289 0.1331492  0.83356132 1.45897523\n",
      " 0.82223289 0.37881104 0.51840081 0.0106422  0.18093594 0.80830749]\n",
      "epoch 8\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014447389892371589 R2: 0.9162283535722221 time: 1703119584.9418015\n",
      "batch_idx: 1 loss: 0.0007257971701122592 R2: 0.9162519403857818 time: 1703119588.4726994\n",
      "batch_idx: 2 loss: 0.0015305379092155561 R2: 0.9162322556082655 time: 1703119591.7216113\n",
      "batch_idx: 3 loss: 0.0008250814309987608 R2: 0.9161661718440872 time: 1703119595.1274817\n",
      "Training [4%] Loss: 0.0011315388748909339 time: 1703119595.1274817\n",
      "weight: [0.65279951 0.83110363 0.13178151 0.13248701 0.83408596 1.45951939\n",
      " 0.82281925 0.37926498 0.51828511 0.01054167 0.18089506 0.80826485]\n",
      "epoch 9\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014445727823394583 R2: 0.9162336374274475 time: 1703119598.5632894\n",
      "batch_idx: 1 loss: 0.0007258556102315948 R2: 0.9162572213100949 time: 1703119601.938101\n",
      "batch_idx: 2 loss: 0.001530422624254057 R2: 0.9162375218727462 time: 1703119605.358461\n",
      "batch_idx: 3 loss: 0.0008250184322059316 R2: 0.9161714179268332 time: 1703119608.7479095\n",
      "Training [4%] Loss: 0.0011314673622577604 time: 1703119608.7479095\n",
      "weight: [0.65430461 0.8313652  0.13195188 0.13182686 0.83460673 1.46005973\n",
      " 0.82340433 0.37971794 0.51816965 0.01044147 0.1808543  0.80822233]\n",
      "epoch 10\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014444071654362326 R2: 0.9162388880620679 time: 1703119612.2637177\n",
      "batch_idx: 1 loss: 0.0007259142766364954 R2: 0.9162624690008417 time: 1703119615.6693199\n",
      "batch_idx: 2 loss: 0.0015303078932189923 R2: 0.9162427544226548 time: 1703119619.0497139\n",
      "batch_idx: 3 loss: 0.0008249558449539462 R2: 0.9161766290495968 time: 1703119622.4014838\n",
      "Training [5%] Loss: 0.0011313962950614165 time: 1703119622.4014838\n",
      "weight: [0.65581345 0.83162771 0.13212401 0.13116874 0.83512369 1.46059631\n",
      " 0.82398812 0.38016992 0.51805444 0.0103416  0.18081366 0.80817993]\n",
      "epoch 11\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014442421538662649 R2: 0.9162441057527527 time: 1703119625.997355\n",
      "batch_idx: 1 loss: 0.0007259731436361278 R2: 0.9162676837377383 time: 1703119629.3547277\n",
      "batch_idx: 2 loss: 0.001530193718852298 R2: 0.9162479534937041 time: 1703119632.6643596\n",
      "batch_idx: 3 loss: 0.0008248936573049261 R2: 0.9161818053441806 time: 1703119636.1007576\n",
      "Training [6%] Loss: 0.0011313256684149042 time: 1703119636.1007576\n",
      "weight: [0.65732587 0.8318912  0.13229793 0.13051264 0.83563691 1.46112919\n",
      " 0.82457065 0.38062093 0.5179395  0.01024205 0.18077314 0.80813766]\n",
      "epoch 12\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014440777653015899 R2: 0.9162492907543379 time: 1703119639.537337\n",
      "batch_idx: 1 loss: 0.0007260321825682016 R2: 0.9162728657795671 time: 1703119642.8339307\n",
      "batch_idx: 2 loss: 0.0015300801053608993 R2: 0.9162531192985087 time: 1703119646.1440065\n",
      "batch_idx: 3 loss: 0.00082483185727554 R2: 0.9161869469137102 time: 1703119649.6130602\n",
      "Training [6%] Loss: 0.0011312554776265577 time: 1703119649.6130602\n",
      "weight: [0.65884171 0.83215566 0.13247365 0.12985854 0.83614645 1.46165842\n",
      " 0.82515193 0.381071   0.51782484 0.01014283 0.18073273 0.8080955 ]\n",
      "epoch 13\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014439140199431206 R2: 0.9162544432996699 time: 1703119652.9695811\n",
      "batch_idx: 1 loss: 0.000726091361496193 R2: 0.9162780153641134 time: 1703119656.3452377\n",
      "batch_idx: 2 loss: 0.0015299670585254446 R2: 0.9162582520264614 time: 1703119659.670149\n",
      "batch_idx: 3 loss: 0.0008247704328198996 R2: 0.9161920538324624 time: 1703119663.2997215\n",
      "Training [6%] Loss: 0.0011311857181961645 time: 1703119663.2997215\n",
      "weight: [0.66036076 0.83242112 0.13265118 0.12920645 0.83665236 1.46218405\n",
      " 0.82573198 0.38152014 0.51771048 0.01004393 0.18069245 0.80805347]\n",
      "epoch 14\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014437509407284003 R2: 0.9162595635994333 time: 1703119666.7266212\n",
      "batch_idx: 1 loss: 0.0007261506448868499 R2: 0.9162831327080678 time: 1703119670.0753016\n",
      "batch_idx: 2 loss: 0.0015298545858158366 R2: 0.9162633518436477 time: 1703119673.4349558\n",
      "batch_idx: 3 loss: 0.0008247093718147861 R2: 0.9161971261458085 time: 1703119676.8093364\n",
      "Training [7%] Loss: 0.0011311163858114682 time: 1703119676.8093364\n",
      "weight: [0.6618828  0.83268758 0.13283054 0.12855634 0.83715471 1.46270614\n",
      " 0.82631081 0.38196835 0.51759643 0.00994534 0.18065228 0.80801156]\n",
      "epoch 15\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014435885535510726 R2: 0.9162646518419976 time: 1703119680.1969297\n",
      "batch_idx: 1 loss: 0.0007262099932685835 R2: 0.916288218006956 time: 1703119683.6030111\n",
      "batch_idx: 2 loss: 0.0015297426965129328 R2: 0.9162684188927781 time: 1703119686.9000106\n",
      "batch_idx: 3 loss: 0.000824648662047921 R2: 0.9162021638702301 time: 1703119690.3519354\n",
      "Training [8%] Loss: 0.0011310474763451274 time: 1703119690.3519354\n",
      "weight: [0.66340756 0.83295505 0.13301174 0.12790822 0.83765354 1.46322474\n",
      " 0.82688843 0.38241565 0.5174827  0.00984707 0.18061223 0.80796977]\n",
      "epoch 16\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014434268874911225 R2: 0.9162697081932633 time: 1703119693.7095172\n",
      "batch_idx: 1 loss: 0.000726269362871722 R2: 0.916293271435072 time: 1703119697.138245\n",
      "batch_idx: 2 loss: 0.001529631401835685 R2: 0.9162734532931806 time: 1703119700.4750025\n",
      "batch_idx: 3 loss: 0.000824588291210132 R2: 0.9162071669935441 time: 1703119703.846583\n",
      "Training [8%] Loss: 0.0011309789858521655 time: 1703119703.846583\n",
      "weight: [0.66493474 0.83322354 0.1331948  0.12726206 0.83814892 1.4637399\n",
      " 0.82746486 0.38286205 0.51736931 0.00974911 0.18057229 0.80792809]\n",
      "epoch 17\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014432659750545774 R2: 0.9162747327965473 time: 1703119707.3948536\n",
      "batch_idx: 1 loss: 0.0007263287052525377 R2: 0.9162982931454179 time: 1703119710.845158\n",
      "batch_idx: 2 loss: 0.001529520715072524 R2: 0.9162784551408689 time: 1703119714.2197356\n",
      "batch_idx: 3 loss: 0.0008245282468923913 R2: 0.916212135475296 time: 1703119717.6255832\n",
      "Training [8%] Loss: 0.0011309109105680077 time: 1703119717.6255832\n",
      "weight: [0.666464   0.83349307 0.13337972 0.12661787 0.83864089 1.46425167\n",
      " 0.82804012 0.38330756 0.51725627 0.00965145 0.18053247 0.80788653]\n",
      "epoch 18\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014431058524207322 R2: 0.9162797257724989 time: 1703119721.0780144\n",
      "batch_idx: 1 loss: 0.0007263879669038099 R2: 0.9163032832697219 time: 1703119724.3749533\n",
      "batch_idx: 2 loss: 0.0015294106517152375 R2: 0.916283424508691 time: 1703119727.85649\n",
      "batch_idx: 3 loss: 0.0008244685165889147 R2: 0.916217069247409 time: 1703119731.3828132\n",
      "Training [9%] Loss: 0.0011308432469071736 time: 1703119731.3828132\n",
      "weight: [0.66799498 0.83376363 0.13356651 0.12597564 0.83912951 1.46476009\n",
      " 0.82861421 0.38375221 0.51714359 0.00955409 0.18049275 0.80784508]\n",
      "epoch 19\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001442946559694242 R2: 0.9162846872190895 time: 1703119734.7929373\n",
      "batch_idx: 1 loss: 0.0007264470888557431 R2: 0.9163082419184734 time: 1703119738.5758255\n",
      "batch_idx: 2 loss: 0.0015293012295933936 R2: 0.9162883614466184 time: 1703119742.39995\n",
      "batch_idx: 3 loss: 0.0008244090877075621 R2: 0.916221968215131 time: 1703119745.8333414\n",
      "Training [10%] Loss: 0.0011307759914627351 time: 1703119745.8333414\n",
      "weight: [0.66952725 0.83403524 0.13375518 0.12533535 0.83961483 1.46526522\n",
      " 0.82918714 0.38419599 0.51703129 0.00945703 0.18045315 0.80780375]\n",
      "epoch 20\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014427881411586908 R2: 0.9162896172116749 time: 1703119749.1679454\n",
      "batch_idx: 1 loss: 0.0007265060062725702 R2: 0.9163131691810678 time: 1703119752.5597465\n",
      "batch_idx: 2 loss: 0.001529192469006312 R2: 0.9162932659821758 time: 1703119756.115207\n",
      "batch_idx: 3 loss: 0.0008243499475891608 R2: 0.9162268322583454 time: 1703119759.3853056\n",
      "Training [10%] Loss: 0.0011307091410066835 time: 1703119759.3853056\n",
      "weight: [0.67106035 0.83430789 0.13394572 0.12469699 0.84009689 1.46576709\n",
      " 0.82975894 0.38463891 0.51691936 0.00936027 0.18041366 0.80776253]\n",
      "epoch 21\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014426306455270939 R2: 0.9162945158031967 time: 1703119762.836531\n",
      "batch_idx: 1 loss: 0.0007265646480516269 R2: 0.9163180651260155 time: 1703119766.209742\n",
      "batch_idx: 2 loss: 0.001529084392849239 R2: 0.9162981381210488 time: 1703119769.6070657\n",
      "batch_idx: 3 loss: 0.000824291083537297 R2: 0.9162316612332913 time: 1703119773.0525382\n",
      "Training [10%] Loss: 0.0011306426924913144 time: 1703119773.0525382\n",
      "weight: [0.67259375 0.83458158 0.13413816 0.12406056 0.84057575 1.46626576\n",
      " 0.83032961 0.38508099 0.51680784 0.00926381 0.18037427 0.80772142]\n",
      "epoch 22\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001442474126183912 R2: 0.9162993830244861 time: 1703119776.4129553\n",
      "batch_idx: 1 loss: 0.0007266229364335573 R2: 0.9163229298012826 time: 1703119779.878367\n",
      "batch_idx: 2 loss: 0.001528977026729391 R2: 0.9163029778479339 time: 1703119783.2545042\n",
      "batch_idx: 3 loss: 0.000824232482860431 R2: 0.9162364549747852 time: 1703119786.7204015\n",
      "Training [11%] Loss: 0.0011305766430518228 time: 1703119786.7204015\n",
      "weight: [0.67412688 0.83485632 0.13433247 0.12342605 0.84105146 1.46676127\n",
      " 0.83089915 0.38552224 0.51669671 0.00916763 0.180335   0.80768043]\n",
      "epoch 23\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014423186414116505 R2: 0.9163042188847742 time: 1703119790.1423311\n",
      "batch_idx: 1 loss: 0.0007266807866344781 R2: 0.9163277632347899 time: 1703119794.0878625\n",
      "batch_idx: 2 loss: 0.0015288703990666104 R2: 0.916307785127627 time: 1703119797.6038558\n",
      "batch_idx: 3 loss: 0.0008241741329282149 R2: 0.9162412132989901 time: 1703119801.054978\n",
      "Training [12%] Loss: 0.0011305109900102384 time: 1703119801.054978\n",
      "weight: [0.67565911 0.8351321  0.13452866 0.12279343 0.84152406 1.46725367\n",
      " 0.83146759 0.38596267 0.51658601 0.00907174 0.18029583 0.80763954]\n",
      "epoch 24\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014421642545937804 R2: 0.9163090233723764 time: 1703119804.5555341\n",
      "batch_idx: 1 loss: 0.0007267381065131435 R2: 0.9163325654350556 time: 1703119807.8970797\n",
      "batch_idx: 2 loss: 0.0015287645411725809 R2: 0.91631255990641 time: 1703119811.272036\n",
      "batch_idx: 3 loss: 0.000824116021243892 R2: 0.9162459360068087 time: 1703119814.6769052\n",
      "Training [12%] Loss: 0.0011304457308808492 time: 1703119814.6769052\n",
      "weight: [0.67718976 0.83540891 0.13472672 0.12216271 0.8419936  1.46774299\n",
      " 0.83203493 0.38640227 0.51647572 0.00897614 0.18025677 0.80759876]\n",
      "epoch 25\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014420110343843701 R2: 0.916313796455649 time: 1703119818.1606135\n",
      "batch_idx: 1 loss: 0.0007267947962888066 R2: 0.9163373363920565 time: 1703119821.6450849\n",
      "batch_idx: 2 loss: 0.0015286594873013524 R2: 0.9163173021137961 time: 1703119825.1120322\n",
      "batch_idx: 3 loss: 0.0008240581355346633 R2: 0.9162506228879563 time: 1703119828.5813782\n",
      "Training [12%] Loss: 0.001130380863377298 time: 1703119828.5813782\n",
      "weight: [0.67871806 0.83568674 0.13492664 0.12153386 0.84246013 1.46822929\n",
      " 0.83260117 0.38684107 0.51636587 0.00888082 0.18021781 0.80755809]\n",
      "epoch 26\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014418590548328262 R2: 0.9163185380842107 time: 1703119831.9869196\n",
      "batch_idx: 1 loss: 0.0007268507483279378 R2: 0.9163420760783222 time: 1703119835.3394608\n",
      "batch_idx: 2 loss: 0.001528555274663168 R2: 0.9163220116646171 time: 1703119839.0362308\n",
      "batch_idx: 3 loss: 0.0008240004638615806 R2: 0.9162552737257762 time: 1703119842.5284293\n",
      "Training [13%] Loss: 0.001130316385421378 time: 1703119842.5284293\n",
      "weight: [0.68024321 0.83596559 0.1351284  0.12090688 0.8429237  1.46871261\n",
      " 0.83316634 0.38727906 0.51625646 0.00878578 0.18017896 0.80751753]\n",
      "epoch 27\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001441708395450993 R2: 0.9163232481904642 time: 1703119845.909515\n",
      "batch_idx: 1 loss: 0.0007269058470207555 R2: 0.9163467844502643 time: 1703119849.4381726\n",
      "batch_idx: 2 loss: 0.0015284519433924721 R2: 0.9163266884615442 time: 1703119852.8488948\n",
      "batch_idx: 3 loss: 0.0008239429947502411 R2: 0.9162598883028469 time: 1703119856.1828992\n",
      "Training [14%] Loss: 0.0011302522951536153 time: 1703119856.1828992\n",
      "weight: [0.68176433 0.83624543 0.13533199 0.12028175 0.84338435 1.46919298\n",
      " 0.83373042 0.38771626 0.5161475  0.00869102 0.18014021 0.80747707]\n",
      "epoch 28\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014415591412079891 R2: 0.9163279266915071 time: 1703119859.4960897\n",
      "batch_idx: 1 loss: 0.0007269599687708597 R2: 0.9163514614498297 time: 1703119862.906541\n",
      "batch_idx: 2 loss: 0.001528349536460491 R2: 0.9163313323980505 time: 1703119866.2903626\n",
      "batch_idx: 3 loss: 0.0008238857173429139 R2: 0.9162644664073472 time: 1703119869.8204143\n",
      "Training [14%] Loss: 0.0011301885909455634 time: 1703119869.8204143\n",
      "weight: [0.68328046 0.83652625 0.13553738 0.11965846 0.84384212 1.46967047\n",
      " 0.83429342 0.38815266 0.51603899 0.00859654 0.18010157 0.80743673]\n",
      "epoch 29\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014414113824369966 R2: 0.9163325734914013 time: 1703119873.210137\n",
      "batch_idx: 1 loss: 0.0007270129821233407 R2: 0.9163561070064313 time: 1703119876.5378273\n",
      "batch_idx: 2 loss: 0.0015282480995222221 R2: 0.9163359433617929 time: 1703119879.9276328\n",
      "batch_idx: 3 loss: 0.0008238286215718043 R2: 0.9162690078402266 time: 1703119883.3648818\n",
      "Training [14%] Loss: 0.0011301252714135909 time: 1703119883.3648818\n",
      "weight: [0.68479058 0.83680802 0.13574455 0.11903698 0.84429707 1.47014511\n",
      " 0.83485536 0.38858827 0.51593094 0.00850233 0.18006303 0.80739648]\n",
      "epoch 30\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014412652146373244 R2: 0.9163371884838455 time: 1703119886.8320305\n",
      "batch_idx: 1 loss: 0.0007270647480581469 R2: 0.9163607210392349 time: 1703119890.188754\n",
      "batch_idx: 2 loss: 0.0015281476806876847 R2: 0.9163405212384902 time: 1703119893.560681\n",
      "batch_idx: 3 loss: 0.0008237716983521659 R2: 0.9162735124230889 time: 1703119897.0795877\n",
      "Training [15%] Loss: 0.0011300623354338305 time: 1703119897.0795877\n",
      "weight: [0.68629363 0.83709072 0.13595346 0.11841731 0.84474924 1.47061694\n",
      " 0.83541623 0.3890231  0.51582336 0.0084084  0.18002459 0.80735635]\n",
      "epoch 31\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014411207381546183 R2: 0.9163417715552941 time: 1703119900.4394007\n",
      "batch_idx: 1 loss: 0.000727115120475925 R2: 0.9163653034597761 time: 1703119903.937561\n",
      "batch_idx: 2 loss: 0.0015280483302080382 R2: 0.9163450659162196 time: 1703119907.3137991\n",
      "batch_idx: 3 loss: 0.0008237149397922543 R2: 0.9162779800067163 time: 1703119910.8920946\n",
      "Training [16%] Loss: 0.001129999782157709 time: 1703119910.8920946\n",
      "weight: [0.68778846 0.83737431 0.13616408 0.11779942 0.84519869 1.47108601\n",
      " 0.83597604 0.38945714 0.51571625 0.00831473 0.17998626 0.80731631]\n",
      "epoch 32\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014409780577224998 R2: 0.9163463225884622 time: 1703119914.3577926\n",
      "batch_idx: 1 loss: 0.0007271639469023882 R2: 0.9163698541749394 time: 1703119917.809618\n",
      "batch_idx: 2 loss: 0.0015279501000683934 R2: 0.9163495772901292 time: 1703119921.220889\n",
      "batch_idx: 3 loss: 0.0008236583394156543 R2: 0.9162824104800646 time: 1703119924.605539\n",
      "Training [16%] Loss: 0.001129937611027234 time: 1703119924.605539\n",
      "weight: [0.68927387 0.83765876 0.13637636 0.11718329 0.84564545 1.47155237\n",
      " 0.83653479 0.38989039 0.51560963 0.00822134 0.17994803 0.80727639]\n",
      "epoch 33\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014408372818504743 R2: 0.9163508414662769 time: 1703119927.9787962\n",
      "batch_idx: 1 loss: 0.0007272110694346778 R2: 0.9163743730902578 time: 1703119931.4511924\n",
      "batch_idx: 2 loss: 0.0015278530434813847 R2: 0.9163540552674748 time: 1703119934.9769025\n",
      "batch_idx: 3 loss: 0.0008236018923892053 R2: 0.9162868037795132 time: 1703119938.35293\n",
      "Training [16%] Loss: 0.0011298758217889355 time: 1703119938.35293\n",
      "weight: [0.69074861 0.83794403 0.13659026 0.11656891 0.84608957 1.47201606\n",
      " 0.83709247 0.39032287 0.51550348 0.00812822 0.1799099  0.80723656]\n",
      "epoch 34\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014406985220456797 R2: 0.9163553280761493 time: 1703119941.742402\n",
      "batch_idx: 1 loss: 0.0007272563259481349 R2: 0.9163788601135406 time: 1703119945.2247396\n",
      "batch_idx: 2 loss: 0.0015277572142790435 R2: 0.9163584997729245 time: 1703119948.6694276\n",
      "batch_idx: 3 loss: 0.0008235455957477939 R2: 0.9162911598981209 time: 1703119952.004665\n",
      "Training [17%] Loss: 0.001129814414505163 time: 1703119952.004665\n",
      "weight: [0.6922114  0.83823008 0.13680572 0.11595626 0.84653111 1.47247713\n",
      " 0.83764908 0.39075455 0.51539783 0.00803537 0.17987187 0.80719684]\n",
      "epoch 35\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001440561891859961 R2: 0.9163597823145816 time: 1703119955.253886\n",
      "batch_idx: 1 loss: 0.0007272995515745612 R2: 0.9163833151587669 time: 1703119958.6078255\n",
      "batch_idx: 2 loss: 0.00152766266620453 R2: 0.9163629107539736 time: 1703119962.0962708\n",
      "batch_idx: 3 loss: 0.0008234894486049811 R2: 0.9162954788945307 time: 1703119965.4946456\n",
      "Training [18%] Loss: 0.0011297533895610085 time: 1703119965.4946456\n",
      "weight: [0.69366092 0.83851686 0.13702268 0.1153453  0.84697011 1.47293562\n",
      " 0.83820463 0.39118546 0.51529267 0.00794278 0.17983394 0.80715723]\n",
      "epoch 36\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014404275057602104 R2: 0.9163642040919828 time: 1703119968.9379473\n",
      "batch_idx: 1 loss: 0.0007273405804529222 R2: 0.9163877381501694 time: 1703119972.2802932\n",
      "batch_idx: 2 loss: 0.001527569452110972 R2: 0.9163672881863313 time: 1703119975.826684\n",
      "batch_idx: 3 loss: 0.0008234334523365113 R2: 0.9162997609011556 time: 1703119979.1683354\n",
      "Training [18%] Loss: 0.001129692747665154 time: 1703119979.1683354\n",
      "weight: [0.69509581 0.83880431 0.13724107 0.11473603 0.84740661 1.47339158\n",
      " 0.83875911 0.39161557 0.515188   0.00785047 0.17979612 0.80711772]\n",
      "epoch 37\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014402954778266715 R2: 0.9163685933375676 time: 1703119982.5372975\n",
      "batch_idx: 1 loss: 0.0007273792477410353 R2: 0.9163921290264773 time: 1703119986.123868\n",
      "batch_idx: 2 loss: 0.0015274776230805843 R2: 0.9163716320790971 time: 1703119989.6363897\n",
      "batch_idx: 3 loss: 0.0008233776107222703 R2: 0.9163040061312046 time: 1703119993.1510346\n",
      "Training [18%] Loss: 0.0011296324898426404 time: 1703119993.1510346\n",
      "weight: [0.69651474 0.83909239 0.13746084 0.11412841 0.84784067 1.47384505\n",
      " 0.83931252 0.3920449  0.51508385 0.00775842 0.17975839 0.80707831]\n",
      "epoch 38\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014401659202935597 R2: 0.9163729500042497 time: 1703119996.7609708\n",
      "batch_idx: 1 loss: 0.0007274153918616794 R2: 0.916396487745159 time: 1703120000.3082993\n",
      "batch_idx: 2 loss: 0.0015273872274841178 R2: 0.9163759424795129 time: 1703120003.7031612\n",
      "batch_idx: 3 loss: 0.0008233219300315317 R2: 0.916308214884116 time: 1703120007.1909268\n",
      "Training [19%] Loss: 0.0011295726174177221 time: 1703120007.1909268\n",
      "weight: [0.69791637 0.83938102 0.13768189 0.11352243 0.84827233 1.47429608\n",
      " 0.83986485 0.39247344 0.51498021 0.00766664 0.17972076 0.807039  ]\n",
      "epoch 39\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014400389419560596 R2: 0.9163772740732996 time: 1703120010.5693867\n",
      "batch_idx: 1 loss: 0.0007274488569403981 R2: 0.9164008142865608 time: 1703120014.045808\n",
      "batch_idx: 2 loss: 0.001527298310007324 R2: 0.9163802194770992 time: 1703120017.3977892\n",
      "batch_idx: 3 loss: 0.0008232664190367976 R2: 0.9163123875490179 time: 1703120020.7857332\n",
      "Training [20%] Loss: 0.0011295131319851448 time: 1703120020.7857332\n",
      "weight: [0.69929939 0.83967015 0.13790415 0.11291806 0.84870163 1.47474471\n",
      " 0.84041611 0.39290118 0.51487708 0.00757513 0.17968323 0.80699979]\n",
      "epoch 40\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014399146464789381 R2: 0.9163815655586994 time: 1703120024.2389739\n",
      "batch_idx: 1 loss: 0.0007274794953750397 R2: 0.9164051086578556 time: 1703120027.5852818\n",
      "batch_idx: 2 loss: 0.001527210910677338 R2: 0.9163844632069541 time: 1703120030.9385188\n",
      "batch_idx: 3 loss: 0.0008232110889431814 R2: 0.9163165246057916 time: 1703120034.3760102\n",
      "Training [20%] Loss: 0.0011294540353686243 time: 1703120034.3760102\n",
      "weight: [0.70066254 0.83995972 0.13812753 0.11231528 0.84912863 1.47519099\n",
      " 0.84096629 0.39332814 0.51477448 0.00748389 0.1796458  0.80696068]\n",
      "epoch 41\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014397931306523019 R2: 0.9163858245108922 time: 1703120037.8593879\n",
      "batch_idx: 1 loss: 0.0007275071704613844 R2: 0.9164093708966009 time: 1703120041.2178679\n",
      "batch_idx: 2 loss: 0.001527125063926518 R2: 0.9163886738520274 time: 1703120044.5622618\n",
      "batch_idx: 3 loss: 0.000823155953223767 R2: 0.9163206266235104 time: 1703120047.998208\n",
      "Training [20%] Loss: 0.0011293953295659928 time: 1703120047.998208\n",
      "weight: [0.70200463 0.84024965 0.13835194 0.11171407 0.84955335 1.47563495\n",
      " 0.84151538 0.3937543  0.51467242 0.00739292 0.17960847 0.80692167]\n",
      "epoch 42\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014396744826497784 R2: 0.9163900510198978 time: 1703120051.4412534\n",
      "batch_idx: 1 loss: 0.0007275317589851219 R2: 0.9164136010737847 time: 1703120054.7542305\n",
      "batch_idx: 2 loss: 0.0015270407977341681 R2: 0.9163928516442091 time: 1703120058.181445\n",
      "batch_idx: 3 loss: 0.00082310102735608 R2: 0.9163246942560479 time: 1703120061.6816397\n",
      "Training [21%] Loss: 0.001129337016681287 time: 1703120061.6816397\n",
      "weight: [0.70332455 0.84053987 0.1385773  0.11111441 0.84997586 1.47607664\n",
      " 0.84206339 0.39417967 0.51457091 0.00730222 0.17957123 0.80688276]\n",
      "epoch 43\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014395587803513153 R2: 0.9163942452175368 time: 1703120065.2336547\n",
      "batch_idx: 1 loss: 0.0007275531536816984 R2: 0.9164177992962742 time: 1703120068.7039616\n",
      "batch_idx: 2 loss: 0.0015269581328862963 R2: 0.9163969968641428 time: 1703120072.0219417\n",
      "batch_idx: 3 loss: 0.0008230463284610971 R2: 0.9163287282349428 time: 1703120075.679151\n",
      "Training [22%] Loss: 0.0011292790988451018 time: 1703120075.679151\n",
      "weight: [0.70462129 0.8408303  0.13880349 0.11051628 0.85039617 1.47651609\n",
      " 0.84261032 0.39460425 0.51446996 0.00721178 0.17953408 0.80684394]\n",
      "epoch 44\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001439446089796893 R2: 0.9163984072787331 time: 1703120079.0294936\n",
      "batch_idx: 1 loss: 0.000727571265461346 R2: 0.9164219657084945 time: 1703120082.4595296\n",
      "batch_idx: 2 loss: 0.00152687708239068 R2: 0.9164011098397206 time: 1703120085.8004599\n",
      "batch_idx: 3 loss: 0.0008229918748532006 R2: 0.9163327293595801 time: 1703120089.2065172\n",
      "Training [22%] Loss: 0.0011292215781255298 time: 1703120089.2065172\n",
      "weight: [0.70589397 0.84112089 0.13903043 0.10991967 0.85081433 1.47695334\n",
      " 0.84315617 0.39502805 0.51436958 0.00712162 0.17949702 0.80680522]\n",
      "epoch 45\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014393364638369307 R2: 0.9164025374217741 time: 1703120092.6276224\n",
      "batch_idx: 1 loss: 0.0007275860253004595 R2: 0.9164261004933026 time: 1703120095.9592361\n",
      "batch_idx: 2 loss: 0.0015267976510777853 R2: 0.9164051909432814 time: 1703120099.2497497\n",
      "batch_idx: 3 loss: 0.0008229376855170281 R2: 0.9163366984851476 time: 1703120102.7963817\n",
      "Training [22%] Loss: 0.0011291644564330509 time: 1703120102.7963817\n",
      "weight: [0.70714184 0.84141155 0.13925802 0.10932455 0.85123037 1.47738841\n",
      " 0.84370095 0.39545107 0.5142698  0.00703173 0.17946005 0.80676659]\n",
      "epoch 46\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014392299410403207 R2: 0.9164066359075427 time: 1703120106.1587112\n",
      "batch_idx: 1 loss: 0.0007275973857108435 R2: 0.9164302038719775 time: 1703120109.434198\n",
      "batch_idx: 2 loss: 0.0015267198354091162 R2: 0.9164092405876415 time: 1703120112.9180467\n",
      "batch_idx: 3 loss: 0.000822883779533722 R2: 0.9163406365087783 time: 1703120116.3733404\n",
      "Training [23%] Loss: 0.0011291077354235006 time: 1703120116.3733404\n",
      "weight: [0.7083643  0.84170222 0.13948615 0.10873093 0.85164433 1.47782134\n",
      " 0.84424465 0.39587333 0.51417063 0.0069421  0.17942318 0.80672805]\n",
      "epoch 47\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001439126544911041 R2: 0.9164107030377217 time: 1703120119.7920341\n",
      "batch_idx: 1 loss: 0.0007276053217164618 R2: 0.9164342761033598 time: 1703120123.182278\n",
      "batch_idx: 2 loss: 0.001526643623502868 R2: 0.9164132592211078 time: 1703120126.664158\n",
      "batch_idx: 3 loss: 0.0008228301754846717 R2: 0.9163445443545525 time: 1703120130.0204055\n",
      "Training [24%] Loss: 0.0011290514164037607 time: 1703120130.0204055\n",
      "weight: [0.70956091 0.84199281 0.13971472 0.10813879 0.85205622 1.47825216\n",
      " 0.8447873  0.39629483 0.51407209 0.00685274 0.17938638 0.80668959]\n",
      "epoch 48\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014390262834503996 R2: 0.9164147391520826 time: 1703120133.4617956\n",
      "batch_idx: 1 loss: 0.0007276098312911241 R2: 0.9164383174821322 time: 1703120136.8981683\n",
      "batch_idx: 2 loss: 0.0015265689953744032 R2: 0.9164172473217336 time: 1703120140.334999\n",
      "batch_idx: 3 loss: 0.0008227768908638984 R2: 0.9163484229580391 time: 1703120143.7241461\n",
      "Training [24%] Loss: 0.0011289955002449562 time: 1703120143.7241461\n",
      "weight: [0.71073137 0.84228327 0.13994363 0.10754812 0.85246606 1.47868087\n",
      " 0.84532891 0.39671559 0.51397421 0.00676365 0.17934967 0.80665122]\n",
      "epoch 49\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001438929149084733 R2: 0.916418744624964 time: 1703120147.2382946\n",
      "batch_idx: 1 loss: 0.0007276109352380525 R2: 0.9164423283363433 time: 1703120150.504267\n",
      "batch_idx: 2 loss: 0.0015264959233766977 R2: 0.9164212053910743 time: 1703120153.810337\n",
      "batch_idx: 3 loss: 0.000822723941530794 R2: 0.9163522732511129 time: 1703120157.2677023\n",
      "Training [24%] Loss: 0.0011289399873075693 time: 1703120157.2677023\n",
      "weight: [0.71187556 0.84257353 0.14017279 0.10695893 0.85287389 1.47910751\n",
      " 0.84586948 0.39713563 0.51387701 0.00667482 0.17931303 0.80661293]\n",
      "epoch 50\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014388351189593702 R2: 0.916422719861108 time: 1703120160.6877847\n",
      "batch_idx: 1 loss: 0.0007276086765220552 R2: 0.9164463090242803 time: 1703120163.9668744\n",
      "batch_idx: 2 loss: 0.001526424372815113 R2: 0.9164251339477023 time: 1703120167.34319\n",
      "batch_idx: 3 loss: 0.0008226713412324736 R2: 0.9163560961476808 time: 1703120170.8750978\n",
      "Training [25%] Loss: 0.001128884877382253 time: 1703120170.8750978\n",
      "weight: [0.71299353 0.84286351 0.1404021  0.10637121 0.85327971 1.47953209\n",
      " 0.84640904 0.39755497 0.51378052 0.00658625 0.17927648 0.80657472]\n",
      "epoch 51\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014387441555809932 R2: 0.9164266652910321 time: 1703120174.2532895\n",
      "batch_idx: 1 loss: 0.0007276031190924729 R2: 0.9164502599308323 time: 1703120177.6065922\n",
      "batch_idx: 2 loss: 0.0015263543027026626 R2: 0.9164290335208218 time: 1703120181.119619\n",
      "batch_idx: 3 loss: 0.000822619101219817 R2: 0.9163598925309578 time: 1703120184.5427601\n",
      "Training [26%] Loss: 0.0011288301696489864 time: 1703120184.5427601\n",
      "weight: [0.71408544 0.84315317 0.14063146 0.10578498 0.85368353 1.4799546\n",
      " 0.84694761 0.39797363 0.51368477 0.00649794 0.17923999 0.80653659]\n",
      "epoch 52\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014386562077731287 R2: 0.9164305813661416 time: 1703120188.071409\n",
      "batch_idx: 1 loss: 0.0007275943462601276 R2: 0.9164541814634785 time: 1703120191.5857937\n",
      "batch_idx: 2 loss: 0.0015262856666167998 R2: 0.9164329046441677 time: 1703120194.9287896\n",
      "batch_idx: 3 loss: 0.0008225672299741601 R2: 0.9163636632427009 time: 1703120198.3887336\n",
      "Training [26%] Loss: 0.001128775862656054 time: 1703120198.3887336\n",
      "weight: [0.71515163 0.84344245 0.14086079 0.10520023 0.85408536 1.48037508\n",
      " 0.84748521 0.39839164 0.51358979 0.00640988 0.17920358 0.80649853]\n",
      "epoch 53\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014385712118956755 R2: 0.9164344685537504 time: 1703120201.7236154\n",
      "batch_idx: 1 loss: 0.0007275824587096668 R2: 0.9164580740480803 time: 1703120205.067479\n",
      "batch_idx: 2 loss: 0.001526218413617332 R2: 0.91643674785044 time: 1703120208.6136665\n",
      "batch_idx: 3 loss: 0.0008225157330528926 R2: 0.9163674090747176 time: 1703120212.0020874\n",
      "Training [26%] Loss: 0.0011287219543188918 time: 1703120212.0020874\n",
      "weight: [0.71619255 0.84373128 0.14109    0.10461699 0.85448521 1.48079351\n",
      " 0.84802187 0.39880903 0.51349561 0.00632207 0.17916724 0.80646054]\n",
      "epoch 54\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014384890932696147 R2: 0.9164383273322014 time: 1703120215.502787\n",
      "batch_idx: 1 loss: 0.0007275675722410635 R2: 0.9164619381246327 time: 1703120218.938497\n",
      "batch_idx: 2 loss: 0.001526152489186557 R2: 0.9164405636664126 time: 1703120222.4117868\n",
      "batch_idx: 3 loss: 0.0008224646130537141 R2: 0.9163711307627643 time: 1703120225.7801583\n",
      "Training [27%] Loss: 0.0011286684419377373 time: 1703120225.7801583\n",
      "weight: [0.71720876 0.84401963 0.14131901 0.10403525 0.85488308 1.48120989\n",
      " 0.84855761 0.39922581 0.51340226 0.0062345  0.17913096 0.80642261]\n",
      "epoch 55\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014384097677427484 R2: 0.9164421581862239 time: 1703120229.146272\n",
      "batch_idx: 1 loss: 0.0007275498153385217 R2: 0.9164657741430868 time: 1703120232.5611978\n",
      "batch_idx: 2 loss: 0.001526087836157023 R2: 0.9164443526088191 time: 1703120235.9387848\n",
      "batch_idx: 3 loss: 0.0008224138696891197 R2: 0.9163748289828344 time: 1703120239.3254035\n",
      "Training [28%] Loss: 0.001128615322231853 time: 1703120239.3254035\n",
      "weight: [0.71820095 0.84430745 0.14154774 0.10345503 0.85527897 1.48162424\n",
      " 0.84909247 0.39964204 0.51330977 0.00614717 0.17909475 0.80638476]\n",
      "epoch 56\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014383331433320428 R2: 0.9164459616026559 time: 1703120242.7612817\n",
      "batch_idx: 1 loss: 0.0007275293266631914 R2: 0.9164695825594105 time: 1703120246.1507223\n",
      "batch_idx: 2 loss: 0.0015260243955979413 R2: 0.9164481151810489 time: 1703120249.5252507\n",
      "batch_idx: 3 loss: 0.0008223634999564583 R2: 0.9163785043496467 time: 1703120252.9146187\n",
      "Training [28%] Loss: 0.0011285625913874085 time: 1703120252.9146187\n",
      "weight: [0.71916984 0.84459469 0.14177612 0.10287636 0.85567287 1.48203654\n",
      " 0.84962648 0.40005773 0.51321818 0.00606007 0.17905859 0.80634696]\n",
      "epoch 57\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014382591218814447 R2: 0.9164497380666032 time: 1703120256.522405\n",
      "batch_idx: 1 loss: 0.0007275062525585371 R2: 0.9164733638319355 time: 1703120259.91301\n",
      "batch_idx: 2 loss: 0.0015259621076381877 R2: 0.9164518518706697 time: 1703120263.4173872\n",
      "batch_idx: 3 loss: 0.0008223134983843655 R2: 0.9163821574171035 time: 1703120266.8490062\n",
      "Training [28%] Loss: 0.0011285102451156338 time: 1703120266.8490062\n",
      "weight: [0.72011626 0.84488132 0.14200408 0.10229924 0.85606479 1.48244679\n",
      " 0.85015966 0.40047292 0.51312751 0.00597319 0.1790225  0.80630923]\n",
      "epoch 58\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014381876006810633 R2: 0.916453488058124 time: 1703120270.367581\n",
      "batch_idx: 1 loss: 0.0007274807446453463 R2: 0.9164771184180867 time: 1703120273.812916\n",
      "batch_idx: 2 loss: 0.0015259009122103064 R2: 0.9164555631476944 time: 1703120277.204079\n",
      "batch_idx: 3 loss: 0.0008222638573343747 R2: 0.9163857886803864 time: 1703120280.6894171\n",
      "Training [29%] Loss: 0.0011284582787177728 time: 1703120280.6894171\n",
      "weight: [0.72104106 0.84516731 0.14223156 0.1017237  0.85645471 1.48285499\n",
      " 0.85069206 0.40088765 0.51303779 0.00588653 0.17898646 0.80627156]\n",
      "epoch 59\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014381184740022207 R2: 0.916457212049424 time: 1703120284.14259\n",
      "batch_idx: 1 loss: 0.0007274529575691097 R2: 0.9164808467715361 time: 1703120287.6423867\n",
      "batch_idx: 2 loss: 0.001525840749706037 R2: 0.9164592494635488 time: 1703120291.0335526\n",
      "batch_idx: 3 loss: 0.0008222145673363213 R2: 0.916389398579341 time: 1703120294.3582687\n",
      "Training [30%] Loss: 0.0011284066871534223 time: 1703120294.3582687\n",
      "weight: [0.72194513 0.84545262 0.1424585  0.10114976 0.85684264 1.48326113\n",
      " 0.85122371 0.40130195 0.51294905 0.00580009 0.17895048 0.80623394]\n",
      "epoch 60\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014380516345133443 R2: 0.9164609105026014 time: 1703120297.742145\n",
      "batch_idx: 1 loss: 0.0007274230469468833 R2: 0.9164845493397854 time: 1703120301.0175314\n",
      "batch_idx: 2 loss: 0.0015257815615392785 R2: 0.9164629112506175 time: 1703120304.5436525\n",
      "batch_idx: 3 loss: 0.0008221656174379009 R2: 0.9163929875027886 time: 1703120308.016043\n",
      "Training [30%] Loss: 0.0011283554651093518 time: 1703120308.016043\n",
      "weight: [0.72282939 0.84573722 0.14268484 0.10057743 0.85722856 1.4836652\n",
      " 0.85175464 0.40171584 0.51286132 0.00571384 0.17891454 0.80619637]\n",
      "epoch 61\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014379869745516384 R2: 0.9164645838678698 time: 1703120311.323043\n",
      "batch_idx: 1 loss: 0.0007273911675455135 R2: 0.9164882265621811 time: 1703120314.7912238\n",
      "batch_idx: 2 loss: 0.0015257232906162896 R2: 0.9164665489222855 time: 1703120318.2431185\n",
      "batch_idx: 3 loss: 0.0008221169955513164 R2: 0.9163965557934247 time: 1703120321.5381906\n",
      "Training [30%] Loss: 0.0011283046070661893 time: 1703120321.5381906\n",
      "weight: [0.72369474 0.84602109 0.14291053 0.10000673 0.85761247 1.4840672\n",
      " 0.85228488 0.40212937 0.51277463 0.0056278  0.17887866 0.80615886]\n",
      "epoch 62\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014379243872355216 R2: 0.9164682325822943 time: 1703120324.9125953\n",
      "batch_idx: 1 loss: 0.0007273574717087491 R2: 0.9164918788683553 time: 1703120328.36465\n",
      "batch_idx: 2 loss: 0.0015256658817163781 R2: 0.9164701628733727 time: 1703120331.7858257\n",
      "batch_idx: 3 loss: 0.0008220686887837047 R2: 0.9164001037530344 time: 1703120335.1408205\n",
      "Training [31%] Loss: 0.0011282541073610883 time: 1703120335.1408205\n",
      "weight: [0.72454209 0.84630421 0.14313554 0.09943768 0.85799437 1.48446711\n",
      " 0.85281447 0.40254257 0.51268898 0.00554194 0.17884283 0.8061214 ]\n",
      "epoch 63\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014378637674115347 R2: 0.9164718570689072 time: 1703120338.6601577\n",
      "batch_idx: 1 loss: 0.0007273221080384204 R2: 0.9164955066770378 time: 1703120342.0200338\n",
      "batch_idx: 2 loss: 0.001525609281788492 R2: 0.9164737534808488 time: 1703120345.3468878\n",
      "batch_idx: 3 loss: 0.0008220206837413249 R2: 0.9164036316477631 time: 1703120348.6559417\n",
      "Training [32%] Loss: 0.001128203960244943 time: 1703120348.6559417\n",
      "weight: [0.72537235 0.84658656 0.1433598  0.0988703  0.85837424 1.48486494\n",
      " 0.85334345 0.40295547 0.51260441 0.00545627 0.17880704 0.80608399]\n",
      "epoch 64\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014378050124368453 R2: 0.9164754577362262 time: 1703120352.154701\n",
      "batch_idx: 1 loss: 0.0007272852203244046 R2: 0.9164991103952419 time: 1703120355.6238017\n",
      "batch_idx: 2 loss: 0.001525553440170807 R2: 0.9164773211047365 time: 1703120359.0101447\n",
      "batch_idx: 3 loss: 0.0008219729668011444 R2: 0.9164071397132197 time: 1703120362.4508457\n",
      "Training [32%] Loss: 0.0011281541599333002 time: 1703120362.4508457\n",
      "weight: [0.72618639 0.84686813 0.1435833  0.09830461 0.85875208 1.48526068\n",
      " 0.85387183 0.40336809 0.51252093 0.00537078 0.1787713  0.80604662]\n",
      "epoch 65\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001437748022804101 R2: 0.9164790349780615 time: 1703120365.7920554\n",
      "batch_idx: 1 loss: 0.0007272469467102314 R2: 0.9165026904177169 time: 1703120369.0874565\n",
      "batch_idx: 2 loss: 0.0015254983087412879 R2: 0.9164808660891687 time: 1703120372.5569313\n",
      "batch_idx: 3 loss: 0.000821925524346249 R2: 0.916410628159326 time: 1703120375.8055172\n",
      "Training [32%] Loss: 0.0011281047006504673 time: 1703120375.8055172\n",
      "weight: [0.72698505 0.84714889 0.14380598 0.09774063 0.85912789 1.48565432\n",
      " 0.85439966 0.40378047 0.51243856 0.00528545 0.1787356  0.8060093 ]\n",
      "epoch 66\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014376927026202649 R2: 0.9164825891735878 time: 1703120379.1937149\n",
      "batch_idx: 1 loss: 0.0007272074190752528 R2: 0.9165062471267003 time: 1703120382.5372615\n",
      "batch_idx: 2 loss: 0.001525443842007835 R2: 0.9164843887634838 time: 1703120385.9471483\n",
      "batch_idx: 3 loss: 0.0008218783429641737 R2: 0.9164140971747596 time: 1703120389.2482939\n",
      "Training [33%] Loss: 0.0011280555766668816 time: 1703120389.2482939\n",
      "weight: [0.72776914 0.84742884 0.14402783 0.09717836 0.85950166 1.48604585\n",
      " 0.85492696 0.40419263 0.5123573  0.00520029 0.17869994 0.80597202]\n",
      "epoch 67\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014376389599532 R2: 0.9164861206876098 time: 1703120392.6740777\n",
      "batch_idx: 1 loss: 0.0007271667626106541 R2: 0.9165097808918482 time: 1703120396.0807242\n",
      "batch_idx: 2 loss: 0.001525389997146661 R2: 0.9164878894433587 time: 1703120399.5481849\n",
      "batch_idx: 3 loss: 0.0008218314096087751 R2: 0.9164175469309723 time: 1703120402.9736502\n",
      "Training [34%] Loss: 0.0011280067823298224 time: 1703120402.9736502\n",
      "weight: [0.72853944 0.84770796 0.1442488  0.09661782 0.8598734  1.48643529\n",
      " 0.85545377 0.4046046  0.51227717 0.00511529 0.17866433 0.80593479]\n",
      "epoch 68\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014375867070621194 R2: 0.916489629871004 time: 1703120406.350911\n",
      "batch_idx: 1 loss: 0.0007271250955646373 R2: 0.9165132920703687 time: 1703120409.9211168\n",
      "batch_idx: 2 loss: 0.0015253367339973373 R2: 0.9164913684319057 time: 1703120413.3759146\n",
      "batch_idx: 3 loss: 0.0008217847117280408 R2: 0.9164209775857162 time: 1703120416.7113636\n",
      "Training [34%] Loss: 0.0011279583120880337 time: 1703120416.7113636\n",
      "weight: [0.7292967  0.84798624 0.14446889 0.09605902 0.86024309 1.48682262\n",
      " 0.85598011 0.4050164  0.51219817 0.00503044 0.17862875 0.8058976 ]\n",
      "epoch 69\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014375358605280373 R2: 0.9164931170612366 time: 1703120420.1529098\n",
      "batch_idx: 1 loss: 0.0007270825291316203 R2: 0.9165167810072837 time: 1703120423.514349\n",
      "batch_idx: 2 loss: 0.0015252840150225078 R2: 0.9164948260207322 time: 1703120426.947943\n",
      "batch_idx: 3 loss: 0.0008217382373606388 R2: 0.9164243892861206 time: 1703120430.357713\n",
      "Training [34%] Loss: 0.001127910160510701 time: 1703120430.357713\n",
      "weight: [0.73004161 0.84826368 0.14468805 0.09550198 0.86061074 1.48720784\n",
      " 0.856506   0.40542806 0.51212031 0.00494574 0.17859322 0.80586045]\n",
      "epoch 70\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014374863413004143 R2: 0.9164965825829954 time: 1703120433.805024\n",
      "batch_idx: 1 loss: 0.0007270391674611825 R2: 0.9165202480357811 time: 1703120437.2740104\n",
      "batch_idx: 2 loss: 0.0015252318052396184 R2: 0.9164982624909375 time: 1703120440.7110856\n",
      "batch_idx: 3 loss: 0.0008216919752049156 R2: 0.9164277821712957 time: 1703120444.2047231\n",
      "Training [35%] Loss: 0.0011278623223015326 time: 1703120444.2047231\n",
      "weight: [0.73077483 0.84854027 0.14490627 0.09494671 0.86097636 1.48759095\n",
      " 0.85703148 0.4058396  0.51204359 0.00486118 0.17855772 0.80582334]\n",
      "epoch 71\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014374380746752307 R2: 0.9165000267488498 time: 1703120447.708939\n",
      "batch_idx: 1 loss: 0.0007269951077636721 R2: 0.9165236934776633 time: 1703120451.1520164\n",
      "batch_idx: 2 loss: 0.0015251800721312447 R2: 0.9165016781140215 time: 1703120454.6299186\n",
      "batch_idx: 3 loss: 0.0008216459146639379 R2: 0.9164311563745284 time: 1703120458.0697641\n",
      "Training [36%] Loss: 0.0011278147923085213 time: 1703120458.0697641\n",
      "weight: [0.73149699 0.848816   0.14512353 0.09439321 0.86133993 1.48797197\n",
      " 0.85755656 0.40625103 0.51196802 0.00477676 0.17852226 0.80578626]\n",
      "epoch 72\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014373909902183368 R2: 0.9165034498599296 time: 1703120461.53859\n",
      "batch_idx: 1 loss: 0.0007269504404919118 R2: 0.9165271176438192 time: 1703120465.0186431\n",
      "batch_idx: 2 loss: 0.0015251287855397066 R2: 0.9165050731527342 time: 1703120468.330368\n",
      "batch_idx: 3 loss: 0.0008216000458703655 R2: 0.9164345120250902 time: 1703120471.6909375\n",
      "Training [36%] Loss: 0.00112776756553008 time: 1703120471.6909375\n",
      "weight: [0.73220867 0.84909087 0.14533982 0.09384149 0.86170147 1.48835088\n",
      " 0.85808127 0.40666238 0.51189358 0.00469247 0.17848683 0.80574923]\n",
      "epoch 73\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001437345021646665 R2: 0.9165068522066105 time: 1703120475.074054\n",
      "batch_idx: 1 loss: 0.0007269052495804289 R2: 0.91653052083475 time: 1703120478.6067207\n",
      "batch_idx: 2 loss: 0.0015250779175509579 R2: 0.9165084478618285 time: 1703120481.966345\n",
      "batch_idx: 3 loss: 0.0008215543596946547 R2: 0.9164378492496891 time: 1703120485.3889573\n",
      "Training [36%] Loss: 0.0011277206371181766 time: 1703120485.3889573\n",
      "weight: [0.73291042 0.84936487 0.14555512 0.09329156 0.86206098 1.48872769\n",
      " 0.85860562 0.40707366 0.51182028 0.00460831 0.17845144 0.80571223]\n",
      "epoch 74\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014373001066779905 R2: 0.9165102340692132 time: 1703120488.8027747\n",
      "batch_idx: 1 loss: 0.0007268596127263399 R2: 0.9165339033410904 time: 1703120492.2626057\n",
      "batch_idx: 2 loss: 0.0015250274423717841 R2: 0.916511802488737 time: 1703120495.5883265\n",
      "batch_idx: 3 loss: 0.0008215088477398098 R2: 0.9164411681736327 time: 1703120498.9305851\n",
      "Training [37%] Loss: 0.001127674002378981 time: 1703120498.9305851\n",
      "weight: [0.73360274 0.84963801 0.14576941 0.09274342 0.86241846 1.48910241\n",
      " 0.85912965 0.40748489 0.51174811 0.00452428 0.17841608 0.80567526]\n",
      "epoch 75\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001437256186858558 R2: 0.9165135957186269 time: 1703120502.2904468\n",
      "batch_idx: 1 loss: 0.0007268136016984329 R2: 0.9165372654441392 time: 1703120505.7577078\n",
      "batch_idx: 2 loss: 0.0015249773362037773 R2: 0.9165151372741885 time: 1703120509.1910715\n",
      "batch_idx: 3 loss: 0.0008214635023256481 R2: 0.916444468921726 time: 1703120512.6152642\n",
      "Training [38%] Loss: 0.001127627656771604 time: 1703120512.6152642\n",
      "weight: [0.73428613 0.84991027 0.14598269 0.09219708 0.86277392 1.48947505\n",
      " 0.85965337 0.40789608 0.51167706 0.00444036 0.17838075 0.80563834]\n",
      "epoch 76\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014372132073763402 R2: 0.9165169374169576 time: 1703120516.0670984\n",
      "batch_idx: 1 loss: 0.0007267672826631405 R2: 0.9165406074163751 time: 1703120519.503003\n",
      "batch_idx: 2 loss: 0.0015249275771167087 R2: 0.9165184524527256 time: 1703120522.8308165\n",
      "batch_idx: 3 loss: 0.0008214183164649861 R2: 0.9164477516189594 time: 1703120526.267986\n",
      "Training [38%] Loss: 0.0011275815959052938 time: 1703120526.267986\n",
      "weight: [0.73496102 0.85018166 0.14619495 0.09165254 0.86312737 1.4898456\n",
      " 0.86017679 0.40830724 0.51160713 0.00435657 0.17834546 0.80560144]\n",
      "epoch 77\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014371711168660707 R2: 0.9165202594180982 time: 1703120529.6882067\n",
      "batch_idx: 1 loss: 0.0007267207165184294 R2: 0.916543929521964 time: 1703120533.0777733\n",
      "batch_idx: 2 loss: 0.001524878144923539 R2: 0.9165217482531947 time: 1703120536.3985481\n",
      "batch_idx: 3 loss: 0.0008213732838340277 R2: 0.9164510163909784 time: 1703120539.872887\n",
      "Training [38%] Loss: 0.0011275358155355168 time: 1703120539.872887\n",
      "weight: [0.73562782 0.85045217 0.14640617 0.0911098  0.86347881 1.49021408\n",
      " 0.86069993 0.40871839 0.51153831 0.00427289 0.1783102  0.80556458]\n",
      "epoch 78\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014371298672112153 R2: 0.9165235619682985 time: 1703120543.2465088\n",
      "batch_idx: 1 loss: 0.0007266739592282458 R2: 0.9165472320172284 time: 1703120546.7161832\n",
      "batch_idx: 2 loss: 0.0015248290210586205 R2: 0.9165250248991457 time: 1703120550.089715\n",
      "batch_idx: 3 loss: 0.0008213283987386378 R2: 0.9164542633644489 time: 1703120553.542147\n",
      "Training [39%] Loss: 0.0011274903115591798 time: 1703120553.542147\n",
      "weight: [0.73628694 0.85072181 0.14661636 0.09056887 0.86382825 1.4905805\n",
      " 0.86122281 0.40912954 0.51147058 0.00418932 0.17827497 0.80552776]\n",
      "epoch 79\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014370894133469024 R2: 0.9165268453066633 time: 1703120556.995878\n",
      "batch_idx: 1 loss: 0.0007266270621520437 R2: 0.9165505151511141 time: 1703120560.4301317\n",
      "batch_idx: 2 loss: 0.0015247801884603644 R2: 0.9165282826092069 time: 1703120563.9142392\n",
      "batch_idx: 3 loss: 0.0008212836560780804 R2: 0.9164574926672643 time: 1703120567.3985152\n",
      "Training [40%] Loss: 0.0011274450800093478 time: 1703120567.3985152\n",
      "weight: [0.73693872 0.85099057 0.14682549 0.09002973 0.8641757  1.49094486\n",
      " 0.86174545 0.4095407  0.51140394 0.00410585 0.17823977 0.80549096]\n",
      "epoch 80\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014370497130666675 R2: 0.9165301096656295 time: 1703120570.802608\n",
      "batch_idx: 1 loss: 0.0007265800723650379 R2: 0.916553779165606 time: 1703120574.1936903\n",
      "batch_idx: 2 loss: 0.0015247316314592006 R2: 0.9165315215973904 time: 1703120577.738863\n",
      "batch_idx: 3 loss: 0.0008212390513073308 R2: 0.9164607044286643 time: 1703120581.2273438\n",
      "Training [40%] Loss: 0.001127400117049559 time: 1703120581.2273438\n",
      "weight: [0.7375835  0.85125846 0.14703358 0.0894924  0.86452118 1.49130717\n",
      " 0.86226785 0.40995187 0.51133836 0.0040225  0.17820461 0.8054542 ]\n",
      "epoch 81\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014370107268353656 R2: 0.9165333552714025 time: 1703120584.614398\n",
      "batch_idx: 1 loss: 0.0007265330329662056 R2: 0.9165570242961477 time: 1703120588.0789287\n",
      "batch_idx: 2 loss: 0.0015246833356713854 R2: 0.9165347420733717 time: 1703120591.6372309\n",
      "batch_idx: 3 loss: 0.0008211945803989548 R2: 0.916463898779264 time: 1703120595.2560632\n",
      "Training [40%] Loss: 0.0011273554189679777 time: 1703120595.2560632\n",
      "weight: [0.7382216  0.85152547 0.14724061 0.08895688 0.86486468 1.49166745\n",
      " 0.86279003 0.41036307 0.51127384 0.00393925 0.17816947 0.80541747]\n",
      "epoch 82\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014369724176097785 R2: 0.9165365823443492 time: 1703120598.6582336\n",
      "batch_idx: 1 loss: 0.0007264859833719483 R2: 0.9165602507719892 time: 1703120602.0308115\n",
      "batch_idx: 2 loss: 0.0015246352878989793 R2: 0.9165379442427476 time: 1703120605.484162\n",
      "batch_idx: 3 loss: 0.0008211502398052895 R2: 0.916467075851045 time: 1703120608.8433828\n",
      "Training [41%] Loss: 0.001127310982171499 time: 1703120608.8433828\n",
      "weight: [0.7388533  0.85179161 0.14744659 0.08842315 0.86520622 1.4920257\n",
      " 0.86331201 0.4107743  0.51121037 0.00385609 0.17813436 0.80538077]\n",
      "epoch 83\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014369347506680227 R2: 0.9165397910993663 time: 1703120612.2484233\n",
      "batch_idx: 1 loss: 0.0007264389595939842 R2: 0.9165634588165558 time: 1703120615.6064823\n",
      "batch_idx: 2 loss: 0.0015245874760361653 R2: 0.9165411283072242 time: 1703120618.997031\n",
      "batch_idx: 3 loss: 0.0008211060264214542 R2: 0.9164702357772739 time: 1703120622.3637595\n",
      "Training [42%] Loss: 0.0011272668031799065 time: 1703120622.3637595\n",
      "weight: [0.73947888 0.85205688 0.1476515  0.08789122 0.86554582 1.49238193\n",
      " 0.86383378 0.41118557 0.51114791 0.00377304 0.17809928 0.8053441 ]\n",
      "epoch 84\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014368976934482467 R2: 0.9165429817462043 time: 1703120625.7305057\n",
      "batch_idx: 1 loss: 0.0007263919945008986 R2: 0.9165666486477543 time: 1703120629.141438\n",
      "batch_idx: 2 loss: 0.001524539888981789 R2: 0.9165442944648229 time: 1703120632.445968\n",
      "batch_idx: 3 loss: 0.0008210619375496582 R2: 0.9164733786924077 time: 1703120635.6968079\n",
      "Training [42%] Loss: 0.0011272228786201482 time: 1703120635.6968079\n",
      "weight: [0.74009859 0.85232127 0.14785535 0.08736108 0.86588348 1.49273617\n",
      " 0.86435538 0.41159688 0.51108647 0.00369009 0.17806423 0.80530746]\n",
      "epoch 85\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014368612153971088 R2: 0.9165461544897792 time: 1703120639.100109\n",
      "batch_idx: 1 loss: 0.0007263451180629802 R2: 0.9165698204782726 time: 1703120642.5597324\n",
      "batch_idx: 2 loss: 0.0015244925165581538 R2: 0.916547442910035 time: 1703120645.976993\n",
      "batch_idx: 3 loss: 0.000821017970865 R2: 0.9164765047319652 time: 1703120649.3419018\n",
      "Training [42%] Loss: 0.0011271792052208107 time: 1703120649.3419018\n",
      "weight: [0.74071267 0.8525848  0.14805814 0.08683273 0.86621922 1.49308841\n",
      " 0.86487679 0.41200824 0.51102603 0.00360723 0.1780292  0.80527085]\n",
      "epoch 86\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014368252878278532 R2: 0.9165493095304258 time: 1703120652.7816978\n",
      "batch_idx: 1 loss: 0.0007262983575805664 R2: 0.9165729745158504 time: 1703120656.260158\n",
      "batch_idx: 2 loss: 0.0015244453494356572 R2: 0.9165505738339649 time: 1703120659.5309362\n",
      "batch_idx: 3 loss: 0.0008209741243830915 R2: 0.9164796140323703 time: 1703120662.967218\n",
      "Training [43%] Loss: 0.001127135779806792 time: 1703120662.967218\n",
      "weight: [0.74132134 0.85284746 0.14825986 0.08630616 0.86655304 1.49343867\n",
      " 0.86539805 0.41241966 0.51096656 0.00352447 0.1779942  0.80523427]\n",
      "epoch 87\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014367898837880702 R2: 0.9165524470641758 time: 1703120666.451399\n",
      "batch_idx: 1 loss: 0.0007262517378962593 R2: 0.9165761109635339 time: 1703120669.7943304\n",
      "batch_idx: 2 loss: 0.0015243983790632475 R2: 0.9165536874244633 time: 1703120673.182342\n",
      "batch_idx: 3 loss: 0.0008209303964294545 R2: 0.9164827067308264 time: 1703120676.620597\n",
      "Training [44%] Loss: 0.001127092599294258 time: 1703120676.620597\n",
      "weight: [0.74192479 0.85310925 0.14846052 0.08578138 0.86688497 1.49378697\n",
      " 0.86591914 0.41283114 0.51090805 0.00344179 0.17795923 0.80519772]\n",
      "epoch 88\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014367549779366138 R2: 0.9165555672829429 time: 1703120680.0404968\n",
      "batch_idx: 1 loss: 0.0007262052815915767 R2: 0.9165792300199012 time: 1703120683.3393571\n",
      "batch_idx: 2 loss: 0.0015243515976041755 R2: 0.9165567838662414 time: 1703120686.8368914\n",
      "batch_idx: 3 loss: 0.0008208867856109015 R2: 0.9164857829651256 time: 1703120690.1948955\n",
      "Training [44%] Loss: 0.0011270496606858168 time: 1703120690.1948955\n",
      "weight: [0.74252323 0.85337019 0.14866012 0.08525837 0.86721501 1.49413331\n",
      " 0.86644009 0.41324268 0.51085049 0.00335921 0.17792429 0.8051612 ]\n",
      "epoch 89\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00143672054642949 R2: 0.9165586703747678 time: 1703120693.4438124\n",
      "batch_idx: 1 loss: 0.0007261590091688036 R2: 0.916582331879275 time: 1703120696.8780856\n",
      "batch_idx: 2 loss: 0.0015243049978769098 R2: 0.9165598633409658 time: 1703120700.283233\n",
      "batch_idx: 3 loss: 0.0008208432907887735 R2: 0.9164888428735182 time: 1703120703.5864973\n",
      "Training [44%] Loss: 0.0011270069610659942 time: 1703120703.5864973\n",
      "weight: [0.74311684 0.85363026 0.14885866 0.08473713 0.86754318 1.49447772\n",
      " 0.8669609  0.41365428 0.51079385 0.00327672 0.17788938 0.80512471]\n",
      "epoch 90\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014366865668141836 R2: 0.9165617565239662 time: 1703120707.018115\n",
      "batch_idx: 1 loss: 0.0007261129392187964 R2: 0.9165854167319193 time: 1703120710.4070175\n",
      "batch_idx: 2 loss: 0.0015242585733007596 R2: 0.9165629260273626 time: 1703120713.7491765\n",
      "batch_idx: 3 loss: 0.0008207999110541254 R2: 0.9164918865945374 time: 1703120717.1548548\n",
      "Training [45%] Loss: 0.0011269644975969663 time: 1703120717.1548548\n",
      "weight: [0.74370578 0.85388948 0.14905613 0.08421765 0.86786948 1.49482019\n",
      " 0.86748157 0.41406596 0.51073812 0.00319432 0.17785449 0.80508824]\n",
      "epoch 91\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001436653017931872 R2: 0.9165648259113273 time: 1703120720.6762927\n",
      "batch_idx: 1 loss: 0.0007260670885756332 R2: 0.9165884847642131 time: 1703120724.1735947\n",
      "batch_idx: 2 loss: 0.0015242123178459597 R2: 0.9165659721012862 time: 1703120727.4644659\n",
      "batch_idx: 3 loss: 0.0008207566457046807 R2: 0.9164949142668645 time: 1703120730.823352\n",
      "Training [46%] Loss: 0.0011269222675145364 time: 1703120730.823352\n",
      "weight: [0.74429021 0.85414784 0.14925255 0.08369993 0.86819394 1.49516076\n",
      " 0.86800212 0.41447771 0.51068328 0.00311201 0.17781962 0.8050518 ]\n",
      "epoch 92\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014366198798272216 R2: 0.9165678787142472 time: 1703120734.301141\n",
      "batch_idx: 1 loss: 0.0007260214724589149 R2: 0.9165915361588283 time: 1703120737.6347191\n",
      "batch_idx: 2 loss: 0.0015241662259878586 R2: 0.9165690017358076 time: 1703120741.029567\n",
      "batch_idx: 3 loss: 0.0008207134942236199 R2: 0.9164979260291742 time: 1703120744.475944\n",
      "Training [46%] Loss: 0.0011268802681244038 time: 1703120744.475944\n",
      "weight: [0.74487027 0.85440535 0.14944792 0.08318397 0.86851657 1.49549942\n",
      " 0.86852255 0.41488953 0.51062931 0.00302978 0.17778479 0.80501539]\n",
      "epoch 93\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014365871336650363 R2: 0.9165709151068832 time: 1703120747.9855702\n",
      "batch_idx: 1 loss: 0.0007259761046046565 R2: 0.9165945710948679 time: 1703120751.412614\n",
      "batch_idx: 2 loss: 0.0015241202926649094 R2: 0.9165720151012804 time: 1703120754.7706418\n",
      "batch_idx: 3 loss: 0.0008206704562599898 R2: 0.916500922019998 time: 1703120758.269993\n",
      "Training [46%] Loss: 0.001126838496798648 time: 1703120758.269993\n",
      "weight: [0.74544612 0.85466202 0.14964223 0.08266974 0.86883738 1.4958362\n",
      " 0.86904286 0.41530142 0.5105762  0.00294763 0.17774997 0.80497901]\n",
      "epoch 94\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014365547616534287 R2: 0.9165739352602683 time: 1703120761.6020918\n",
      "batch_idx: 1 loss: 0.000725930997385485 R2: 0.9165975897480164 time: 1703120764.9834526\n",
      "batch_idx: 2 loss: 0.0015240745132401568 R2: 0.9165750123654075 time: 1703120768.34512\n",
      "batch_idx: 3 loss: 0.0008206275316107381 R2: 0.9165039023775992 time: 1703120771.8421257\n",
      "Training [47%] Loss: 0.001126796950972452 time: 1703120771.8421257\n",
      "weight: [0.74601788 0.85491784 0.14983549 0.08215725 0.86915638 1.4961711\n",
      " 0.86956307 0.4157134  0.51052393 0.00286557 0.17771519 0.80494265]\n",
      "epoch 95\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001436522746972924 R2: 0.9165769393424357 time: 1703120775.3451056\n",
      "batch_idx: 1 loss: 0.0007258861619210966 R2: 0.916600592290664 time: 1703120778.6880147\n",
      "batch_idx: 2 loss: 0.0015240288834659798 R2: 0.9165779936932946 time: 1703120782.0136833\n",
      "batch_idx: 3 loss: 0.0008205847202042078 R2: 0.9165068672398512 time: 1703120785.435776\n",
      "Training [48%] Loss: 0.001126755628141052 time: 1703120785.435776\n",
      "weight: [0.74658566 0.85517282 0.15002771 0.0816465  0.86947359 1.49650415\n",
      " 0.87008317 0.41612545 0.51047247 0.0027836  0.17768043 0.80490632]\n",
      "epoch 96\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014364910737111529 R2: 0.9165799275185315 time: 1703120788.8007274\n",
      "batch_idx: 1 loss: 0.0007258416081796276 R2: 0.9166035788920356 time: 1703120792.1351862\n",
      "batch_idx: 2 loss: 0.0015239833994517235 R2: 0.9165809592475164 time: 1703120795.6359668\n",
      "batch_idx: 3 loss: 0.0008205420220850672 R2: 0.9165098167441238 time: 1703120799.0175257\n",
      "Training [48%] Loss: 0.0011267145258568928 time: 1703120799.0175257\n",
      "weight: [0.7471496  0.85542696 0.15021888 0.08113746 0.86978902 1.49683535\n",
      " 0.87060318 0.41653758 0.51042182 0.0027017  0.17764569 0.80487002]\n",
      "epoch 97\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014364597268025372 R2: 0.9165828999508973 time: 1703120802.3831718\n",
      "batch_idx: 1 loss: 0.0007257973450706745 R2: 0.9166065497182891 time: 1703120805.757845\n",
      "batch_idx: 2 loss: 0.0015239380576341547 R2: 0.9165839091881637 time: 1703120809.20811\n",
      "batch_idx: 3 loss: 0.0008204994374004986 R2: 0.9165127510271832 time: 1703120812.5673962\n",
      "Training [48%] Loss: 0.0011266736417269662 time: 1703120812.5673962\n",
      "weight: [0.74770979 0.85568027 0.15040901 0.08063014 0.87010269 1.49716472\n",
      " 0.8711231  0.41694979 0.51037195 0.00261989 0.17761098 0.80483375]\n",
      "epoch 98\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001436428691972741 R2: 0.9165858567991816 time: 1703120816.0415206\n",
      "batch_idx: 1 loss: 0.0007257533805307417 R2: 0.9166095049326358 time: 1703120819.4060793\n",
      "batch_idx: 2 loss: 0.0015238928547503079 R2: 0.9165868436729016 time: 1703120822.766876\n",
      "batch_idx: 3 loss: 0.0008204569663876352 R2: 0.9165156702250957 time: 1703120826.1729302\n",
      "Training [49%] Loss: 0.0011266329734103565 time: 1703120826.1729302\n",
      "weight: [0.74826634 0.85593275 0.15059811 0.08012453 0.87041461 1.49749228\n",
      " 0.87164292 0.41736208 0.51032285 0.00253816 0.1775763  0.8047975 ]\n",
      "epoch 99\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014363979556873854 R2: 0.9165887982204042 time: 1703120829.6578019\n",
      "batch_idx: 1 loss: 0.0007257097216016023 R2: 0.9166124446954254 time: 1703120833.1087122\n",
      "batch_idx: 2 loss: 0.0015238477878126244 R2: 0.9165897628570006 time: 1703120836.4942791\n",
      "batch_idx: 3 loss: 0.0008204146093620685 R2: 0.9165185744731505 time: 1703120839.7462325\n",
      "Training [50%] Loss: 0.0011265925186159202 time: 1703120839.7462325\n",
      "weight: [0.74881935 0.8561844  0.15078618 0.07962061 0.87072479 1.49781803\n",
      " 0.87216267 0.41777445 0.5102745  0.00245652 0.17754163 0.80476128]\n",
      "epoch 100\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014363675051046727 R2: 0.9165917243690604 time: 1703120843.121109\n",
      "batch_idx: 1 loss: 0.0007256663745022691 R2: 0.9166153691642466 time: 1703120846.4915721\n",
      "batch_idx: 2 loss: 0.0015238028540862248 R2: 0.9165926668934062 time: 1703120849.8212514\n",
      "batch_idx: 3 loss: 0.0008203723667074229 R2: 0.9165214639057668 time: 1703120853.3552105\n",
      "Training [50%] Loss: 0.0011265522751001474 time: 1703120853.3552105\n",
      "weight: [0.74936891 0.85643523 0.15097323 0.07911839 0.87103325 1.49814199\n",
      " 0.87268233 0.4181869  0.51022688 0.00237495 0.177507   0.80472508]\n",
      "epoch 101\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014363373280316981 R2: 0.9165946353971604 time: 1703120856.8051255\n",
      "batch_idx: 1 loss: 0.0007256233446950474 R2: 0.9166182784940006 time: 1703120860.1792307\n",
      "batch_idx: 2 loss: 0.0015237580510680186 R2: 0.9165955559327644 time: 1703120863.5508049\n",
      "batch_idx: 3 loss: 0.0008203302388658711 R2: 0.9165243386564359 time: 1703120866.941873\n",
      "Training [50%] Loss: 0.0011265122406651587 time: 1703120866.941873\n",
      "weight: [0.74991511 0.85668524 0.15115925 0.07861785 0.87134001 1.49846418\n",
      " 0.87320192 0.41859944 0.51017998 0.00229346 0.17747239 0.80468891]\n",
      "epoch 102\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014363074128839874 R2: 0.9165975314543292 time: 1703120870.301307\n",
      "batch_idx: 1 loss: 0.0007255806369462625 R2: 0.9166211728369976 time: 1703120873.6911957\n",
      "batch_idx: 2 loss: 0.0015237133764675853 R2: 0.9165984301234774 time: 1703120877.1746676\n",
      "batch_idx: 3 loss: 0.000820288226329508 R2: 0.9165271988576557 time: 1703120880.7044764\n",
      "Training [51%] Loss: 0.0011264724131568359 time: 1703120880.7044764\n",
      "weight: [0.75045802 0.85693443 0.15134425 0.07811898 0.87164506 1.49878461\n",
      " 0.87372144 0.41901205 0.51013378 0.00221205 0.1774378  0.80465277]\n",
      "epoch 103\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014362777486481703 R2: 0.9166004126878559 time: 1703120884.2264981\n",
      "batch_idx: 1 loss: 0.000725538255381948 R2: 0.9166240523430155 time: 1703120887.657207\n",
      "batch_idx: 2 loss: 0.0015236688281896425 R2: 0.9166012896117385 time: 1703120891.172724\n",
      "batch_idx: 3 loss: 0.0008202463296325447 R2: 0.9165300446408733 time: 1703120894.6132526\n",
      "Training [52%] Loss: 0.0011264327904630764 time: 1703120894.6132526\n",
      "weight: [0.75099773 0.85718282 0.15152824 0.07762178 0.87194844 1.4991033\n",
      " 0.87424089 0.41942475 0.51008826 0.00213072 0.17740324 0.80461665]\n",
      "epoch 104\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001436248324847359 R2: 0.9166032792427486 time: 1703120897.9800773\n",
      "batch_idx: 1 loss: 0.0007254962035391644 R2: 0.9166269171593765 time: 1703120901.4127214\n",
      "batch_idx: 2 loss: 0.001523624404317949 R2: 0.9166041345415706 time: 1703120904.9348102\n",
      "batch_idx: 3 loss: 0.0008202045493442311 R2: 0.9165328761364343 time: 1703120908.4508636\n",
      "Training [52%] Loss: 0.001126393370512176 time: 1703120908.4508636\n",
      "weight: [0.75153431 0.85743039 0.15171123 0.07712624 0.87225015 1.49942025\n",
      " 0.87476027 0.41983752 0.5100434  0.00204947 0.1773687  0.80458056]\n",
      "epoch 105\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014362191315091058 R2: 0.916606131261801 time: 1703120911.9505556\n",
      "batch_idx: 1 loss: 0.0007254544844130446 R2: 0.9166297674310174 time: 1703120915.3556387\n",
      "batch_idx: 2 loss: 0.0015235801031005226 R2: 0.916606965054869 time: 1703120918.806816\n",
      "batch_idx: 3 loss: 0.000820162886062446 R2: 0.916535693473547 time: 1703120922.36265\n",
      "Training [52%] Loss: 0.0011263541512712798 time: 1703120922.36265\n",
      "weight: [0.75206784 0.85767716 0.15189321 0.07663235 0.87255021 1.49973548\n",
      " 0.87527959 0.42025038 0.5099992  0.00196829 0.17733418 0.80454449]\n",
      "epoch 106\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001436190159135701 R2: 0.9166089688856462 time: 1703120925.7911391\n",
      "batch_idx: 1 loss: 0.0007254131005001733 R2: 0.9166326033005502 time: 1703120929.2627118\n",
      "batch_idx: 2 loss: 0.0015235359229361265 R2: 0.9166097812914475 time: 1703120932.6651275\n",
      "batch_idx: 3 loss: 0.000820121340407907 R2: 0.9165384967802327 time: 1703120936.075475\n",
      "Training [53%] Loss: 0.0011263151307449768 time: 1703120936.075475\n",
      "weight: [0.75259837 0.85792314 0.1520742  0.0761401  0.87284863 1.50004901\n",
      " 0.87579884 0.42066332 0.50995564 0.00188719 0.17729969 0.80450845]\n",
      "epoch 107\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001436161398676616 R2: 0.9166117922528028 time: 1703120939.4056299\n",
      "batch_idx: 1 loss: 0.0007253720538384689 R2: 0.9166354249083227 time: 1703120942.8477604\n",
      "batch_idx: 2 loss: 0.0015234918623617806 R2: 0.9166125833890583 time: 1703120946.1496615\n",
      "batch_idx: 3 loss: 0.000820079913018952 R2: 0.9165412861833031 time: 1703120949.532155\n",
      "Training [54%] Loss: 0.0011262763069739543 time: 1703120949.532155\n",
      "weight: [0.75312597 0.85816832 0.15225419 0.07564948 0.87314542 1.50036084\n",
      " 0.87631804 0.42107633 0.50991269 0.00180617 0.17726523 0.80447244]\n",
      "epoch 108\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014361328415028888 R2: 0.9166146014997171 time: 1703120953.048999\n",
      "batch_idx: 1 loss: 0.0007253313460438965 R2: 0.9166382323924804 time: 1703120956.346482\n",
      "batch_idx: 2 loss: 0.0015234479200413491 R2: 0.9166153714834392 time: 1703120959.7659893\n",
      "batch_idx: 3 loss: 0.000820038604546819 R2: 0.9165440618083295 time: 1703120963.2497125\n",
      "Training [54%] Loss: 0.0011262376780337385 time: 1703120963.2497125\n",
      "weight: [0.75365071 0.8584127  0.1524332  0.07516048 0.8734406  1.500671\n",
      " 0.87683719 0.42148943 0.50987035 0.00172523 0.17723078 0.80443645]\n",
      "epoch 109\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014361044793833563 R2: 0.9166173967608261 time: 1703120966.6698985\n",
      "batch_idx: 1 loss: 0.000725290978344311 R2: 0.9166410258890052 time: 1703120970.1437683\n",
      "batch_idx: 2 loss: 0.0015234040947550047 R2: 0.9166181457083507 time: 1703120973.6539333\n",
      "batch_idx: 3 loss: 0.0008199974156514285 R2: 0.9165468237796132 time: 1703120977.0285342\n",
      "Training [54%] Loss: 0.0011261992420335252 time: 1703120977.0285342\n",
      "weight: [0.75417264 0.8586563  0.15261122 0.0746731  0.87373419 1.5009795\n",
      " 0.87735628 0.4219026  0.5098286  0.00164436 0.17719636 0.80440049]\n",
      "epoch 110\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001436076304462484 R2: 0.9166201781685809 time: 1703120980.3860598\n",
      "batch_idx: 1 loss: 0.000725250951610618 R2: 0.9166438055317819 time: 1703120983.7636764\n",
      "batch_idx: 2 loss: 0.0015233603853896005 R2: 0.9166209061956095 time: 1703120987.2758656\n",
      "batch_idx: 3 loss: 0.0008199563469975357 R2: 0.9165495722201769 time: 1703120990.6060607\n",
      "Training [55%] Loss: 0.0011261609971150595 time: 1703120990.6060607\n",
      "weight: [0.75469181 0.85889911 0.15278827 0.07418733 0.87402618 1.50128634\n",
      " 0.87787531 0.42231584 0.50978742 0.00156357 0.17716197 0.80436455]\n",
      "epoch 111\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014360483092397823 R2: 0.916622945853509 time: 1703120993.9784126\n",
      "batch_idx: 1 loss: 0.0007252112663855486 R2: 0.9166465714526503 time: 1703120997.4832242\n",
      "batch_idx: 2 loss: 0.0015233167909297343 R2: 0.9166236530751156 time: 1703121000.917946\n",
      "batch_idx: 3 loss: 0.0008199153992513332 R2: 0.9165523072517349 time: 1703121004.2435822\n",
      "Training [56%] Loss: 0.0011261229414515996 time: 1703121004.2435822\n",
      "weight: [7.55208285e-01 8.59141150e-01 1.52964354e-01 7.37031587e-02\n",
      " 8.74316606e-01 1.50159155e+00 8.78394302e-01 4.22729165e-01\n",
      " 5.09746807e-01 1.48285814e-03 1.77127600e-01 8.04328637e-01]\n",
      "epoch 112\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00143602048655059 R2: 0.9166256999442342 time: 1703121007.7705307\n",
      "batch_idx: 1 loss: 0.0007251719229101639 R2: 0.9166493237814372 time: 1703121011.15739\n",
      "batch_idx: 2 loss: 0.001523273310449604 R2: 0.9166263864748968 time: 1703121014.535609\n",
      "batch_idx: 3 loss: 0.0008198745730773973 R2: 0.9165550289946939 time: 1703121017.923482\n",
      "Training [56%] Loss: 0.0011260850732469389 time: 1703121017.923482\n",
      "weight: [7.55722107e-01 8.59382410e-01 1.53139469e-01 7.32205745e-02\n",
      " 8.74605471e-01 1.50189513e+00 8.78913243e-01 4.23142561e-01\n",
      " 5.09706739e-01 1.40221974e-03 1.77093253e-01 8.04292750e-01]\n",
      "epoch 113\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014359928295481115 R2: 0.9166284405675343 time: 1703121021.4975376\n",
      "batch_idx: 1 loss: 0.0007251329211483206 R2: 0.9166520626460166 time: 1703121024.9512959\n",
      "batch_idx: 2 loss: 0.001523229943105451 R2: 0.9166291065211347 time: 1703121028.4064205\n",
      "batch_idx: 3 loss: 0.0008198338691359228 R2: 0.9165577375681352 time: 1703121031.8743892\n",
      "Training [56%] Loss: 0.0011260473907344516 time: 1703121031.8743892\n",
      "weight: [7.56233326e-01 8.59622898e-01 1.53313624e-01 7.27395714e-02\n",
      " 8.74892791e-01 1.50219711e+00 8.79432137e-01 4.23556031e-01\n",
      " 5.09667205e-01 1.32165700e-03 1.77058930e-01 8.04256889e-01]\n",
      "epoch 114\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001435965331686724 R2: 0.9166311678483605 time: 1703121035.250613\n",
      "batch_idx: 1 loss: 0.0007250942608093239 R2: 0.9166547881723431 time: 1703121038.689964\n",
      "batch_idx: 2 loss: 0.001523186688128652 R2: 0.9166318133381995 time: 1703121042.2304506\n",
      "batch_idx: 3 loss: 0.0008197932880803057 R2: 0.9165604330898075 time: 1703121045.6830173\n",
      "Training [57%] Loss: 0.0011260098921762514 time: 1703121045.6830173\n",
      "weight: [7.56741988e-01 8.59862619e-01 1.53486826e-01 7.22601406e-02\n",
      " 8.75178577e-01 1.50249749e+00 8.79950986e-01 4.23969573e-01\n",
      " 5.09628191e-01 1.24116974e-03 1.77024631e-01 8.04221053e-01]\n",
      "epoch 115\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014359379867063089 R2: 0.9166338819098897 time: 1703121049.1215265\n",
      "batch_idx: 1 loss: 0.0007250559413687575 R2: 0.9166575004844993 time: 1703121052.541846\n",
      "batch_idx: 2 loss: 0.0015231435448192943 R2: 0.9166345070486839 time: 1703121056.1190004\n",
      "batch_idx: 3 loss: 0.0008197528305549532 R2: 0.9165631156761262 time: 1703121059.5611725\n",
      "Training [58%] Loss: 0.0011259725758623283 time: 1703121059.5611725\n",
      "weight: [7.57248137e-01 8.60101576e-01 1.53659080e-01 7.17822735e-02\n",
      " 8.75462843e-01 1.50279628e+00 8.80469792e-01 4.24383186e-01\n",
      " 5.09589683e-01 1.16075779e-03 1.76990356e-01 8.04185242e-01]\n",
      "epoch 116\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014359107886176064 R2: 0.9166365828735502 time: 1703121062.8834975\n",
      "batch_idx: 1 loss: 0.0007250179620878086 R2: 0.9166601997047368 time: 1703121066.351885\n",
      "batch_idx: 2 loss: 0.00152310051254033 R2: 0.9166371877734238 time: 1703121069.6438975\n",
      "batch_idx: 3 loss: 0.0008197124971933744 R2: 0.9165657854421723 time: 1703121072.948639\n",
      "Training [58%] Loss: 0.0011259354401097798 time: 1703121072.948639\n",
      "weight: [7.57751816e-01 8.60339773e-01 1.53830392e-01 7.13059615e-02\n",
      " 8.75745602e-01 1.50309350e+00 8.80988556e-01 4.24796869e-01\n",
      " 5.09551670e-01 1.08042100e-03 1.76956104e-01 8.04149457e-01]\n",
      "epoch 117\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014358837316885216 R2: 0.916639270859046 time: 1703121076.4599617\n",
      "batch_idx: 1 loss: 0.0007249803220311204 R2: 0.9166628859535122 time: 1703121079.7436645\n",
      "batch_idx: 2 loss: 0.0015230575907121296 R2: 0.9166398556315446 time: 1703121083.1429365\n",
      "batch_idx: 3 loss: 0.0008196722886164692 R2: 0.9165684425016833 time: 1703121086.5938396\n",
      "Training [58%] Loss: 0.00112589848326206 time: 1703121086.5938396\n",
      "weight: [7.58253065e-01 8.60577215e-01 1.54000766e-01 7.08311959e-02\n",
      " 8.76026866e-01 1.50338916e+00 8.81507278e-01 4.25210621e-01\n",
      " 5.09514137e-01 1.00015922e-03 1.76921877e-01 8.04113697e-01]\n",
      "epoch 118\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014358568104312784 R2: 0.9166419459844141 time: 1703121090.0165048\n",
      "batch_idx: 1 loss: 0.0007249430200832847 R2: 0.91666555934952 time: 1703121093.4538465\n",
      "batch_idx: 2 loss: 0.0015230147788074778 R2: 0.916642510740483 time: 1703121096.8108528\n",
      "batch_idx: 3 loss: 0.0008196322054310285 R2: 0.9165710869670664 time: 1703121100.265607\n",
      "Training [59%] Loss: 0.0011258617036882673 time: 1703121100.265607\n",
      "weight: [7.58751922e-01 8.60813905e-01 1.54170210e-01 7.03579683e-02\n",
      " 8.76306648e-01 1.50368328e+00 8.82025961e-01 4.25624440e-01\n",
      " 5.09477073e-01 9.19972324e-04 1.76887673e-01 8.04077963e-01]\n",
      "epoch 119\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014358300195903503 R2: 0.916644608366029 time: 1703121103.5919468\n",
      "batch_idx: 1 loss: 0.0007249060549641294 R2: 0.9166682200097414 time: 1703121106.964396\n",
      "batch_idx: 2 loss: 0.0015229720763469744 R2: 0.9166451532160143 time: 1703121110.38542\n",
      "batch_idx: 3 loss: 0.0008195922482284246 R2: 0.9165737189493951 time: 1703121113.8010015\n",
      "Training [60%] Loss: 0.0011258250997824696 time: 1703121113.8010015\n",
      "weight: [7.59248426e-01 8.61049848e-01 1.54338728e-01 6.98862700e-02\n",
      " 8.76584961e-01 1.50397586e+00 8.82544604e-01 4.26038325e-01\n",
      " 5.09440466e-01 8.39860201e-04 1.76853493e-01 8.04042254e-01]\n",
      "epoch 120\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014358033541311804 R2: 0.9166472581186577 time: 1703121117.133211\n",
      "batch_idx: 1 loss: 0.0007248694252428551 R2: 0.9166708680494745 time: 1703121120.551984\n",
      "batch_idx: 2 loss: 0.0015229294828947733 R2: 0.9166477831722805 time: 1703121123.9752927\n",
      "batch_idx: 3 loss: 0.0008195524175834735 R2: 0.9165763385584225 time: 1703121127.5212796\n",
      "Training [60%] Loss: 0.0011257886699630707 time: 1703121127.5212796\n",
      "weight: [7.59742613e-01 8.61285047e-01 1.54506326e-01 6.94160924e-02\n",
      " 8.76861815e-01 1.50426693e+00 8.83063210e-01 4.26452275e-01\n",
      " 5.09404304e-01 7.59822743e-04 1.76819337e-01 8.04006570e-01]\n",
      "epoch 121\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014357768092295134 R2: 0.9166498953554619 time: 1703121130.900959\n",
      "batch_idx: 1 loss: 0.0007248331293511323 R2: 0.9166735035823578 time: 1703121134.3402808\n",
      "batch_idx: 2 loss: 0.0015228869980546673 R2: 0.9166504007218336 time: 1703121137.7375526\n",
      "batch_idx: 3 loss: 0.0008195127140534301 R2: 0.9165789459025702 time: 1703121141.0709665\n",
      "Training [60%] Loss: 0.0011257524126721857 time: 1703121141.0709665\n",
      "weight: [7.60234516e-01 8.61519506e-01 1.54673010e-01 6.89474271e-02\n",
      " 8.77137225e-01 1.50455649e+00 8.83581778e-01 4.26866289e-01\n",
      " 5.09368576e-01 6.79859859e-04 1.76785205e-01 8.03970912e-01]\n",
      "epoch 122\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001435750380261422 R2: 0.9166525201880521 time: 1703121144.5127501\n",
      "batch_idx: 1 loss: 0.0007247971655952389 R2: 0.916676126720412 time: 1703121147.875898\n",
      "batch_idx: 2 loss: 0.0015228446214664564 R2: 0.9166530059756385 time: 1703121151.3595414\n",
      "batch_idx: 3 loss: 0.0008194731381771441 R2: 0.9165815410889507 time: 1703121154.7494714\n",
      "Training [61%] Loss: 0.0011257163263750653 time: 1703121154.7494714\n",
      "weight: [7.60724169e-01 8.61753230e-01 1.54838786e-01 6.84802656e-02\n",
      " 8.77411202e-01 1.50484455e+00 8.84100309e-01 4.27280365e-01\n",
      " 5.09333269e-01 5.99971463e-04 1.76751096e-01 8.03935279e-01]\n",
      "epoch 123\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014357240627938892 R2: 0.9166551327265052 time: 1703121158.1685133\n",
      "batch_idx: 1 loss: 0.0007247615321672883 R2: 0.9166787375740755 time: 1703121161.526832\n",
      "batch_idx: 2 loss: 0.0015228023528026078 R2: 0.9166555990431251 time: 1703121164.8235683\n",
      "batch_idx: 3 loss: 0.0008194336904743339 R2: 0.916584124223377 time: 1703121168.4081283\n",
      "Training [62%] Loss: 0.0011256804095595297 time: 1703121168.4081283\n",
      "weight: [7.61211604e-01 8.61986222e-01 1.55003659e-01 6.80145993e-02\n",
      " 8.77683757e-01 1.50513112e+00 8.84618805e-01 4.27694501e-01\n",
      " 5.09298374e-01 5.20157481e-04 1.76717012e-01 8.03899671e-01]\n",
      "epoch 124\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014356978525759448 R2: 0.9166577330793901 time: 1703121172.0415256\n",
      "batch_idx: 1 loss: 0.0007247262271556692 R2: 0.916681336252234 time: 1703121175.528078\n",
      "batch_idx: 2 loss: 0.0015227601917651985 R2: 0.9166581800322005 time: 1703121179.1908748\n",
      "batch_idx: 3 loss: 0.0008193943714449803 R2: 0.9165866954103608 time: 1703121182.8689837\n",
      "Training [62%] Loss: 0.0011256446607354482 time: 1703121182.8689837\n",
      "weight: [7.61696853e-01 8.62218486e-01 1.55167636e-01 6.75504199e-02\n",
      " 8.77954903e-01 1.50541623e+00 8.85137265e-01 4.28108698e-01\n",
      " 5.09263879e-01 4.40417847e-04 1.76682951e-01 8.03864089e-01]\n",
      "epoch 125\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014356717455303136 R2: 0.9166603213537933 time: 1703121186.3876739\n",
      "batch_idx: 1 loss: 0.0007246912485546705 R2: 0.9166839228622383 time: 1703121190.245469\n",
      "batch_idx: 2 loss: 0.001522718138083045 R2: 0.9166607490492791 time: 1703121194.0751286\n",
      "batch_idx: 3 loss: 0.0008193551815688114 R2: 0.9165892547531355 time: 1703121197.8866363\n",
      "Training [62%] Loss: 0.0011256090784342102 time: 1703121197.8866363\n",
      "weight: [7.62179944e-01 8.62450026e-01 1.55330720e-01 6.70877189e-02\n",
      " 8.78224652e-01 1.50569987e+00 8.85655691e-01 4.28522952e-01\n",
      " 5.09229775e-01 3.60752502e-04 1.76648914e-01 8.03828532e-01]\n",
      "epoch 126\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014356457377455094 R2: 0.9166628976553509 time: 1703121201.214828\n",
      "batch_idx: 1 loss: 0.0007246565942734857 R2: 0.9166864975099444 time: 1703121204.6991062\n",
      "batch_idx: 2 loss: 0.0015226761915090794 R2: 0.9166633061993062 time: 1703121208.089389\n",
      "batch_idx: 3 loss: 0.0008193161213048873 R2: 0.9165918023536556 time: 1703121211.6164005\n",
      "Training [63%] Loss: 0.0011255736612082404 time: 1703121211.6164005\n",
      "weight: [7.62660907e-01 8.62680846e-01 1.55492919e-01 6.66264880e-02\n",
      " 8.78493015e-01 1.50598207e+00 8.86174082e-01 4.28937263e-01\n",
      " 5.09196050e-01 2.81161396e-04 1.76614901e-01 8.03793001e-01]\n",
      "epoch 127\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001435619825468417 R2: 0.9166654620882737 time: 1703121215.1026406\n",
      "batch_idx: 1 loss: 0.0007246222621444954 R2: 0.916689060299747 time: 1703121218.6352286\n",
      "batch_idx: 2 loss: 0.0015226343518179408 R2: 0.916665851585792 time: 1703121222.1769078\n",
      "batch_idx: 3 loss: 0.0008192771910912938 R2: 0.9165943383126146 time: 1703121225.6173766\n",
      "Training [64%] Loss: 0.0011255384076305367 time: 1703121225.6173766\n",
      "weight: [7.63139769e-01 8.62910950e-01 1.55654239e-01 6.61667189e-02\n",
      " 8.78760003e-01 1.50626283e+00 8.86692440e-01 4.29351629e-01\n",
      " 5.09162695e-01 2.01644486e-04 1.76580912e-01 8.03757495e-01]\n",
      "epoch 128\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014355940050972532 R2: 0.9166680147553594 time: 1703121229.090285\n",
      "batch_idx: 1 loss: 0.0007245882499309587 R2: 0.9166916113345975 time: 1703121232.6168556\n",
      "batch_idx: 2 loss: 0.0015225926188037436 R2: 0.9166683853108285 time: 1703121236.0901709\n",
      "batch_idx: 3 loss: 0.0008192383913448639 R2: 0.9165968627294584 time: 1703121239.4425323\n",
      "Training [64%] Loss: 0.001125503316294205 time: 1703121239.4425323\n",
      "weight: [7.63616557e-01 8.63140341e-01 1.55814683e-01 6.57084032e-02\n",
      " 8.79025629e-01 1.50654217e+00 8.87210763e-01 4.29766049e-01\n",
      " 5.09129700e-01 1.22201733e-04 1.76546947e-01 8.03722015e-01]\n",
      "epoch 129\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001435568273174897 R2: 0.9166705557580397 time: 1703121242.9885364\n",
      "batch_idx: 1 loss: 0.0007245545553342071 R2: 0.9166941507160213 time: 1703121246.6169496\n",
      "batch_idx: 2 loss: 0.0015225509922779977 R2: 0.9166709074751141 time: 1703121250.0358481\n",
      "batch_idx: 3 loss: 0.0008191997224610229 R2: 0.916599375702398 time: 1703121253.4580543\n",
      "Training [64%] Loss: 0.001125468385812031 time: 1703121253.4580543\n",
      "weight: [7.64091297e-01 8.63369024e-01 1.55974259e-01 6.52515328e-02\n",
      " 8.79289903e-01 1.50682010e+00 8.87729053e-01 4.30180522e-01\n",
      " 5.09097056e-01 4.28331063e-05 1.76513006e-01 8.03686560e-01]\n",
      "epoch 130\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014355426263826352 R2: 0.9166730851963795 time: 1703121256.9564407\n",
      "batch_idx: 1 loss: 0.0007245211760002351 R2: 0.9166966785441751 time: 1703121260.5956032\n",
      "batch_idx: 2 loss: 0.0015225094720677367 R2: 0.9166734181779785 time: 1703121264.0498095\n",
      "batch_idx: 3 loss: 0.0008191611848136663 R2: 0.9166018773284167 time: 1703121267.4705024\n",
      "Training [65%] Loss: 0.0011254336148160684 time: 1703121267.4705024\n",
      "weight: [ 7.64564014e-01  8.63597003e-01  1.56132972e-01  6.47960994e-02\n",
      "  8.79552837e-01  1.50709662e+00  8.88247310e-01  4.30595045e-01\n",
      "  5.09064754e-01 -3.64614199e-05  1.76479090e-01  8.03651131e-01]\n",
      "epoch 131\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014355170615341464 R2: 0.91667560316912 time: 1703121271.0691009\n",
      "batch_idx: 1 loss: 0.0007244881095258954 R2: 0.9166991949178398 time: 1703121274.4377766\n",
      "batch_idx: 2 loss: 0.001522468058013721 R2: 0.9166759175174108 time: 1703121277.8789308\n",
      "batch_idx: 3 loss: 0.0008191227787550917 R2: 0.9166043677032908 time: 1703121281.312462\n",
      "Training [66%] Loss: 0.0011253990019572135 time: 1703121281.312462\n",
      "weight: [ 7.65034732e-01  8.63824280e-01  1.56290827e-01  6.43420949e-02\n",
      "  8.79814442e-01  1.50737176e+00  8.88765534e-01  4.31009619e-01\n",
      "  5.09032784e-01 -1.15681866e-04  1.76445197e-01  8.03615727e-01]\n",
      "epoch 132\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014354915755699132 R2: 0.9166781097736857 time: 1703121284.8571599\n",
      "batch_idx: 1 loss: 0.0007244553534645588 R2: 0.9167016999344637 time: 1703121288.2808435\n",
      "batch_idx: 2 loss: 0.0015224267499688684 R2: 0.9166784055900823 time: 1703121291.871664\n",
      "batch_idx: 3 loss: 0.0008190845046160093 R2: 0.9166068469216017 time: 1703121295.3750913\n",
      "Training [66%] Loss: 0.0011253645459048374 time: 1703121295.3750913\n",
      "weight: [ 7.65503476e-01  8.64050860e-01  1.56447831e-01  6.38895112e-02\n",
      "  8.80074728e-01  1.50764552e+00  8.89283726e-01  4.31424240e-01\n",
      "  5.09001139e-01 -1.94828249e-04  1.76411328e-01  8.03580349e-01]\n",
      "epoch 133\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014354661655518232 R2: 0.9166806051062176 time: 1703121298.8793948\n",
      "batch_idx: 1 loss: 0.0007244229053314915 R2: 0.9167041936901799 time: 1703121302.4023015\n",
      "batch_idx: 2 loss: 0.0015223855477967418 R2: 0.9166808824913583 time: 1703121305.7449539\n",
      "batch_idx: 3 loss: 0.0008190463627055563 R2: 0.9166093150767469 time: 1703121309.1982281\n",
      "Training [66%] Loss: 0.0011253302453464033 time: 1703121309.1982281\n",
      "weight: [ 7.65970267e-01  8.64276747e-01  1.56603988e-01  6.34383401e-02\n",
      "  8.80333707e-01  1.50791790e+00  8.89801884e-01  4.31838909e-01\n",
      "  5.08969809e-01 -2.73900579e-04  1.76377484e-01  8.03544997e-01]\n",
      "epoch 134\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014354408286581274 R2: 0.9166830892615903 time: 1703121312.7445028\n",
      "batch_idx: 1 loss: 0.0007243907626086966 R2: 0.9167066762798349 time: 1703121316.150627\n",
      "batch_idx: 2 loss: 0.0015223444513701627 R2: 0.9166833483153327 time: 1703121319.6804895\n",
      "batch_idx: 3 loss: 0.0008190083533114146 R2: 0.9166117722609594 time: 1703121323.1335423\n",
      "Training [67%] Loss: 0.0011252960989871002 time: 1703121323.1335423\n",
      "weight: [ 7.66435128e-01  8.64501944e-01  1.56759304e-01  6.29885737e-02\n",
      "  8.80591389e-01  1.50818894e+00  8.90320010e-01  4.32253623e-01\n",
      "  5.08938786e-01 -3.52898865e-04  1.76343663e-01  8.03509670e-01]\n",
      "epoch 135\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014354155621785695 R2: 0.9166855623334287 time: 1703121326.6340852\n",
      "batch_idx: 1 loss: 0.0007243589227495294 R2: 0.9167091477970025 time: 1703121330.085446\n",
      "batch_idx: 2 loss: 0.0015223034605699858 R2: 0.9166858031548489 time: 1703121333.7409682\n",
      "batch_idx: 3 loss: 0.0008189704766998769 R2: 0.9166142185653159 time: 1703121337.2293785\n",
      "Training [68%] Loss: 0.0011252621055494905 time: 1703121337.2293785\n",
      "weight: [ 7.66898080e-01  8.64726456e-01  1.56913785e-01  6.25402039e-02\n",
      "  8.80847785e-01  1.50845862e+00  8.90838103e-01  4.32668381e-01\n",
      "  5.08908063e-01 -4.31823110e-04  1.76309867e-01  8.03474369e-01]\n",
      "epoch 136\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014353903635098686 R2: 0.916688024414144 time: 1703121340.6464717\n",
      "batch_idx: 1 loss: 0.0007243273831829048 R2: 0.9167116083340201 time: 1703121344.2081332\n",
      "batch_idx: 2 loss: 0.0015222625752839042 R2: 0.9166882471015135 time: 1703121347.643924\n",
      "batch_idx: 3 loss: 0.0008189327331160599 R2: 0.9166166540797608 time: 1703121351.0400596\n",
      "Training [68%] Loss: 0.0011252282637731843 time: 1703121351.0400596\n",
      "weight: [ 7.67359145e-01  8.64950285e-01  1.57067435e-01  6.20932230e-02\n",
      "  8.81102906e-01  1.50872697e+00  8.91356163e-01  4.33083181e-01\n",
      "  5.08877631e-01 -5.10673314e-04  1.76276096e-01  8.03439094e-01]\n",
      "epoch 137\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014353652301512978 R2: 0.9166904755949348 time: 1703121354.471529\n",
      "batch_idx: 1 loss: 0.0007242961413172415 R2: 0.9167140579819927 time: 1703121358.0653117\n",
      "batch_idx: 2 loss: 0.0015222217954053963 R2: 0.9166906802457216 time: 1703121361.5077975\n",
      "batch_idx: 3 loss: 0.0008188951227840405 R2: 0.9166190788931077 time: 1703121364.844417\n",
      "Training [68%] Loss: 0.001125194572414494 time: 1703121364.844417\n",
      "weight: [ 7.67818341e-01  8.65173435e-01  1.57220262e-01  6.16476229e-02\n",
      "  8.81356762e-01  1.50899400e+00  8.91874190e-01  4.33498023e-01\n",
      "  5.08847483e-01 -5.89449475e-04  1.76242348e-01  8.03403845e-01]\n",
      "epoch 138\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014353401597006032 R2: 0.9166929159658206 time: 1703121368.407359\n",
      "batch_idx: 1 loss: 0.0007242651945440821 R2: 0.9167164968308358 time: 1703121371.8755574\n",
      "batch_idx: 2 loss: 0.001522181120832724 R2: 0.9166931026766759 time: 1703121375.2809749\n",
      "batch_idx: 3 loss: 0.0008188576459070883 R2: 0.91662149309307 time: 1703121378.732556\n",
      "Training [69%] Loss: 0.0011251610302461246 time: 1703121378.732556\n",
      "weight: [ 7.68275690e-01  8.65395911e-01  1.57372269e-01  6.12033958e-02\n",
      "  8.81609363e-01  1.50925971e+00  8.92392184e-01  4.33912905e-01\n",
      "  5.08817612e-01 -6.68151586e-04  1.76208625e-01  8.03368621e-01]\n",
      "epoch 139\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014353151498500052 R2: 0.9166953456156521 time: 1703121382.0599735\n",
      "batch_idx: 1 loss: 0.0007242345402414992 R2: 0.9167189249692752 time: 1703121385.6376832\n",
      "batch_idx: 2 loss: 0.0015221405514680704 R2: 0.9166955144824179 time: 1703121389.1462865\n",
      "batch_idx: 3 loss: 0.0008188203026678794 R2: 0.9166238967662584 time: 1703121392.6357157\n",
      "Training [70%] Loss: 0.0011251276360568635 time: 1703121392.6357157\n",
      "weight: [ 7.68731209e-01  8.65617715e-01  1.57523463e-01  6.07605340e-02\n",
      "  8.81860719e-01  1.50952412e+00  8.92910144e-01  4.34327825e-01\n",
      "  5.08788010e-01 -7.46779639e-04  1.76174926e-01  8.03333423e-01]\n",
      "epoch 140\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014352901983825024 R2: 0.9166977646321455 time: 1703121396.0476637\n",
      "batch_idx: 1 loss: 0.0007242041757771917 R2: 0.916721342484885 time: 1703121399.3381557\n",
      "batch_idx: 2 loss: 0.0015221000872166746 R2: 0.9166979157498268 time: 1703121402.9161866\n",
      "batch_idx: 3 loss: 0.0008187830932287752 R2: 0.9166262899982105 time: 1703121406.3821673\n",
      "Training [70%] Loss: 0.001125094388651286 time: 1703121406.3821673\n",
      "weight: [ 7.69184919e-01  8.65838852e-01  1.57673849e-01  6.03190298e-02\n",
      "  8.82110841e-01  1.50978724e+00  8.93428072e-01  4.34742782e-01\n",
      "  5.08758671e-01 -8.25333623e-04  1.76141252e-01  8.03298251e-01]\n",
      "epoch 141\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014352653031682434 R2: 0.9167001731018731 time: 1703121409.7484498\n",
      "batch_idx: 1 loss: 0.0007241740985114019 R2: 0.9167237494640912 time: 1703121413.2092311\n",
      "batch_idx: 2 loss: 0.0015220597279860684 R2: 0.916700306564658 time: 1703121416.9130971\n",
      "batch_idx: 3 loss: 0.000818746017732069 R2: 0.9166286728733961 time: 1703121420.3667843\n",
      "Training [70%] Loss: 0.0011250612868494456 time: 1703121420.3667843\n",
      "weight: [ 7.69636835e-01  8.66059325e-01  1.57823432e-01  5.98788754e-02\n",
      "  8.82359739e-01  1.51004908e+00  8.93945966e-01  4.35157775e-01\n",
      "  5.08729588e-01 -9.03813525e-04  1.76107602e-01  8.03263105e-01]\n",
      "epoch 142\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014352404621611706 R2: 0.9167025711103193 time: 1703121423.818161\n",
      "batch_idx: 1 loss: 0.0007241443057995929 R2: 0.9167261459922063 time: 1703121427.2069018\n",
      "batch_idx: 2 loss: 0.001522019473685418 R2: 0.9167026870115509 time: 1703121430.7535095\n",
      "batch_idx: 3 loss: 0.0008187090763002993 R2: 0.9166310454752422 time: 1703121434.2545068\n",
      "Training [71%] Loss: 0.0011250283294866202 time: 1703121434.2545068\n",
      "weight: [ 7.70086977e-01  8.66279137e-01  1.57972217e-01  5.94400631e-02\n",
      "  8.82607422e-01  1.51030964e+00  8.94463826e-01  4.35572803e-01\n",
      "  5.08700754e-01 -9.82219331e-04  1.76073977e-01  8.03227985e-01]\n",
      "epoch 143\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014352156733957002 R2: 0.9167049587418615 time: 1703121437.7712605\n",
      "batch_idx: 1 loss: 0.0007241147949949538 R2: 0.9167285321534422 time: 1703121441.1645837\n",
      "batch_idx: 2 loss: 0.001521979324224863 R2: 0.9167050571740557 time: 1703121444.7012758\n",
      "batch_idx: 3 loss: 0.0008186722690365293 R2: 0.9166334078861335 time: 1703121448.1228979\n",
      "Training [72%] Loss: 0.0011249955154130117 time: 1703121448.1228979\n",
      "weight: [ 7.70535362e-01  8.66498292e-01  1.58120210e-01  5.90025856e-02\n",
      "  8.82853900e-01  1.51056894e+00  8.94981651e-01  4.35987863e-01\n",
      "  5.08672163e-01 -1.06055102e-03  1.76040376e-01  8.03192892e-01]\n",
      "epoch 144\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014351909349837172 R2: 0.9167073360798226 time: 1703121451.5853229\n",
      "batch_idx: 1 loss: 0.0007240855634506542 R2: 0.9167309080309234 time: 1703121455.1766474\n",
      "batch_idx: 2 loss: 0.0015219392795149426 R2: 0.9167074171346398 time: 1703121458.7373545\n",
      "batch_idx: 3 loss: 0.000818635596024671 R2: 0.9166357601874383 time: 1703121462.1553416\n",
      "Training [72%] Loss: 0.0011249628434934964 time: 1703121462.1553416\n",
      "weight: [ 7.70982005e-01  8.66716794e-01  1.58267416e-01  5.85664351e-02\n",
      "  8.83099183e-01  1.51082698e+00  8.95499443e-01  4.36402955e-01\n",
      "  5.08643810e-01 -1.13880858e-03  1.76006800e-01  8.03157824e-01]\n",
      "epoch 145\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014351662451115282 R2: 0.9167097032064507 time: 1703121465.561427\n",
      "batch_idx: 1 loss: 0.0007240566085220172 R2: 0.9167332737067172 time: 1703121469.0600646\n",
      "batch_idx: 2 loss: 0.001521899339466054 R2: 0.9167097669747207 time: 1703121472.576261\n",
      "batch_idx: 3 loss: 0.0008185990573298284 R2: 0.9166381024595169 time: 1703121476.1577773\n",
      "Training [72%] Loss: 0.001124930312607357 time: 1703121476.1577773\n",
      "weight: [ 7.71426924e-01  8.66934646e-01  1.58413840e-01  5.81316042e-02\n",
      "  8.83343281e-01  1.51108379e+00  8.96017199e-01  4.36818078e-01\n",
      "  5.08615687e-01 -1.21699199e-03  1.75973249e-01  8.03122782e-01]\n",
      "epoch 146\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014351416020370591 R2: 0.9167120602029748 time: 1703121479.718062\n",
      "batch_idx: 1 loss: 0.00072402792756844 R2: 0.9167356292618377 time: 1703121483.183459\n",
      "batch_idx: 2 loss: 0.0015218595039880078 R2: 0.916712106774677 time: 1703121486.5393596\n",
      "batch_idx: 3 loss: 0.0008185626529985923 R2: 0.9166404347817453 time: 1703121489.8841634\n",
      "Training [73%] Loss: 0.0011248979216480247 time: 1703121489.8841634\n",
      "weight: [ 7.71870134e-01  8.67151851e-01  1.58559488e-01  5.76980855e-02\n",
      "  8.83586203e-01  1.51133936e+00  8.96534921e-01  4.37233230e-01\n",
      "  5.08587789e-01 -1.29510122e-03  1.75939722e-01  8.03087767e-01]\n",
      "epoch 147\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014351170040871862 R2: 0.9167144071495926 time: 1703121493.4322772\n",
      "batch_idx: 1 loss: 0.0007239995179552463 R2: 0.9167379747762807 time: 1703121496.9405344\n",
      "batch_idx: 2 loss: 0.0015218197729895404 R2: 0.9167144366138583 time: 1703121500.527526\n",
      "batch_idx: 3 loss: 0.0008185263830594262 R2: 0.9166427572325094 time: 1703121504.1793149\n",
      "Training [74%] Loss: 0.0011248656695228498 time: 1703121504.1793149\n",
      "weight: [ 7.72311651e-01  8.67368413e-01  1.58704365e-01  5.72658716e-02\n",
      "  8.83827958e-01  1.51159371e+00  8.97052607e-01  4.37648409e-01\n",
      "  5.08560111e-01 -1.37313626e-03  1.75906221e-01  8.03052777e-01]\n",
      "epoch 148\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014350924496551083 R2: 0.9167167441254996 time: 1703121508.0043118\n",
      "batch_idx: 1 loss: 0.0007239713770553305 R2: 0.9167403103290169 time: 1703121511.4291275\n",
      "batch_idx: 2 loss: 0.0015217801463779479 R2: 0.9167167565706096 time: 1703121514.928415\n",
      "batch_idx: 3 loss: 0.0008184902475229889 R2: 0.9166450698892469 time: 1703121518.4238405\n",
      "Training [74%] Loss: 0.0011248335551528438 time: 1703121518.4238405\n",
      "weight: [ 7.72751489e-01  8.67584336e-01  1.58848475e-01  5.68349552e-02\n",
      "  8.84068555e-01  1.51184684e+00  8.97570257e-01  4.38063615e-01\n",
      "  5.08532648e-01 -1.45109707e-03  1.75872744e-01  8.03017814e-01]\n",
      "epoch 149\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014350679371978882 R2: 0.9167190712089022 time: 1703121521.808754\n",
      "batch_idx: 1 loss: 0.0007239435022506982 R2: 0.9167426359980336 time: 1703121525.1833584\n",
      "batch_idx: 2 loss: 0.0015217406240587482 R2: 0.9167190667222955 time: 1703121528.6753588\n",
      "batch_idx: 3 loss: 0.0008184542463824954 R2: 0.9166473728284357 time: 1703121532.1978679\n",
      "Training [74%] Loss: 0.0011248015774724576 time: 1703121532.1978679\n",
      "weight: [ 0.77318966  0.86779962  0.15899182  0.05640533  0.884308    1.51209877\n",
      "  0.89808787  0.43847885  0.50850539 -0.00152898  0.17583929  0.80298288]\n",
      "epoch 150\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014350434652341147 R2: 0.916721388477035 time: 1703121535.6495633\n",
      "batch_idx: 1 loss: 0.0007239158909338923 R2: 0.9167449518603373 time: 1703121538.960133\n",
      "batch_idx: 2 loss: 0.0015217012059352945 R2: 0.9167213671453011 time: 1703121542.4913578\n",
      "batch_idx: 3 loss: 0.0008184183796140713 R2: 0.916649666125623 time: 1703121545.919009\n",
      "Training [75%] Loss: 0.0011247697354293431 time: 1703121545.919009\n",
      "weight: [ 0.77362619  0.86801428  0.15913442  0.05597699  0.88454632  1.5123495\n",
      "  0.89860545  0.4388941   0.50847834 -0.0016068   0.17580586  0.80294797]\n",
      "epoch 151\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014350190323416032 R2: 0.9167236960061741 time: 1703121549.2672179\n",
      "batch_idx: 1 loss: 0.0007238885405092956 R2: 0.9167472579919715 time: 1703121552.8645034\n",
      "batch_idx: 2 loss: 0.0015216618919085434 R2: 0.9167236579150566 time: 1703121556.257531\n",
      "batch_idx: 3 loss: 0.0008183826471771242 R2: 0.9166519498554363 time: 1703121559.6593518\n",
      "Training [76%] Loss: 0.0011247380279841416 time: 1703121559.6593518\n",
      "weight: [ 0.77406108  0.8682283   0.15927626  0.05554992  0.8847835   1.51259905\n",
      "  0.89912299  0.43930938  0.50845149 -0.00168453  0.17577246  0.80291308]\n",
      "epoch 152\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434994637155232 R2: 0.9167259938716571 time: 1703121563.2389023\n",
      "batch_idx: 1 loss: 0.0007238614483943233 R2: 0.9167495544680324 time: 1703121566.7421198\n",
      "batch_idx: 2 loss: 0.0015216226818767825 R2: 0.916725939106049 time: 1703121570.2060645\n",
      "batch_idx: 3 loss: 0.0008183470490146794 R2: 0.9166542240915934 time: 1703121573.5639014\n",
      "Training [76%] Loss: 0.0011247064541102542 time: 1703121573.5639014\n",
      "weight: [ 0.77449435  0.8684417   0.15941736  0.05512412  0.88501955  1.51284742\n",
      "  0.89964049  0.43972468  0.50842484 -0.0017622   0.17573909  0.80287823]\n",
      "epoch 153\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434970278364909 R2: 0.9167282821478879 time: 1703121576.9535484\n",
      "batch_idx: 1 loss: 0.0007238346120205115 R2: 0.9167518413626915 time: 1703121580.2969737\n",
      "batch_idx: 2 loss: 0.001521583575735373 R2: 0.916728210791845 time: 1703121583.841114\n",
      "batch_idx: 3 loss: 0.0008183115850538021 R2: 0.9166564889069176 time: 1703121587.45263\n",
      "Training [76%] Loss: 0.0011246750127936488 time: 1703121587.45263\n",
      "weight: [ 0.77492602  0.86865447  0.15955771  0.05469958  0.8852545   1.51309463\n",
      "  0.90015796  0.44013999  0.50839837 -0.00183979  0.17570573  0.80284339]\n",
      "epoch 154\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434945954713491 R2: 0.9167305609083677 time: 1703121590.9538894\n",
      "batch_idx: 1 loss: 0.0007238080288345368 R2: 0.9167541187491965 time: 1703121594.4591238\n",
      "batch_idx: 2 loss: 0.0015215445733765853 R2: 0.9167304730450935 time: 1703121597.9666748\n",
      "batch_idx: 3 loss: 0.000818276255205885 R2: 0.9166587443733508 time: 1703121601.459184\n",
      "Training [77%] Loss: 0.0011246437030326246 time: 1703121601.459184\n",
      "weight: [ 0.77535609  0.86886663  0.15969733  0.0542763   0.88548834  1.51334067\n",
      "  0.90067538  0.44055533  0.50837209 -0.0019173   0.17567241  0.80280859]\n",
      "epoch 155\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014349216649949905 R2: 0.9167328302256882 time: 1703121604.8779082\n",
      "batch_idx: 1 loss: 0.0007237816962991153 R2: 0.9167563866999014 time: 1703121608.3088233\n",
      "batch_idx: 2 loss: 0.0015215056746893676 R2: 0.9167327259375581 time: 1703121611.7830296\n",
      "batch_idx: 3 loss: 0.0008182410593670789 R2: 0.916660990561971 time: 1703121615.2273805\n",
      "Training [78%] Loss: 0.001124612523837638 time: 1703121615.2273805\n",
      "weight: [ 0.77578457  0.86907817  0.15983622  0.05385427  0.88572109  1.51358557\n",
      "  0.90119277  0.44097069  0.50834599 -0.00199474  0.1756391   0.80277381]\n",
      "epoch 156\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014348974080526393 R2: 0.9167350901715625 time: 1703121618.6177325\n",
      "batch_idx: 1 loss: 0.0007237556118938551 R2: 0.9167586452862663 time: 1703121622.0378752\n",
      "batch_idx: 2 loss: 0.0015214668795592334 R2: 0.9167349695401141 time: 1703121625.5556033\n",
      "batch_idx: 3 loss: 0.0008182059974186194 R2: 0.9166632275429963 time: 1703121629.0386622\n",
      "Training [78%] Loss: 0.0011245814742310868 time: 1703121629.0386622\n",
      "weight: [ 0.77621149  0.8692891   0.15997438  0.05343347  0.88595275  1.51382932\n",
      "  0.90171012  0.44138606  0.50832007 -0.00207211  0.17560583  0.80273906]\n",
      "epoch 157\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434873182777204 R2: 0.9167373408168368 time: 1703121632.4915245\n",
      "batch_idx: 1 loss: 0.0007237297731159818 R2: 0.9167608945788907 time: 1703121636.0141106\n",
      "batch_idx: 2 loss: 0.0015214281878681139 R2: 0.9167372039227656 time: 1703121639.5836787\n",
      "batch_idx: 3 loss: 0.0008181710692272054 R2: 0.9166654553858027 time: 1703121643.0367036\n",
      "Training [78%] Loss: 0.0011245505532471263 time: 1703121643.0367036\n",
      "weight: [ 0.77663685  0.86949941  0.16011182  0.05301391  0.88618334  1.51407195\n",
      "  0.90222742  0.44180144  0.50829432 -0.0021494   0.17557258  0.80270434]\n",
      "epoch 158\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014348489881052498 R2: 0.9167395822314918 time: 1703121646.3802075\n",
      "batch_idx: 1 loss: 0.0007237041774810764 R2: 0.9167631346475046 time: 1703121649.8592408\n",
      "batch_idx: 2 loss: 0.0015213895994941903 R2: 0.9167394291546758 time: 1703121653.2583246\n",
      "batch_idx: 3 loss: 0.0008181362746453632 R2: 0.9166676741589426 time: 1703121656.7343895\n",
      "Training [79%] Loss: 0.00112451975993147 time: 1703121656.7343895\n",
      "weight: [ 0.77706067  0.86970912  0.16024854  0.05259558  0.88641285  1.51431344\n",
      "  0.90274469  0.44221685  0.50826874 -0.00222662  0.17553935  0.80266964]\n",
      "epoch 159\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014348248230175587 R2: 0.9167418144846746 time: 1703121660.2666886\n",
      "batch_idx: 1 loss: 0.0007236788225236455 R2: 0.9167653655610003 time: 1703121663.7036397\n",
      "batch_idx: 2 loss: 0.0015213511143118814 R2: 0.9167416453041628 time: 1703121667.1571915\n",
      "batch_idx: 3 loss: 0.0008181016135117948 R2: 0.9166698839301402 time: 1703121670.6255503\n",
      "Training [80%] Loss: 0.0011244890933412202 time: 1703121670.6255503\n",
      "weight: [ 0.77748296  0.86991823  0.16038455  0.05217847  0.8866413   1.51455383\n",
      "  0.90326192  0.44263226  0.50824332 -0.00230376  0.17550615  0.80263497]\n",
      "epoch 160\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014348006865375366 R2: 0.9167440376446919 time: 1703121674.0759676\n",
      "batch_idx: 1 loss: 0.0007236537057977177 R2: 0.9167675873874389 time: 1703121677.614061\n",
      "batch_idx: 2 loss: 0.0015213127321916744 R2: 0.9167438524387139 time: 1703121681.0174122\n",
      "batch_idx: 3 loss: 0.0008180670856517429 R2: 0.9166720847663246 time: 1703121684.6289654\n",
      "Training [80%] Loss: 0.0011244585525446678 time: 1703121684.6289654\n",
      "weight: [ 0.77790372  0.87012674  0.16051986  0.05176257  0.8868687   1.5147931\n",
      "  0.9037791   0.44304768  0.50821807 -0.00238083  0.17547297  0.80260032]\n",
      "epoch 161\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014347765777297636 R2: 0.9167462517790452 time: 1703121687.9957554\n",
      "batch_idx: 1 loss: 0.0007236288248773147 R2: 0.9167698001940595 time: 1703121691.3637567\n",
      "batch_idx: 2 loss: 0.001521274453000116 R2: 0.9167460506250092 time: 1703121694.8365555\n",
      "batch_idx: 3 loss: 0.000818032690877338 R2: 0.9166742767336299 time: 1703121698.3028462\n",
      "Training [80%] Loss: 0.001124428136621133 time: 1703121698.3028462\n",
      "weight: [ 0.77832298  0.87033465  0.16065446  0.05134787  0.88709506  1.51503128\n",
      "  0.90429624  0.44346312  0.50819298 -0.00245782  0.17543983  0.8025657 ]\n",
      "epoch 162\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014347524956984964 R2: 0.9167484569544182 time: 1703121701.711221\n",
      "batch_idx: 1 loss: 0.0007236041773569412 R2: 0.9167720040473023 time: 1703121705.1006052\n",
      "batch_idx: 2 loss: 0.0015212362765997256 R2: 0.9167482399289295 time: 1703121708.5385158\n",
      "batch_idx: 3 loss: 0.000817998428987965 R2: 0.9166764598974024 time: 1703121711.9189079\n",
      "Training [81%] Loss: 0.0011243978446607821 time: 1703121711.9189079\n",
      "weight: [ 0.77874074  0.87054196  0.16078837  0.05093438  0.88732037  1.51526837\n",
      "  0.90481334  0.44387856  0.50816804 -0.00253474  0.1754067   0.80253111]\n",
      "epoch 163\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014347284395863583 R2: 0.9167506532367125 time: 1703121715.3489013\n",
      "batch_idx: 1 loss: 0.0007235797608519314 R2: 0.916774199012808 time: 1703121718.8005724\n",
      "batch_idx: 2 loss: 0.0015211982028489612 R2: 0.9167504204155627 time: 1703121722.411505\n",
      "batch_idx: 3 loss: 0.0008179642997705917 R2: 0.9166786343222245 time: 1703121725.9148703\n",
      "Training [82%] Loss: 0.0011243676757644607 time: 1703121725.9148703\n",
      "weight: [ 0.77915701  0.87074869  0.16092158  0.05052208  0.88754466  1.51550437\n",
      "  0.9053304   0.44429402  0.50814326 -0.00261159  0.1753736   0.80249655]\n",
      "epoch 164\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014347044085729198 R2: 0.9167528406910405 time: 1703121729.4105334\n",
      "batch_idx: 1 loss: 0.0007235555729988457 R2: 0.91677638515545 time: 1703121732.9559453\n",
      "batch_idx: 2 loss: 0.001521160231602189 R2: 0.9167525921492287 time: 1703121736.3979127\n",
      "batch_idx: 3 loss: 0.0008179303030001224 R2: 0.9166808000719218 time: 1703121739.7822826\n",
      "Training [82%] Loss: 0.0011243376290435193 time: 1703121739.7822826\n",
      "weight: [ 0.77957181  0.87095482  0.1610541   0.05011097  0.88776792  1.5157393\n",
      "  0.90584741  0.44470948  0.50811863 -0.00268836  0.17534053  0.80246201]\n",
      "epoch 165\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014346804018735234 R2: 0.9167550193817531 time: 1703121743.2705228\n",
      "batch_idx: 1 loss: 0.0007235316114557451 R2: 0.9167785625393208 time: 1703121746.7966702\n",
      "batch_idx: 2 loss: 0.001521122362709673 R2: 0.91675475519348 time: 1703121750.123743\n",
      "batch_idx: 3 loss: 0.0008178964384397393 R2: 0.9166829572095686 time: 1703121753.576534\n",
      "Training [82%] Loss: 0.0011243077036196703 time: 1703121753.576534\n",
      "weight: [ 0.77998514  0.87116038  0.16118594  0.04970104  0.88799017  1.51597317\n",
      "  0.90636438  0.44512494  0.50809414 -0.00276505  0.17530748  0.8024275 ]\n",
      "epoch 166\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014346564187379556 R2: 0.9167571893724411 time: 1703121757.1399734\n",
      "batch_idx: 1 loss: 0.000723507873902477 R2: 0.9167807312277617 time: 1703121760.5902493\n",
      "batch_idx: 2 loss: 0.0015210845960175463 R2: 0.9167569096111221 time: 1703121764.03981\n",
      "batch_idx: 3 loss: 0.0008178627058412361 R2: 0.9166851057975041 time: 1703121767.4492478\n",
      "Training [83%] Loss: 0.0011242778986248038 time: 1703121767.4492478\n",
      "weight: [ 0.78039702  0.87136535  0.1613171   0.04929229  0.88821142  1.51620598\n",
      "  0.9068813   0.44554041  0.5080698  -0.00284167  0.17527446  0.80239302]\n",
      "epoch 167\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014346324584493192 R2: 0.9167593507259525 time: 1703121770.9796429\n",
      "batch_idx: 1 loss: 0.0007234843580408912 R2: 0.9167828912833758 time: 1703121774.4858513\n",
      "batch_idx: 2 loss: 0.0015210469313678553 R2: 0.9167590554642123 time: 1703121777.820873\n",
      "batch_idx: 3 loss: 0.0008178291049453435 R2: 0.9166872458973451 time: 1703121781.33871\n",
      "Training [84%] Loss: 0.0011242482132008522 time: 1703121781.33871\n",
      "weight: [ 0.78080745  0.87156974  0.16144759  0.0488847   0.88843167  1.51643773\n",
      "  0.90739817  0.44595589  0.5080456  -0.00291822  0.17524147  0.80235856]\n",
      "epoch 168\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014346085203228718 R2: 0.9167615035043953 time: 1703121784.7044702\n",
      "batch_idx: 1 loss: 0.0007234610615950456 R2: 0.9167850427680261 time: 1703121788.3901463\n",
      "batch_idx: 2 loss: 0.0015210093685985074 R2: 0.9167611928140976 time: 1703121791.991903\n",
      "batch_idx: 3 loss: 0.0008177956354820653 R2: 0.9166893775699935 time: 1703121795.6659753\n",
      "Training [84%] Loss: 0.0011242186464996225 time: 1703121795.6659753\n",
      "weight: [ 0.78121645  0.87177356  0.1615774   0.04847827  0.88865092  1.51666845\n",
      "  0.907915    0.44637137  0.50802153 -0.00299469  0.1752085   0.80232414]\n",
      "epoch 169\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014345846037049363 R2: 0.9167636477691637 time: 1703121799.0578327\n",
      "batch_idx: 1 loss: 0.000723437982311339 R2: 0.9167871857428558 time: 1703121802.7595863\n",
      "batch_idx: 2 loss: 0.0015209719075433472 R2: 0.9167633217213906 time: 1703121806.3527167\n",
      "batch_idx: 3 loss: 0.0008177622971709981 R2: 0.9166915008756439 time: 1703121809.7724915\n",
      "Training [84%] Loss: 0.0011241891976826552 time: 1703121809.7724915\n",
      "weight: [ 0.78162402  0.8719768   0.16170655  0.048073    0.88886919  1.51689813\n",
      "  0.90843179  0.44678685  0.50799761 -0.00307108  0.17517555  0.80228974]\n",
      "epoch 170\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014345607079718126 R2: 0.9167657835809339 time: 1703121813.305197\n",
      "batch_idx: 1 loss: 0.0007234151179586841 R2: 0.9167893202683015 time: 1703121816.7925725\n",
      "batch_idx: 2 loss: 0.0015209345480321386 R2: 0.9167654422460115 time: 1703121820.2767243\n",
      "batch_idx: 3 loss: 0.0008177290897216419 R2: 0.9166936158738064 time: 1703121823.8416824\n",
      "Training [85%] Loss: 0.0011241598659210692 time: 1703121823.8416824\n",
      "weight: [ 0.78203018  0.87217947  0.16183504  0.04766888  0.88908649  1.51712678\n",
      "  0.90894852  0.44720233  0.50797381 -0.00314741  0.17514263  0.80225536]\n",
      "epoch 171\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434536832528802 R2: 0.9167679109996817 time: 1703121827.3146594\n",
      "batch_idx: 1 loss: 0.0007233924663285599 R2: 0.9167914464040965 time: 1703121830.8217897\n",
      "batch_idx: 2 loss: 0.0015208972898906295 R2: 0.9167675544471775 time: 1703121834.3867192\n",
      "batch_idx: 3 loss: 0.0008176960128337323 R2: 0.916695722623302 time: 1703121837.8701847\n",
      "Training [86%] Loss: 0.001124130650395431 time: 1703121837.8701847\n",
      "weight: [ 0.78243493  0.87238158  0.16196287  0.0472659   0.88930282  1.51735441\n",
      "  0.90946521  0.44761781  0.50795015 -0.00322365  0.17510974  0.80222101]\n",
      "epoch 172\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014345129768091602 R2: 0.9167700300846965 time: 1703121841.4800656\n",
      "batch_idx: 1 loss: 0.0007233700252351138 R2: 0.9167935642092907 time: 1703121844.9871235\n",
      "batch_idx: 2 loss: 0.0015208601329405652 R2: 0.9167696583834297 time: 1703121848.6140041\n",
      "batch_idx: 3 loss: 0.0008176630661975149 R2: 0.9166978211822773 time: 1703121852.0634682\n",
      "Training [86%] Loss: 0.0011241015502955886 time: 1703121852.0634682\n",
      "weight: [ 0.78283829  0.87258312  0.16209005  0.04686406  0.88951818  1.51758103\n",
      "  0.90998185  0.44803328  0.50792662 -0.00329982  0.17507687  0.8021867 ]\n",
      "epoch 173\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014344891402732127 R2: 0.9167721408945793 time: 1703121855.5111995\n",
      "batch_idx: 1 loss: 0.0007233477925152046 R2: 0.9167956737422512 time: 1703121859.0242686\n",
      "batch_idx: 2 loss: 0.0015208230769997403 R2: 0.9167717541126296 time: 1703121862.440487\n",
      "batch_idx: 3 loss: 0.0008176302494940913 R2: 0.9166999116082207 time: 1703121866.1565084\n",
      "Training [86%] Loss: 0.0011240725648205621 time: 1703121866.1565084\n",
      "weight: [ 0.78324026  0.8727841   0.16221658  0.04646335  0.88973259  1.51780664\n",
      "  0.91049844  0.44844876  0.50790322 -0.00337592  0.17504403  0.8021524 ]\n",
      "epoch 174\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014344653224073944 R2: 0.9167742434872677 time: 1703121869.6670845\n",
      "batch_idx: 1 loss: 0.0007233257660284103 R2: 0.9167977750606783 time: 1703121873.2169151\n",
      "batch_idx: 2 loss: 0.0015207861218820547 R2: 0.9167738416919773 time: 1703121876.6534224\n",
      "batch_idx: 3 loss: 0.0008175975623956732 R2: 0.9167019939579714 time: 1703121880.0720074\n",
      "Training [87%] Loss: 0.001124043693178383 time: 1703121880.0720074\n",
      "weight: [ 0.78364085  0.87298453  0.16234247  0.04606376  0.88994605  1.51803126\n",
      "  0.91101498  0.44886423  0.50787995 -0.00345194  0.17501122  0.80211814]\n",
      "epoch 175\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014344415227233705 R2: 0.9167763379200361 time: 1703121883.526606\n",
      "batch_idx: 1 loss: 0.0007233039436570712 R2: 0.9167998682216153 time: 1703121886.9370453\n",
      "batch_idx: 2 loss: 0.0015207492673975577 R2: 0.9167759211780233 time: 1703121890.420289\n",
      "batch_idx: 3 loss: 0.0008175650045659127 R2: 0.916704068287714 time: 1703121894.0085876\n",
      "Training [88%] Loss: 0.001124014934585978 time: 1703121894.0085876\n",
      "weight: [ 0.78404008  0.8731844   0.16246771  0.0456653   0.89015858  1.51825489\n",
      "  0.91153146  0.4492797   0.5078568  -0.00352789  0.17497843  0.8020839 ]\n",
      "epoch 176\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434417740757196 R2: 0.916778424249513 time: 1703121897.5376356\n",
      "batch_idx: 1 loss: 0.0007232823233062198 R2: 0.9168019532814556 time: 1703121900.9549305\n",
      "batch_idx: 2 loss: 0.0015207125133525038 R2: 0.9167779926266716 time: 1703121904.4593992\n",
      "batch_idx: 3 loss: 0.0008175325756601658 R2: 0.916706134653006 time: 1703121907.9657803\n",
      "Training [88%] Loss: 0.0011239862882690213 time: 1703121907.9657803\n",
      "weight: [ 0.78443795  0.87338371  0.16259233  0.04526794  0.89037016  1.51847753\n",
      "  0.9120479   0.44969516  0.50783377 -0.00360376  0.17494567  0.80204969]\n",
      "epoch 177\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434393976068482 R2: 0.9167805025316748 time: 1703121911.4047763\n",
      "batch_idx: 1 loss: 0.0007232609029036023 R2: 0.9168040302959579 time: 1703121914.6539397\n",
      "batch_idx: 2 loss: 0.00152067585954942 R2: 0.9167800560931962 time: 1703121918.3195403\n",
      "batch_idx: 3 loss: 0.000817500275325787 R2: 0.9167081931087843 time: 1703121921.7260032\n",
      "Training [88%] Loss: 0.001123957753461823 time: 1703121921.7260032\n",
      "weight: [ 0.78483447  0.87358248  0.16271631  0.04487169  0.89058082  1.5186992\n",
      "  0.91256429  0.45011062  0.50781086 -0.00367956  0.17491293  0.80201551]\n",
      "epoch 178\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014343702282396129 R2: 0.9167825728218814 time: 1703121925.211102\n",
      "batch_idx: 1 loss: 0.0007232396803995789 R2: 0.9168060993202485 time: 1703121928.6043007\n",
      "batch_idx: 2 loss: 0.0015206393057871658 R2: 0.9167821116322431 time: 1703121932.258879\n",
      "batch_idx: 3 loss: 0.000817468103202398 R2: 0.9167102437093616 time: 1703121935.7505653\n",
      "Training [89%] Loss: 0.0011239293294071889 time: 1703121935.7505653\n",
      "weight: [ 0.78522964  0.8737807   0.16283966  0.04447655  0.89079056  1.51891989\n",
      "  0.91308062  0.45052607  0.50778807 -0.00375528  0.17488023  0.80198136]\n",
      "epoch 179\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014343464968749556 R2: 0.9167846351748621 time: 1703121939.021446\n",
      "batch_idx: 1 loss: 0.0007232186537670817 R2: 0.9168081604088355 time: 1703121942.513649\n",
      "batch_idx: 2 loss: 0.0015206028518610123 R2: 0.9167841592978462 time: 1703121946.043325\n",
      "batch_idx: 3 loss: 0.0008174360589221811 R2: 0.9167122865084553 time: 1703121949.4207103\n",
      "Training [90%] Loss: 0.0011239010153563077 time: 1703121949.4207103\n",
      "weight: [ 0.78562348  0.87397837  0.16296239  0.0440825   0.89099939  1.51913963\n",
      "  0.9135969   0.45094151  0.5077654  -0.00383093  0.17484754  0.80194723]\n",
      "epoch 180\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434322781600123 R2: 0.9167866896447296 time: 1703121952.9665198\n",
      "batch_idx: 1 loss: 0.0007231978210015292 R2: 0.9168102136156197 time: 1703121956.4680917\n",
      "batch_idx: 2 loss: 0.0015205664975626902 R2: 0.916786199143432 time: 1703121959.8886988\n",
      "batch_idx: 3 loss: 0.0008174041421101024 R2: 0.9167143215591695 time: 1703121963.312938\n",
      "Training [90%] Loss: 0.001123872810568611 time: 1703121963.312938\n",
      "weight: [ 0.786016    0.87417551  0.1630845   0.04368954  0.89120731  1.51935841\n",
      "  0.91411313  0.45135694  0.50774285 -0.0039065   0.17481489  0.80191313]\n",
      "epoch 181\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014342990820612783 R2: 0.9167887362850046 time: 1703121966.7345123\n",
      "batch_idx: 1 loss: 0.0007231771801207221 R2: 0.9168122589938991 time: 1703121970.1426144\n",
      "batch_idx: 2 loss: 0.0015205302426804757 R2: 0.9167882312218388 time: 1703121973.6090002\n",
      "batch_idx: 3 loss: 0.0008173723523842357 R2: 0.9167163489140362 time: 1703121977.2741067\n",
      "Training [90%] Loss: 0.0011238447143116779 time: 1703121977.2741067\n",
      "weight: [ 0.7864072   0.8743721   0.163206    0.04329766  0.89141433  1.51957624\n",
      "  0.9146293   0.45177236  0.50772041 -0.003982    0.17478226  0.80187906]\n",
      "epoch 182\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014342753979244205 R2: 0.9167907751485999 time: 1703121980.852943\n",
      "batch_idx: 1 loss: 0.0007231567291647465 R2: 0.9168142965963723 time: 1703121984.4544315\n",
      "batch_idx: 2 loss: 0.001520494086999273 R2: 0.9167902555853068 time: 1703121987.932703\n",
      "batch_idx: 3 loss: 0.0008173406893559672 R2: 0.916718368624997 time: 1703121991.4921093\n",
      "Training [91%] Loss: 0.0011238167258611018 time: 1703121991.4921093\n",
      "weight: [ 0.78679709  0.87456816  0.16332689  0.04290686  0.89162046  1.51979313\n",
      "  0.91514542  0.45218777  0.50769809 -0.00405742  0.17474965  0.80184501]\n",
      "epoch 183\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014342517288747122 R2: 0.9167928062878538 time: 1703121994.8306925\n",
      "batch_idx: 1 loss: 0.0007231364661958378 R2: 0.9168163264751696 time: 1703121998.440429\n",
      "batch_idx: 2 loss: 0.001520458030300666 R2: 0.9167922722855041 time: 1703122001.9752126\n",
      "batch_idx: 3 loss: 0.0008173091526302752 R2: 0.9167203807434217 time: 1703122005.5188844\n",
      "Training [92%] Loss: 0.0011237888445003728 time: 1703122005.5188844\n",
      "weight: [ 0.78718569  0.87476369  0.16344717  0.04251713  0.89182569  1.52000908\n",
      "  0.91566148  0.45260317  0.50767588 -0.00413277  0.17471707  0.801811  ]\n",
      "epoch 184\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014342280746158392 R2: 0.9167948297545164 time: 1703122009.0601115\n",
      "batch_idx: 1 loss: 0.0007231163892982722 R2: 0.916818348681829 time: 1703122012.4881449\n",
      "batch_idx: 2 loss: 0.0015204220723630218 R2: 0.916794281373526 time: 1703122015.9547844\n",
      "batch_idx: 3 loss: 0.0008172777418059716 R2: 0.9167223853201218 time: 1703122019.5774667\n",
      "Training [92%] Loss: 0.0011237610695207763 time: 1703122019.5774667\n",
      "weight: [ 0.78757299  0.87495868  0.16356684  0.04212848  0.89203005  1.5202241\n",
      "  0.91617748  0.45301855  0.50765378 -0.00420805  0.17468452  0.80177701]\n",
      "epoch 185\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014342044348693913 R2: 0.9167968455997754 time: 1703122023.045131\n",
      "batch_idx: 1 loss: 0.0007230964965781949 R2: 0.9168203632673337 time: 1703122026.6176198\n",
      "batch_idx: 2 loss: 0.0015203862129615612 R2: 0.9167962828999047 time: 1703122029.9893496\n",
      "batch_idx: 3 loss: 0.0008172464564759306 R2: 0.9167243824053489 time: 1703122033.6608098\n",
      "Training [92%] Loss: 0.0011237334002212696 time: 1703122033.6608098\n",
      "weight: [ 0.787959    0.87515315  0.16368592  0.04174088  0.89223353  1.5204382\n",
      "  0.91669343  0.45343392  0.50763179 -0.00428324  0.174652    0.80174305]\n",
      "epoch 186\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014341808093742564 R2: 0.9167988538742492 time: 1703122037.065352\n",
      "batch_idx: 1 loss: 0.0007230767861635126 R2: 0.916822370282105 time: 1703122040.4613028\n",
      "batch_idx: 2 loss: 0.0015203504518684218 R2: 0.9167982769146252 time: 1703122044.0073104\n",
      "batch_idx: 3 loss: 0.0008172152962273577 R2: 0.9167263720488122 time: 1703122047.442305\n",
      "Training [93%] Loss: 0.001123705835908387 time: 1703122047.442305\n",
      "weight: [ 0.78834374  0.87534709  0.16380441  0.04135434  0.89243615  1.52065139\n",
      "  0.91720932  0.45384928  0.50760991 -0.00435837  0.1746195   0.80170912]\n",
      "epoch 187\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014341571978859935 R2: 0.9168008546280136 time: 1703122050.8122315\n",
      "batch_idx: 1 loss: 0.000723057256203692 R2: 0.916824369776014 time: 1703122054.2446828\n",
      "batch_idx: 2 loss: 0.0015203147888527813 R2: 0.9168002634671227 time: 1703122057.7911546\n",
      "batch_idx: 3 loss: 0.0008171842606419793 R2: 0.9167283542996703 time: 1703122061.3360052\n",
      "Training [94%] Loss: 0.0011236783758961115 time: 1703122061.3360052\n",
      "weight: [ 0.78872721  0.87554051  0.1639223   0.04096884  0.8926379   1.52086367\n",
      "  0.91772516  0.45426462  0.50758815 -0.00443341  0.17458703  0.80167521]\n",
      "epoch 188\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434133600176346 R2: 0.9168028479105897 time: 1703122064.6592445\n",
      "batch_idx: 1 loss: 0.0007230379048696201 R2: 0.9168263617983902 time: 1703122068.1409116\n",
      "batch_idx: 2 loss: 0.0015202792236808775 R2: 0.9168022426062932 time: 1703122071.5882156\n",
      "batch_idx: 3 loss: 0.0008171533492963215 R2: 0.9167303292065642 time: 1703122074.9420013\n",
      "Training [94%] Loss: 0.0011236510195057913 time: 1703122074.9420013\n",
      "weight: [ 0.78910942  0.87573341  0.16403961  0.0405844   0.89283879  1.52107504\n",
      "  0.91824093  0.45467995  0.50756649 -0.00450839  0.17455459  0.80164133]\n",
      "epoch 189\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014341100160325888 R2: 0.916804833770968 time: 1703122078.4160907\n",
      "batch_idx: 1 loss: 0.0007230187303534348 R2: 0.9168283463980252 time: 1703122081.8716521\n",
      "batch_idx: 2 loss: 0.0015202437561161622 R2: 0.9168042143805037 time: 1703122085.3518183\n",
      "batch_idx: 3 loss: 0.0008171225617618742 R2: 0.9167322968175993 time: 1703122088.758976\n",
      "Training [94%] Loss: 0.001123623766066015 time: 1703122088.758976\n",
      "weight: [ 0.78949038  0.87592579  0.16415633  0.04020099  0.89303883  1.52128552\n",
      "  0.91875665  0.45509526  0.50754494 -0.00458329  0.17452217  0.80160748]\n",
      "epoch 190\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014340864452571233 R2: 0.9168068122576045 time: 1703122092.0938637\n",
      "batch_idx: 1 loss: 0.0007229997308683341 R2: 0.9168303236231881 time: 1703122095.6782222\n",
      "batch_idx: 2 loss: 0.0015202083859193177 R2: 0.9168061788376021 time: 1703122099.1819973\n",
      "batch_idx: 3 loss: 0.0008170918976053614 R2: 0.9167342571803705 time: 1703122102.4563808\n",
      "Training [95%] Loss: 0.0011235966149125342 time: 1703122102.4563808\n",
      "weight: [ 0.78987009  0.87611766  0.16427247  0.03981862  0.89323803  1.5214951\n",
      "  0.9192723   0.45551055  0.5075235  -0.00465811  0.17448978  0.80157366]\n",
      "epoch 191\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014340628876668266 R2: 0.9168087834184332 time: 1703122106.0568469\n",
      "batch_idx: 1 loss: 0.0007229809046484023 R2: 0.9168322935216272 time: 1703122109.7741401\n",
      "batch_idx: 2 loss: 0.0015201731128483907 R2: 0.9168081360249177 time: 1703122113.2803686\n",
      "batch_idx: 3 loss: 0.0008170613563889208 R2: 0.916736210341958 time: 1703122116.6693087\n",
      "Training [96%] Loss: 0.0011235695653881352 time: 1703122116.6693087\n",
      "weight: [ 0.79024855  0.87630901  0.16438804  0.03943728  0.89343639  1.5217038\n",
      "  0.9197879   0.45592582  0.50750216 -0.00473286  0.17445741  0.80153987]\n",
      "epoch 192\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014340393430926739 R2: 0.9168107473008777 time: 1703122120.253698\n",
      "batch_idx: 1 loss: 0.0007229622499484039 R2: 0.9168342561405757 time: 1703122123.6960962\n",
      "batch_idx: 2 loss: 0.0015201379366588407 R2: 0.9168100859892785 time: 1703122127.1144185\n",
      "batch_idx: 3 loss: 0.0008170309376703338 R2: 0.916738156348943 time: 1703122130.6367455\n",
      "Training [96%] Loss: 0.001123542616842563 time: 1703122130.6367455\n",
      "weight: [ 0.79062579  0.87649986  0.16450304  0.03905696  0.89363392  1.52191163\n",
      "  0.92030343  0.45634107  0.50748093 -0.00480753  0.17442507  0.80150611]\n",
      "epoch 193\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001434015811379165 R2: 0.9168127039518484 time: 1703122134.1999228\n",
      "batch_idx: 1 loss: 0.0007229437650436291 R2: 0.9168362115267709 time: 1703122137.6748524\n",
      "batch_idx: 2 loss: 0.001520102857103649 R2: 0.9168120287770083 time: 1703122141.1178744\n",
      "batch_idx: 3 loss: 0.0008170006410032078 R2: 0.9167400952474181 time: 1703122144.5928252\n",
      "Training [96%] Loss: 0.0011235157686324128 time: 1703122144.5928252\n",
      "weight: [ 0.7910018   0.87669019  0.16461747  0.03867766  0.89383062  1.52211858\n",
      "  0.9208189   0.4567563   0.50745981 -0.00488213  0.17439276  0.80147237]\n",
      "epoch 194\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014339922923839335 R2: 0.9168146534177598 time: 1703122147.9512544\n",
      "batch_idx: 1 loss: 0.0007229254482296423 R2: 0.9168381597264398 time: 1703122151.3694422\n",
      "batch_idx: 2 loss: 0.0015200678739333796 R2: 0.9168139644339407 time: 1703122154.8798637\n",
      "batch_idx: 3 loss: 0.0008169704659371938 R2: 0.9167420270829691 time: 1703122158.5024655\n",
      "Training [97%] Loss: 0.0011234890201210373 time: 1703122158.5024655\n",
      "weight: [ 0.7913766   0.87688002  0.16473133  0.03829937  0.8940265   1.52232466\n",
      "  0.92133432  0.45717151  0.50743879 -0.00495665  0.17436048  0.80143866]\n",
      "epoch 195\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014339687859772276 R2: 0.9168165957445303 time: 1703122161.9806008\n",
      "batch_idx: 1 loss: 0.0007229072978221444 R2: 0.9168401007853314 time: 1703122165.4605634\n",
      "batch_idx: 2 loss: 0.001520032986896277 R2: 0.9168158930054157 time: 1703122168.933779\n",
      "batch_idx: 3 loss: 0.0008169404120181771 R2: 0.916743951900718 time: 1703122172.286699\n",
      "Training [98%] Loss: 0.0011234623706784567 time: 1703122172.286699\n",
      "weight: [ 0.79175018  0.87706935  0.16484464  0.03792209  0.89422157  1.52252988\n",
      "  0.92184966  0.4575867   0.50741788 -0.0050311   0.17432822  0.80140498]\n",
      "epoch 196\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014339452920415273 R2: 0.9168185309775934 time: 1703122175.7502606\n",
      "batch_idx: 1 loss: 0.0007228893121566996 R2: 0.9168420347487054 time: 1703122179.2408206\n",
      "batch_idx: 2 loss: 0.001519998195738348 R2: 0.9168178145363074 time: 1703122182.7369316\n",
      "batch_idx: 3 loss: 0.0008169104787884537 R2: 0.9167458697453045 time: 1703122186.1648283\n",
      "Training [98%] Loss: 0.0011234358196812572 time: 1703122186.1648283\n",
      "weight: [ 0.79212256  0.87725818  0.16495738  0.03754582  0.89441582  1.52273425\n",
      "  0.92236495  0.45800187  0.50739708 -0.00510547  0.17429599  0.80137133]\n",
      "epoch 197\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014339218104710814 R2: 0.9168204591618986 time: 1703122189.7045102\n",
      "batch_idx: 1 loss: 0.0007228714895886022 R2: 0.9168439616613424 time: 1703122193.2287602\n",
      "batch_idx: 2 loss: 0.0015199635002034358 R2: 0.9168197290710085 time: 1703122196.6999896\n",
      "batch_idx: 3 loss: 0.0008168806657869451 R2: 0.9167477806609033 time: 1703122200.3284094\n",
      "Training [98%] Loss: 0.0011234093665125162 time: 1703122200.3284094\n",
      "weight: [ 0.79249374  0.87744652  0.16506958  0.03717054  0.89460927  1.52293777\n",
      "  0.92288017  0.45841701  0.50737637 -0.00517977  0.17426379  0.8013377 ]\n",
      "epoch 198\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014338983411715093 R2: 0.9168223803419326 time: 1703122203.8271062\n",
      "batch_idx: 1 loss: 0.0007228538284926027 R2: 0.9168458815675592 time: 1703122207.271527\n",
      "batch_idx: 2 loss: 0.0015199289000333099 R2: 0.9168216366534507 time: 1703122210.8648894\n",
      "batch_idx: 3 loss: 0.0008168509725493392 R2: 0.9167496846912252 time: 1703122214.3514729\n",
      "Training [99%] Loss: 0.0011233830105616903 time: 1703122214.3514729\n",
      "weight: [ 0.79286373  0.87763435  0.16518122  0.03679626  0.89480192  1.52314045\n",
      "  0.92339533  0.45883213  0.50735578 -0.00525399  0.17423161  0.80130411]\n",
      "epoch 199\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014338748840594313 R2: 0.9168242945617064 time: 1703122217.8696036\n",
      "batch_idx: 1 loss: 0.000722836327262749 R2: 0.9168477945112047 time: 1703122221.5121613\n",
      "batch_idx: 2 loss: 0.0015198943949677305 R2: 0.9168235373270998 time: 1703122225.0592601\n",
      "batch_idx: 3 loss: 0.0008168213986083186 R2: 0.9167515818795238 time: 1703122228.4573696\n",
      "Training [100%] Loss: 0.0011233567512245574 time: 1703122228.4573696\n",
      "weight: [ 0.79323254  0.8778217   0.16529232  0.03642297  0.89499378  1.52334229\n",
      "  0.92391042  0.45924723  0.50733529 -0.00532814  0.17419946  0.80127054]\n",
      "epoch 200\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00143385143906203 R2: 0.9168262018647735 time: 1703122231.7796805\n",
      "batch_idx: 1 loss: 0.0007228189843121306 R2: 0.9168497005356725 time: 1703122235.2310894\n",
      "batch_idx: 2 loss: 0.0015198599847445601 R2: 0.916825431134981 time: 1703122238.7275302\n",
      "batch_idx: 3 loss: 0.0008167919434936821 R2: 0.9167534722686101 time: 1703122242.1064246\n",
      "Training [100%] Loss: 0.0011233305879031008 time: 1703122242.1064246\n",
      "weight: [ 0.79360017  0.87800855  0.16540288  0.03605066  0.89518485  1.52354329\n",
      "  0.92442544  0.45966229  0.5073149  -0.00540221  0.17416734  0.801237  ]\n",
      "train_MSE: 0.0011297152521731462\n",
      "train_RMSE: 0.0336112369926063\n",
      "train_MAE: 0.027342318922649284\n",
      "train_MAPE: 0.05976060734088151\n",
      "train_R2: 0.9167534722686101\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/UAAAIhCAYAAAAPY5p0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXJUlEQVR4nO3deXwU9eH/8fde2ZyEI5BDICAVEDnksIBWIx5Uq1i1VileqEWU0oqtpSIqwVJRVOrPUqVVRPGrBfpT1IpU6BdBLaBBQRD9AZUrlUuuJEDYJLuf3x/JTrK5SDCwmdnX8/GdB7szn5n5zGa+bd/zOcZljDECAAAAAAC24452BQAAAAAAwIkh1AMAAAAAYFOEegAAAAAAbIpQDwAAAACATRHqAQAAAACwKUI9AAAAAAA2RagHAAAAAMCmCPUAAAAAANgUoR4AAAAAAJsi1AMAbO2ll16Sy+WSy+XSsmXLamw3xuh73/ueXC6XLrzwwoht+/fv14QJE9SjRw8lJSUpNTVV3bt3180336x169bVeo7altrOezLl5ubK5XKd0nM2BxdeeGGNv2FTevbZZ/XSSy+dtOOfap06ddKVV14Z7WoAAE4yb7QrAABAU0hJSdGsWbNqhL7ly5fr66+/VkpKSsT6w4cPa9CgQTp8+LB++9vfqk+fPiouLtamTZv0xhtvaO3aterdu3fEPrNnz1b37t1rnLtHjx5Nfj2o6dlnnz3px09LS9PIkSNP6nkAAGhKhHoAgCPccMMNevXVV/XnP/9ZLVq0sNbPmjVLgwcPVmFhYUT5v//97/rPf/6jpUuXasiQIRHbfv3rXysUCtU4R8+ePTVgwICTcwE4Lh6eAABQE93vAQCO8LOf/UyS9Le//c1aV1BQoNdff1233357jfL79++XJGVmZtZ6PLe7af4rcty4cUpKSqrxUEEqfxCRnp6u0tJSSdK8efM0dOhQZWZmKiEhQWeeeabuv/9+HTly5Ljncblcys3NrbG+U6dONVqed+/erdGjR6t9+/aKi4tT586dNXnyZJWVlR33PI2p4/PPP6+uXbvK7/erR48eeu211zRy5Eh16tQpotzkyZM1cOBAtW7dWi1atFC/fv00a9YsGWMiylXvfr9t2za5XC49+eSTmj59ujp37qzk5GQNHjxYq1atith3y5YtGj58uLKysuT3+5Wenq6LL75Ya9eutX6nDRs2aPny5dawiur1rM4Yo2effVZnn322EhIS1KpVK1133XXasmVLjXr37NlTH374oQYNGqSEhASddtppeuihhxQMBiPKHjhwQGPGjNFpp52muLg4nX766Zo4caICgUBEuVAopD/96U/WuVu2bKlBgwbp7bffrlHPf/7zn+rXr58SEhLUvXt3vfjii/VeFwDAXgj1AABHaNGiha677rqIwPK3v/1NbrdbN9xwQ43ygwcPliTdcsstevPNN62QX59gMKiysrKIpXooq+7222/X0aNHNX/+/Ij1hw4d0ltvvaWbbrpJPp9PkrR582b96Ec/0qxZs/TPf/5T48aN0/z58zVs2LDj1q2hdu/ere9///t677339PDDD2vRokW64447NHXqVI0aNeq4+ze0jn/961915513qnfv3nrjjTf04IMPavLkybXOP7Bt2zaNHj1a8+fP1xtvvKFrr71Wv/zlL/X73/++Qdf05z//WUuWLNHTTz+tV199VUeOHNGPfvQjFRQUWGV+9KMf6dNPP9W0adO0ZMkSPffcc+rbt68OHTokSVqwYIFOP/109e3bVytXrtTKlSu1YMGCes87evRojRs3TpdcconefPNNPfvss9qwYYPOPfdc7dmzJ6Ls7t27NXz4cN1444166623dN1112nKlCm65557rDLHjh3TkCFDNGfOHP3617/WwoULddNNN2natGm69tprI443cuRI3XPPPTrnnHM0b948zZ07V1dddZW2bdsWUe7zzz/Xb37zG917771666231Lt3b91xxx364IMPGvTbAgBswAAAYGOzZ882kkxeXp55//33jSTzxRdfGGOMOeecc8zIkSONMcacddZZJicnJ2LfRx55xMTFxRlJRpLp3Lmzueuuu8znn39e6zlqWzwez3Hr2K9fP3PuuedGrHv22WeNJLN+/fpa9wmFQqa0tNQsX77cSIqo06RJk0z1/wqXZCZNmlTjONnZ2ebWW2+1vo8ePdokJyeb7du3R5R78sknjSSzYcOG417P8eoYDAZNRkaGGThwYET57du3G5/PZ7Kzs+s8ZjAYNKWlpeaRRx4xbdq0MaFQyNqWk5MT8TfcunWrkWR69eplysrKrPWffPKJkWT+9re/GWOM2bdvn5Fknn766Xqvp7Z7pC4rV640ksxTTz0VsT4/P98kJCSY8ePHR9Rbknnrrbciyo4aNcq43W7rbzFz5kwjycyfPz+i3OOPP24kmcWLFxtjjPnggw+MJDNx4sR665idnW3i4+Mj/tbFxcWmdevWZvTo0Q26TgBA80dLPQDAMXJyctSlSxe9+OKLWr9+vfLy8mrteh/20EMPaceOHXrxxRc1evRoJScna+bMmerfv39EN/6wOXPmKC8vL2L5+OOPj1uv2267TStWrNDGjRutdbNnz9Y555yjnj17Wuu2bNmiESNGKCMjQx6PRz6fTzk5OZKkr776qjE/RZ3eeecdDRkyRFlZWRE9Di6//HJJ5RML1qchddy4caN2796t66+/PmLfjh076rzzzqtxzKVLl+qSSy5RamqqdcyHH35Y+/fv1969e497TVdccYU8Ho/1PTzB4fbt2yVJrVu3VpcuXfTEE09o+vTpWrNmTa1zJjTGO++8I5fLpZtuuinid8zIyFCfPn1q9EhISUnRVVddFbFuxIgRCoVCVqv50qVLlZSUpOuuuy6iXHj4xP/+7/9KkhYtWiRJ+sUvfnHcep599tnq2LGj9T0+Pl5du3a1fhsAgP0R6gEAjuFyuXTbbbfpf/7nfzRz5kx17dpV559/fr37pKen67bbbtPMmTO1bt06LV++XHFxcRHdosPOPPNMDRgwIGLp37//cet14403yu/3W69L+/LLL5WXl6fbbrvNKnP48GGdf/75+vjjjzVlyhQtW7ZMeXl5euONNyRJxcXFjfgl6rZnzx794x//kM/ni1jOOussSdK+ffvq3LehdQwPZUhPT69xjOrrPvnkEw0dOlRS+Rj8f//738rLy9PEiRMjjlmfNm3aRHz3+/0R+7pcLv3v//6vfvjDH2ratGnq16+f2rZtq1/96lcqKio67vFrs2fPHhljlJ6eXuO3XLVqVY3fsbbfIiMjQ1Ll77V//35lZGTUeF1hu3bt5PV6rXLffvutPB6PtX99qv82Uvnv01T3EwAg+pj9HgDgKCNHjtTDDz+smTNn6g9/+EOj97/gggs0dOhQvfnmm9q7d6/atWv3nevUqlUr/fjHP9acOXM0ZcoUzZ49W/Hx8dbkflJ5K+3OnTu1bNkyq+VbkjXm+3j8fn+NydQk1ZgrIC0tTb17967zt8nKyqrzHA2tYzhIVh9XLpWPLa9q7ty58vl8eueddxQfH2+tf/PNN+usx4nIzs7WrFmzJEmbNm3S/PnzlZubq5KSEs2cObPRx0tLS5PL5dKHH35oPUSoqvq6+n6L8O/Vpk0bffzxxzLGRAT7vXv3qqysTGlpaZKktm3bKhgMavfu3XVO9AgAiB201AMAHOW0007Tb3/7Ww0bNky33nprneX27NlTaxfsYDCozZs3KzExUS1btmyyet12223auXOn3n33Xf3P//yPrrnmmojjh0Nc9TD4l7/8pUHH79Spk9atWxexbunSpTp8+HDEuiuvvFJffPGFunTpUqPXwYABA+oN9Q2tY7du3ZSRkVFjcsAdO3ZoxYoVNY7p9Xojus8XFxfrlVdeOc4Vn7iuXbvqwQcfVK9evfTZZ59Z6xvTgn3llVfKGKNvvvmm1t+xV69eEeWLiopqzEz/2muvye1264ILLpAkXXzxxTp8+HCNBxpz5syxtkuyhko899xzDb9oAIBj0VIPAHCcxx577LhlXnnlFf3lL3/RiBEjdM455yg1NVX//e9/9cILL2jDhg16+OGHFRcXF7HPF198Uetr37p06aK2bdvWe76hQ4eqffv2GjNmjHbv3h3R9V6Szj33XLVq1Up33XWXJk2aJJ/Pp1dffVWff/55A65Yuvnmm/XQQw/p4YcfVk5Ojr788kvNmDFDqampEeUeeeQRLVmyROeee65+9atfqVu3bjp27Ji2bdumd999VzNnzlT79u1rPUdD6+h2uzV58mSNHj1a1113nW6//XYdOnRIkydPVmZmZsTrAq+44gpNnz5dI0aM0J133qn9+/frySefrLX1+0StW7dOY8eO1U9/+lOdccYZiouL09KlS7Vu3Trdf//9VrlevXpp7ty5mjdvnk4//XTFx8fXCOdh5513nu68807ddtttWr16tS644AIlJSVp165d+uijj9SrVy/dfffdVvk2bdro7rvv1o4dO9S1a1e9++67ev7553X33XdbY95vueUW/fnPf9att96qbdu2qVevXvroo4/06KOP6kc/+pEuueQSSdL555+vm2++WVOmTNGePXt05ZVXyu/3a82aNUpMTNQvf/nLJvvtAAA2EOWJ+gAA+E6qzn5fn+ozm3/55ZfmN7/5jRkwYIBp27at8Xq9plWrViYnJ8e88sortZ6jruX5559vUF0feOABI8l06NDBBIPBGttXrFhhBg8ebBITE03btm3Nz3/+c/PZZ58ZSWb27NlWudpmvw8EAmb8+PGmQ4cOJiEhweTk5Ji1a9fWmP3eGGO+/fZb86tf/cp07tzZ+Hw+07p1a9O/f38zceJEc/jw4XqvoaF1NMaYv/71r+Z73/ueiYuLM127djUvvvii+fGPf2z69u0bUe7FF1803bp1M36/35x++ulm6tSpZtasWUaS2bp1q1Wurtnvn3jiiRr1VJW3AezZs8eMHDnSdO/e3SQlJZnk5GTTu3dv88c//jFi1vxt27aZoUOHmpSUFCOp3ln6q9Z94MCBJikpySQkJJguXbqYW265xaxevTqi3meddZZZtmyZGTBggPH7/SYzM9M88MADprS0NOJ4+/fvN3fddZfJzMw0Xq/XZGdnmwkTJphjx45FlAsGg+aPf/yj6dmzp4mLizOpqalm8ODB5h//+IdVJjs721xxxRU16lz9dwQA2JvLGGNO/aMEAAAQaw4dOqSuXbvq6quv1l//+tdoV+eUufDCC7Vv3z598cUX0a4KAMCB6H4PAACa3O7du/WHP/xBQ4YMUZs2bbR9+3b98Y9/VFFRUa1vFgAAACeGUA8AAJqc3+/Xtm3bNGbMGB04cECJiYkaNGiQZs6cab0+DwAAfHd0vwcAAAAAwKZ4pR0AAAAAADZlm1B/1VVXqWPHjoqPj1dmZqZuvvlm7dy5s959jDHKzc1VVlaWEhISdOGFF2rDhg2nqMYAAAAAAJxctgn1Q4YM0fz587Vx40a9/vrr+vrrr3XdddfVu8+0adM0ffp0zZgxQ3l5ecrIyNCll16qoqKiU1RrAAAAAABOHtuOqX/77bd19dVXKxAIyOfz1dhujFFWVpbGjRun3/3ud5KkQCCg9PR0Pf744xo9enSDzhMKhbRz506lpKTI5XI16TUAAAAAAFCdMUZFRUXKysqS211/W7wtZ78/cOCAXn31VZ177rm1BnpJ2rp1q3bv3q2hQ4da6/x+v3JycrRixYo6Q30gEFAgELC+f/PNN+rRo0fTXgAAAAAAAMeRn5+v9u3b11vGVqH+d7/7nWbMmKGjR49q0KBBeuedd+osu3v3bklSenp6xPr09HRt3769zv2mTp2qyZMn11ifn5+vFi1anGDNAQAAAABomMLCQnXo0EEpKSnHLRvV7ve5ubm1Buiq8vLyNGDAAEnSvn37dODAAW3fvl2TJ09Wamqq3nnnnVq7xa9YsULnnXeedu7cqczMTGv9qFGjlJ+fr3/+85+1nq96S334xywoKCDUAwAAAABOusLCQqWmpjYoh0a1pX7s2LEaPnx4vWU6depkfU5LS1NaWpq6du2qM888Ux06dNCqVas0ePDgGvtlZGRIKm+xrxrq9+7dW6P1viq/3y+/39/IKwEAAAAA4NSLaqgPh/QTEe5gULVVvarOnTsrIyNDS5YsUd++fSVJJSUlWr58uR5//PETqzAAAAAAAM2ILV5p98knn2jGjBlau3attm/frvfff18jRoxQly5dIlrpu3fvrgULFkiSXC6Xxo0bp0cffVQLFizQF198oZEjRyoxMVEjRoyI1qUAAAAAANBkbDFRXkJCgt544w1NmjRJR44cUWZmpi677DLNnTs3oqv8xo0bVVBQYH0fP368iouLNWbMGB08eFADBw7U4sWLGzTZAAAAAAAAzZ1t31N/qjRmggIAAAAAAL6rxuRQW3S/BwAAAAAANRHqAQAAAACwKUI9AAAAAAA2RagHAAAAAMCmCPUAAAAAANgUoR4AAAAAAJsi1AMAAAAAYFOEegAAAAAAbIpQDwAAAACATRHqAQAAAACwKUI9AAAAAAA25Y12BdA08rYd0LdFAfXt2FKZqQnRrg4AAAAA4BSgpd4hnlq8UWNe/Uyfbj8Y7aoAAAAAAE4RQr1D+Dzlf8rSYCjKNQEAAAAAnCqEeoeoDPUmyjUBAAAAAJwqhHqH8LpdkmipBwAAAIBYQqh3CJ+3/E9ZRks9AAAAAMQMQr1D+GipBwAAAICYQ6h3CMbUAwAAAEDsIdQ7hJfZ7wEAAAAg5hDqHSLOU979voxQDwAAAAAxg1DvEOGW+hK63wMAAABAzCDUO0R4TD0t9QAAAAAQOwj1DuHzMPs9AAAAAMQaQr1DWLPfh+h+DwAAAACxglDvEN5wS30ZLfUAAAAAECsI9Q4RFx5TT0s9AAAAAMQMQr1DeN3lLfUljKkHAAAAgJhBqHcIn5fZ7wEAAAAg1hDqHcLnrpgoj/fUAwAAAEDMINQ7hM/LK+0AAAAAINYQ6h3Ca7XUE+oBAAAAIFYQ6h0i/J76MrrfAwAAAEDMINQ7hM9D93sAAAAAiDWEeocIt9QzUR4AAAAAxA5CvUN4aakHAAAAgJhDqHeIuPCY+hAt9QAAAAAQKwj1DuGtCPUlZbTUAwAAAECsINQ7RHiivLIQoR4AAAAAYgWh3iGYKA8AAAAAYg+h3iEqQz0t9QAAAAAQKwj1DuF1M/s9AAAAAMQaQr1DxHkrZr+n+z0AAAAAxAxCvUOEW+rLQkbGEOwBAAAAIBYQ6h3C5638UzJZHgAAAADEBkK9Q/jcVUM94+oBAAAAIBYQ6h0i/J56iXH1AAAAABArbBPqr7rqKnXs2FHx8fHKzMzUzTffrJ07d9a7z8iRI+VyuSKWQYMGnaIan1oed2WoL6GlHgAAAABigm1C/ZAhQzR//nxt3LhRr7/+ur7++mtdd911x93vsssu065du6zl3XffPQW1PfVcLpfiKt5VXxYi1AMAAABALPBGuwINde+991qfs7Ozdf/99+vqq69WaWmpfD5fnfv5/X5lZGSciipGndfjUklQKi2j+z0AAAAAxALbtNRXdeDAAb366qs699xz6w30krRs2TK1a9dOXbt21ahRo7R37956ywcCARUWFkYsduGraKkvpaUeAAAAAGKCrUL97373OyUlJalNmzbasWOH3nrrrXrLX3755Xr11Ve1dOlSPfXUU8rLy9NFF12kQCBQ5z5Tp05VamqqtXTo0KGpL+OkCU+Wx+z3AAAAABAbohrqc3Nza0xkV31ZvXq1Vf63v/2t1qxZo8WLF8vj8eiWW26RMXV3Nb/hhht0xRVXqGfPnho2bJgWLVqkTZs2aeHChXXuM2HCBBUUFFhLfn5+k17zyRRuqWf2ewAAAACIDVEdUz927FgNHz683jKdOnWyPqelpSktLU1du3bVmWeeqQ4dOmjVqlUaPHhwg86XmZmp7Oxsbd68uc4yfr9ffr+/QcdrbrwVLfXMfg8AAAAAsSGqoT4c0k9EuIW+vq701e3fv1/5+fnKzMw8oXM2d7TUAwAAAEBsscWY+k8++UQzZszQ2rVrtX37dr3//vsaMWKEunTpEtFK3717dy1YsECSdPjwYd13331auXKltm3bpmXLlmnYsGFKS0vTNddcE61LOal87oqJ8mipBwAAAICYYItX2iUkJOiNN97QpEmTdOTIEWVmZuqyyy7T3LlzI7rKb9y4UQUFBZIkj8ej9evXa86cOTp06JAyMzM1ZMgQzZs3TykpKdG6lJPK52WiPAAAAACIJbYI9b169dLSpUuPW67qpHkJCQl67733Tma1mh2v1VJP93sAAAAAiAW26H6PhomzxtTTUg8AAAAAsYBQ7yDMfg8AAAAAsYVQ7yDMfg8AAAAAsYVQ7yA+DxPlAQAAAEAsIdQ7SLilvjRESz0AAAAAxAJCvYN4w6G+jJZ6AAAAAIgFhHoHCXe/LwsR6gEAAAAgFhDqHcTHe+oBAAAAIKYQ6h3E52WiPAAAAACIJYR6B/FaLfWEegAAAACIBYR6B4nz8p56AAAAAIglhHoH8brLu9+X0FIPAAAAADGBUO8g4ffU01IPAAAAALGBUO8g4VfaMaYeAAAAAGIDod5Bwi31vNIOAAAAAGIDod5BvB5mvwcAAACAWEKod5C4iu73ZSFCPQAAAADEAkK9g4Rb6kvK6H4PAAAAALGAUO8g1uz3tNQDAAAAQEwg1DsIs98DAAAAQGwh1DsIs98DAAAAQGwh1DuI101LPQAAAADEEkK9g/i8FWPqaakHAAAAgJhAqHcQn5v31AMAAABALCHUOwgT5QEAAABAbCHUO4iXifIAAAAAIKYQ6h0kLvyeelrqAQAAACAmEOodxFvR/b6ElnoAAAAAiAmEegcJv6e+LERLPQAAAADEAkK9g1gT5ZUR6gEAAAAgFhDqHSTcUl8aovs9AAAAAMQCQr2DeHmlHQAAAADEFEK9g4RnvzdGCtJaDwAAAACOR6h3kPB76iVa6wEAAAAgFhDqHcTrdlmfy2ipBwAAAADHI9Q7iKdKqA/yrnoAAAAAcDxCvYN4XFVb6ul+DwAAAABOR6h3ELfbpXBjPRPlAQAAAIDzEeodxusu/5Myph4AAAAAnI9Q7zDhcfW01AMAAACA8xHqHSY8Az4t9QAAAADgfIR6h/F4wi31TJQHAAAAAE5HqHcYWuoBAAAAIHYQ6h0mPKa+jPfUAwAAAIDjEeodJjz7PRPlAQAAAIDzEeodxkP3ewAAAACIGYR6h/HySjsAAAAAiBm2C/WBQEBnn322XC6X1q5dW29ZY4xyc3OVlZWlhIQEXXjhhdqwYcOpqWiUVLbUM/s9AAAAADid7UL9+PHjlZWV1aCy06ZN0/Tp0zVjxgzl5eUpIyNDl156qYqKik5yLaPHQ0s9AAAAAMQMW4X6RYsWafHixXryySePW9YYo6effloTJ07Utddeq549e+rll1/W0aNH9dprr52C2kaH18OYegAAAACIFbYJ9Xv27NGoUaP0yiuvKDEx8bjlt27dqt27d2vo0KHWOr/fr5ycHK1YsaLO/QKBgAoLCyMWO/GEZ7/nlXYAAAAA4Hi2CPXGGI0cOVJ33XWXBgwY0KB9du/eLUlKT0+PWJ+enm5tq83UqVOVmppqLR06dDjxikeBl9nvAQAAACBmRDXU5+bmyuVy1busXr1af/rTn1RYWKgJEyY0+hwulyviuzGmxrqqJkyYoIKCAmvJz89v9DmjiTH1AAAAABA7vNE8+dixYzV8+PB6y3Tq1ElTpkzRqlWr5Pf7I7YNGDBAN954o15++eUa+2VkZEgqb7HPzMy01u/du7dG631Vfr+/xnnsxMvs9wAAAAAQM6Ia6tPS0pSWlnbccs8884ymTJlifd+5c6d++MMfat68eRo4cGCt+3Tu3FkZGRlasmSJ+vbtK0kqKSnR8uXL9fjjjzfNBTRDtNQDAAAAQOyIaqhvqI4dO0Z8T05OliR16dJF7du3t9Z3795dU6dO1TXXXCOXy6Vx48bp0Ucf1RlnnKEzzjhDjz76qBITEzVixIhTWv9TiTH1AAAAABA7bBHqG2rjxo0qKCiwvo8fP17FxcUaM2aMDh48qIEDB2rx4sVKSUmJYi1PLmv2e0I9AAAAADieLUN9p06dZEzN0Fp9ncvlUm5urnJzc09RzaKPlnoAAAAAiB22eKUdGs7jqRhTH2SiPAAAAABwOkK9w9BSDwAAAACxg1DvMMx+DwAAAACxg1DvMLTUAwAAAEDsINQ7DLPfAwAAAEDsINQ7DC31AAAAABA7CPUOUzmmntnvAQAAAMDpCPUO4/PQUg8AAAAAsYJQ7zDWmPogoR4AAAAAnI5Q7zCMqQcAAACA2EGodxjeUw8AAAAAsYNQ7zC01AMAAABA7CDUO4zHw+z3AAAAABArCPUOQ0s9AAAAAMQOQr3DWLPfE+oBAAAAwPEI9Q5DSz0AAAAAxA5CvcNYs9/znnoAAAAAcDxCvcPQUg8AAAAAsYNQ7zCV76ln9nsAAAAAcDpCvcN4PbTUAwAAAECsINQ7DLPfAwAAAEDsINQ7DGPqAQAAACB2EOodpnJMPaEeAAAAAJyOUO8wtNQDAAAAQOwg1DsMs98DAAAAQOwg1DuMt2KivLIgLfUAAAAA4HSEeodhTD0AAAAAxA5CvcOE31NPqAcAAAAA5yPUO4yHifIAAAAAIGYQ6h3GS/d7AAAAAIgZhHqHqWypZ/Z7AAAAAHA6Qr3DhGe/p6UeAAAAAJyPUO8wjKkHAAAAgNhBqHcYa0w976kHAAAAAMcj1DsMLfUAAAAAEDsI9Q7De+oBAAAAIHYQ6h2G2e8BAAAAIHYQ6h0mPPt9yEghWusBAAAAwNEI9Q4TbqmXpKAh1AMAAACAkxHqHcZbNdTTUg8AAAAAjkaod5iqLfXMgA8AAAAAzkaod5iIlnreVQ8AAAAAjkaod5jIlnpmwAcAAAAAJyPUO4zL5bKCPWPqAQAAAMDZCPUOVPmuekI9AAAAADgZod6BvLTUAwAAAEBMINQ7EC31AAAAABAbbBfqA4GAzj77bLlcLq1du7besiNHjpTL5YpYBg0adGoqGkWVLfVMlAcAAAAATma7UD9+/HhlZWU1uPxll12mXbt2Wcu77757EmvXPHjc5X9WWuoBAAAAwNm80a5AYyxatEiLFy/W66+/rkWLFjVoH7/fr4yMjJNcs+Yl3FJfxnvqAQAAAMDRbNNSv2fPHo0aNUqvvPKKEhMTG7zfsmXL1K5dO3Xt2lWjRo3S3r176y0fCARUWFgYsdgNr7QDAAAAgNhgi1BvjNHIkSN11113acCAAQ3e7/LLL9err76qpUuX6qmnnlJeXp4uuugiBQKBOveZOnWqUlNTraVDhw5NcQmnlNfDRHkAAAAAEAuiGupzc3NrTGRXfVm9erX+9Kc/qbCwUBMmTGjU8W+44QZdccUV6tmzp4YNG6ZFixZp06ZNWrhwYZ37TJgwQQUFBdaSn5//XS/zlKOlHgAAAABiQ1TH1I8dO1bDhw+vt0ynTp00ZcoUrVq1Sn6/P2LbgAEDdOONN+rll19u0PkyMzOVnZ2tzZs311nG7/fXOI/dWGPqmf0eAAAAABwtqqE+LS1NaWlpxy33zDPPaMqUKdb3nTt36oc//KHmzZungQMHNvh8+/fvV35+vjIzM0+ovnYRnv2elnoAAAAAcDZbjKnv2LGjevbsaS1du3aVJHXp0kXt27e3ynXv3l0LFiyQJB0+fFj33XefVq5cqW3btmnZsmUaNmyY0tLSdM0110TlOk6VypZ6Qj0AAAAAOJmtXml3PBs3blRBQYEkyePxaP369ZozZ44OHTqkzMxMDRkyRPPmzVNKSkqUa3pyWWPqeaUdAAAAADiaLUN9p06dZEzNwFp1XUJCgt57771TWa1mg5Z6AAAAAIgNtuh+j8Zh9nsAAAAAiA2EegeqfE89s98DAAAAgJMR6h2I2e8BAAAAIDYQ6h2IMfUAAAAAEBsI9Q7EmHoAAAAAiA2EegeipR4AAAAAYgOh3oEq31PPRHkAAAAA4GSEegeipR4AAAAAYgOh3oGY/R4AAAAAYgOh3oFoqQcAAACA2ECodyCPh9nvAQAAACAWEOodiJZ6AAAAAIgNhHoHqnxPPbPfAwAAAICTEeodiJZ6AAAAAIgNhHoHsma/DxLqAQAAAMDJCPUOREs9AAAAAMQGQr0DVY6pJ9QDAAAAgJMR6h2IlnoAAAAAiA2EegeqfE89s98DAAAAgJMR6h2IlnoAAAAAiA2EegeyZr8n1AMAAACAoxHqHYiWegAAAACIDYR6B7Jmv+c99QAAAADgaIR6B6KlHgAAAABiA6HegSrfU8/s9wAAAADgZIR6B/J6aKkHAAAAgFhAqHcgZr8HAAAAgNhAqHcgj4uWegAAAACIBYR6BwqPqQ8R6gEAAADA0Qj1DsTs9wAAAAAQGwj1DlQ5+z2hHgAAAACcjFDvQIR6AAAAAIgNhHoH8hLqAQAAACAmEOodyG2NqQ9FuSYAAAAAgJOJUO9AtNQDAAAAQGwg1DuQNabeEOoBAAAAwMkI9Q7kdZf/WYNBQj0AAAAAOBmh3oEqMj3vqQcAAAAAh2tUqJ82bZqKi4ut7x988IECgYD1vaioSGPGjGm62uGEhFvqQ3S/BwAAAABHa1SonzBhgoqKiqzvV155pb755hvr+9GjR/WXv/yl6WqHE+KxZr8n1AMAAACAkzUq1JtqLb/Vv6N5sCbKY0w9AAAAADgaY+odyMvs9wAAAAAQEwj1DkT3ewAAAACIDd7G7vDCCy8oOTlZklRWVqaXXnpJaWlpkhQx3h7RY3W/J9QDAAAAgKM1KtR37NhRzz//vPU9IyNDr7zySo0yiK6qod4YI5fLFeUaAQAAAABOhkaF+m3btp2kaqAphcfUS1LISB4yPQAAAAA4EmPqHchTJdSXhUJRrAkAAAAA4GRqVKj/+OOPtWjRooh1c+bMUefOndWuXTvdeeedCgQCTVrBsE6dOsnlckUs999/f737GGOUm5urrKwsJSQk6MILL9SGDRtOSv2ak6qhnnH1AAAAAOBcjQr1ubm5WrdunfV9/fr1uuOOO3TJJZfo/vvv1z/+8Q9NnTq1ySsZ9sgjj2jXrl3W8uCDD9Zbftq0aZo+fbpmzJihvLw8ZWRk6NJLL3X8hH6EegAAAACIDY0K9WvXrtXFF19sfZ87d64GDhyo559/Xr/+9a/1zDPPaP78+U1eybCUlBRlZGRYS3gW/toYY/T0009r4sSJuvbaa9WzZ0+9/PLLOnr0qF577bWTVsfmwOuu/LMS6gEAAADAuRoV6g8ePKj09HTr+/Lly3XZZZdZ38855xzl5+c3Xe2qefzxx9WmTRudffbZ+sMf/qCSkpI6y27dulW7d+/W0KFDrXV+v185OTlasWJFnfsFAgEVFhZGLHZTpaGed9UDAAAAgIM1KtSnp6dr69atkqSSkhJ99tlnGjx4sLW9qKhIPp+vaWtY4Z577tHcuXP1/vvva+zYsXr66ac1ZsyYOsvv3r3bqnNV6enp1rbaTJ06VampqdbSoUOHprmAU8jlclld8EOEegAAAABwrEaF+ssuu0z333+/PvzwQ02YMEGJiYk6//zzre3r1q1Tly5dGny83NzcGpPfVV9Wr14tSbr33nuVk5Oj3r176+c//7lmzpypWbNmaf/+/fWeo/o72o/33vYJEyaooKDAWk5mz4OTKRzqaakHAAAAAOdq1Hvqp0yZomuvvVY5OTlKTk7WSy+9pLi4OGv7iy++GNHd/XjGjh2r4cOH11umU6dOta4fNGiQJOk///mP2rRpU2N7RkaGpPIW+8zMTGv93r17a7TeV+X3++X3+49X9WbPU/HggjH1AAAAAOBcjQr1bdu21YcffqiCggIlJyfL4/FEbP/73/+ulJSUBh8vLS1NaWlpjamCZc2aNZIUEdir6ty5szIyMrRkyRL17dtXUvmQgeXLl+vxxx8/oXPaiZeWegAAAABwvEaF+ttvv71B5V588cUTqkxdVq5cqVWrVmnIkCFKTU1VXl6e7r33Xl111VXq2LGjVa579+6aOnWqrrnmGrlcLo0bN06PPvqozjjjDJ1xxhl69NFHlZiYqBEjRjRp/Zojj4eWegAAAABwukaF+pdeeknZ2dnq27evjDl1YdHv92vevHmaPHmyAoGAsrOzNWrUKI0fPz6i3MaNG1VQUGB9Hz9+vIqLizVmzBgdPHhQAwcO1OLFixvVm8Cuwi31hHoAAAAAcC6XaUQ6HzNmjObOnauOHTvq9ttv10033aTWrVufzPpFXWFhoVJTU1VQUKAWLVpEuzoN9v0//Et7iwJa+Ksf6Kys1GhXBwAAAADQQI3JoY2a/f7ZZ5/Vrl279Lvf/U7/+Mc/1KFDB11//fV67733TmnLPY7Pa73SLsoVAQAAAACcNI0K9VJ5V/if/exnWrJkib788kudddZZGjNmjLKzs3X48OGTUUecgPCY+jJSPQAAAAA4VqNDfVXhd8kbYxQiPDYrvNIOAAAAAJyv0aE+EAjob3/7my699FJ169ZN69ev14wZM7Rjxw4lJyefjDriBHiYKA8AAAAAHK9Rs99XnSjvtttu09y5c9WmTZuTVTd8B153+fMaQj0AAAAAOFejQv3MmTPVsWNHde7cWcuXL9fy5ctrLffGG280SeVw4tzu8Jh6Qj0AAAAAOFWjQv0tt9wiV8VYbTRvvKceAAAAAJyvUaH+pZdeOknVQFNjTD0AAAAAON93mv0ezZeX7vcAAAAA4HiEeody01IPAAAAAI5HqHcoa0y9IdQDAAAAgFMR6h2qckx9KMo1AQAAAACcLIR6hwqH+rIgLfUAAAAA4FSEeocKd78P0f0eAAAAAByLUO9QHma/BwAAAADHI9Q7FO+pBwAAAADnI9Q7lMdd/qdlTD0AAAAAOBeh3qEYUw8AAAAAzkeodyi3izH1AAAAAOB0hHqH8jKmHgAAAAAcj1DvUB4PoR4AAAAAnI5Q71BeXmkHAAAAAI5HqHeo8Jj6YCgU5ZoAAAAAAE4WQr1DVY6pj3JFAAAAAAAnDaHeoSrH1JPqAQAAAMCpCPUO5eGVdgAAAADgeIR6h+KVdgAAAADgfIR6h/K4y/+0hHoAAAAAcC5CvUN5Kv6yhHoAAAAAcC5CvUOFW+oZUw8AAAAAzkWod6jwmPoQoR4AAAAAHItQ71AeN7PfAwAAAIDTEeodysPs9wAAAADgeIR6hyLUAwAAAIDzEeodykv3ewAAAABwPEK9Q7mtlvpQlGsCAAAAADhZCPUORUs9AAAAADgfod6hwmPqQ4ZQDwAAAABORah3KOuVdsHIUP/p9gO69cVP9J+9RdGoFgAAAACgCRHqHcpby+z3x0qD+slzK7V807f66wdbolU1AAAAAEATIdQ7lMdd/qcNVul+P+ujrdZneuUDAAAAgP0R6h2qekv9/sMB/fn9/1jbmT8PAAAAAOyPUO9Q7mpj6td9U6CjJUFr+5FAWVTqBQAAAABoOoR6h/JWm/3+WJVAL0lHSgj1AAAAAGB3hHqH8lR7T31xaWSoP0xLPQAAAADYHqHeoTzVxtSHQ31SnEcS3e8BAAAAwAkI9Q5V2VIfkiQVV3S/b5PslyQdCQRr3xEAAAAAYBu2CfWdOnWSy+WKWO6///569xk5cmSNfQYNGnSKahxd1pj68kyvYxUt9WnJcZLofg8AAAAATuCNdgUa45FHHtGoUaOs78nJycfd57LLLtPs2bOt73FxcSelbs2N2xXZUn+stPzftIqW+qNMlAcAAAAAtmerUJ+SkqKMjIxG7eP3+xu9jxN4PbWPqU9LKQ/1pUGjQFlQfq8nOhUEAAAAAHxntul+L0mPP/642rRpo7PPPlt/+MMfVFJSctx9li1bpnbt2qlr164aNWqU9u7dW2/5QCCgwsLCiMWOvHVMlJeWVNlTgXH1AAAAAGBvtmmpv+eee9SvXz+1atVKn3zyiSZMmKCtW7fqhRdeqHOfyy+/XD/96U+VnZ2trVu36qGHHtJFF12kTz/9VH6/v9Z9pk6dqsmTJ5+syzhlPO7y5zXhV9qF31OfHO9VvM+tY6UhHQmUqXVSbAxHAAAAAAAnimpLfW5ubo2J7Kovq1evliTde++9ysnJUe/evfXzn/9cM2fO1KxZs7R///46j3/DDTfoiiuuUM+ePTVs2DAtWrRImzZt0sKFC+vcZ8KECSooKLCW/Pz8Jr/uU8Hjqr2lPt7nUbK//FkOk+UBAAAAgL1FtaV+7NixGj58eL1lOnXqVOv68Cz2//nPf9SmTZsGnS8zM1PZ2dnavHlznWX8fn+drfh24qljTH28z6Mkv1f7DpfwrnoAAAAAsLmohvq0tDSlpaWd0L5r1qyRVB7UG2r//v3Kz89v1D52VX1MffiVdgk+j5LiaKkHAAAAACewxUR5K1eu1B//+EetXbtWW7du1fz58zV69GhdddVV6tixo1Wue/fuWrBggSTp8OHDuu+++7Ry5Upt27ZNy5Yt07Bhw5SWlqZrrrkmWpdyylS+0s7IGKPiilfaJVTpfs9EeQAAAABgb7aYKM/v92vevHmaPHmyAoGAsrOzNWrUKI0fPz6i3MaNG1VQUCBJ8ng8Wr9+vebMmaNDhw4pMzNTQ4YM0bx585SSkhKNyzilwi31khQylRPlJcR5lOQvf40d3e8BAAAAwN5sEer79eunVatWHbecMcb6nJCQoPfee+9kVqtZC4+pl8q74FcdU5/IRHkAAAAA4Ai26H6PxgvPfi9FhvoEn0fJceHu94R6AAAAALAzQr1Deap0vy8Lhap1v68I9SWMqQcAAAAAOyPUO1TEmPpQ1VfauZXMmHoAAAAAcARCvUNVbak/VhZUWcWr7RJ8VVrqCfUAAAAAYGuEeodyuVwK5/qqE+LFVwn1TJQHAAAAAPZGqHcwr7v8z3v4WHl4d7kkv9dd+Z76EkI9AAAAANgZod7Bwl3ww93sE3weuVyuKi31TJQHAAAAAHZGqHewcKgvqhLqJSmJifIAAAAAwBEI9Q4WDvXh7vfxFaE+mYnyAAAAAMARCPUOFn6tXXjsfLyv/M/NRHkAAAAA4AyEegdzh1vqw93v4yq638dVttQbY6JTOQAAAADAd0aodzBvte731cfUh4wUKAtFp3IAAAAAgO+MUO9g1We/D4+pD7fUS3TBBwAAAAA7I9Q7mLeO2e/dbpcS45gBHwAAAADsjlDvYO7q3e8rgrzEZHkAAAAA4ASEegfzVp8oz1cZ6sMt9cdKg6e+YgAAAACAJkGodzCPu/zPW31MvSTFe8s/F5cwUR4AAAAA2BWh3sE8FX/dw7WF+op31tNSDwAAAAD2Rah3sHBLfW3d78MB/1gZoR4AAAAA7IpQ72Be65V25cE9Ia7yzx0O9cUlhHoAAAAAsCtCvYN5XHVPlGd1vy9jTD0AAAAA2BWh3sE8FS31YVXH1IcDfoAx9QAAAABgW4R6B/N6IkN91ffUW2PqCfUAAAAAYFuEeger3lJf20R5xYR6AAAAALAtQr2DhcfUh1Xtfu+3XmnHmHoAAAAAsCtCvYM1ZEw93e8BAAAAwL4I9Q5WY0x9be+pp6UeAAAAAGyLUO9gWakJEd8jJsrzhrvf01IPAAAAAHZFqHew+37YTfde0lUuV3krfdsUv7UtHPAJ9QAAAABgX95oVwAnT7zPo3suOUM3DeqokmBIyX5vxDZJOlZGqAcAAAAAuyLUx4A2yf4a6/zeilfalRDqAQAAAMCu6H4fo+J5pR0AAAAA2B6hPkYl0P0eAAAAAGyPUB+jwmPqA7TUAwAAAIBtEepjVDjUFzP7PQAAAADYFqE+Rlnd7wn1AAAAAGBbhPoYVTlRXlDGmCjXBgAAAABwIgj1Mcpf0VIfMlJpkFAPAAAAAHZEqI9R4e73EuPqAQAAAMCuCPUxyudxye0q/xwg1AMAAACALRHqY5TL5bJmwD/Ga+0AAAAAwJYI9THMCvVltNQDAAAAgB0R6mNYeFx9cQmhHgAAAADsiFAfw/xVXmsHAAAAALAfQn0Mi/eGu98zph4AAAAA7IhQH8MS4uh+DwAAAAB2RqiPYfEV3e8DTJQHAAAAALZkq1C/cOFCDRw4UAkJCUpLS9O1115bb3ljjHJzc5WVlaWEhARdeOGF2rBhwymqbfNndb9nTD0AAAAA2JJtQv3rr7+um2++Wbfddps+//xz/fvf/9aIESPq3WfatGmaPn26ZsyYoby8PGVkZOjSSy9VUVHRKap188Z76gEAAADA3rzRrkBDlJWV6Z577tETTzyhO+64w1rfrVu3Ovcxxujpp5/WxIkTrRb9l19+Wenp6Xrttdc0evTok17v5i4c6otpqQcAAAAAW7JFS/1nn32mb775Rm63W3379lVmZqYuv/zyervSb926Vbt379bQoUOtdX6/Xzk5OVqxYkWd+wUCARUWFkYsThXPK+0AAAAAwNZsEeq3bNkiScrNzdWDDz6od955R61atVJOTo4OHDhQ6z67d++WJKWnp0esT09Pt7bVZurUqUpNTbWWDh06NNFVND90vwcAAAAAe4tqqM/NzZXL5ap3Wb16tUKh8tA5ceJE/eQnP1H//v01e/ZsuVwu/f3vf6/3HC6XK+K7MabGuqomTJiggoICa8nPz//uF9pMJfiYKA8AAAAA7CyqY+rHjh2r4cOH11umU6dO1sR2PXr0sNb7/X6dfvrp2rFjR637ZWRkSCpvsc/MzLTW7927t0brfVV+v19+v7/B12BndL8HAAAAAHuLaqhPS0tTWlraccv1799ffr9fGzdu1A9+8ANJUmlpqbZt26bs7Oxa9+ncubMyMjK0ZMkS9e3bV5JUUlKi5cuX6/HHH2+6i7CxeFrqAQAAAMDWbDGmvkWLFrrrrrs0adIkLV68WBs3btTdd98tSfrpT39qlevevbsWLFggqbzb/bhx4/Too49qwYIF+uKLLzRy5EglJiYe91V4scLPmHoAAAAAsDVbvNJOkp544gl5vV7dfPPNKi4u1sCBA7V06VK1atXKKrNx40YVFBRY38ePH6/i4mKNGTNGBw8e1MCBA7V48WKlpKRE4xKanQReaQcAAAAAtuYyxphoV6I5KywsVGpqqgoKCtSiRYtoV6dJvbNup8a+tkYDO7fWvNGDo10dAAAAAIAal0Nt0f0eJ0e8t6L7fRnd7wEAAADAjgj1MSwhrjzUB+h+DwAAAAC2RKiPYeFX2jGmHgAAAADsiVAfw8KvtDtaQqgHAAAAADsi1MewlolxkqSCo6VivkQAAAAAsB9CfQxrXRHqS4IhHaG1HgAAAABsh1AfwxLiPNa4+oNHSqJcGwAAAABAYxHqY1y4tf7gUUI9AAAAANgNoT7GtUoqD/UHaKkHAAAAANsh1Me41km01AMAAACAXRHqY1yrxHBLfWmUawIAAAAAaCxCfYyzWurpfg8AAAAAtkOoj3FWSz3d7wEAAADAdgj1Ma51kk8SLfUAAAAAYEeE+hjH7PcAAAAAYF+E+hjHe+oBAAAAwL4I9TGusqW+cvb7f/9nn9b/tyBaVQIAAAAANBChPsZVfU+9MUavfrxdN77wsW6a9bGCIRPl2gEAAAAA6kOoj3EtE8snyguGjOavzteDb34hSSooLtU3B4ujWTUAAAAAwHEQ6mOc3+tRst8rScp9+0uZKo3zX+87HKVaAQAAAAAaglAPtap4rV1xaVBxHrdyuraVJG359kg0qwUAAAAAOA5CPawZ8CVp4Omt1fO0FpKkLd/SUg8AAAAAzZk32hVA9IVnwJekId3aKTWhvOWelnoAAAAAaN4I9YhoqR/SvZ0OVbyz/mta6gEAAACgWSPUw2qp75yWpM5pSSooLv++tyigomOlSon3RbN6AAAAAIA6MKYeOiurfAz9VX2yJEmpCT6lJfslSVv30QUfAAAAAJorWuqhq88+Td0yUtQ9o4W17vS2Sdp3OKAt3x5R7/Yto1c5AAAAAECdaKmH3G6XzspKlcftstZ1aZskiRnwAQAAAKA5I9SjVqenJUuSvqb7PQAAAAA0W4R61KpD60RJ0jcHi6NcEwAAAABAXQj1qFX7VgmSpG8OEeoBAAAAoLki1KNWWS3LQ/23RQEdKw1GuTYAAAAAgNoQ6lGrVok+Jfg8kqRdBceiXBsAAAAAQG0I9aiVy+XSaeEu+IyrBwAAAIBmiVCPOp3WMjyu/miUawIAAAAAqA2hHnWyWuoP0f0eAAAAAJojQj3qZLXU0/0eAAAAAJolQj3qRPd7AAAAAGjeCPWo02m8qx4AAAAAmjVCPeoUbqnfdeiYgiET5doAAAAAAKoj1KNO7VL88rhdKgsZfVsUiHZ1AAAAAADVEOpRJ6/HrYwW8ZIYVw8AAAAAzRGhHvUKj6vfcYBQDwAAAADNDaEe9eqR2UKS9Hl+QZRrAgAAAACojlCPevXPbiVJ+mzHwSjXBAAAAABQHaEe9QqH+g07C3W0pCzKtQEAAAAAVEWoR72yWiYoMzVewZDRuv/SBR8AAAAAmhNbhfqFCxdq4MCBSkhIUFpamq699tp6y48cOVIulytiGTRo0CmqrXP0q2it/3Q7XfABAAAAoDnxRrsCDfX6669r1KhRevTRR3XRRRfJGKP169cfd7/LLrtMs2fPtr7HxcWdzGo6Uv+OrbRw3S59RqgHAAAAgGbFFqG+rKxM99xzj5544gndcccd1vpu3bodd1+/36+MjIyTWT3HC4+r/3THQZUFQ/J6bNXBAwAAAAAcyxbp7LPPPtM333wjt9utvn37KjMzU5dffrk2bNhw3H2XLVumdu3aqWvXrho1apT27t1bb/lAIKDCwsKIJdb1yGqhVok+HTpaqr98sCXa1QEAAAAAVLBFqN+ypTxI5ubm6sEHH9Q777yjVq1aKScnRwcOHKhzv8svv1yvvvqqli5dqqeeekp5eXm66KKLFAgE6txn6tSpSk1NtZYOHTo0+fXYjc/j1sPDekiSnv7XJv2/3TzoAAAAAIDmIKqhPjc3t8ZEdtWX1atXKxQKSZImTpyon/zkJ+rfv79mz54tl8ulv//973Ue/4YbbtAVV1yhnj17atiwYVq0aJE2bdqkhQsX1rnPhAkTVFBQYC35+flNft12dPXZp+nSHukqDRpNXPCFjDHRrhIAAAAAxLyojqkfO3ashg8fXm+ZTp06qaioSJLUo0cPa73f79fpp5+uHTt2NPh8mZmZys7O1ubNm+ss4/f75ff7G3zMWOFyuTTl6p76YNO3+nT7QX2weZ9yuraNdrUAAAAAIKZFNdSnpaUpLS3tuOX69+8vv9+vjRs36gc/+IEkqbS0VNu2bVN2dnaDz7d//37l5+crMzPzhOscy9JbxOvmQdl64aOtmr5kky44I00ulyva1QIAAACAmGWLMfUtWrTQXXfdpUmTJmnx4sXauHGj7r77bknST3/6U6tc9+7dtWDBAknS4cOHdd9992nlypXatm2bli1bpmHDhiktLU3XXHNNVK7DCUbndFGCz6PP8w9p2cZvo10dAAAAAIhptnilnSQ98cQT8nq9uvnmm1VcXKyBAwdq6dKlatWqlVVm48aNKigokCR5PB6tX79ec+bM0aFDh5SZmakhQ4Zo3rx5SklJidZl2F7bFL9uHNhRL3y0Va9+vENDureLdpUAAAAAIGa5DDOe1auwsFCpqakqKChQixYtol2dZuE/e4t0yfQP5HG7tHLCRWqXEh/tKgEAAACAYzQmh9qi+z2al++1S1Hfji0VDBm9ueabaFcHAAAAAGIWoR4n5Kf9O0iS5q/+L6+3AwAAAIAoIdTjhFzZJ1PxPrf+s/ewFq7fFe3qAAAAAEBMItTjhLSI92n0BV0kSblvb9ChoyVRrhEAAAAAxB5CPU7YmCFd9L12ydp3uEQjZ+dp/up87Sk8Fu1qAQAAAEDMsM0r7dD8+L0ePXZtL414/mOtzT+ktfmHJElnZrbQvZecoUt7pMvlckW3kgAAAADgYLzS7jh4pd3xbdt3RG9/vlNLvtyjL3YWKHxH9evYUnde0EWXnNlOXg+dQgAAAACgIRqTQwn1x0Gob5yDR0r0wkdb9MKHWxUoC0mSWib6dFG3drq0R7ou6NpWSX46iAAAAABAXQj1TYhQf2L2Fh7Tyyu36W+f5OvAkcpJ9OK8bp3XpY16tW+pjq0T1bF1orLbJKptsl9uN131AQAAAIBQ34QI9d9NWTCkT7cf1JIv92jJV3u0ff/RWsv5vW51aJ2oTm0SdWZmC52Vlaqep7XQaS0TGJcPAAAAIKYQ6psQob7pGGO0ee9hLd/4rbbsO6IdB45ox4Gj2nnomIKh2m/DxDhPRIt+xzZJyq74fFrLBMbqAwAAAHCcxuRQBjfjlHG5XOqanqKu6SkR60uDIe08VKwdB45qy7dHtGFngb74plCb9hTpaElQ/293kf7f7qIax/O4XTqtZYKy2ySqfatEZaXGK7NlgjJT4yuWBCXEeU7V5QEAAADAKUdL/XHQUh89gbKg/nuwWDv2H9X2/Ue0/cDR8s8HjmrHgaMqqZiIrz4tE33KTE2oCPzlQT8c+DNT45WRGq94H8EfAAAAQPNBSz0cwe/1qEvbZHVpm1xjWyhktKfomLbvLw/6/z1UrF2HirWr4Jh2FZT/e7QkqENHS3XoaKm+2lVY53naJMUpoyLoZ1UE/4xUv9omx6ttil9pyXFqlRjHRH4AAAAAmh1a6o+Dlnp7MsaosLhMuwqLtevQMe0sKNbugmPaeagy9O8qKNax0uO39kvlXf3bJMUpLdlfEfT9SkuJU9sq31slxql1UpxaJvpo/QcAAABwwmipR8xzuVxKTfQpNdGn7hm1/z+BMUaHjpZWBv6CY9p1qPzzroJj2nc4oH2HAzp4tFTBkNHeooD2FgWkXcc/f2KcJyLkt06Ks763SvSpVVKcWifGqVXF+tQEn+J9bmb6BwAAANAohHrELJfLVR6qk+J0VlZqneVKgyHtP1yifYcD+vZwQN8WlYf9fUUl+vZwQPuKAtp/pDz8HzxSorKQ0dGSoI6WFOubQ8UNro/P41KLeJ9SE3xKSfCpRbxXqQk+tUjwWetbJHirfC4vE94e5+VNAAAAAECsIdQDx+HzuJVRMane8RhjVBQo08EjJTpwpESHjpbqwJESHTxaYv178EipDhwt0cHw94qeAKVBo/1HSrT/SMkJ1TPB51FKvFfJ8V4l+8uXJL9XKRX/Vl8f/ly+3qNkv09Jfo+S4rzMHwAAAADYBKEeaEIuV3lre4t4n7LbJDVoH2PKW/YLiktVeKxUBUdLVXisTIXFpda6wuKyKp/L1xdVlCkKlEmSikuDKi4Nlg8R+I6S4jzWg4DEOI8SfV4lxHmUGOex/k2M8yrBF/7sUUKct3K7r3x/q2zF/vQmAAAAAJoWoR6IMpfLpaSK1vMsJTR6/7JgSIcDZSosLlPhsVIdDpTpSKBMh8PLsfLvRRHrgzp8rFRHAsHKcoEyBUPl82YeKQnqSEnTPCCoyut21fpQICHOI7/Xo3ifW/G+in+9nsrPPo/8Po/iveHtHiX4Isv7q5X3eXiAAAAAAOcj1AM25/W41TIxTi0T477TcYwxCpSFrAcB4aBfXBKsmCOgTMWl4c9BFZeUVfxbsa605rojJeX7l1U8LCgLGRUdK1PRsTJJTfvAoDqP2xXxEMBvPSioXBd+GBDncSvO65bfW/5vePF7y3sX+D1u+X3uKuU8VcpUlPeUf666zcMwBgAAAJxkhHoAksp7DITDblqyv0mPXVIWKg/6pdUeBFSE/uLSoI6VhnSsNKhjZeWfA6XB8u+loYp1VcvUvT0sGDJWj4No8bpddYT/yIcCVbf5PG55PW7FeVzyedzyecvXxXlc8noqP/sqPvu8bvncVcu6qhyn8nN4m88d+Zn5EwAAAOyNUA/gpAsH2FT5Tup5wr0NjtXykOBYlYcAgSoPAUrKQioJhhQoK19fUla+LlDxb0l4fTBUY1vA+hy0jmFMZX3KQkZlFQ8wmitvxQOByAcAroqHB+XrfR63fO7yz16PW163K2I/j9tlbfd5ynsoeD2V67zuyv3C230el7zW9vC+FZ/D5RtyjCr18bhdvBYSAADEHEI9AMeo2tsgGowxKguZGg8FSoIVDxCCdTwwKKvcVho0Kg2GVBosX1daZlQWqvheVrmtfLtRWZXPpWWhKttNxOeSis9VHzpIFQ8eQkGpNCo/WZOLfDBQ0bvB7ZIn4gFB5IMCn8clj7u8XHgfj6t8u7vKA4PwErm+omzFww2Py2U91HC7atvXLY9b8lTUsc7jVxzT+ux2y+OpcvyKfT1ul9wuye1yyVXxr6fiMw84AACIDYR6AGgiLld567HP41ZS045gaBLGGAVDFQ8egqGKhwDGeoBQVuVzbdvKHy4YBSv+LQuGKh4KhB8ulJcp/16xLmQUDBqVhiqPUf5v+bHLguV1Cm8vDYasOpYGK8uW1bK9NuV1br49I06lcMh3W/9GPgDwVDwwcFVZX97bocp+7ur7ueRxq+Z+VR4quN21na/8c/icKv+/iIcRLkmq8jm8LfyAImKdKtZVKR/+rFrWVS3vUnldrONWW+eueBgSrrNL5b+Dq+JHdVc/hiofotS5TuG6ll+ku+o1uSPL17h2VbnOKseI+B0UWbbqPVB57CqfK7bVdZyKLZWfXbWfJ/w3c1U7TsVqq6ys89dd3xrfq5flIRUA1IlQDwAxwhVu/fUoar0Zmkq4V0TVBwXhBwPB8AOB6g8GqqwrLxP5kCH8EKKsYnuo4hzBoFGw4oFIeCmr9jlkrQspaFT+73HLVlmsBy4hhUJSWbX9q+5T1wONmr+Ryo9b/u1k/jmAU6auhwNyqdaHElXLqur3Wh9mVH+oUMcDi1ofklSeo3L/uh5gVH1YUf0hSfWHIlWOXfV6q52ryq41HpaE11X9Hq5H7ftH1jNyP1eNsnWdI2J9Lceufu66tqm262rANTeqrtXOXaP+dR3nBOta/ZpV59+inuM0sK6V56p5D1S/hrp+j4j19dS1+nVV31b9Pqh+/ur1q+/+Pd7+ripnqe33aJHg07ld0moe0KYI9QAA26nsFSFJ9n5AcSLCIT9kjIyRQqb8cyhU5bOp6J1R8TkUqiwbNEYmvL7igULlcSr+DVX5XHGeYI1zqmLfyLJV6xJ+uBCKqIeRkazjSJVlTdXP1rkkoyrraikvU88xqpU3Va6h1mNI1u9XV/mIdXVcy/HKV69b+Jw1jiFVq1v42srvh/BxFD6uqp63fOeIelQ7vyqOX2N7lf1U47gmvFuNYT0nU2V9qp6Uh1YAGqfXaan6xy9/EO1qNBlCPQAANuN2uxTHmwvQzIQfXNT1cEBVvld+jixb28MDU22/ygcQtZStdh7rIUD181R78FH50CiyvrUdq97jRGyrqHN99bWup9qDmhrnqTxXeLuqnafmtsiHHdV/+8j9Ix/UVP1Q/e9V/bzVt6nacep6+FRXXWs7dmUda99WuW/jfqPa6lrbeatvUx31P95vpOrlG1DHWv/+jfiNFLGtrvNW1qu+v3/136H2uta1rcrfuMa11X3f1na91etT57aIg0SWOz0tucZ57IxQDwAAgO8s3K294ls0qwIAMcUd7QoAAAAAAIATQ6gHAAAAAMCmCPUAAAAAANgUoR4AAAAAAJsi1AMAAAAAYFOEegAAAAAAbIpQDwAAAACATRHqAQAAAACwKUI9AAAAAAA2RagHAAAAAMCmCPUAAAAAANgUoR4AAAAAAJsi1AMAAAAAYFOEegAAAAAAbIpQDwAAAACATRHqAQAAAACwKUI9AAAAAAA2RagHAAAAAMCmvNGuQHNnjJEkFRYWRrkmAAAAAIBYEM6f4TxaH0L9cRQVFUmSOnToEOWaAAAAAABiSVFRkVJTU+st4zINif4xLBQKaefOnUpJSZHL5Yp2depUWFioDh06KD8/Xy1atIh2dYBacZ+iueMehR1wn6K54x5Fc2eHe9QYo6KiImVlZcntrn/UPC31x+F2u9W+fftoV6PBWrRo0WxvTCCM+xTNHfco7ID7FM0d9yiau+Z+jx6vhT6MifIAAAAAALApQj0AAAAAADZFqHcIv9+vSZMmye/3R7sqQJ24T9HccY/CDrhP0dxxj6K5c9o9ykR5AAAAAADYFC31AAAAAADYFKEeAAAAAACbItQDAAAAAGBThHoAAAAAAGyKUO8Qzz77rDp37qz4+Hj1799fH374YbSrhBjxwQcfaNiwYcrKypLL5dKbb74Zsd0Yo9zcXGVlZSkhIUEXXnihNmzYEFEmEAjol7/8pdLS0pSUlKSrrrpK//3vf0/hVcDJpk6dqnPOOUcpKSlq166drr76am3cuDGiDPcpoum5555T79691aJFC7Vo0UKDBw/WokWLrO3cn2hupk6dKpfLpXHjxlnruE8Rbbm5uXK5XBFLRkaGtd3J9yih3gHmzZuncePGaeLEiVqzZo3OP/98XX755dqxY0e0q4YYcOTIEfXp00czZsyodfu0adM0ffp0zZgxQ3l5ecrIyNCll16qoqIiq8y4ceO0YMECzZ07Vx999JEOHz6sK6+8UsFg8FRdBhxs+fLl+sUvfqFVq1ZpyZIlKisr09ChQ3XkyBGrDPcpoql9+/Z67LHHtHr1aq1evVoXXXSRfvzjH1v/Y5P7E81JXl6e/vrXv6p3794R67lP0RycddZZ2rVrl7WsX7/e2uboe9TA9r7//e+bu+66K2Jd9+7dzf333x+lGiFWSTILFiywvodCIZORkWEee+wxa92xY8dMamqqmTlzpjHGmEOHDhmfz2fmzp1rlfnmm2+M2+02//znP09Z3RE79u7daySZ5cuXG2O4T9E8tWrVyrzwwgvcn2hWioqKzBlnnGGWLFlicnJyzD333GOM4T9H0TxMmjTJ9OnTp9ZtTr9Haam3uZKSEn366acaOnRoxPqhQ4dqxYoVUaoVUG7r1q3avXt3xP3p9/uVk5Nj3Z+ffvqpSktLI8pkZWWpZ8+e3MM4KQoKCiRJrVu3lsR9iuYlGAxq7ty5OnLkiAYPHsz9iWblF7/4ha644gpdcsklEeu5T9FcbN68WVlZWercubOGDx+uLVu2SHL+PeqNdgXw3ezbt0/BYFDp6ekR69PT07V79+4o1QooF74Ha7s/t2/fbpWJi4tTq1atapThHkZTM8bo17/+tX7wgx+oZ8+ekrhP0TysX79egwcP1rFjx5ScnKwFCxaoR48e1v+Q5P5EtM2dO1efffaZ8vLyamzjP0fRHAwcOFBz5sxR165dtWfPHk2ZMkXnnnuuNmzY4Ph7lFDvEC6XK+K7MabGOiBaTuT+5B7GyTB27FitW7dOH330UY1t3KeIpm7dumnt2rU6dOiQXn/9dd16661avny5tZ37E9GUn5+ve+65R4sXL1Z8fHyd5bhPEU2XX3659blXr14aPHiwunTpopdfflmDBg2S5Nx7lO73NpeWliaPx1Pj6dHevXtrPIkCTrXwjKP13Z8ZGRkqKSnRwYMH6ywDNIVf/vKXevvtt/X++++rffv21nruUzQHcXFx+t73vqcBAwZo6tSp6tOnj/7P//k/3J9oFj799FPt3btX/fv3l9frldfr1fLly/XMM8/I6/Va9xn3KZqTpKQk9erVS5s3b3b8f5YS6m0uLi5O/fv315IlSyLWL1myROeee26UagWU69y5szIyMiLuz5KSEi1fvty6P/v37y+fzxdRZteuXfriiy+4h9EkjDEaO3as3njjDS1dulSdO3eO2M59iubIGKNAIMD9iWbh4osv1vr167V27VprGTBggG688UatXbtWp59+Ovcpmp1AIKCvvvpKmZmZzv/P0mjMzoemNXfuXOPz+cysWbPMl19+acaNG2eSkpLMtm3bol01xICioiKzZs0as2bNGiPJTJ8+3axZs8Zs377dGGPMY489ZlJTU80bb7xh1q9fb372s5+ZzMxMU1hYaB3jrrvuMu3btzf/+te/zGeffWYuuugi06dPH1NWVhaty4KD3H333SY1NdUsW7bM7Nq1y1qOHj1qleE+RTRNmDDBfPDBB2br1q1m3bp15oEHHjBut9ssXrzYGMP9ieap6uz3xnCfIvp+85vfmGXLlpktW7aYVatWmSuvvNKkpKRYmcjJ9yih3iH+/Oc/m+zsbBMXF2f69etnvaoJONnef/99I6nGcuuttxpjyl8hMmnSJJORkWH8fr+54IILzPr16yOOUVxcbMaOHWtat25tEhISzJVXXml27NgRhauBE9V2f0oys2fPtspwnyKabr/9duu/w9u2bWsuvvhiK9Abw/2J5ql6qOc+RbTdcMMNJjMz0/h8PpOVlWWuvfZas2HDBmu7k+9RlzHGRKePAAAAAAAA+C4YUw8AAAAAgE0R6gEAAAAAsClCPQAAAAAANkWoBwAAAADApgj1AAAAAADYFKEeAAAAAACbItQDAAAAAGBThHoAAAAAAGyKUA8AAJqVZcuWyeVy6dChQ9GuCgAAzR6hHgAAAAAAmyLUAwAAAABgU4R6AAAQwRijadOm6fTTT1dCQoL69Omj//t//6+kyq7xCxcuVJ8+fRQfH6+BAwdq/fr1Ecd4/fXXddZZZ8nv96tTp0566qmnIrYHAgGNHz9eHTp0kN/v1xlnnKFZs2ZFlPn00081YMAAJSYm6txzz9XGjRtP7oUDAGBDhHoAABDhwQcf1OzZs/Xcc89pw4YNuvfee3XTTTdp+fLlVpnf/va3evLJJ5WXl6d27drpqquuUmlpqaTyMH799ddr+PDhWr9+vXJzc/XQQw/ppZdesva/5ZZbNHfuXD3zzDP66quvNHPmTCUnJ0fUY+LEiXrqqae0evVqeb1e3X777afk+gEAsBOXMcZEuxIAAKB5OHLkiNLS0rR06VINHjzYWv/zn/9cR48e1Z133qkhQ4Zo7ty5uuGGGyRJBw4cUPv27fXSSy/p+uuv14033qhvv/1WixcvtvYfP368Fi5cqA0bNmjTpk3q1q2blixZoksuuaRGHZYtW6YhQ4boX//6ly6++GJJ0rvvvqsrrrhCxcXFio+PP8m/AgAA9kFLPQAAsHz55Zc6duyYLr30UiUnJ1vLnDlz9PXXX1vlqgb+1q1bq1u3bvrqq68kSV999ZXOO++8iOOed9552rx5s4LBoNauXSuPx6OcnJx669K7d2/rc2ZmpiRp79693/kaAQBwEm+0KwAAAJqPUCgkSVq4cKFOO+20iG1+vz8i2FfncrkklY/JD38Oq9oxMCEhoUF18fl8NY4drh8AAChHSz0AALD06NFDfr9fO3bs0Pe+972IpUOHDla5VatWWZ8PHjyoTZs2qXv37tYxPvroo4jjrlixQl27dpXH41GvXr0UCoUixugDAIATQ0s9AACwpKSk6L777tO9996rUCikH/zgByosLNSKFSuUnJys7OxsSdIjjzyiNm3aKD09XRMnTlRaWpquvvpqSdJvfvMbnXPOOfr973+vG264QStXrtSMGTP07LPPSpI6deqkW2+9VbfffrueeeYZ9enTR9u3b9fevXt1/fXXR+vSAQCwJUI9AACI8Pvf/17t2rXT1KlTtWXLFrVs2VL9+vXTAw88YHV/f+yxx3TPPfdo8+bN6tOnj95++23FxcVJkvr166f58+fr4Ycf1u9//3tlZmbqkUce0ciRI61zPPfcc3rggQc0ZswY7d+/Xx07dtQDDzwQjcsFAMDWmP0eAAA0WHhm+oMHD6ply5bRrg4AADGPMfUAAAAAANgUoR4AAAAAAJui+z0AAAAAADZFSz0AAAAAADZFqAcAAAAAwKYI9QAAAAAA2BShHgAAAAAAmyLUAwAAAABgU4R6AAAAAABsilAPAAAAAIBNEeoBAAAAALCp/w+bfQzG1VkMcAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs=200\n",
    "\n",
    "start_time=time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss  = []\n",
    "    total_r2  = []\n",
    "    print(f\"epoch {epoch+1}\\n-------------------------------\")\n",
    "    for it, batch_index in enumerate (chain(*[X_batches])):\n",
    "        # Update the weights by one optimizer step\n",
    "        \n",
    "        X_batch = X[batch_index]\n",
    "        Y_batch = Y[batch_index]\n",
    "        weights, _, _ = opt.step(cost, weights, X_batch, Y_batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        predictions = [QNN(weights, x) for x in X]\n",
    "        r2 = R2(Y, predictions)\n",
    "        cost_t=cost(weights,X_batch,Y_batch)\n",
    "        total_loss.append(cost_t)\n",
    "        total_r2.append(r2)\n",
    "        end_timet=time.time()\n",
    "        print(\"batch_idx:\",it,\"loss:\",cost_t,\"R2:\",r2,\"time:\",end_timet)\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    r2_list.append(sum(total_r2)/len(total_r2))\n",
    "    print('Training [{:.0f}%]'.format(100. * (epoch + 1) / n_epochs),\"Loss:\", loss_list[-1], \"time:\",end_timet)\n",
    "    print(\"weight:\",weights)\n",
    "    \n",
    "    \n",
    "predictions = [QNN(weights, x) for x in X]\n",
    "\n",
    "train_R2 = R2(Y, predictions)\n",
    "train_MSE=metrics.mean_squared_error(Y,predictions)\n",
    "train_RMSE=train_MSE**(1/2)\n",
    "train_MAE=metrics.mean_absolute_error(Y,predictions)\n",
    "train_MAPE=metrics.mean_absolute_percentage_error(Y,predictions)\n",
    "\n",
    "print(\"train_MSE:\",train_MSE)\n",
    "print(\"train_RMSE:\",train_RMSE)\n",
    "print(\"train_MAE:\",train_MAE)\n",
    "print(\"train_MAPE:\",train_MAPE)\n",
    "print(\"train_R2:\",train_R2)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "plt.title(\"MSE value against epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.plot(range(len(loss_list)), np.log(loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90deb265-6d46-4ecd-882d-03a49eb3e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=xtv_test_log\n",
    "Y_test=ytv_test_log\n",
    "test_predictions = [QNN(weights, x) for x in X_test]\n",
    "\n",
    "test_R2 = R2(Y_test, test_predictions)\n",
    "test_MSE=metrics.mean_squared_error(Y_test,test_predictions)\n",
    "test_RMSE=test_MSE**(1/2)\n",
    "test_MAE=metrics.mean_absolute_error(Y_test,test_predictions)\n",
    "test_MAPE=metrics.mean_absolute_percentage_error(Y_test,test_predictions)\n",
    "\n",
    "print(\"test_MSE:\",test_MSE)\n",
    "print(\"test_RMSE:\",test_RMSE)\n",
    "print(\"test_MAE:\",test_MAE)\n",
    "print(\"test_MAPE:\",test_MAPE)\n",
    "print(\"test_R2:\",test_R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
