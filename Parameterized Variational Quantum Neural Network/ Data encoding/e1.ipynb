{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586edb7a-4b3b-475e-8736-e85f04cf1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as npp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# set the random seed\n",
    "npp.random.seed(42)\n",
    "\n",
    "# create a device to execute the circuit on\n",
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "@qml.qnode(dev, diff_method=\"parameter-shift\", interface=\"autograd\")\n",
    "def circuit(params,inputs):\n",
    "    qml.RX(inputs[0], wires=0)\n",
    "    qml.RX(inputs[1], wires=1)\n",
    "    qml.RX(inputs[2], wires=2)\n",
    "    qml.RX(inputs[3], wires=3)\n",
    "    \n",
    "\n",
    "    qml.U3(params[0],params[1],params[2], wires=0)\n",
    "    qml.U3(params[3],params[4],params[5], wires=1)\n",
    "    qml.U3(params[6],params[7],params[8], wires=2)\n",
    "    qml.U3(params[9],params[10],params[11], wires=3)\n",
    "    \n",
    "\n",
    "    qml.broadcast(qml.CNOT, wires=[0, 1, 2,3], pattern=\"ring\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #return qml.expval(qml.PauliX(0) @ qml.PauliI(1)@ qml.PauliY(2)@ qml.PauliI(3))\n",
    "    return qml.expval(qml.PauliX(0) @  qml.PauliY(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21f8a3e-a4ab-4c9d-bcf5-73c1b9429ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "def norminv(x):\n",
    "    return ((1.0/math.sqrt(2.0*math.pi)) * math.exp(-x*x*0.5))\n",
    "\n",
    "def d1(S0, K, r, T, sigma, q):\n",
    "    deno = (sigma * math.sqrt(T))\n",
    "    if (deno==0):\n",
    "        return 0\n",
    "    logReturns = math.log(S0/float(K)) if ((S0/float(K)) > 0.0) else 0.0\n",
    "    return (float(logReturns) + (float(r) - float(q) + float(sigma)*float(sigma)*0.5)*float(T)) / float(deno)\n",
    "    \n",
    "def d2(S0, K, r, T, sigma, q):\n",
    "        return d1(S0, K, r, T, sigma, q)-sigma*math.sqrt(T)\n",
    "        \n",
    "def bsformula(callput, S0, K, r, T, sigma, q=0):\n",
    "    N = stats.norm.cdf\n",
    "                \n",
    "    def optionValueOfCall(S0, K, r, T, sigma, q):       \n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        _d2 = d2(S0, K, r, T, sigma, q)\n",
    "        return S0*math.exp(-q*T)*N(_d1)- K*math.exp(-r*T)*N(_d2)\n",
    "      \n",
    "    def optionValueOfPut(S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        _d2 = d2(S0, K, r, T, sigma, q)\n",
    "        return float(K)*math.exp(-float(r)*float(T))*N(-_d2) - float(S0)*math.exp(-float(q)*float(T))*N(-_d1)\n",
    "        \n",
    "    def delta(callput, S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)        \n",
    "        if callput.lower() == \"call\":            \n",
    "            return N(_d1) * math.exp(-q*T)\n",
    "        else:\n",
    "            return (N(_d1)-1)* math.exp(-q*T)\n",
    "    \n",
    "    def vega(S0, K, r, T, sigma, q):\n",
    "        _d1 = d1(S0, K, r, T, sigma, q)\n",
    "        return S0  * math.sqrt(T) * norminv(_d1)  * math.exp(-q*T)\n",
    "    \n",
    "    if callput.lower()==\"call\":\n",
    "        optionValue = optionValueOfCall(S0, K, r, T, sigma, q)\n",
    "    else:\n",
    "        optionValue = optionValueOfPut(S0, K, r, T, sigma, q)\n",
    "        \n",
    "    _delta = delta(callput, S0, K, r, T, sigma, q)\n",
    "    _vega = vega(S0, K, r, T, sigma, q)\n",
    "    \n",
    "    return (optionValue, _delta, _vega)\n",
    "\n",
    "def bsm_iv_generator(num_sample = 100,tao_bound=[0.01,2.0],  sigma_bound=[0.01,2.0], \n",
    "                     money_bound=[0.3,3.0], rr_bound=[0.01,0.2], callput='call', seed=42):\n",
    "    \n",
    "    # input parameters: when callput is not in 'call' or 'put', randomly generate the option price followed by root-finding methods to\n",
    "    # compute the corresponding implied vol\n",
    "    # return: X_input = [time,stock,rr, dividen, option_price]. Y_outpu  = volatility \n",
    "    np.random.seed(seed)\n",
    "    tao_min,tao_max = tao_bound[0],tao_bound[1]\n",
    "    \n",
    "    sigma_min, sigma_max = sigma_bound[0],sigma_bound[1]\n",
    "    moneyness_min,moneyness_max = money_bound[0],money_bound[1]\n",
    "    rr_min,rr_max = rr_bound[0],rr_bound[1]\n",
    "   \n",
    "    \n",
    "\n",
    "    num_sample = int(num_sample)\n",
    "    xx = np.zeros([num_sample,4],dtype='float')\n",
    "    \n",
    "   \n",
    "    xx[:,0] = np.random.uniform(sigma_min, sigma_max,xx.shape[0])\n",
    "    xx[:,1] = np.random.uniform(tao_min,tao_max,xx.shape[0])\n",
    "    xx[:,2] = np.random.uniform(moneyness_min,moneyness_max,xx.shape[0])\n",
    "    xx[:,3] = np.random.uniform(rr_min,rr_max,xx.shape[0])\n",
    "   \n",
    "    \n",
    "   \n",
    "    strike=1.0 #fixed strike\n",
    "    #callput = 'call' # call option\n",
    "    v = np.zeros(xx.shape[0]) # option value\n",
    "    k = np.ones(xx.shape[0]) # strike price, just in order to match the shape of v\n",
    "    \n",
    "    if callput in ['call','put']:        \n",
    "        for i in range(0,xx.shape[0]):        \n",
    "            sigma, T, S0, interest = xx[i,0],xx[i,1],xx[i,2],xx[i,3]\n",
    "            ## use the Black-Schole function in compfin.py\n",
    "            v[i] = bsformula(callput, S0, strike, interest, T, sigma)[0]              \n",
    "            \n",
    "  \n",
    "    v= v.reshape(xx.shape[0],1)     \n",
    "    xx_sample = np.concatenate((xx,v),axis=1) #sigma, time, s, r, v\n",
    "    \n",
    "    \n",
    "    X_input   = xx_sample[:,1:]   # time,stock,rr, option_price\n",
    "    Y_output  =  xx_sample[:,0] # sigma -implied volatility is the predictive variable.\n",
    "  \n",
    "    return X_input,Y_output\n",
    "#  log-transformation of the option value\n",
    "def logscale_vol(x_train_dat,y_train_dat,otm_lower=0.0000001):\n",
    "   # input data: x_train_dat = [time,stock,rr, option_price], y_train_dat = sigma  \n",
    "   \n",
    "    xtv_train_log=x_train_dat.copy()    \n",
    "    ytv_train_log =y_train_dat.copy()\n",
    "    \n",
    "    \n",
    "    #v_lower[v_lower<0.0]=0.0 # V=max(S-E*exp(-rt),0)  \n",
    "    xintrinsic_train=xtv_train_log[:,1]-1.0*np.exp(-1.0*xtv_train_log[:,2]*xtv_train_log[:,0])\n",
    "    xintrinsic_train[xintrinsic_train<0.0]=0.0 ## \\tilde{V} = max(S-E*exp(-rt),0)\n",
    "    xtv_train_log[:,-1] = xtv_train_log[:,-1] -xintrinsic_train\n",
    "    \n",
    "    ## remove intrisinc values below the threshold (otm_lower \\approx machine pricision)  \n",
    "   \n",
    "    ytv_train_log = ytv_train_log[~np.less(xtv_train_log[:,-1],otm_lower)]\n",
    "    xtv_train_log = xtv_train_log[~np.less(xtv_train_log[:,-1],otm_lower),:]\n",
    "    xtv_train_log[:,-1]=np.log(xtv_train_log[:,-1])\n",
    "\n",
    "    return xtv_train_log,ytv_train_log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce82ab6f-af86-47ed-9c2c-ddf97780cd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maturity time  range:\n",
      "0.500695213053119 0.59856504541106\n",
      "Stock price  range:\n",
      "0.9802024633538488 1.0196021540041706\n",
      "interest rate  range:\n",
      "0.030719674431487792 0.07952525710003366\n",
      "option value  range:\n",
      "0.09931091344863496 0.21642392770778063\n",
      "sigma range:\n",
      "0.30220884684944094 0.6947547746402069\n",
      "(100, 4)\n",
      "maturity time  range:\n",
      "0.500695213053119 0.59856504541106\n",
      "Stock price  range:\n",
      "0.9802024633538488 1.0196021540041706\n",
      "interest rate  range:\n",
      "0.030719674431487792 0.07952525710003366\n",
      "time option-value  range:\n",
      "-2.6542232063018565 -1.5996371627169406\n",
      "sigma range:\n",
      "0.30220884684944094 0.6947547746402069\n",
      "(80, 4)\n",
      "Parameters: [0.10312387 0.90255291 0.50525237 0.82645747 0.3200496  0.89552323\n",
      " 0.38920168 0.01083765 0.90538198 0.09128668 0.31931364 0.95006197]\n",
      "inputs: [0.95060715 0.57343789 0.63183721 0.44844552]\n",
      "Expectation value: 0.0005655187455467017\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xin_input,Yin_output=bsm_iv_generator(num_sample = 100,tao_bound=[0.5,0.6],  sigma_bound=[0.3,0.7], \n",
    "                                      money_bound=[0.98,1.02], rr_bound=[0.03,0.08],callput='call')\n",
    "\n",
    "#check the data value range on each dimension\n",
    "## xin = [maturity time, Stock price, interest rate, dividend, option value]\n",
    "\n",
    "xlabel =  ['maturity time', 'Stock price', 'interest rate','option value']\n",
    "for i in range(0, len(xlabel)):\n",
    "    print(xlabel[i]+'  range:')\n",
    "    print(np.min(Xin_input[:,i]),np.max(Xin_input[:,i]))\n",
    "    \n",
    "print('sigma range:')\n",
    "print(np.min(Yin_output),np.max(Yin_output))\n",
    "print(np.shape(Xin_input))\n",
    "\n",
    "# generate and shuffle the data set into training and test part\n",
    "xtv_train_log_all,ytv_train_log_all=logscale_vol(Xin_input,Yin_output,otm_lower=1e-4)\n",
    "'''\n",
    "for i in range(4):\n",
    "    xtv_train_log_all[:,i]= min_max_normalization(xtv_train_log_all[:,i])\n",
    "'''\n",
    "#ytv_train_log_all=ytv_train_log_all/2\n",
    "xtv_train_log,xtv_test_log, ytv_train_log, ytv_test_log   = train_test_split(xtv_train_log_all,ytv_train_log_all,test_size=0.2,random_state=42)\n",
    "\n",
    "xlabel =  ['maturity time', 'Stock price', 'interest rate','time option-value']\n",
    "for i in range(0, len(xlabel)):\n",
    "    print(xlabel[i]+'  range:')\n",
    "    print(np.min(xtv_train_log_all[:,i]),np.max(xtv_train_log_all[:,i]))\n",
    "    \n",
    "print('sigma range:')\n",
    "print(np.min(ytv_train_log),np.max(ytv_train_log))\n",
    "## how many samples after cleaning\n",
    "print(np.shape(xtv_train_log))\n",
    "\n",
    "\n",
    "params = npp.random.random([12], requires_grad=True)\n",
    "inputs = npp.random.random([4], requires_grad=True)\n",
    "print(\"Parameters:\", params)\n",
    "print(\"inputs:\", inputs)\n",
    "print(\"Expectation value:\", circuit(params,inputs))\n",
    "\n",
    "\n",
    "qnode = qml.QNode(circuit, dev)\n",
    "qml.draw_mpl(circuit, decimals=1, style=\"sketch\")(params,inputs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc5c5020-7fea-46b3-85c1-c67a90814673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.002751093322450944\n",
      "[-2.75109332e-03 -5.46887979e-03 -5.21626761e-03 -1.23017647e-03\n",
      " -1.46530337e-02 -7.19723332e-03 -9.80016480e-06 -1.17335267e-03\n",
      " -7.42488494e-04  9.46896497e-04  1.19173812e-04  1.47217079e-04]\n",
      "[-2.75109332e-03 -5.46887979e-03 -5.21626761e-03 -1.23017647e-03\n",
      " -1.46530337e-02 -7.19723332e-03 -9.80016480e-06 -1.17335267e-03\n",
      " -7.42488494e-04  9.46896497e-04  1.19173812e-04  1.47217079e-04]\n",
      "[-2.75109332e-03 -5.46887979e-03 -5.21626761e-03 -1.23017647e-03\n",
      " -1.46530337e-02 -7.19723332e-03 -9.80016480e-06 -1.17335267e-03\n",
      " -7.42488494e-04  9.46896497e-04  1.19173812e-04  1.47217079e-04]\n"
     ]
    }
   ],
   "source": [
    "def parameter_shift_term(qnode,params,inputs, i):\n",
    "    shifted = params.copy()\n",
    "    shifted[i] += np.pi/2\n",
    "    forward = qnode(shifted,inputs)  # forward evaluation\n",
    "\n",
    "    shifted[i] -= np.pi\n",
    "    backward = qnode(shifted,inputs) # backward evaluation\n",
    "\n",
    "    return 0.5 * (forward - backward)\n",
    "\n",
    "# gradient with respect to the first parameter\n",
    "print(parameter_shift_term(circuit,params,inputs, 0))\n",
    "\n",
    "\n",
    "def parameter_shift(qnode, params,inputs):\n",
    "    gradients = np.zeros([len(params)])\n",
    "\n",
    "    for i in range(len(params)):\n",
    "        gradients[i] = parameter_shift_term(qnode,params,inputs, i)\n",
    "\n",
    "    return gradients\n",
    "\n",
    "print(parameter_shift(circuit, params,inputs))\n",
    "\n",
    "grad_function = qml.grad(circuit)\n",
    "print(grad_function(params,inputs)[0])\n",
    "\n",
    "\n",
    "print(qml.gradients.param_shift(circuit)(params,inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9715830-fa60-4d48-bbc4-27dc40dbdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from itertools import chain\n",
    "import time\n",
    "def QNN(weights, angles):\n",
    "    return circuit(weights, angles)\n",
    "\n",
    "def cost(weights, features, labels):\n",
    "    predictions = [QNN(weights, f) for f in features]\n",
    "    \n",
    "    return square_loss(labels, predictions)\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def R2(labels, predictions):\n",
    "\n",
    "    r2 = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        r2 = r2 + metrics.r2_score(labels, predictions)\n",
    "    r2 = r2 / len(labels)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48fdbeb0-8d5d-419e-be05-d99d3936b2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=xtv_train_log\n",
    "Y=ytv_train_log\n",
    "weights_init = npp.random.random([12], requires_grad=True)\n",
    "opt = qml.AdamOptimizer(0.01)\n",
    "batch_size = 20\n",
    "batches = len (X) // batch_size\n",
    "X_batches = npp.array_split(npp.arange(len(X)) , batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2218b3c-8997-4af9-84d6-318bffadf9d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.25625686787092355 R2: -17.493572145414213 time: 1703089111.6858625\n",
      "batch_idx: 1 loss: 0.26113442256470976 R2: -17.489026464464878 time: 1703089114.285699\n",
      "batch_idx: 2 loss: 0.2242439882625526 R2: -17.484512832836575 time: 1703089116.9405143\n",
      "batch_idx: 3 loss: 0.261852511618362 R2: -17.477824199827843 time: 1703089119.61303\n",
      "Training [0%] Loss: 0.250871947579137 time: 1703089119.61303\n",
      "weight: [0.14225957 0.9417279  0.54438693 0.8142367  0.33218294 0.90761373\n",
      " 0.39521453 0.02186923 0.91609984 0.07870565 0.30717884 0.93784464]\n",
      "epoch 2\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.2559302885064917 R2: -17.46820479600977 time: 1703089122.245481\n",
      "batch_idx: 1 loss: 0.26060709993185727 R2: -17.455123624024118 time: 1703089124.775721\n",
      "batch_idx: 2 loss: 0.2236875170231611 R2: -17.437984609050382 time: 1703089127.5034518\n",
      "batch_idx: 3 loss: 0.2609991236613859 R2: -17.416405907004677 time: 1703089130.1705065\n",
      "Training [0%] Loss: 0.25030600728072394 time: 1703089130.1705065\n",
      "weight: [ 0.18152324  0.98108894  0.5836619   0.84477403  0.30148716  0.87688922\n",
      "  0.36330645 -0.00994412  0.88440277  0.10871908  0.33784959  0.96845196]\n",
      "epoch 3\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.2548936054412986 R2: -17.38957890041101 time: 1703089132.9158814\n",
      "batch_idx: 1 loss: 0.2591262590985833 R2: -17.356818396001636 time: 1703089135.6558912\n",
      "batch_idx: 2 loss: 0.2222209228627902 R2: -17.316695985455162 time: 1703089138.3259003\n",
      "batch_idx: 3 loss: 0.2589345995980165 R2: -17.268530597083636 time: 1703089141.0010056\n",
      "Training [1%] Loss: 0.24879384675017213 time: 1703089141.0010056\n",
      "weight: [ 0.22231043  1.02185589  0.62446363  0.88121575  0.26491832  0.84027356\n",
      "  0.37626155 -0.04760952  0.84685097  0.14480751  0.3746273   1.00512854]\n",
      "epoch 4\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.2525193638229939 R2: -17.21106956057958 time: 1703089143.6307652\n",
      "batch_idx: 1 loss: 0.2559660518142241 R2: -17.143567269651136 time: 1703089146.1756485\n",
      "batch_idx: 2 loss: 0.21914430088594367 R2: -17.0641527571876 time: 1703089148.8258147\n",
      "batch_idx: 3 loss: 0.25478557394513696 R2: -16.972030132391858 time: 1703089151.4659083\n",
      "Training [1%] Loss: 0.2456038226170747 time: 1703089151.4659083\n",
      "weight: [ 0.26448481  1.06395186  0.66666111  0.9208914   0.22520166  0.80049016\n",
      "  0.40918774 -0.08811908  0.80617329  0.18404712  0.41502962  1.04539856]\n",
      "epoch 5\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.24789981342303244 R2: -16.865646301864896 time: 1703089154.13574\n",
      "batch_idx: 1 loss: 0.2501117045334858 R2: -16.74407513795152 time: 1703089156.7605934\n",
      "batch_idx: 2 loss: 0.21352129787634838 R2: -16.605321940512788 time: 1703089159.415811\n",
      "batch_idx: 3 loss: 0.24745140338664 R2: -16.448486347229853 time: 1703089161.985742\n",
      "Training [1%] Loss: 0.23974605480487665 time: 1703089161.985742\n",
      "weight: [ 0.30840366  1.10779075  0.7106069   0.96348251  0.18271241  0.75792451\n",
      "  0.44781474 -0.13109904  0.76287227  0.22616155  0.45629074  1.08802153]\n",
      "epoch 6\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.23992911830736388 R2: -16.271908718009392 time: 1703089164.6597166\n",
      "batch_idx: 1 loss: 0.24037906607285414 R2: -16.074339909383987 time: 1703089167.325477\n",
      "batch_idx: 2 loss: 0.2042607623389013 R2: -15.853660746254013 time: 1703089169.9415119\n",
      "batch_idx: 3 loss: 0.23568142365777608 R2: -15.608457747168362 time: 1703089172.630652\n",
      "Training [1%] Loss: 0.23006259259422387 time: 1703089172.630652\n",
      "weight: [ 0.35431615  1.15364496  0.75654153  1.00877803  0.13760353  0.71274357\n",
      "  0.49043099 -0.17649258  0.71727346  0.27102118  0.46989796  1.11969337]\n",
      "epoch 7\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.22734318320380723 R2: -15.337063249942045 time: 1703089175.295694\n",
      "batch_idx: 1 loss: 0.22542539219184418 R2: -15.03837484557639 time: 1703089178.0207162\n",
      "batch_idx: 2 loss: 0.19011896155647576 R2: -14.711648774395973 time: 1703089180.6655304\n",
      "batch_idx: 3 loss: 0.2181408383979872 R2: -14.356082244064734 time: 1703089183.3157907\n",
      "Training [1%] Loss: 0.2152570938375286 time: 1703089183.3157907\n",
      "weight: [ 0.4022785   1.20157836  0.80450713  1.05625846  0.09004148  0.6651333\n",
      "  0.53640646 -0.22421055  0.66979797  0.31836821  0.44442079  1.11725676]\n",
      "epoch 8\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.20891341703442717 R2: -13.971364367012947 time: 1703089185.9470148\n",
      "batch_idx: 1 loss: 0.20416773625314516 R2: -13.557305513127094 time: 1703089188.615691\n",
      "batch_idx: 2 loss: 0.1702628147684298 R2: -13.115085348960378 time: 1703089191.3641999\n",
      "batch_idx: 3 loss: 0.19417052402258447 R2: -12.644136073788532 time: 1703089193.965739\n",
      "Training [2%] Loss: 0.19437862301964667 time: 1703089193.965739\n",
      "weight: [ 0.45217945  1.25147649  0.85436757  1.10436301  0.04026322  0.6153588\n",
      "  0.58533178 -0.27408487  0.62107583  0.36774316  0.40858893  1.10890863]\n",
      "epoch 9\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.18421810393168164 R2: -12.145385872871515 time: 1703089196.6759257\n",
      "batch_idx: 1 loss: 0.1764881366582066 R2: -11.619518577289577 time: 1703089199.2917528\n",
      "batch_idx: 2 loss: 0.14477313209982684 R2: -11.070583205228221 time: 1703089202.028248\n",
      "batch_idx: 3 loss: 0.16411583218030038 R2: -10.499006102790183 time: 1703089204.6255326\n",
      "Training [2%] Loss: 0.16739880121750386 time: 1703089204.6255326\n",
      "weight: [ 0.50373131  1.30303371  0.9057893   1.14776366 -0.01137496  0.56382034\n",
      "  0.63682621 -0.32584085  0.57209714  0.41800278  0.38789345  1.1313872 ]\n",
      "epoch 10\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.1538939183063483 R2: -9.908444974230939 time: 1703089207.2402287\n",
      "batch_idx: 1 loss: 0.14349997987476687 R2: -9.301448589828842 time: 1703089209.7958295\n",
      "batch_idx: 2 loss: 0.11505173009791594 R2: -8.684909068362114 time: 1703089212.4757984\n",
      "batch_idx: 3 loss: 0.1298630907833282 R2: -8.059447054201621 time: 1703089215.180747\n",
      "Training [2%] Loss: 0.1355771797655898 time: 1703089215.180747\n",
      "weight: [ 0.55641383  1.35568348  0.95817132  1.1710575  -0.06432414  0.51114304\n",
      "  0.69041271 -0.37903985  0.52437241  0.46541092  0.37747093  1.16346983]\n",
      "epoch 11\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.12020147585097204 R2: -7.430016665956214 time: 1703089217.8465948\n",
      "batch_idx: 1 loss: 0.10798907463090224 R2: -6.799949772277036 time: 1703089220.5756907\n",
      "batch_idx: 2 loss: 0.08401059434413906 R2: -6.1788580229207914 time: 1703089223.1357448\n",
      "batch_idx: 3 loss: 0.09468517992568345 R2: -5.566455251412658 time: 1703089225.7957394\n",
      "Training [2%] Loss: 0.10172158118792421 time: 1703089225.7957394\n",
      "weight: [ 0.60937598  1.40847802  1.01053016  1.16067115 -0.11775704  0.45832398\n",
      "  0.74539748 -0.43299168  0.47999871  0.49992036  0.35612302  1.17284363]\n",
      "epoch 12\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.08660176216239449 R2: -4.968773337377002 time: 1703089228.425472\n",
      "batch_idx: 1 loss: 0.07379775181611709 R2: -4.389413316830258 time: 1703089231.1107106\n",
      "batch_idx: 2 loss: 0.05549466958355448 R2: -3.838515863594977 time: 1703089233.7904773\n",
      "batch_idx: 3 loss: 0.06254269816362765 R2: -3.3129970004708555 time: 1703089236.5307345\n",
      "Training [2%] Loss: 0.06960922043142342 time: 1703089236.5307345\n",
      "weight: [ 0.66131744  1.45994875  1.06137739  1.12793755 -0.17044071  0.40694658\n",
      "  0.80071499 -0.48663501  0.44137637  0.50813441  0.35155844  1.17340157]\n",
      "epoch 13\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.057008748665762755 R2: -2.818554469058453 time: 1703089239.151041\n",
      "batch_idx: 1 loss: 0.04500465497848145 R2: -2.3584257330437803 time: 1703089241.765748\n",
      "batch_idx: 2 loss: 0.03304284142930889 R2: -1.9401188272841718 time: 1703089244.386967\n",
      "batch_idx: 3 loss: 0.03711283986632563 R2: -1.5587581185315718 time: 1703089247.0356789\n",
      "Training [3%] Loss: 0.04304227123496968 time: 1703089247.0356789\n",
      "weight: [ 0.71042633  1.50806207  1.10870607  1.08898711 -0.2205853   0.35927801\n",
      "  0.85475076 -0.53841387  0.41040648  0.48962346  0.37092788  1.16999202]\n",
      "epoch 14\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.034617852658263566 R2: -1.216595437712543 time: 1703089249.740793\n",
      "batch_idx: 1 loss: 0.024594125211258706 R2: -0.9141640600553986 time: 1703089252.336952\n",
      "batch_idx: 2 loss: 0.018502616830950704 R2: -0.6537192066225422 time: 1703089254.965934\n",
      "batch_idx: 3 loss: 0.020380799685480108 R2: -0.4288826232209953 time: 1703089257.565768\n",
      "Training [3%] Loss: 0.024523848596488273 time: 1703089257.565768\n",
      "weight: [ 0.75452312  1.55048231  1.15027733  1.05919787 -0.26590555  0.31789297\n",
      "  0.90523713 -0.58624088  0.38759804  0.45374404  0.39800898  1.14800572]\n",
      "epoch 15\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.020521998327271432 R2: -0.23804742078153743 time: 1703089260.235873\n",
      "batch_idx: 1 loss: 0.01293831269334968 R2: -0.07938141891439895 time: 1703089262.8658888\n",
      "batch_idx: 2 loss: 0.011117113627410512 R2: 0.04932554886454543 time: 1703089265.5259678\n",
      "batch_idx: 3 loss: 0.011497922888300843 R2: 0.15396151131115107 time: 1703089268.2477124\n",
      "Training [3%] Loss: 0.014018836884083116 time: 1703089268.2477124\n",
      "weight: [ 0.79155549  1.58526715  1.1842874   1.04830598 -0.30413967  0.28468913\n",
      "  0.94946076 -0.62773628  0.37190768  0.40762062  0.43492309  1.11724586]\n",
      "epoch 16\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.013209965939502003 R2: 0.2379443574387597 time: 1703089270.8907669\n",
      "batch_idx: 1 loss: 0.00781927713245006 R2: 0.30372463225328983 time: 1703089273.5759706\n",
      "batch_idx: 2 loss: 0.008250108074578589 R2: 0.355019835621306 time: 1703089276.1807206\n",
      "batch_idx: 3 loss: 0.007711902402200464 R2: 0.3954244937578038 time: 1703089278.875453\n",
      "Training [3%] Loss: 0.00924781338718278 time: 1703089278.875453\n",
      "weight: [ 0.82030412  1.61164114  1.21006054  1.05144627 -0.33387178  0.26001021\n",
      "  0.98499006 -0.66087081  0.36143911  0.35496245  0.48243654  1.08625708]\n",
      "epoch 17\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.009880191004600093 R2: 0.4278689292417708 time: 1703089281.5455363\n",
      "batch_idx: 1 loss: 0.006092586170942974 R2: 0.45406984416445006 time: 1703089284.190217\n",
      "batch_idx: 2 loss: 0.007140344033594902 R2: 0.4769127151704417 time: 1703089286.8658412\n",
      "batch_idx: 3 loss: 0.006179840170212873 R2: 0.49746001703401754 time: 1703089289.5207803\n",
      "Training [3%] Loss: 0.00732324034483771 time: 1703089289.5207803\n",
      "weight: [ 0.84080687  1.63019371  1.22819749  1.05712597 -0.35503496  0.24276446\n",
      "  1.01063601 -0.68474578  0.35431359  0.29800794  0.53735722  1.05946483]\n",
      "epoch 18\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.008114168363840362 R2: 0.5171122450130262 time: 1703089292.1206713\n",
      "batch_idx: 1 loss: 0.005332574687809257 R2: 0.5365265236280382 time: 1703089294.6658263\n",
      "batch_idx: 2 loss: 0.006126823482109383 R2: 0.557076462185712 time: 1703089297.3614852\n",
      "batch_idx: 3 loss: 0.005137942403851808 R2: 0.578119435172318 time: 1703089299.9154835\n",
      "Training [4%] Loss: 0.006177877234402703 time: 1703089299.9154835\n",
      "weight: [ 0.85422426  1.64241976  1.24014419  1.05661693 -0.3687811   0.2312067\n",
      "  1.02696234 -0.69998578  0.34916154  0.2387108   0.596805    1.04512447]\n",
      "epoch 19\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.006675625861728323 R2: 0.5997057144577267 time: 1703089302.6259375\n",
      "batch_idx: 1 loss: 0.004441212743119866 R2: 0.6218683913021293 time: 1703089305.1992903\n",
      "batch_idx: 2 loss: 0.00479795405839282 R2: 0.6447465004930072 time: 1703089307.806517\n",
      "batch_idx: 3 loss: 0.004043830584273685 R2: 0.6669308405871436 time: 1703089310.5955973\n",
      "Training [4%] Loss: 0.004989655811878673 time: 1703089310.5955973\n",
      "weight: [ 0.86237861  1.65010381  1.24763206  1.04787496 -0.37699721  0.22360345\n",
      "  1.03605158 -0.70853539  0.34521119  0.17927958  0.65809823  1.05213912]\n",
      "epoch 20\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0053938966396323874 R2: 0.6877165945249152 time: 1703089313.2195392\n",
      "batch_idx: 1 loss: 0.0034023742753955402 R2: 0.7068987029813418 time: 1703089315.945815\n",
      "batch_idx: 2 loss: 0.0035413687884213777 R2: 0.7239393044637199 time: 1703089318.5855963\n",
      "batch_idx: 3 loss: 0.003164387516541388 R2: 0.7379292637150171 time: 1703089321.2457168\n",
      "Training [4%] Loss: 0.0038755068049976735 time: 1703089321.2457168\n",
      "weight: [ 0.86731486  1.65492218  1.25231268  1.03561194 -0.38183294  0.21855896\n",
      "  1.04088007 -0.71312914  0.34217583  0.12266974  0.71627769  1.0731082 ]\n",
      "epoch 21\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.004623847162700023 R2: 0.7493178228155718 time: 1703089323.8455343\n",
      "batch_idx: 1 loss: 0.0027114837912031817 R2: 0.7583626992207111 time: 1703089326.5359678\n",
      "batch_idx: 2 loss: 0.0028647667949047596 R2: 0.765508256715373 time: 1703089329.20559\n",
      "batch_idx: 3 loss: 0.0027272553422284297 R2: 0.7720273061325147 time: 1703089331.8524265\n",
      "Training [4%] Loss: 0.0032318382727590986 time: 1703089331.8524265\n",
      "weight: [ 0.87089245  1.65822585  1.25554014  1.02872377 -0.38524778  0.21512372\n",
      "  1.04447143 -0.71653947  0.34004876  0.07266759  0.75747135  1.0733473 ]\n",
      "epoch 22\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0042451788253800955 R2: 0.7793072515607821 time: 1703089334.5007112\n",
      "batch_idx: 1 loss: 0.002344613244396015 R2: 0.7865028816403379 time: 1703089337.1270747\n",
      "batch_idx: 2 loss: 0.0025025670879937232 R2: 0.7936593435547014 time: 1703089339.8276765\n",
      "batch_idx: 3 loss: 0.0023203705604841595 R2: 0.801096246709967 time: 1703089342.4559383\n",
      "Training [4%] Loss: 0.002853182429563498 time: 1703089342.4559383\n",
      "weight: [ 0.87421561  1.66082146  1.25812562  1.03291165 -0.38839899  0.21274486\n",
      "  1.04860577 -0.7204048   0.33879512  0.03183364  0.76863114  1.03967581]\n",
      "epoch 23\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.003748250184620317 R2: 0.8089778913975817 time: 1703089345.075578\n",
      "batch_idx: 1 loss: 0.0019950636573705578 R2: 0.8162704889050671 time: 1703089347.7059882\n",
      "batch_idx: 2 loss: 0.002182680410780688 R2: 0.8229618317917315 time: 1703089350.4154851\n",
      "batch_idx: 3 loss: 0.0019272575392384028 R2: 0.8291759199688276 time: 1703089353.0257635\n",
      "Training [5%] Loss: 0.0024633129480024912 time: 1703089353.0257635\n",
      "weight: [ 8.77468301e-01  1.66297066e+00  1.26031675e+00  1.04556494e+00\n",
      " -3.91474671e-01  2.11092371e-01  1.05333336e+00 -7.24785952e-01\n",
      "  3.38186324e-01 -7.94781285e-04  7.59418180e-01  9.92812234e-01]\n",
      "epoch 24\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0032670089079433287 R2: 0.8350814048737474 time: 1703089355.6667242\n",
      "batch_idx: 1 loss: 0.0017260294739282211 R2: 0.8402937251773329 time: 1703089358.3008714\n",
      "batch_idx: 2 loss: 0.0019532200962359323 R2: 0.8449353054090883 time: 1703089360.9111881\n",
      "batch_idx: 3 loss: 0.0016500894840702478 R2: 0.8491605980410254 time: 1703089363.635932\n",
      "Training [5%] Loss: 0.0021490869905444326 time: 1703089363.635932\n",
      "weight: [ 0.88045992  1.6647052   1.26212302  1.06123159 -0.39426919  0.20993939\n",
      "  1.05801916 -0.72911446  0.33794072 -0.02800774  0.74343549  0.94729167]\n",
      "epoch 25\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002929959278968916 R2: 0.8530912860304432 time: 1703089366.4356635\n",
      "batch_idx: 1 loss: 0.001534668455771218 R2: 0.8566543160041196 time: 1703089369.098041\n",
      "batch_idx: 2 loss: 0.0018045165112511824 R2: 0.8598638031943577 time: 1703089371.79979\n",
      "batch_idx: 3 loss: 0.0014553995732047573 R2: 0.862829079930018 time: 1703089374.5523214\n",
      "Training [5%] Loss: 0.0019311359547990186 time: 1703089374.5523214\n",
      "weight: [ 0.88307652  1.66605968  1.26356318  1.07649945 -0.39665705  0.20912663\n",
      "  1.06225404 -0.73302316  0.33786827 -0.05188816  0.72745467  0.90976216]\n",
      "epoch 26\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002713003133270131 R2: 0.8655831009492522 time: 1703089377.1959517\n",
      "batch_idx: 1 loss: 0.0013800435142450576 R2: 0.8681157757900941 time: 1703089379.8797626\n",
      "batch_idx: 2 loss: 0.0017114412998177637 R2: 0.8703730049437501 time: 1703089382.4459302\n",
      "batch_idx: 3 loss: 0.0013085682945422738 R2: 0.8724425410651755 time: 1703089384.9458404\n",
      "Training [5%] Loss: 0.0017782640604688065 time: 1703089384.9458404\n",
      "weight: [ 0.88537657  1.66712258  1.26471987  1.09055797 -0.39869804  0.20853923\n",
      "  1.06604587 -0.73652311  0.33789208 -0.07303041  0.71342343  0.88111807]\n",
      "epoch 27\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0025765765181519373 R2: 0.8743562782219023 time: 1703089387.5959513\n",
      "batch_idx: 1 loss: 0.001254017593001142 R2: 0.8760906502848499 time: 1703089390.395641\n",
      "batch_idx: 2 loss: 0.0016626991625767278 R2: 0.8776121135343405 time: 1703089393.095921\n",
      "batch_idx: 3 loss: 0.0011993111998406093 R2: 0.8789914535281091 time: 1703089395.8484766\n",
      "Training [5%] Loss: 0.0016731511183926042 time: 1703089395.8484766\n",
      "weight: [ 0.88750864  1.66800363  1.26570339  1.10392976 -0.40055219  0.20808913\n",
      "  1.06963474 -0.73983694  0.33800329 -0.09103289  0.70195438  0.86041215]\n",
      "epoch 28\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002489400058301017 R2: 0.8803160364818943 time: 1703089398.635512\n",
      "batch_idx: 1 loss: 0.0011584645232764284 R2: 0.8815049874894199 time: 1703089401.2755597\n",
      "batch_idx: 2 loss: 0.0016420529806309334 R2: 0.8825828156539457 time: 1703089403.9506078\n",
      "batch_idx: 3 loss: 0.0011191481716454055 R2: 0.8835787184358217 time: 1703089406.8257306\n",
      "Training [6%] Loss: 0.001602266433463446 time: 1703089406.8257306\n",
      "weight: [ 0.88961057  1.66879384  1.2666067   1.11724356 -0.40237066  0.20770873\n",
      "  1.07326598 -0.74319186  0.33821069 -0.1053157   0.69372159  0.84688912]\n",
      "epoch 29\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0024203872250150985 R2: 0.884630816250492 time: 1703089409.5139997\n",
      "batch_idx: 1 loss: 0.0010888432438616597 R2: 0.8855836408960819 time: 1703089412.2457156\n",
      "batch_idx: 2 loss: 0.0016278964304905004 R2: 0.886503590931609 time: 1703089414.9855828\n",
      "batch_idx: 3 loss: 0.0010578285942955468 R2: 0.8873697174403643 time: 1703089417.6258469\n",
      "Training [6%] Loss: 0.0015487388734157013 time: 1703089417.6258469\n",
      "weight: [ 0.89174609  1.66954193  1.26747847  1.13059291 -0.40422412  0.20735228\n",
      "  1.07704225 -0.74668393  0.33850737 -0.11579639  0.68914362  0.8398482 ]\n",
      "epoch 30\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002347966953734003 R2: 0.8883270264579093 time: 1703089420.3309839\n",
      "batch_idx: 1 loss: 0.0010389310721479919 R2: 0.8891867663518266 time: 1703089422.985554\n",
      "batch_idx: 2 loss: 0.001608681609564469 R2: 0.8900184091137786 time: 1703089425.575935\n",
      "batch_idx: 3 loss: 0.0010107911480575012 R2: 0.8907871960650278 time: 1703089428.277256\n",
      "Training [6%] Loss: 0.0015015926958759913 time: 1703089428.277256\n",
      "weight: [ 0.89389003  1.6702513   1.26831888  1.14347531 -0.40608346  0.20699891\n",
      "  1.08088247 -0.75023958  0.3388595  -0.12317709  0.68774432  0.83796995]\n",
      "epoch 31\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0022709337027827146 R2: 0.8916048569287371 time: 1703089430.9154887\n",
      "batch_idx: 1 loss: 0.0010058915590746976 R2: 0.8923263336669149 time: 1703089433.5656505\n",
      "batch_idx: 2 loss: 0.00158796289876803 R2: 0.8929904093823436 time: 1703089436.2437332\n",
      "batch_idx: 3 loss: 0.0009776666458815426 R2: 0.8935959383077625 time: 1703089438.9257898\n",
      "Training [6%] Loss: 0.0014606137016267462 time: 1703089438.9257898\n",
      "weight: [ 0.89595819  1.67089555  1.26909614  1.15512321 -0.40785099  0.20665104\n",
      "  1.08458093 -0.75366929  0.33921542 -0.12873375  0.68819987  0.83934715]\n",
      "epoch 32\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002200550759420028 R2: 0.8942002726538961 time: 1703089441.6837733\n",
      "batch_idx: 1 loss: 0.0009854564841269026 R2: 0.8947467237661234 time: 1703089444.318667\n",
      "batch_idx: 2 loss: 0.0015732958176005508 R2: 0.8952218898727734 time: 1703089447.0556698\n",
      "batch_idx: 3 loss: 0.0009546358068730564 R2: 0.8956727745495717 time: 1703089449.7055662\n",
      "Training [6%] Loss: 0.0014284847170051346 time: 1703089449.7055662\n",
      "weight: [ 0.89786005  1.67144286  1.26977313  1.16492053 -0.40941973  0.20632456\n",
      "  1.08792055 -0.7567718   0.33952561 -0.13378281  0.68902681  0.84215556]\n",
      "epoch 33\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002145209425951475 R2: 0.8960990389367305 time: 1703089452.3971648\n",
      "batch_idx: 1 loss: 0.0009690186698081048 R2: 0.8965212457222688 time: 1703089455.0805259\n",
      "batch_idx: 2 loss: 0.0015674328808795751 R2: 0.896873471791862 time: 1703089457.7757242\n",
      "batch_idx: 3 loss: 0.0009345511477955942 R2: 0.8972343486328794 time: 1703089460.4555035\n",
      "Training [7%] Loss: 0.0014040530311086872 time: 1703089460.4555035\n",
      "weight: [ 0.89954361  1.67187605  1.27032943  1.17264496 -0.41072559  0.20603495\n",
      "  1.09077186 -0.75942608  0.33976001 -0.13918177  0.68922839  0.84519447]\n",
      "epoch 34\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002105903254259782 R2: 0.897563248881165 time: 1703089463.1554773\n",
      "batch_idx: 1 loss: 0.000949087658968065 R2: 0.8979179588647522 time: 1703089466.054236\n",
      "batch_idx: 2 loss: 0.00156946425812929 R2: 0.8982046835864704 time: 1703089468.6957486\n",
      "batch_idx: 3 loss: 0.0009129940736510078 R2: 0.8985081882985215 time: 1703089471.4305892\n",
      "Training [7%] Loss: 0.0013843623112520362 time: 1703089471.4305892\n",
      "weight: [ 0.90101234  1.67220035  1.27076983  1.17846942 -0.41176883  0.20578687\n",
      "  1.09313249 -0.76162868  0.33991425 -0.14512046  0.68850579  0.84794623]\n",
      "epoch 35\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002079937789779285 R2: 0.8987797393081538 time: 1703089474.0905862\n",
      "batch_idx: 1 loss: 0.0009245151990717777 R2: 0.8990742643551561 time: 1703089476.9184628\n",
      "batch_idx: 2 loss: 0.0015777613928533746 R2: 0.8993061831185605 time: 1703089479.5157146\n",
      "batch_idx: 3 loss: 0.0008907191171916047 R2: 0.8995446534295863 time: 1703089482.1455646\n",
      "Training [7%] Loss: 0.0013682333747240105 time: 1703089482.1455646\n",
      "weight: [ 0.90231403  1.6724388   1.2711192   1.18280957 -0.41260233  0.20557236\n",
      "  1.09510311 -0.76347209  0.34000431 -0.15123716  0.68711214  0.85034704]\n",
      "epoch 36\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002063512991447834 R2: 0.8997623499039886 time: 1703089484.825695\n",
      "batch_idx: 1 loss: 0.0008993149643388252 R2: 0.8999848566221464 time: 1703089487.4708707\n",
      "batch_idx: 2 loss: 0.0015899030538164504 R2: 0.900161148704697 time: 1703089490.165594\n",
      "batch_idx: 3 loss: 0.0008709000584419049 R2: 0.9003315685922834 time: 1703089492.73588\n",
      "Training [7%] Loss: 0.0013559077670112537 time: 1703089492.73588\n",
      "weight: [ 0.90351336  1.67262089  1.27140975  1.1861334  -0.41330004  0.20537667\n",
      "  1.09682575 -0.7650877   0.34005449 -0.15693437  0.6855554   0.85252738]\n",
      "epoch 37\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020520028101846275 R2: 0.9005017683454438 time: 1703089495.3559012\n",
      "batch_idx: 1 loss: 0.0008781215497682418 R2: 0.9006602362628465 time: 1703089497.9458766\n",
      "batch_idx: 2 loss: 0.001602310395801961 R2: 0.9007945506869387 time: 1703089500.5657105\n",
      "batch_idx: 3 loss: 0.0008558185447092819 R2: 0.900915586242618 time: 1703089503.2007656\n",
      "Training [7%] Loss: 0.001347063325116028 time: 1703089503.2007656\n",
      "weight: [ 0.90466394  1.67277086  1.271668    1.18881188 -0.4139239   0.20518679\n",
      "  1.09841941 -0.76658578  0.34008524 -0.16171917  0.68429365  0.85462298]\n",
      "epoch 38\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0020410269270703723 R2: 0.9010535755260543 time: 1703089505.7789233\n",
      "batch_idx: 1 loss: 0.0008632789906689988 R2: 0.9011710564103288 time: 1703089508.3766472\n",
      "batch_idx: 2 loss: 0.0016119205323543266 R2: 0.9012790889533102 time: 1703089511.0108218\n",
      "batch_idx: 3 loss: 0.0008458992514895937 R2: 0.9013715532685941 time: 1703089513.685785\n",
      "Training [8%] Loss: 0.0013405314253958228 time: 1703089513.685785\n",
      "weight: [ 0.90579176  1.6729007   1.27190697  1.19104868 -0.41450361  0.20499751\n",
      "  1.09994097 -0.76801892  0.34010586 -0.16541858  0.68352779  0.85667418]\n",
      "epoch 39\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002028474096826982 R2: 0.901484777348435 time: 1703089516.3057897\n",
      "batch_idx: 1 loss: 0.0008545992518985725 R2: 0.9015776112774591 time: 1703089518.9556105\n",
      "batch_idx: 2 loss: 0.0016180638668513239 R2: 0.90166313203668 time: 1703089521.7269177\n",
      "batch_idx: 3 loss: 0.0008402049786666284 R2: 0.9017361298850437 time: 1703089524.3599856\n",
      "Training [8%] Loss: 0.0013353355485608766 time: 1703089524.3599856\n",
      "weight: [ 0.90689484  1.67301005  1.27212613  1.19289259 -0.41503558  0.20481238\n",
      "  1.10138329 -0.76937996  0.34011398 -0.1681974   0.68316637  0.85861887]\n",
      "epoch 40\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.002015078767657397 R2: 0.9018224698896372 time: 1703089527.0305536\n",
      "batch_idx: 1 loss: 0.0008501705570397482 R2: 0.9018968584206422 time: 1703089529.6342616\n",
      "batch_idx: 2 loss: 0.0016222407610896675 R2: 0.901958639472595 time: 1703089532.3186731\n",
      "batch_idx: 3 loss: 0.0008369971264777806 R2: 0.9020155839367175 time: 1703089534.9399703\n",
      "Training [8%] Loss: 0.0013311218030661483 time: 1703089534.9399703\n",
      "weight: [ 0.90795551  1.67309152  1.27231726  1.19430592 -0.41549729  0.20464\n",
      "  1.10270281 -0.77062773  0.3401007  -0.17041047  0.68294943  0.86035394]\n",
      "epoch 41\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00200291657129841 R2: 0.9020755668308249 time: 1703089537.6556346\n",
      "batch_idx: 1 loss: 0.000847347846708427 R2: 0.9021357572230642 time: 1703089540.3356974\n",
      "batch_idx: 2 loss: 0.0016264112138611613 R2: 0.9021776288054026 time: 1703089542.987662\n",
      "batch_idx: 3 loss: 0.0008343808338976374 R2: 0.9022227339471746 time: 1703089545.695745\n",
      "Training [8%] Loss: 0.001327764116441409 time: 1703089545.695745\n",
      "weight: [ 0.90895648  1.67313765  1.27247211  1.19524431 -0.41586652  0.20448856\n",
      "  1.10385678 -0.7717218   0.34005736 -0.17239918  0.68262829  0.86180559]\n",
      "epoch 42\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001993581030862573 R2: 0.9022636706708136 time: 1703089548.345747\n",
      "batch_idx: 1 loss: 0.0008439632837787892 R2: 0.9023136143697018 time: 1703089551.0058115\n",
      "batch_idx: 2 loss: 0.0016316909798583864 R2: 0.9023428933366743 time: 1703089553.655639\n",
      "batch_idx: 3 loss: 0.0008311545238240495 R2: 0.902379210780593 time: 1703089556.3679438\n",
      "Training [8%] Loss: 0.0013250974545809496 time: 1703089556.3679438\n",
      "weight: [ 0.90989215  1.6731459   1.27258792  1.19570942 -0.41613526  0.20436178\n",
      "  1.10482985 -0.77264743  0.33998043 -0.1743471   0.68208967  0.86296188]\n",
      "epoch 43\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001987419884986376 R2: 0.9024092681567971 time: 1703089559.045942\n",
      "batch_idx: 1 loss: 0.000839272636651263 R2: 0.9024498762429529 time: 1703089561.6555195\n",
      "batch_idx: 2 loss: 0.0016380779146007048 R2: 0.9024719134450694 time: 1703089564.2883718\n",
      "batch_idx: 3 loss: 0.0008272519420566978 R2: 0.9024996702346325 time: 1703089566.9257627\n",
      "Training [9%] Loss: 0.0013230055945737604 time: 1703089566.9257627\n",
      "weight: [ 0.91077075  1.67311971  1.27266854  1.19575924 -0.41631262  0.20425799\n",
      "  1.10563967 -0.77342088  0.33987251 -0.1762519   0.68137664  0.86386443]\n",
      "epoch 44\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019837020444162645 R2: 0.9025237260060012 time: 1703089569.570752\n",
      "batch_idx: 1 loss: 0.0008339346792021725 R2: 0.9025541876106329 time: 1703089572.2118068\n",
      "batch_idx: 2 loss: 0.0016447723007521381 R2: 0.9025716732437354 time: 1703089574.8159277\n",
      "batch_idx: 3 loss: 0.0008233891295007329 R2: 0.902590994698007 time: 1703089577.4026046\n",
      "Training [9%] Loss: 0.0013214495384678271 time: 1703089577.4026046\n",
      "weight: [ 0.91160886  1.67306615  1.27272179  1.19548394 -0.41641821  0.20417212\n",
      "  1.10632408 -0.77407745  0.33973996 -0.17799766  0.68062557  0.8645799 ]\n",
      "epoch 45\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001981172468386495 R2: 0.9026114253509737 time: 1703089580.0881257\n",
      "batch_idx: 1 loss: 0.0008291547148159368 R2: 0.9026326770936413 time: 1703089582.7084653\n",
      "batch_idx: 2 loss: 0.001650737107580769 R2: 0.9026472436019537 time: 1703089585.3855338\n",
      "batch_idx: 3 loss: 0.0008203347529252989 R2: 0.902660194664733 time: 1703089588.0256333\n",
      "Training [9%] Loss: 0.001320349760927125 time: 1703089588.0256333\n",
      "weight: [ 0.91242294  1.6729923   1.27275548  1.19496902 -0.41647177  0.20409886\n",
      "  1.10692113 -0.7746527   0.3395892  -0.1794643   0.6799723   0.86517055]\n",
      "epoch 46\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019787131763177677 R2: 0.9026779948932525 time: 1703089590.7180884\n",
      "batch_idx: 1 loss: 0.0008257800216122406 R2: 0.9026930672578054 time: 1703089593.4858353\n",
      "batch_idx: 2 loss: 0.0016552955383504421 R2: 0.9027054567769299 time: 1703089596.1105652\n",
      "batch_idx: 3 loss: 0.0008184103708866851 R2: 0.9027148746349398 time: 1703089598.6455095\n",
      "Training [9%] Loss: 0.001319549776791784 time: 1703089598.6455095\n",
      "weight: [ 0.91322318  1.67290246  1.27277438  1.19426775 -0.4164854   0.204035\n",
      "  1.10745416 -0.77516842  0.33942399 -0.18060731  0.67948236  0.8656751 ]\n",
      "epoch 47\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019758387445574215 R2: 0.9027297821602206 time: 1703089601.363606\n",
      "batch_idx: 1 loss: 0.0008239040413399081 R2: 0.9027417512509777 time: 1703089604.0071275\n",
      "batch_idx: 2 loss: 0.0016584418561183113 R2: 0.9027517580526118 time: 1703089606.530852\n",
      "batch_idx: 3 loss: 0.0008174162348604604 R2: 0.9027596635645871 time: 1703089609.2557502\n",
      "Training [9%] Loss: 0.0013189002192190253 time: 1703089609.2557502\n",
      "weight: [ 0.91401226  1.67279758  1.27277959  1.19339545 -0.41646186  0.20397998\n",
      "  1.10792859 -0.77562961  0.33924477 -0.18147286  0.6791367   0.86610564]\n",
      "epoch 48\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001972742530353133 R2: 0.9027710401379837 time: 1703089611.8220534\n",
      "batch_idx: 1 loss: 0.0008230025355839535 R2: 0.9027818111972529 time: 1703089614.5755217\n",
      "batch_idx: 2 loss: 0.0016606778737494874 R2: 0.902789285259104 time: 1703089617.2109945\n",
      "batch_idx: 3 loss: 0.0008168541921089323 R2: 0.9027966757078382 time: 1703089619.8809793\n",
      "Training [10%] Loss: 0.0013183192829488764 time: 1703089619.8809793\n",
      "weight: [ 0.91478845  1.67267658  1.27277002  1.19234374 -0.4163983   0.20393475\n",
      "  1.10833914 -0.77603125  0.33905002 -0.18215727  0.67886719  0.86645843]\n",
      "epoch 49\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001969929845823392 R2: 0.9028047754488002 time: 1703089622.5159307\n",
      "batch_idx: 1 loss: 0.0008223597032441067 R2: 0.9028151027718975 time: 1703089625.1059444\n",
      "batch_idx: 2 loss: 0.0016625819263936306 R2: 0.9028206973346894 time: 1703089627.8008845\n",
      "batch_idx: 3 loss: 0.0008162538719924527 R2: 0.9028278405322256 time: 1703089630.3957493\n",
      "Training [10%] Loss: 0.0013177813368633953 time: 1703089630.3957493\n",
      "weight: [ 0.91555011  1.67253839  1.27274461  1.19110247 -0.41629196  0.20390014\n",
      "  1.10868078 -0.77636853  0.33883825 -0.18274868  0.67860931  0.86672895]\n",
      "epoch 50\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00196778150292585 R2: 0.9028339085082424 time: 1703089633.0342166\n",
      "batch_idx: 1 loss: 0.0008214950705349623 R2: 0.9028436758410896 time: 1703089635.5655293\n",
      "batch_idx: 2 loss: 0.0016644689042010733 R2: 0.9028484736174092 time: 1703089638.1506424\n",
      "batch_idx: 3 loss: 0.0008154119416762934 R2: 0.9028551296495809 time: 1703089640.8008206\n",
      "Training [10%] Loss: 0.0013172893548345447 time: 1703089640.8008206\n",
      "weight: [ 0.91629872  1.67238334  1.27270383  1.18967549 -0.41614411  0.20387575\n",
      "  1.1089561  -0.77664387  0.33860943 -0.18328937  0.67833695  0.8669216 ]\n",
      "epoch 51\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019663378378099823 R2: 0.9028605421065382 time: 1703089643.5069902\n",
      "batch_idx: 1 loss: 0.0008203514838330336 R2: 0.9028692324215941 time: 1703089646.1607578\n",
      "batch_idx: 2 loss: 0.0016663146329759313 R2: 0.9028740848085498 time: 1703089648.7557678\n",
      "batch_idx: 3 loss: 0.0008144172438832448 R2: 0.9028799331250417 time: 1703089651.3709507\n",
      "Training [10%] Loss: 0.001316855299625548 time: 1703089651.3709507\n",
      "weight: [ 0.91703903  1.67221334  1.27264979  1.18808294 -0.41596029  0.20385993\n",
      "  1.10917593 -0.77686742  0.33836509 -0.18377463  0.67806438  0.86705034]\n",
      "epoch 52\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019653509163302203 R2: 0.902885536385804 time: 1703089653.9420516\n",
      "batch_idx: 1 loss: 0.0008191811797587051 R2: 0.9028928948430682 time: 1703089656.595584\n",
      "batch_idx: 2 loss: 0.00166789738494207 R2: 0.9028981802605441 time: 1703089659.1558805\n",
      "batch_idx: 3 loss: 0.0008134921573120282 R2: 0.9029032585488516 time: 1703089661.8482614\n",
      "Training [10%] Loss: 0.0013164804095857558 time: 1703089661.8482614\n",
      "weight: [ 0.91777718  1.67203092  1.27258531  1.18635231 -0.4157479   0.20385053\n",
      "  1.10935453 -0.77705259  0.33810742 -0.18417868  0.67782365  0.86713293]\n",
      "epoch 53\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001964490134607079 R2: 0.9029092485566048 time: 1703089664.4459624\n",
      "batch_idx: 1 loss: 0.0008182781166148541 R2: 0.9029155932488793 time: 1703089667.1293921\n",
      "batch_idx: 2 loss: 0.0016690132463288356 R2: 0.902921276315278 time: 1703089669.8258617\n",
      "batch_idx: 3 loss: 0.0008128015579313031 R2: 0.902925987000196 time: 1703089672.440636\n",
      "Training [11%] Loss: 0.001316145763870518 time: 1703089672.440636\n",
      "weight: [ 0.91851825  1.67183819  1.27251275  1.18450645 -0.41551308  0.20384578\n",
      "  1.10950381 -0.77721059  0.3378382  -0.18448459  0.67763779  0.86718379]\n",
      "epoch 54\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019635433678025466 R2: 0.9029320995174567 time: 1703089675.0868106\n",
      "batch_idx: 1 loss: 0.0008177687199326024 R2: 0.9029380649775633 time: 1703089677.6855152\n",
      "batch_idx: 2 loss: 0.001669621177598908 R2: 0.9029438814403283 time: 1703089680.3318532\n",
      "batch_idx: 3 loss: 0.0008123589789140082 R2: 0.9029486760230153 time: 1703089682.915637\n",
      "Training [11%] Loss: 0.0013158230610620164 time: 1703089682.915637\n",
      "weight: [ 0.91926512  1.67163624  1.27243331  1.18255665 -0.4152591   0.20384467\n",
      "  1.10963018 -0.77734746  0.33755821 -0.184699    0.67750724  0.86721027]\n",
      "epoch 55\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001962494335945864 R2: 0.9029545398258708 time: 1703089685.5615606\n",
      "batch_idx: 1 loss: 0.0008175717832541003 R2: 0.9029606536965231 time: 1703089688.2116585\n",
      "batch_idx: 2 loss: 0.0016698446997827133 R2: 0.9029663767665334 time: 1703089690.869322\n",
      "batch_idx: 3 loss: 0.0008120561811327034 R2: 0.9029715049821034 time: 1703089693.4408073\n",
      "Training [11%] Loss: 0.0013154917500288455 time: 1703089693.4408073\n",
      "weight: [ 0.92001882  1.67142525  1.2723473   1.18050398 -0.4149868   0.20384689\n",
      "  1.10973546 -0.77746491  0.33726735 -0.18484717  0.67741425  0.86721374]\n",
      "epoch 56\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001961457912406756 R2: 0.9029769768142744 time: 1703089696.0677583\n",
      "batch_idx: 1 loss: 0.0008175000463559836 R2: 0.9029834392207698 time: 1703089698.6698298\n",
      "batch_idx: 2 loss: 0.0016698662977776293 R2: 0.9029890585167525 time: 1703089701.2359512\n",
      "batch_idx: 3 loss: 0.0008117604526589498 R2: 0.9029945186504035 time: 1703089703.8779252\n",
      "Training [11%] Loss: 0.0013151461772998299 time: 1703089703.8779252\n",
      "weight: [ 0.92077976  1.67120517  1.2722547   1.17834613 -0.41469626  0.2038523\n",
      "  1.10981997 -0.77756326  0.33696529 -0.18495716  0.67733748  0.86719365]\n",
      "epoch 57\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001960553407602925 R2: 0.9029997643669766 time: 1703089706.4455724\n",
      "batch_idx: 1 loss: 0.0008173996436123996 R2: 0.903006475933793 time: 1703089709.098873\n",
      "batch_idx: 2 loss: 0.001669814097346406 R2: 0.9030121569259046 time: 1703089711.7755795\n",
      "batch_idx: 3 loss: 0.0008114002365886923 R2: 0.903017789352524 time: 1703089714.4658387\n",
      "Training [11%] Loss: 0.0013147918462876058 time: 1703089714.4658387\n",
      "weight: [ 0.92154895  1.67097616  1.27215578  1.17608416 -0.41438827  0.20386059\n",
      "  1.10988547 -0.77764418  0.33665196 -0.18504638  0.67726464  0.86715127]\n",
      "epoch 58\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019598156947040362 R2: 0.9030231081985814 time: 1703089717.0658245\n",
      "batch_idx: 1 loss: 0.0008172290380698821 R2: 0.903029853014664 time: 1703089719.766595\n",
      "batch_idx: 2 loss: 0.001669716522538858 R2: 0.9030357745539123 time: 1703089722.4558802\n",
      "batch_idx: 3 loss: 0.0008109875037401494 R2: 0.9030414184847475 time: 1703089725.126545\n",
      "Training [12%] Loss: 0.0013144371897632315 time: 1703089725.126545\n",
      "weight: [ 0.92232821  1.67073886  1.27205129  1.17372474 -0.41406483  0.20387115\n",
      "  1.10993592 -0.77771142  0.33632773 -0.1851184   0.6771957   0.86709083]\n",
      "epoch 59\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001959189481858231 R2: 0.9030470237346243 time: 1703089727.805827\n",
      "batch_idx: 1 loss: 0.0008170430816246592 R2: 0.9030536722188456 time: 1703089730.4307125\n",
      "batch_idx: 2 loss: 0.0016695330409824017 R2: 0.9030599076712787 time: 1703089733.090659\n",
      "batch_idx: 3 loss: 0.0008105795471425351 R2: 0.9030655181051367 time: 1703089735.765576\n",
      "Training [12%] Loss: 0.0013140862879019567 time: 1703089735.765576\n",
      "weight: [ 0.92311979  1.67049413  1.27194218  1.17127775 -0.4137285   0.20388325\n",
      "  1.10997638 -0.77776974  0.33599321 -0.18516913  0.67713733  0.86701805]\n",
      "epoch 60\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001958585157220422 R2: 0.9030714398144871 time: 1703089738.4457066\n",
      "batch_idx: 1 loss: 0.000816919589555902 R2: 0.9030780332003447 time: 1703089741.0757535\n",
      "batch_idx: 2 loss: 0.0016692182788889906 R2: 0.9030845357822554 time: 1703089743.672669\n",
      "batch_idx: 3 loss: 0.0008102230284312273 R2: 0.9030901845204165 time: 1703089746.4788568\n",
      "Training [12%] Loss: 0.0013137365135241356 time: 1703089746.4788568\n",
      "weight: [ 0.92392563  1.67024267  1.27182926  1.1687518  -0.41338146  0.20389628\n",
      "  1.11001115 -0.77782323  0.33564889 -0.18519555  0.67709484  0.86693785]\n",
      "epoch 61\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001957941835068415 R2: 0.9030963145720058 time: 1703089749.1959114\n",
      "batch_idx: 1 loss: 0.0008168941102650583 R2: 0.9031029995898562 time: 1703089751.8658206\n",
      "batch_idx: 2 loss: 0.0016687678582436361 R2: 0.903109666155871 time: 1703089754.510756\n",
      "batch_idx: 3 loss: 0.0008099229453224666 R2: 0.9031154570878657 time: 1703089757.2479365\n",
      "Training [12%] Loss: 0.001313381687224894 time: 1703089757.2479365\n",
      "weight: [ 0.92474697  1.66998485  1.27171298  1.16615143 -0.41302494  0.20390987\n",
      "  1.11004276 -0.77787426  0.33529492 -0.18520046  0.67706763  0.86685294]\n",
      "epoch 62\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001957253625971249 R2: 0.903121668819586 time: 1703089759.925822\n",
      "batch_idx: 1 loss: 0.0008169439704966665 R2: 0.9031285753564111 time: 1703089762.6102266\n",
      "batch_idx: 2 loss: 0.001668220683587342 R2: 0.903135329945995 time: 1703089765.3055959\n",
      "batch_idx: 3 loss: 0.0008096496963776887 R2: 0.9031413180414202 time: 1703089767.965894\n",
      "Training [12%] Loss: 0.0013130169941082367 time: 1703089767.965894\n",
      "weight: [ 0.92558443  1.66972075  1.27159347  1.16347736 -0.41265933  0.20392388\n",
      "  1.11007215 -0.77792376  0.33493114 -0.18519143  0.67705025  0.86676404]\n",
      "epoch 63\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001956551696261067 R2: 0.9031475644301912 time: 1703089770.6160507\n",
      "batch_idx: 1 loss: 0.0008170174344137374 R2: 0.9031547310972519 time: 1703089773.2278204\n",
      "batch_idx: 2 loss: 0.0016676290299593086 R2: 0.9031615672075187 time: 1703089776.0106993\n",
      "batch_idx: 3 loss: 0.0008093679472958524 R2: 0.9031677360087776 time: 1703089778.6455634\n",
      "Training [13%] Loss: 0.0013126415269824913 time: 1703089778.6455634\n",
      "weight: [ 0.92643844  1.66945031  1.27147074  1.16072912 -0.41228473  0.20393822\n",
      "  1.11009973 -0.77797212  0.3345573  -0.18517635  0.67703657  0.86667125]\n",
      "epoch 64\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019558671425966624 R2: 0.9031740630641723 time: 1703089781.2455583\n",
      "batch_idx: 1 loss: 0.0008170746320173581 R2: 0.9031814458733068 time: 1703089783.846028\n",
      "batch_idx: 2 loss: 0.0016670268965284611 R2: 0.9031884071615842 time: 1703089786.6212118\n",
      "batch_idx: 3 loss: 0.0008090610430657126 R2: 0.9031947014638038 time: 1703089789.2408578\n",
      "Training [13%] Loss: 0.0013122574285520485 time: 1703089789.2408578\n",
      "weight: [ 0.92730955  1.66917356  1.27134489  1.15790742 -0.41190143  0.20395278\n",
      "  1.11012624 -0.77802005  0.33417323 -0.18515971  0.67702338  0.8665752 ]\n",
      "epoch 65\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001955205976055144 R2: 0.9032011903453503 time: 1703089792.0406168\n",
      "batch_idx: 1 loss: 0.0008171084659927148 R2: 0.9032087242350981 time: 1703089794.785979\n",
      "batch_idx: 2 loss: 0.0016664193317674973 R2: 0.9032158558991673 time: 1703089797.535934\n",
      "batch_idx: 3 loss: 0.0008087352627095901 R2: 0.9032222323483691 time: 1703089800.2057557\n",
      "Training [13%] Loss: 0.0013118672591312364 time: 1703089800.2057557\n",
      "weight: [ 0.92819854  1.66889065  1.27121611  1.15501486 -0.41151001  0.20396737\n",
      "  1.110153   -0.77806882  0.33377886 -0.18514217  0.67701096  0.86647739]\n",
      "epoch 66\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019545499595935824 R2: 0.9032289334577829 time: 1703089802.786886\n",
      "batch_idx: 1 loss: 0.0008171366852187792 R2: 0.9032365898249706 time: 1703089805.38557\n",
      "batch_idx: 2 loss: 0.0016657939806703805 R2: 0.9032439050754751 time: 1703089808.0361497\n",
      "batch_idx: 3 loss: 0.000808406832828312 R2: 0.9032503602921528 time: 1703089810.6709375\n",
      "Training [13%] Loss: 0.0013114718645777636 time: 1703089810.6709375\n",
      "weight: [ 0.92910622  1.66860176  1.27108467  1.15205485 -0.41111114  0.20398182\n",
      "  1.11018149 -0.77811984  0.33337418 -0.18512251  0.67700119  0.86637958]\n",
      "epoch 67\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019538749171819723 R2: 0.9032572690207195 time: 1703089813.2958305\n",
      "batch_idx: 1 loss: 0.0008171792429730663 R2: 0.9032650691628842 time: 1703089815.8196192\n",
      "batch_idx: 2 loss: 0.0016651401336241697 R2: 0.9032725495391327 time: 1703089818.4259522\n",
      "batch_idx: 3 loss: 0.0008080860886918752 R2: 0.9032791109765791 time: 1703089821.196\n",
      "Training [13%] Loss: 0.001311070095617771 time: 1703089821.196\n",
      "weight: [ 0.93003327  1.66830699  1.27095072  1.14902999 -0.41070531  0.20399599\n",
      "  1.11021281 -0.77817415  0.33295909 -0.18510015  0.67699518  0.8662831 ]\n",
      "epoch 68\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019531682176136098 R2: 0.9032861899615561 time: 1703089823.8758783\n",
      "batch_idx: 1 loss: 0.000817241514777018 R2: 0.9032941772023039 time: 1703089826.5057697\n",
      "batch_idx: 2 loss: 0.001664459565448803 R2: 0.9033017961250918 time: 1703089829.227023\n",
      "batch_idx: 3 loss: 0.0008077710229151276 R2: 0.903308493006653 time: 1703089831.9156027\n",
      "Training [14%] Loss: 0.0013106600801886397 time: 1703089831.9156027\n",
      "weight: [ 0.93098015  1.66800632  1.2708143   1.14594133 -0.41029265  0.20400984\n",
      "  1.11024745 -0.77823223  0.33253336 -0.1850761   0.67699238  0.86618852]\n",
      "epoch 69\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019524329719358725 R2: 0.9033157116514288 time: 1703089834.5757134\n",
      "batch_idx: 1 loss: 0.0008173136935683246 R2: 0.9033239152424246 time: 1703089837.2356052\n",
      "batch_idx: 2 loss: 0.0016637639549306866 R2: 0.9033316610135385 time: 1703089839.913214\n",
      "batch_idx: 3 loss: 0.0008074520417991526 R2: 0.903338502874495 time: 1703089842.6057515\n",
      "Training [14%] Loss: 0.0013102406655585092 time: 1703089842.6057515\n",
      "weight: [ 0.93194716  1.66769966  1.27067536  1.14278886 -0.40987308  0.20402335\n",
      "  1.11028546 -0.77829418  0.33209669 -0.1850523   0.6769912   0.86609587]\n",
      "epoch 70\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001951679726017155 R2: 0.9033458602511691 time: 1703089845.1905625\n",
      "batch_idx: 1 loss: 0.0008173818692216464 R2: 0.9033542803540596 time: 1703089847.9356718\n",
      "batch_idx: 2 loss: 0.001663065013584622 R2: 0.9033621614984219 time: 1703089850.585666\n",
      "batch_idx: 3 loss: 0.0008071210222671841 R2: 0.9033691379040502 time: 1703089853.2556155\n",
      "Training [14%] Loss: 0.0013098119077726519 time: 1703089853.2556155\n",
      "weight: [ 0.93293458  1.66738687  1.27053385  1.13957258 -0.40944648  0.20403651\n",
      "  1.11032687 -0.77836     0.33164874 -0.18503027  0.67699038  0.86600511]\n",
      "epoch 71\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019509154474651722 R2: 0.9033766564654668 time: 1703089855.8925018\n",
      "batch_idx: 1 loss: 0.0008174390280255862 R2: 0.9033852750765794 time: 1703089858.5557613\n",
      "batch_idx: 2 loss: 0.0016623670269685655 R2: 0.9033933089635282 time: 1703089861.2006235\n",
      "batch_idx: 3 loss: 0.0008067766125987013 R2: 0.9034004043639767 time: 1703089863.86569\n",
      "Training [14%] Loss: 0.0013093745287645064 time: 1703089863.86569\n",
      "weight: [ 0.93394278  1.66706788  1.27038973  1.13629326 -0.40901283  0.20404931\n",
      "  1.11037185 -0.7784299   0.33118922 -0.18501041  0.67698967  0.8659165 ]\n",
      "epoch 72\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019501387936392914 R2: 0.9034081076430119 time: 1703089866.580899\n",
      "batch_idx: 1 loss: 0.0008174877106029762 R2: 0.9034169097051654 time: 1703089869.1456277\n",
      "batch_idx: 2 loss: 0.001661666797205499 R2: 0.9034251080672044 time: 1703089871.8460383\n",
      "batch_idx: 3 loss: 0.0008064228909929839 R2: 0.9034323161764268 time: 1703089874.515651\n",
      "Training [14%] Loss: 0.0013089290481101876 time: 1703089874.515651\n",
      "weight: [ 0.93497215  1.66674263  1.27024303  1.13295235 -0.40857217  0.20406171\n",
      "  1.11042074 -0.7785042   0.33071786 -0.18499222  0.67698966  0.8658305 ]\n",
      "epoch 73\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019493433080415693 R2: 0.9034402122545989 time: 1703089877.1556742\n",
      "batch_idx: 1 loss: 0.0008175347758766442 R2: 0.9034491979635961 time: 1703089879.7456965\n",
      "batch_idx: 2 loss: 0.0016609588840460223 R2: 0.903457561264219 time: 1703089882.455846\n",
      "batch_idx: 3 loss: 0.0008060643835565244 R2: 0.9034648879444378 time: 1703089885.0737567\n",
      "Training [15%] Loss: 0.00130847533788019 time: 1703089885.0737567\n",
      "weight: [ 0.93602309  1.66641107  1.27009373  1.12955149 -0.40812456  0.20407369\n",
      "  1.11047384 -0.77858322  0.33023436 -0.18497506  0.67699103  0.86574758]\n",
      "epoch 74\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019485236931102421 R2: 0.9034729697343996 time: 1703089887.702633\n",
      "batch_idx: 1 loss: 0.0008175846173712626 R2: 0.9034821511292807 time: 1703089890.3258867\n",
      "batch_idx: 2 loss: 0.0016602406177450737 R2: 0.9034906733589013 time: 1703089892.995761\n",
      "batch_idx: 3 loss: 0.0008057023568220059 R2: 0.9034981290040781 time: 1703089895.6486373\n",
      "Training [15%] Loss: 0.0013080128212621463 time: 1703089895.6486373\n",
      "weight: [ 0.93709596  1.66607309  1.2699418   1.12609198 -0.40766994  0.20408525\n",
      "  1.1105313  -0.7786671   0.32973839 -0.18495872  0.67699401  0.865668  ]\n",
      "epoch 75\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001947679360284794 R2: 0.9035063862385047 time: 1703089898.3271575\n",
      "batch_idx: 1 loss: 0.0008176365099627472 R2: 0.9035157754428885 time: 1703089900.9258745\n",
      "batch_idx: 2 loss: 0.0016595131648508145 R2: 0.9035244524409352 time: 1703089903.555633\n",
      "batch_idx: 3 loss: 0.0008053348617333535 R2: 0.903532042921705 time: 1703089906.2355988\n",
      "Training [15%] Loss: 0.0013075409742079275 time: 1703089906.2355988\n",
      "weight: [ 0.93819105  1.66572858  1.26978719  1.12257482 -0.40720818  0.20409638\n",
      "  1.11059311 -0.77875587  0.32922959 -0.18494343  0.67699838  0.86559179]\n",
      "epoch 76\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001946813266058842 R2: 0.903540473034847 time: 1703089908.8396878\n",
      "batch_idx: 1 loss: 0.0008176868773138593 R2: 0.903550073968631 time: 1703089911.4157743\n",
      "batch_idx: 2 loss: 0.0016587791000982118 R2: 0.9035589076086078 time: 1703089914.0950224\n",
      "batch_idx: 3 loss: 0.0008049593387912831 R2: 0.903566631403726 time: 1703089916.7968738\n",
      "Training [15%] Loss: 0.001307059645565549 time: 1703089916.7968738\n",
      "weight: [ 0.93930865  1.66537738  1.2696298   1.11900106 -0.40673912  0.2041071\n",
      "  1.11065921 -0.7788495   0.32870754 -0.18492948  0.67700385  0.86551894]\n",
      "epoch 77\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019459283379718764 R2: 0.9035752409348928 time: 1703089919.4358423\n",
      "batch_idx: 1 loss: 0.0008177331694743703 R2: 0.9035850500781256 time: 1703089922.0505269\n",
      "batch_idx: 2 loss: 0.0016580395436235802 R2: 0.9035940461607057 time: 1703089924.6567686\n",
      "batch_idx: 3 loss: 0.0008045749234905673 R2: 0.903601898166747 time: 1703089927.2357607\n",
      "Training [15%] Loss: 0.0013065689936400987 time: 1703089927.2357607\n",
      "weight: [ 0.94044906  1.66501937  1.26946957  1.1153722  -0.40626264  0.20411741\n",
      "  1.11072962 -0.77894801  0.32817187 -0.18491692  0.67701037  0.86544954]\n",
      "epoch 78\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001945025046448694 R2: 0.9036106962935693 time: 1703089929.9470322\n",
      "batch_idx: 1 loss: 0.0008177757418655216 R2: 0.9036207092036271 time: 1703089932.649537\n",
      "batch_idx: 2 loss: 0.0016572933373907735 R2: 0.9036298726376953 time: 1703089935.3460383\n",
      "batch_idx: 3 loss: 0.0008041826800779418 R2: 0.9036378496229581 time: 1703089938.0731528\n",
      "Training [16%] Loss: 0.0013060692014457327 time: 1703089938.0731528\n",
      "weight: [ 0.94161263  1.66465443  1.26930646  1.1116902  -0.40577864  0.2041273\n",
      "  1.11080442 -0.77905151  0.32762217 -0.18490551  0.67701816  0.86538378]\n",
      "epoch 79\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019441017232414617 R2: 0.903646841393447 time: 1703089940.6360185\n",
      "batch_idx: 1 loss: 0.0008178168058165642 R2: 0.9036570579715368 time: 1703089943.3967912\n",
      "batch_idx: 2 loss: 0.0016565383359287706 R2: 0.9036663899946389 time: 1703089945.9910462\n",
      "batch_idx: 3 loss: 0.0008037841946549983 R2: 0.9036744927348798 time: 1703089948.6757329\n",
      "Training [16%] Loss: 0.0013055602649104487 time: 1703089948.6757329\n",
      "weight: [ 0.94279971  1.66428245  1.26914041  1.10795735 -0.40528707  0.20413677\n",
      "  1.11088372 -0.77916013  0.32705805 -0.18489495  0.6770275   0.86532187]\n",
      "epoch 80\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001943156532574659 R2: 0.903683677658391 time: 1703089951.4056683\n",
      "batch_idx: 1 loss: 0.0008178581827662116 R2: 0.9036941022002626 time: 1703089954.0846217\n",
      "batch_idx: 2 loss: 0.001655773132606148 R2: 0.9037036013122884 time: 1703089956.7361903\n",
      "batch_idx: 3 loss: 0.0008033801748182974 R2: 0.9037118325946946 time: 1703089959.4416564\n",
      "Training [16%] Loss: 0.0013050420056913289 time: 1703089959.4416564\n",
      "weight: [ 0.94401064  1.6639033   1.26897137  1.10417601 -0.40478781  0.20414583\n",
      "  1.11096758 -0.77927395  0.32647907 -0.18488508  0.67703854  0.86526401]\n",
      "epoch 81\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019421889684203713 R2: 0.9037212081987731 time: 1703089962.18589\n",
      "batch_idx: 1 loss: 0.0008179000689134235 R2: 0.9037318457383223 time: 1703089964.900682\n",
      "batch_idx: 2 loss: 0.0016549976802418154 R2: 0.903741510456953 time: 1703089967.6155915\n",
      "batch_idx: 3 loss: 0.0008029702100714005 R2: 0.9037498718415268 time: 1703089970.3088465\n",
      "Training [16%] Loss: 0.0013045142319117527 time: 1703089970.3088465\n",
      "weight: [ 0.94524576  1.66351686  1.26879927  1.10034856 -0.40428076  0.20415448\n",
      "  1.11105604 -0.77939302  0.32588479 -0.18487593  0.67705126  0.86521029]\n",
      "epoch 82\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019411997700969148 R2: 0.9037594377576346 time: 1703089973.0642576\n",
      "batch_idx: 1 loss: 0.0008179415265020751 R2: 0.9037702908789038 time: 1703089975.691294\n",
      "batch_idx: 2 loss: 0.001654212639888769 R2: 0.9037801214586952 time: 1703089978.3208492\n",
      "batch_idx: 3 loss: 0.0008025535364391712 R2: 0.903788611919345 time: 1703089980.9557326\n",
      "Training [16%] Loss: 0.0013039768682317325 time: 1703089980.9557326\n",
      "weight: [ 0.94650539  1.66312296  1.26862404  1.09647755 -0.40376579  0.20416272\n",
      "  1.1111491  -0.77951739  0.32527474 -0.18486757  0.67706557  0.86516083]\n",
      "epoch 83\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019401898021308398 R2: 0.9037983708696233 time: 1703089983.706016\n",
      "batch_idx: 1 loss: 0.0008179817590010248 R2: 0.9038094395410768 time: 1703089986.3657033\n",
      "batch_idx: 2 loss: 0.0016534184033375082 R2: 0.9038194375193329 time: 1703089989.1740596\n",
      "batch_idx: 3 loss: 0.000802129849914145 R2: 0.903828054589531 time: 1703089991.9518702\n",
      "Training [17%] Loss: 0.0013034299535958794 time: 1703089991.9518702\n",
      "weight: [ 0.94778987  1.66272149  1.26844562  1.09256574 -0.40324276  0.20417056\n",
      "  1.11124679 -0.77964711  0.32464843 -0.18486002  0.67708145  0.86511573]\n",
      "epoch 84\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019391591640643881 R2: 0.9038380103316767 time: 1703089994.665807\n",
      "batch_idx: 1 loss: 0.0008180208453066982 R2: 0.9038492939858666 time: 1703089997.4799592\n",
      "batch_idx: 2 loss: 0.001652614720569592 R2: 0.9038594606220395 time: 1703090000.090216\n",
      "batch_idx: 3 loss: 0.0008016994578340549 R2: 0.9038682023301957 time: 1703090002.7258537\n",
      "Training [17%] Loss: 0.0013028735469436832 time: 1703090002.7258537\n",
      "weight: [ 0.94909956  1.6623123   1.26826393  1.0886162  -0.40271159  0.20417799\n",
      "  1.11134918 -0.77978226  0.32400538 -0.18485323  0.67709894  0.86507516]\n",
      "epoch 85\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019381072283705223 R2: 0.9038783572372265 time: 1703090005.2866998\n",
      "batch_idx: 1 loss: 0.000818059467864786 R2: 0.9038898566086433 time: 1703090007.8806205\n",
      "batch_idx: 2 loss: 0.0016518010586353184 R2: 0.9039001919297869 time: 1703090010.498907\n",
      "batch_idx: 3 loss: 0.0008012628407194223 R2: 0.9039090576078257 time: 1703090013.1008134\n",
      "Training [17%] Loss: 0.0013023076488975123 time: 1703090013.1008134\n",
      "weight: [ 0.95043482  1.66189525  1.26807892  1.08463214 -0.40217216  0.20418502\n",
      "  1.11145634 -0.77992293  0.32334507 -0.18484713  0.6771181   0.86503929]\n",
      "epoch 86\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019370332968753658 R2: 0.9039194121165876 time: 1703090015.755664\n",
      "batch_idx: 1 loss: 0.0008180981809505045 R2: 0.9039311292901433 time: 1703090018.3132026\n",
      "batch_idx: 2 loss: 0.001650977143696815 R2: 0.9039416324168682 time: 1703090021.0209496\n",
      "batch_idx: 3 loss: 0.0008008201892925334 R2: 0.9039506220054593 time: 1703090023.6456683\n",
      "Training [17%] Loss: 0.0013017322027038046 time: 1703090023.6456683\n",
      "weight: [ 0.951796    1.66147021  1.26789052  1.08061683 -0.40162436  0.20419164\n",
      "  1.1115683  -0.78006921  0.32266696 -0.18484173  0.67713894  0.86500828]\n",
      "epoch 87\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019359371167077932 R2: 0.9039611758812418 time: 1703090026.2360005\n",
      "batch_idx: 1 loss: 0.0008181370058379476 R2: 0.9039731130377738 time: 1703090028.7758722\n",
      "batch_idx: 2 loss: 0.001650143142334742 R2: 0.9039837831335278 time: 1703090031.3566966\n",
      "batch_idx: 3 loss: 0.0008003713347505368 R2: 0.9039928960562251 time: 1703090033.9857\n",
      "Training [17%] Loss: 0.0013011471499077547 time: 1703090033.9857\n",
      "weight: [ 0.95318346  1.66103703  1.26769865  1.07657359 -0.40106808  0.20419788\n",
      "  1.1116851  -0.78022115  0.32197051 -0.18483704  0.67716142  0.86498226]\n",
      "epoch 88\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001934818844370189 R2: 0.9040036498178109 time: 1703090036.6357522\n",
      "batch_idx: 1 loss: 0.0008181756162728959 R2: 0.904015808183958 time: 1703090039.3059125\n",
      "batch_idx: 2 loss: 0.0016492994216416735 R2: 0.9040266450083736 time: 1703090041.9305992\n",
      "batch_idx: 3 loss: 0.000799916016102746 R2: 0.9040358797687326 time: 1703090044.755548\n",
      "Training [18%] Loss: 0.001300552474596876 time: 1703090044.755548\n",
      "weight: [ 0.95459755  1.66059554  1.26750323  1.07250573 -0.40050318  0.20420372\n",
      "  1.11180675 -0.78037879  0.32125514 -0.18483313  0.67718548  0.86496133]\n",
      "epoch 89\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019336786600103952 R2: 0.9040468349481883 time: 1703090047.4059203\n",
      "batch_idx: 1 loss: 0.0008182137719520459 R2: 0.9040592148335568 time: 1703090050.0990176\n",
      "batch_idx: 2 loss: 0.0016484462223439965 R2: 0.9040702185392384 time: 1703090052.678684\n",
      "batch_idx: 3 loss: 0.0007994541429025075 R2: 0.9040795732064885 time: 1703090055.400751\n",
      "Training [18%] Loss: 0.0012999481993022362 time: 1703090055.400751\n",
      "weight: [ 0.95603865  1.6601456   1.2673042   1.06841665 -0.39992952  0.20420917\n",
      "  1.11193329 -0.78054221  0.32052023 -0.18483002  0.67721106  0.86494562]\n",
      "epoch 90\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019325164890834218 R2: 0.9040907315597625 time: 1703090058.0156229\n",
      "batch_idx: 1 loss: 0.0008182515362324094 R2: 0.90410333311975 time: 1703090060.6859548\n",
      "batch_idx: 2 loss: 0.0016475835566579534 R2: 0.9041145037273483 time: 1703090063.4159684\n",
      "batch_idx: 3 loss: 0.0007989858183676624 R2: 0.904123976612196 time: 1703090066.045808\n",
      "Training [18%] Loss: 0.0012993343500853618 time: 1703090066.045808\n",
      "weight: [ 0.9575071   1.65968705  1.26710146  1.06430977 -0.39934699  0.20421423\n",
      "  1.11206474 -0.78071145  0.31976518 -0.18482771  0.67723816  0.86493524]\n",
      "epoch 91\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001931332054889092 R2: 0.9041353393293654 time: 1703090068.69921\n",
      "batch_idx: 1 loss: 0.0008182891493554476 R2: 0.90414816313618 time: 1703090071.300492\n",
      "batch_idx: 2 loss: 0.0016467113440824862 R2: 0.9041595002871313 time: 1703090073.8456924\n",
      "batch_idx: 3 loss: 0.0007985111776408257 R2: 0.9041690901327412 time: 1703090076.455567\n",
      "Training [18%] Loss: 0.0012987109314919628 time: 1703090076.455567\n",
      "weight: [ 0.95900329  1.65921972  1.26689494  1.06018848 -0.39875544  0.2042189\n",
      "  1.11220111 -0.78088657  0.31898933 -0.1848262   0.67726677  0.86493032]\n",
      "epoch 92\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019301251141868622 R2: 0.9041806577963312 time: 1703090079.1079686\n",
      "batch_idx: 1 loss: 0.0008183267834621949 R2: 0.9041937047523728 time: 1703090081.74609\n",
      "batch_idx: 2 loss: 0.001645829577024783 R2: 0.9042052078995987 time: 1703090084.2956743\n",
      "batch_idx: 3 loss: 0.0007980302500602898 R2: 0.9042149135608495 time: 1703090086.9656143\n",
      "Training [18%] Loss: 0.0012980779311835325 time: 1703090086.9656143\n",
      "weight: [ 0.96052757  1.65874346  1.26668455  1.0560561  -0.39815473  0.20422319\n",
      "  1.11234242 -0.78106762  0.31819201 -0.18482547  0.67729685  0.86493096]\n",
      "epoch 93\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001928895601027029 R2: 0.9042266866839178 time: 1703090089.5856225\n",
      "batch_idx: 1 loss: 0.0008183644468645298 R2: 0.9042399575676336 time: 1703090092.2868416\n",
      "batch_idx: 2 loss: 0.0016449383458968093 R2: 0.9042516263035323 time: 1703090094.855766\n",
      "batch_idx: 3 loss: 0.0007975429685894411 R2: 0.9042614463793933 time: 1703090097.5210862\n",
      "Training [19%] Loss: 0.0012974353405944524 time: 1703090097.5210862\n",
      "weight: [ 0.96208032  1.65825808  1.2664702   1.05191585 -0.39754472  0.20422711\n",
      "  1.11248866 -0.78125463  0.31737251 -0.18482555  0.67732837  0.86493726]\n",
      "epoch 94\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00192764357084208 R2: 0.9042734258543431 time: 1703090100.1806755\n",
      "batch_idx: 1 loss: 0.0008184020837609208 R2: 0.9042869210523664 time: 1703090102.7758067\n",
      "batch_idx: 2 loss: 0.0016440377392355637 R2: 0.904298755231436 time: 1703090105.3868833\n",
      "batch_idx: 3 loss: 0.0007970492732759703 R2: 0.9043086880257141 time: 1703090108.046049\n",
      "Training [19%] Loss: 0.0012967831667786338 time: 1703090108.046049\n",
      "weight: [ 0.96366191  1.65776341  1.26625181  1.04777088 -0.39692525  0.20423064\n",
      "  1.11263983 -0.78144763  0.31653012 -0.18482644  0.67736131  0.8649493 ]\n",
      "epoch 95\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019263690574558585 R2: 0.904320875092567 time: 1703090110.7457078\n",
      "batch_idx: 1 loss: 0.0008184397156615232 R2: 0.9043345947316462 time: 1703090113.435778\n",
      "batch_idx: 2 loss: 0.0016431277499159163 R2: 0.9043465943423662 time: 1703090116.0608299\n",
      "batch_idx: 3 loss: 0.0007965491817684165 R2: 0.904356638102314 time: 1703090118.705842\n",
      "Training [19%] Loss: 0.0012961214262004288 time: 1703090118.705842\n",
      "weight: [ 0.96527272  1.65725927  1.26602927  1.04362421 -0.39629617  0.20423379\n",
      "  1.11279592 -0.78164667  0.31566407 -0.18482811  0.67739564  0.86496717]\n",
      "epoch 96\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019250720048813858 R2: 0.904369034021479 time: 1703090121.376667\n",
      "batch_idx: 1 loss: 0.0008184774764248177 R2: 0.9043829782664117 time: 1703090123.8857188\n",
      "batch_idx: 2 loss: 0.0016422082742305034 R2: 0.9043951432609985 time: 1703090126.5058393\n",
      "batch_idx: 3 loss: 0.0007960427696096012 R2: 0.904405296386612 time: 1703090129.1759644\n",
      "Training [19%] Loss: 0.001295450131286577 time: 1703090129.1759644\n",
      "weight: [ 0.96691313  1.65674549  1.26580249  1.03947877 -0.39565732  0.20423657\n",
      "  1.11295691 -0.78185176  0.31477357 -0.18483053  0.67743135  0.86499096]\n",
      "epoch 97\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019237523149034888 R2: 0.9044179022346965 time: 1703090131.7757657\n",
      "batch_idx: 1 loss: 0.000818515539548159 R2: 0.9044320714271394 time: 1703090134.511089\n",
      "batch_idx: 2 loss: 0.0016412791758288285 R2: 0.9044444016944213 time: 1703090137.1010537\n",
      "batch_idx: 3 loss: 0.0007955301075705317 R2: 0.904454662728382 time: 1703090139.7416809\n",
      "Training [19%] Loss: 0.001294769284462752 time: 1703090139.7416809\n",
      "weight: [ 0.96858351  1.65622186  1.26557138  1.03533735 -0.39500854  0.20423896\n",
      "  1.11312281 -0.78206296  0.31385781 -0.18483369  0.67746845  0.86502076]\n",
      "epoch 98\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019224099260528344 R2: 0.904467479491975 time: 1703090142.3468485\n",
      "batch_idx: 1 loss: 0.0008185540412215453 R2: 0.9044818740580214 time: 1703090145.00105\n",
      "batch_idx: 2 loss: 0.0016403403332029322 R2: 0.90449436952654 time: 1703090147.6904564\n",
      "batch_idx: 3 loss: 0.0007950112307393592 R2: 0.9045047370068902 time: 1703090150.3733122\n",
      "Training [20%] Loss: 0.0012940788828041676 time: 1703090150.3733122\n",
      "weight: [ 0.97028427  1.65568822  1.26533584  1.03120258 -0.39434967  0.20424098\n",
      "  1.11329359 -0.78228029  0.31291594 -0.18483753  0.67750693  0.86505666]\n",
      "epoch 99\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019210448337478112 R2: 0.9045177658011602 time: 1703090153.115714\n",
      "batch_idx: 1 loss: 0.0008185930750203406 R2: 0.9045323861056144 time: 1703090155.7456088\n",
      "batch_idx: 2 loss: 0.0016393916316591762 R2: 0.9045450468373563 time: 1703090158.480769\n",
      "batch_idx: 3 loss: 0.0007944861597770291 R2: 0.9045555192079382 time: 1703090161.0565486\n",
      "Training [20%] Loss: 0.0012933789250510893 time: 1703090161.0565486\n",
      "weight: [ 0.97201578  1.65514436  1.26509576  1.02707697 -0.39368055  0.20424261\n",
      "  1.11346924 -0.78250379  0.31194707 -0.18484203  0.6775468   0.86509874]\n",
      "epoch 100\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019196570467754457 R2: 0.9045687613706738 time: 1703090163.646038\n",
      "batch_idx: 1 loss: 0.0008186327395924254 R2: 0.9045836076951671 time: 1703090166.2860184\n",
      "batch_idx: 2 loss: 0.0016384329286201912 R2: 0.9045964338808483 time: 1703090168.9657016\n",
      "batch_idx: 3 loss: 0.0007939549363462488 R2: 0.9046070095384803 time: 1703090171.605661\n",
      "Training [20%] Loss: 0.0012926694128335778 time: 1703090171.605661\n",
      "weight: [ 0.97377844  1.6545901   1.26485105  1.02296286 -0.39300102  0.20424386\n",
      "  1.11364975 -0.78273349  0.31095028 -0.18484715  0.67758805  0.86514709]\n",
      "epoch 101\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019182465406197453 R2: 0.9046204665473345 time: 1703090174.2907734\n",
      "batch_idx: 1 loss: 0.0008186731729748792 R2: 0.9046355391901763 time: 1703090176.9758174\n",
      "batch_idx: 2 loss: 0.001637464039381098 R2: 0.9046485310825775 time: 1703090179.6356826\n",
      "batch_idx: 3 loss: 0.0007934176319323754 R2: 0.9046592084766069 time: 1703090182.3531365\n",
      "Training [20%] Loss: 0.0012919503462270245 time: 1703090182.3531365\n",
      "weight: [ 0.97557266  1.65402523  1.2646016   1.01886245 -0.39231092  0.20424472\n",
      "  1.11383511 -0.78296943  0.30992462 -0.18485284  0.6776307   0.86520181]\n",
      "epoch 102\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019168132533485993 R2: 0.904672881831536 time: 1703090184.9956324\n",
      "batch_idx: 1 loss: 0.0008187145407361912 R2: 0.9046881812022608 time: 1703090187.6392045\n",
      "batch_idx: 2 loss: 0.001636484755401004 R2: 0.9047013390755156 time: 1703090190.2800283\n",
      "batch_idx: 3 loss: 0.00079287432871392 R2: 0.9047121167451463 time: 1703090192.9556017\n",
      "Training [20%] Loss: 0.0012912217195499287 time: 1703090192.9556017\n",
      "weight: [ 0.97739884  1.65344956  1.2643473   1.01477782 -0.39161008  0.2042452\n",
      "  1.11402532 -0.78321168  0.30886911 -0.18485904  0.67767477  0.86526302]\n",
      "epoch 103\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001915357112835299 R2: 0.9047260079509366 time: 1703090195.621083\n",
      "batch_idx: 1 loss: 0.0008187570022445594 R2: 0.9047415345743556 time: 1703090198.2787268\n",
      "batch_idx: 2 loss: 0.0016354948702671853 R2: 0.9047548587429534 time: 1703090200.9310284\n",
      "batch_idx: 3 loss: 0.0007923251002250751 R2: 0.9047657352750067 time: 1703090203.505653\n",
      "Training [21%] Loss: 0.0012904835213930295 time: 1703090203.505653\n",
      "weight: [ 0.97925739  1.6528629   1.26408807  1.01071088 -0.39089836  0.20424528\n",
      "  1.11422038 -0.78346027  0.30778271 -0.18486571  0.67772027  0.86533082]\n",
      "epoch 104\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001913878055487991 R2: 0.9047798459139562 time: 1703090206.146705\n",
      "batch_idx: 1 loss: 0.0008188006945741202 R2: 0.9047956003759685 time: 1703090208.740633\n",
      "batch_idx: 2 loss: 0.0016344941880937357 R2: 0.904809091234417 time: 1703090211.3880987\n",
      "batch_idx: 3 loss: 0.0007917700113516984 R2: 0.904820065211703 time: 1703090213.9859564\n",
      "Training [21%] Loss: 0.0012897357373768863 time: 1703090213.9859564\n",
      "weight: [ 0.98114872  1.65226505  1.26382378  1.0066634  -0.39017559  0.20424498\n",
      "  1.11442029 -0.78371528  0.30666436 -0.18487281  0.67776724  0.86540532]\n",
      "epoch 105\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019123760178060007 R2: 0.9048343970036671 time: 1703090216.6458185\n",
      "batch_idx: 1 loss: 0.0008188457433318891 R2: 0.9048503799204518 time: 1703090219.2397888\n",
      "batch_idx: 2 loss: 0.0016334825148754007 R2: 0.9048640379542631 time: 1703090221.8368502\n",
      "batch_idx: 3 loss: 0.000791209131147395 R2: 0.9048751079531833 time: 1703090224.4658618\n",
      "Training [21%] Loss: 0.0012889783517901715 time: 1703090224.4658618\n",
      "weight: [ 0.98307325  1.6516558   1.26355434  1.00263704 -0.38944164  0.20424427\n",
      "  1.11462507 -0.78397677  0.30551294 -0.18488028  0.67781569  0.86548667]\n",
      "epoch 106\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019108509165355434 R2: 0.9048896627425714 time: 1703090227.1012795\n",
      "batch_idx: 1 loss: 0.00081889227882645 R2: 0.9049058747836574 time: 1703090229.7377183\n",
      "batch_idx: 2 loss: 0.0016324596506064315 R2: 0.9049197005472978 time: 1703090232.3759894\n",
      "batch_idx: 3 loss: 0.0007906425405828172 R2: 0.904930865172673 time: 1703090234.9866636\n",
      "Training [21%] Loss: 0.0012882113466378105 time: 1703090234.9866636\n",
      "weight: [ 0.98503141  1.65103496  1.26327965  0.99863331 -0.38869635  0.20424317\n",
      "  1.11483474 -0.78424482  0.3043273  -0.18488807  0.67786566  0.865575  ]\n",
      "epoch 107\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001909302640815597 R2: 0.9049456448767034 time: 1703090237.676784\n",
      "batch_idx: 1 loss: 0.0008189404371732464 R2: 0.9049620868041741 time: 1703090240.3714097\n",
      "batch_idx: 2 loss: 0.0016314253931671327 R2: 0.9049760808977256 time: 1703090243.028022\n",
      "batch_idx: 3 loss: 0.0007900703283469229 R2: 0.9049873388055263 time: 1703090245.72103\n",
      "Training [21%] Loss: 0.0012874346998757247 time: 1703090245.72103\n",
      "weight: [ 0.98702362  1.65040234  1.2629996   0.99465361 -0.38793959  0.20424167\n",
      "  1.11504932 -0.78451952  0.30310626 -0.18489615  0.67791716  0.86567046]\n",
      "epoch 108\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019077310601526263 R2: 0.9050023453886746 time: 1703090248.3670714\n",
      "batch_idx: 1 loss: 0.0008189903484863004 R2: 0.9050190180672641 time: 1703090251.0001988\n",
      "batch_idx: 2 loss: 0.0016303795485349579 R2: 0.9050331811348874 time: 1703090253.6701877\n",
      "batch_idx: 3 loss: 0.0007894925828669747 R2: 0.9050445310204209 time: 1703090256.3310273\n",
      "Training [22%] Loss: 0.0012866483850102147 time: 1703090256.3310273\n",
      "weight: [ 0.98905031  1.64975773  1.26271409  0.99069922 -0.38717121  0.20423976\n",
      "  1.11526885 -0.78480098  0.30184855 -0.18490445  0.67797023  0.8657732 ]\n",
      "epoch 109\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019061360341603548 R2: 0.9050597665117183 time: 1703090258.9756274\n",
      "batch_idx: 1 loss: 0.0008190421277825195 R2: 0.9050766708882826 time: 1703090261.6110315\n",
      "batch_idx: 2 loss: 0.0016293219363121732 R2: 0.9050910036304882 time: 1703090264.2471328\n",
      "batch_idx: 3 loss: 0.0007889093904195302 R2: 0.9051024442032288 time: 1703090266.9957464\n",
      "Training [22%] Loss: 0.0012858523721686443 time: 1703090266.9957464\n",
      "weight: [ 0.99111193  1.64910094  1.26242303  0.98677132 -0.3863911   0.20423746\n",
      "  1.11549337 -0.78508929  0.30055291 -0.18491295  0.67802489  0.86588341]\n",
      "epoch 110\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019045174126083339 R2: 0.9051179107206115 time: 1703090269.725694\n",
      "batch_idx: 1 loss: 0.0008190958767148244 R2: 0.905135047804085 time: 1703090272.5957587\n",
      "batch_idx: 2 loss: 0.0016282523876489734 R2: 0.9051495509828701 time: 1703090275.1757135\n",
      "batch_idx: 3 loss: 0.0007883208396546789 R2: 0.9051610809569643 time: 1703090277.8919656\n",
      "Training [22%] Loss: 0.0012850466291567024 time: 1703090277.8919656\n",
      "weight: [ 0.9932089   1.64843178  1.26212631  0.98287097 -0.38559913  0.20423476\n",
      "  1.11572294 -0.78538458  0.29921798 -0.1849216   0.67808119  0.86600126]\n",
      "epoch 111\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0019028750286259166 R2: 0.9051767807051461 time: 1703090280.4407103\n",
      "batch_idx: 1 loss: 0.0008191516901107386 R2: 0.9051941515670462 time: 1703090283.3104937\n",
      "batch_idx: 2 loss: 0.0016271707414922496 R2: 0.9052088259969221 time: 1703090286.0107224\n",
      "batch_idx: 3 loss: 0.0007877270258244591 R2: 0.9052204440997068 time: 1703090288.7906954\n",
      "Training [22%] Loss: 0.0012842311215133409 time: 1703090288.7906954\n",
      "weight: [ 0.99534169  1.64775005  1.26182383  0.97899917 -0.38479519  0.20423166\n",
      "  1.11595762 -0.78568697  0.29784237 -0.18493036  0.67813915  0.86612694]\n",
      "epoch 112\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00190120869477868 R2: 0.9052363793470161 time: 1703090291.5582387\n",
      "batch_idx: 1 loss: 0.0008192096580140059 R2: 0.905253985132782 time: 1703090294.3660045\n",
      "batch_idx: 2 loss: 0.0016260768447654867 R2: 0.90526883166823 time: 1703090297.0358536\n",
      "batch_idx: 3 loss: 0.0007871280505009794 R2: 0.905280536647709 time: 1703090299.5956771\n",
      "Training [22%] Loss: 0.001283405812014788 time: 1703090299.5956771\n",
      "weight: [ 0.99751071  1.64705556  1.26151551  0.9751568  -0.38397916  0.20422817\n",
      "  1.11619748 -0.78599662  0.29642464 -0.18493918  0.67819881  0.86626064]\n",
      "epoch 113\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018995182057310195 R2: 0.9052967097089633 time: 1703090302.3056314\n",
      "batch_idx: 1 loss: 0.0008192698619318331 R2: 0.9053145516404568 time: 1703090304.8759508\n",
      "batch_idx: 2 loss: 0.0016249705557072453 R2: 0.9053295711708579 time: 1703090307.5270212\n",
      "batch_idx: 3 loss: 0.0007865240189868537 R2: 0.9053413617893732 time: 1703090310.215889\n",
      "Training [23%] Loss: 0.001282570660589238 time: 1703090310.215889\n",
      "weight: [ 0.99971644  1.64634814  1.26120124  0.97134467 -0.38315096  0.2042243\n",
      "  1.1164426  -0.78631367  0.29496328 -0.18494804  0.67826019  0.86640259]\n",
      "epoch 114\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018978033428080504 R2: 0.9053577750267072 time: 1703090312.921636\n",
      "batch_idx: 1 loss: 0.0008193323709962999 R2: 0.9053758543915981 time: 1703090315.5060513\n",
      "batch_idx: 2 loss: 0.001623851746106976 R2: 0.9053910478424998 time: 1703090318.0856433\n",
      "batch_idx: 3 loss: 0.0007859150395983233 R2: 0.9054029228629903 time: 1703090320.785773\n",
      "Training [23%] Loss: 0.0012817256248774125 time: 1703090320.785773\n",
      "weight: [ 1.00195931  1.64562759  1.26088094  0.96756354 -0.38231049  0.20422005\n",
      "  1.11669306 -0.78663828  0.29345675 -0.1849569   0.67832333  0.86655299]\n",
      "epoch 115\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018960638751421472 R2: 0.9054195786923257 time: 1703090323.4233282\n",
      "batch_idx: 1 loss: 0.0008193972421597582 R2: 0.9054378968318039 time: 1703090326.0460393\n",
      "batch_idx: 2 loss: 0.0016227203006267416 R2: 0.9054532651643022 time: 1703090328.6360543\n",
      "batch_idx: 3 loss: 0.0007853012256277206 R2: 0.9054652233417071 time: 1703090331.3783424\n",
      "Training [23%] Loss: 0.0012808706608890919 time: 1703090331.3783424\n",
      "weight: [ 1.00423978  1.64489374  1.26055452  0.96381408 -0.38145766  0.20421542\n",
      "  1.11694898 -0.78697064  0.29190341 -0.18496572  0.67838826  0.86671208]\n",
      "epoch 116\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018942995576707814 R2: 0.9054821242295562 time: 1703090333.965725\n",
      "batch_idx: 1 loss: 0.0008194645227184034 R2: 0.9055006825338744 time: 1703090336.705922\n",
      "batch_idx: 2 loss: 0.0016215761152038554 R2: 0.9055162267383231 time: 1703090339.3359814\n",
      "batch_idx: 3 loss: 0.0007846826975103406 R2: 0.9055282668186857 time: 1703090341.8256857\n",
      "Training [23%] Loss: 0.001280005723275845 time: 1703090341.8256857\n",
      "weight: [ 1.0065583   1.64414642  1.26022188  0.96009689 -0.38059241  0.20421044\n",
      "  1.11721045 -0.78731093  0.2903016  -0.18497448  0.67845501  0.86688007]\n",
      "epoch 117\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018925101298333646 R2: 0.90554541526958 time: 1703090344.505645\n",
      "batch_idx: 1 loss: 0.0008195342513288787 R2: 0.9055642151787223 time: 1703090347.1599026\n",
      "batch_idx: 2 loss: 0.001620419096919045 R2: 0.9055799362664917 time: 1703090349.8158276\n",
      "batch_idx: 3 loss: 0.000784059583276445 R2: 0.9055920569862362 time: 1703090352.4191856\n",
      "Training [23%] Loss: 0.0012791307653394332 time: 1703090352.4191856\n",
      "weight: [ 1.00891531  1.64338545  1.25988295  0.95641254 -0.37971468  0.20420512\n",
      "  1.1174776  -0.78765934  0.28864956 -0.18498314  0.67852362  0.86705721]\n",
      "epoch 118\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001890695316856044 R2: 0.9056094555318074 time: 1703090355.04606\n",
      "batch_idx: 1 loss: 0.00081960645661284 R2: 0.9056284985332136 time: 1703090357.618986\n",
      "batch_idx: 2 loss: 0.0016192491652641566 R2: 0.9056443975311247 time: 1703090360.2456632\n",
      "batch_idx: 3 loss: 0.0007834320179738962 R2: 0.9056565976107291 time: 1703090362.8019109\n",
      "Training [24%] Loss: 0.0012782457391767343 time: 1703090362.8019109\n",
      "weight: [ 1.01131127  1.64261067  1.25953764  0.95276154 -0.37882441  0.20419947\n",
      "  1.11775055 -0.7880161   0.28694549 -0.18499166  0.67859411  0.86724375]\n",
      "epoch 119\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018888548319300035 R2: 0.9056742488060993 time: 1703090365.6556525\n",
      "batch_idx: 1 loss: 0.000819681155522416 R2: 0.9056935364271735 time: 1703090368.3959148\n",
      "batch_idx: 2 loss: 0.0016180662531537562 R2: 0.9057096143744253 time: 1703090370.9756744\n",
      "batch_idx: 3 loss: 0.0007828001437489357 R2: 0.9057218925088423 time: 1703090373.625625\n",
      "Training [24%] Loss: 0.001277350596088778 time: 1703090373.625625\n",
      "weight: [ 1.01374663  1.64182192  1.25918588  0.94914436 -0.37792157  0.20419351\n",
      "  1.11802943 -0.78838142  0.28518751 -0.18500002  0.67866651  0.86743992]\n",
      "epoch 120\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001886988377066083 R2: 0.9057397989314934 time: 1703090376.2856202\n",
      "batch_idx: 1 loss: 0.00081975835321614 R2: 0.9057593327313779 time: 1703090378.9760041\n",
      "batch_idx: 2 loss: 0.0016168703068893345 R2: 0.9057755906757008 time: 1703090381.625696\n",
      "batch_idx: 3 loss: 0.0007821641109756868 R2: 0.9057879455267399 time: 1703090384.3207538\n",
      "Training [24%] Loss: 0.0012764452870368112 time: 1703090384.3207538\n",
      "weight: [ 1.01622184  1.64101906  1.2588276   0.94556144 -0.37700612  0.20418726\n",
      "  1.1183144  -0.78875554  0.28337366 -0.1850082   0.67874085  0.86764597]\n",
      "epoch 121\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001885095642662833 R2: 0.9058061097714033 time: 1703090386.925868\n",
      "batch_idx: 1 loss: 0.0008198380438190307 R2: 0.9058258913359369 time: 1703090389.525963\n",
      "batch_idx: 2 loss: 0.0016156612858306875 R2: 0.9058423303274076 time: 1703090392.196146\n",
      "batch_idx: 3 loss: 0.0007815240794591631 R2: 0.905854760519148 time: 1703090394.830828\n",
      "Training [24%] Loss: 0.0012755297629429285 time: 1703090394.830828\n",
      "weight: [ 1.01873733  1.64020195  1.25846272  0.94201316 -0.37607806  0.20418074\n",
      "  1.1186056  -0.7891387   0.28150193 -0.18501615  0.67881716  0.86786216]\n",
      "epoch 122\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018831763073526198 R2: 0.9058731851888003 time: 1703090397.5956311\n",
      "batch_idx: 1 loss: 0.0008199202105295111 R2: 0.9058932161275519 time: 1703090400.2557395\n",
      "batch_idx: 2 loss: 0.001614439162704247 R2: 0.9059098372116002 time: 1703090402.9156344\n",
      "batch_idx: 3 loss: 0.000780880218955896 R2: 0.9059223413255498 time: 1703090405.5308983\n",
      "Training [24%] Loss: 0.0012746039748855686 time: 1703090405.5308983\n",
      "weight: [ 1.02129355  1.63937044  1.25809118  0.93849988 -0.37513737  0.204174\n",
      "  1.1189032  -0.78953117  0.27957021 -0.18502386  0.67889546  0.86808872]\n",
      "epoch 123\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018812300388755233 R2: 0.9059410290231886 time: 1703090408.1687732\n",
      "batch_idx: 1 loss: 0.0008200048247467683 R2: 0.9059613109652093 time: 1703090410.805719\n",
      "batch_idx: 2 loss: 0.0016132039244867522 R2: 0.9059781151766009 time: 1703090413.4202218\n",
      "batch_idx: 3 loss: 0.000780232709320784 R2: 0.9059906917443653 time: 1703090416.036084\n",
      "Training [25%] Loss: 0.001273667874357457 time: 1703090416.036084\n",
      "weight: [ 1.02389092  1.63852443  1.25771291  0.93502197 -0.37418408  0.20416704\n",
      "  1.11920738 -0.78993321  0.27757634 -0.18503129  0.67897577  0.86832589]\n",
      "epoch 124\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018792564952551812 R2: 0.9060096450676349 time: 1703090418.6966743\n",
      "batch_idx: 1 loss: 0.0008200918451266281 R2: 0.9060301796552185 time: 1703090421.46826\n",
      "batch_idx: 2 loss: 0.0016119555731962463 R2: 0.9060471680128062 time: 1703090424.0477142\n",
      "batch_idx: 3 loss: 0.0007795817409523708 R2: 0.9060598155073608 time: 1703090426.72998\n",
      "Training [25%] Loss: 0.0012727214136326066 time: 1703090426.72998\n",
      "weight: [ 1.02652988  1.63766378  1.25732787  0.93157972 -0.3732182   0.20415991\n",
      "  1.1195183  -0.79034512  0.27551805 -0.18503841  0.6790581   0.86857392]\n",
      "epoch 125\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018772553254113853 R2: 0.9060790370437752 time: 1703090429.2786946\n",
      "batch_idx: 1 loss: 0.0008201812172210374 R2: 0.9060998259261765 time: 1703090431.895718\n",
      "batch_idx: 2 loss: 0.0016106941263202528 R2: 0.9061169994270128 time: 1703090434.507019\n",
      "batch_idx: 3 loss: 0.000778927515638578 R2: 0.906129716254731 time: 1703090437.1408265\n",
      "Training [25%] Loss: 0.0012717645461478135 time: 1703090437.1408265\n",
      "weight: [ 1.02921084  1.63678842  1.25693601  0.92817344 -0.37223978  0.20415264\n",
      "  1.11983617 -0.79076717  0.27339302 -0.18504519  0.67914249  0.86883304]\n",
      "epoch 126\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00187522616931542 R2: 0.9061492085749071 time: 1703090439.785663\n",
      "batch_idx: 1 loss: 0.000820272873373624 R2: 0.9061702534034076 time: 1703090442.395791\n",
      "batch_idx: 2 loss: 0.0016094196172180338 R2: 0.906187613015747 time: 1703090445.190684\n",
      "batch_idx: 3 loss: 0.0007782702473853965 R2: 0.9062003975093079 time: 1703090447.796086\n",
      "Training [25%] Loss: 0.0012707972268231184 time: 1703090447.796086\n",
      "weight: [ 1.03193422  1.63589823  1.25653727  0.92480341 -0.37124888  0.20414527\n",
      "  1.12016118 -0.79119969  0.27119883 -0.18505161  0.67922894  0.86910345]\n",
      "epoch 127\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018731686583452292 R2: 0.9062201631585649 time: 1703090450.4709647\n",
      "batch_idx: 1 loss: 0.0008203667322677847 R2: 0.9062414655822278 time: 1703090453.0060782\n",
      "batch_idx: 2 loss: 0.0016081320958348689 R2: 0.9062590122380951 time: 1703090455.6909785\n",
      "batch_idx: 3 loss: 0.0007776101629715586 R2: 0.9062718626487231 time: 1703090458.3556287\n",
      "Training [25%] Loss: 0.0012698194123548603 time: 1703090458.3556287\n",
      "weight: [ 1.0347004   1.63499316  1.25613163  0.92146992 -0.37024557  0.20413784\n",
      "  1.12049353 -0.79164298  0.26893297 -0.18505764  0.67931745  0.86938537]\n",
      "epoch 128\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001871082416067026 R2: 0.9062919041390435 time: 1703090461.065954\n",
      "batch_idx: 1 loss: 0.0008204626980860368 R2: 0.9063134657998132 time: 1703090463.717844\n",
      "batch_idx: 2 loss: 0.001606831629646516 R2: 0.9063312003877174 time: 1703090466.4004526\n",
      "batch_idx: 3 loss: 0.0007769475024059186 R2: 0.9063441148760492 time: 1703090469.027539\n",
      "Training [26%] Loss: 0.0012688310615513745 time: 1703090469.027539\n",
      "weight: [ 1.03750979  1.63407314  1.25571905  0.9181732  -0.36922994  0.2041304\n",
      "  1.12083345 -0.79209739  0.26659286 -0.18506324  0.67940803  0.86967899]\n",
      "epoch 129\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018689670590925876 R2: 0.9063644346788781 time: 1703090471.693275\n",
      "batch_idx: 1 loss: 0.0008205606596815237 R2: 0.9063862572059523 time: 1703090474.356017\n",
      "batch_idx: 2 loss: 0.001605518304567176 R2: 0.9064041805635144 time: 1703090476.94085\n",
      "batch_idx: 3 loss: 0.0007762825195411647 R2: 0.9064171571896777 time: 1703090479.6659536\n",
      "Training [26%] Loss: 0.0012678321357206131 time: 1703090479.6659536\n",
      "weight: [ 1.04036275  1.63313813  1.25529951  0.91491352 -0.3682021   0.204123\n",
      "  1.12118114 -0.79256325  0.26417582 -0.18506838  0.67950069  0.86998447]\n",
      "epoch 130\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018668221977126414 R2: 0.9064377577284116 time: 1703090482.3358994\n",
      "batch_idx: 1 loss: 0.0008206604899610254 R2: 0.9064598427327498 time: 1703090484.950666\n",
      "batch_idx: 2 loss: 0.0016041922257666104 R2: 0.9064779556386293 time: 1703090487.6871254\n",
      "batch_idx: 3 loss: 0.0007756154828278332 R2: 0.9064909923523364 time: 1703090490.380646\n",
      "Training [26%] Loss: 0.0012668225990670277 time: 1703090490.380646\n",
      "weight: [ 1.04325964  1.63218811  1.25487299  0.91169112 -0.36716218  0.20411569\n",
      "  1.12153685 -0.79304091  0.26167909 -0.18507303  0.67959542  0.87030196]\n",
      "epoch 131\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018646474364346084 R2: 0.9065118759935157 time: 1703090492.9560921\n",
      "batch_idx: 1 loss: 0.0008207620452853422 R2: 0.9065342250629049 time: 1703090495.596029\n",
      "batch_idx: 2 loss: 0.0016028535185593918 R2: 0.9065525282279134 time: 1703090498.227312\n",
      "batch_idx: 3 loss: 0.0007749466760256318 R2: 0.9065656228583725 time: 1703090500.7678475\n",
      "Training [26%] Loss: 0.0012658024190762434 time: 1703090500.7678475\n",
      "weight: [ 1.04620081  1.63122306  1.2544395   0.90850625 -0.36611034  0.20410852\n",
      "  1.12190081 -0.79353075  0.25909982 -0.18507716  0.67969221  0.87063156]\n",
      "epoch 132\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018624423746959578 R2: 0.9065867919020055 time: 1703090503.505737\n",
      "batch_idx: 1 loss: 0.0008208651646712346 R2: 0.9066094065962081 time: 1703090506.0715818\n",
      "batch_idx: 2 loss: 0.0016015023294711004 R2: 0.9066279006539035 time: 1703090508.7357223\n",
      "batch_idx: 3 loss: 0.0007742763988082909 R2: 0.9066410508988175 time: 1703090511.3925452\n",
      "Training [26%] Loss: 0.0012647715669116461 time: 1703090511.3925452\n",
      "weight: [ 1.04918656  1.630243    1.25399903  0.90535913 -0.36504674  0.20410154\n",
      "  1.12227326 -0.79403313  0.25643507 -0.18508074  0.67979103  0.87097338]\n",
      "epoch 133\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018602066077844255 R2: 0.9066625075685751 time: 1703090513.9480014\n",
      "batch_idx: 1 loss: 0.0008209696688459458 R2: 0.906685389414052 time: 1703090516.6108372\n",
      "batch_idx: 2 loss: 0.001600138827412248 R2: 0.9067040749109625 time: 1703090519.1889944\n",
      "batch_idx: 3 loss: 0.0007736049673610389 R2: 0.9067172783244564 time: 1703090521.7956438\n",
      "Training [27%] Loss: 0.0012637300178509146 time: 1703090521.7956438\n",
      "weight: [ 1.05221721  1.62924797  1.2535516   0.90225001 -0.36397158  0.20409484\n",
      "  1.12265446 -0.79454845  0.25368181 -0.18508372  0.67989188  0.87132745]\n",
      "epoch 134\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018579397278022628 R2: 0.9067390247576558 time: 1703090524.3170726\n",
      "batch_idx: 1 loss: 0.0008210753593261673 R2: 0.906762175242014 time: 1703090527.0006933\n",
      "batch_idx: 2 loss: 0.0015987632048625414 R2: 0.9067810526271952 time: 1703090529.605957\n",
      "batch_idx: 3 loss: 0.0007729327150495988 R2: 0.9067943066070541 time: 1703090532.3218052\n",
      "Training [27%] Loss: 0.0012626777517601427 time: 1703090532.3218052\n",
      "weight: [ 1.05529301  1.62823802  1.25309723  0.8991791  -0.36288507  0.20408845\n",
      "  1.12304466 -0.79507709  0.25083694 -0.18508608  0.67999471  0.87169377]\n",
      "epoch 135\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018556413246056946 R2: 0.9068163448438039 time: 1703090534.9958322\n",
      "batch_idx: 1 loss: 0.000821182017555184 R2: 0.906839765410249 time: 1703090537.5437267\n",
      "batch_idx: 2 loss: 0.001597375679076912 R2: 0.9068588350239979 time: 1703090540.201081\n",
      "batch_idx: 3 loss: 0.000772259993117929 R2: 0.9068721367983696 time: 1703090542.8057563\n",
      "Training [27%] Loss: 0.0012616147535889299 time: 1703090542.8057563\n",
      "weight: [ 1.05841424  1.62721325  1.25263595  0.89614666 -0.36178746  0.20408247\n",
      "  1.12344413 -0.79561948  0.24789724 -0.18508778  0.68009948  0.87207229]\n",
      "epoch 136\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018533109868243511 R2: 0.9068944687695873 time: 1703090545.481093\n",
      "batch_idx: 1 loss: 0.0008212894039969826 R2: 0.9069181608114484 time: 1703090548.0756912\n",
      "batch_idx: 2 loss: 0.0015959764933835083 R2: 0.9069374228731218 time: 1703090550.7759213\n",
      "batch_idx: 3 loss: 0.0007715871713403633 R2: 0.9069507694864699 time: 1703090553.340041\n",
      "Training [27%] Loss: 0.0012605410138863014 time: 1703090553.340041\n",
      "weight: [ 1.06158109  1.62617376  1.25216782  0.8931529  -0.360679    0.20407694\n",
      "  1.12385312 -0.79617602  0.24485943 -0.18508877  0.68020616  0.87246291]\n",
      "epoch 137\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018509483030644397 R2: 0.9069733970010473 time: 1703090555.8859165\n",
      "batch_idx: 1 loss: 0.0008213972571352194 R2: 0.9069973618560224 time: 1703090558.480843\n",
      "batch_idx: 2 loss: 0.0015945659185881127 R2: 0.907016816451035 time: 1703090561.115822\n",
      "batch_idx: 3 loss: 0.0007709146386263421 R2: 0.9070302047490992 time: 1703090563.8457365\n",
      "Training [27%] Loss: 0.0012594565293535284 time: 1703090563.8457365\n",
      "weight: [ 1.06479375  1.6251197   1.2516929   0.89019807 -0.35955998  0.20407195\n",
      "  1.12427192 -0.79674714  0.24172015 -0.18508902  0.68031468  0.87286547]\n",
      "epoch 138\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018485528632804248 R2: 0.9070531294803663 time: 1703090566.4644923\n",
      "batch_idx: 1 loss: 0.0008215052924380386 R2: 0.9070773684243549 time: 1703090569.1457305\n",
      "batch_idx: 2 loss: 0.0015931442544379435 R2: 0.9070970154903426 time: 1703090571.7357664\n",
      "batch_idx: 3 loss: 0.0007702428036222195 R2: 0.907110442104108 time: 1703090574.459281\n",
      "Training [28%] Loss: 0.0012583613034446565 time: 1703090574.459281\n",
      "weight: [ 1.06805238  1.62405123  1.25121124  0.88728238 -0.35843073  0.20406758\n",
      "  1.1247008  -0.79733328  0.23847596 -0.18508849  0.68042497  0.87327972]\n",
      "epoch 139\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018461242602605637 R2: 0.9071336655753788 time: 1703090577.102375\n",
      "batch_idx: 1 loss: 0.0008216132013568039 R2: 0.9071581798159501 time: 1703090579.6858294\n",
      "batch_idx: 2 loss: 0.0015917118311128784 R2: 0.9071780191278892 time: 1703090582.2956572\n",
      "batch_idx: 3 loss: 0.0007695720953190508 R2: 0.9071914804567728 time: 1703090584.989192\n",
      "Training [28%] Loss: 0.0012572553470123241 time: 1703090584.989192\n",
      "weight: [ 1.07135708  1.62296856  1.25072296  0.88440608 -0.35729157  0.20406389\n",
      "  1.12514004 -0.79793487  0.23512333 -0.18508713  0.68053696  0.87370535]\n",
      "epoch 140\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018436620912443504 R2: 0.9072150040256671 time: 1703090587.5913577\n",
      "batch_idx: 1 loss: 0.0008217206503527358 R2: 0.9072397946951869 time: 1703090590.8559115\n",
      "batch_idx: 2 loss: 0.0015902690107577882 R2: 0.9072598258494209 time: 1703090593.6856716\n",
      "batch_idx: 3 loss: 0.0007689029636305168 R2: 0.9072733180436499 time: 1703090596.4376845\n",
      "Training [28%] Loss: 0.0012561386789963478 time: 1703090596.4376845\n",
      "weight: [ 1.07470791  1.62187192  1.25022813  0.8815694  -0.35614289  0.20406096\n",
      "  1.12558991 -0.79855237  0.2316587  -0.18508491  0.68065057  0.87414194]\n",
      "epoch 141\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018411659597431667 R2: 0.9072971428851476 time: 1703090599.173166\n",
      "batch_idx: 1 loss: 0.0008218272799189661 R2: 0.9073222110334548 time: 1703090601.8459413\n",
      "batch_idx: 2 loss: 0.001588816189071193 R2: 0.9073424334305555 time: 1703090604.4874108\n",
      "batch_idx: 3 loss: 0.0007682358799141172 R2: 0.9073559523726844 time: 1703090607.1693492\n",
      "Training [28%] Loss: 0.0012550113271618606 time: 1703090607.1693492\n",
      "weight: [ 1.0781049   1.6207616   1.24972688  0.87877255 -0.35498508  0.20405889\n",
      "  1.12605071 -0.79918623  0.22807841 -0.18508178  0.68076569  0.874589  ]\n",
      "epoch 142\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018386354776039366 R2: 0.9073800794609701 time: 1703090609.7891417\n",
      "batch_idx: 1 loss: 0.0008219327036116273 R2: 0.907405426047349 time: 1703090612.5508814\n",
      "batch_idx: 2 loss: 0.0015873537969314992 R2: 0.9074258388738686 time: 1703090615.2109845\n",
      "batch_idx: 3 loss: 0.0007675713374418095 R2: 0.9074393801593746 time: 1703090617.865938\n",
      "Training [28%] Loss: 0.0012538733288972182 time: 1703090617.865938\n",
      "weight: [ 1.08154801  1.6196379   1.24921935  0.87601578 -0.35381855  0.20405774\n",
      "  1.12652271 -0.79983691  0.22437877 -0.18507769  0.6808822   0.87504591]\n",
      "epoch 143\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018360702673112766 R2: 0.9074638102484632 time: 1703090620.4501626\n",
      "batch_idx: 1 loss: 0.0008220365071389152 R2: 0.9074894361328047 time: 1703090623.1384046\n",
      "batch_idx: 2 loss: 0.0015858823020279196 R2: 0.907510038341796 time: 1703090625.8357797\n",
      "batch_idx: 3 loss: 0.000766909851828274 R2: 0.9075235972588779 time: 1703090628.4538932\n",
      "Training [29%] Loss: 0.0012527247320765964 time: 1703090628.4538932\n",
      "weight: [ 1.08503714  1.61850117  1.24870567  0.87329931 -0.35264378  0.20405761\n",
      "  1.12700619 -0.80050487  0.22055606 -0.1850726   0.681       0.87551196]\n",
      "epoch 144\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018334699645339923 R2: 0.9075483308618301 time: 1703090631.1961927\n",
      "batch_idx: 1 loss: 0.0008221382475385438 R2: 0.9075742367948942 time: 1703090633.7759266\n",
      "batch_idx: 2 loss: 0.0015844022104787973 R2: 0.9075950270851448 time: 1703090636.5006607\n",
      "batch_idx: 3 loss: 0.0007662519614014845 R2: 0.907608598593882 time: 1703090639.1656873\n",
      "Training [29%] Loss: 0.0012515655959882044 time: 1703090639.1656873\n",
      "weight: [ 1.08857216  1.6173518   1.24818602  0.87062336 -0.35146123  0.20405857\n",
      "  1.12750143 -0.80119058  0.2166065  -0.18506646  0.68111894  0.87598628]\n",
      "epoch 145\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001830834220958407 R2: 0.9076336359605284 time: 1703090641.850734\n",
      "batch_idx: 1 loss: 0.0008222374524471407 R2: 0.9076598225731468 time: 1703090644.546109\n",
      "batch_idx: 2 loss: 0.001582914068430856 R2: 0.9076807993671059 time: 1703090647.1859112\n",
      "batch_idx: 3 loss: 0.0007655982274907356 R2: 0.9076943780779864 time: 1703090649.7408433\n",
      "Training [29%] Loss: 0.001250395992331785 time: 1703090649.7408433\n",
      "weight: [ 1.09215284  1.61619022  1.24766058  0.86798814 -0.35027141  0.20406071\n",
      "  1.1280087  -0.80189449  0.21252633 -0.18505922  0.68123887  0.87646791]\n",
      "epoch 146\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018281627074541995 R2: 0.9077197191711563 time: 1703090652.3218427\n",
      "batch_idx: 1 loss: 0.0008223336194740028 R2: 0.9077461869621434 time: 1703090654.9271557\n",
      "batch_idx: 2 loss: 0.0015814184636210114 R2: 0.9077673483825442 time: 1703090657.5361276\n",
      "batch_idx: 3 loss: 0.0007649492346195344 R2: 0.9077809285344639 time: 1703090660.235849\n",
      "Training [29%] Loss: 0.001249216006292187 time: 1703090660.235849\n",
      "weight: [ 1.0957789   1.61501693  1.24712954  0.86539387 -0.34907487  0.20406411\n",
      "  1.12852828 -0.80261708  0.20831175 -0.18505084  0.68135963  0.8769557 ]\n",
      "epoch 147\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00182545511759554 R2: 0.907806573004813 time: 1703090663.045834\n",
      "batch_idx: 1 loss: 0.0008224262157153231 R2: 0.9078333223272933 time: 1703090665.7356858\n",
      "batch_idx: 2 loss: 0.0015799160268680362 R2: 0.907854666172503 time: 1703090668.406367\n",
      "batch_idx: 3 loss: 0.0007643055905988177 R2: 0.9078682416103542 time: 1703090671.1258762\n",
      "Training [29%] Loss: 0.0012480257376944292 time: 1703090671.1258762\n",
      "weight: [ 1.09944996  1.61383243  1.24659313  0.86284075 -0.34787217  0.20406885\n",
      "  1.12906041 -0.80335881  0.20395901 -0.18504127  0.68148105  0.87744838]\n",
      "epoch 148\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018227111715505256 R2: 0.907894188769745 time: 1703090673.9175694\n",
      "batch_idx: 1 loss: 0.0008225146774480581 R2: 0.9079212198157324 time: 1703090676.5259712\n",
      "batch_idx: 2 loss: 0.001578407433461952 R2: 0.9079427435338182 time: 1703090679.2007174\n",
      "batch_idx: 3 loss: 0.0007636679265077424 R2: 0.9079563076858916 time: 1703090681.850868\n",
      "Training [30%] Loss: 0.0012468253022420695 time: 1703090681.850868\n",
      "weight: [ 1.1031656   1.61263729  1.24605158  0.86032896 -0.3466639   0.20407502\n",
      "  1.12960536 -0.80412012  0.19946436 -0.18503046  0.68160294  0.87794451]\n",
      "epoch 149\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018199306203643718 R2: 0.9079825564793597 time: 1703090684.5214312\n",
      "batch_idx: 1 loss: 0.0008225984100289824 R2: 0.9080098692622819 time: 1703090687.135044\n",
      "batch_idx: 2 loss: 0.0015768934044256243 R2: 0.9080315699238655 time: 1703090689.8325999\n",
      "batch_idx: 3 loss: 0.0007630368965398846 R2: 0.9080451157792023 time: 1703090692.426143\n",
      "Training [30%] Loss: 0.0012456148328397157 time: 1703090692.426143\n",
      "weight: [ 1.10692526  1.61143214  1.24550515  0.85785867 -0.34545068  0.20408269\n",
      "  1.13016336 -0.80490147  0.19482414 -0.18501837  0.6817251   0.8784425 ]\n",
      "epoch 150\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018171132506669342 R2: 0.9080716647556388 time: 1703090695.070719\n",
      "batch_idx: 1 loss: 0.0008226767880213835 R2: 0.9080992590905543 time: 1703090697.816131\n",
      "batch_idx: 2 loss: 0.0015753747076206449 R2: 0.9081211333605251 time: 1703090700.4231954\n",
      "batch_idx: 3 loss: 0.0007624131776941504 R2: 0.9081346534464247 time: 1703090703.1159565\n",
      "Training [30%] Loss: 0.0012443944810007783 time: 1703090703.1159565\n",
      "weight: [ 1.11072832  1.61021763  1.24495412  0.85543006 -0.34423316  0.20409193\n",
      "  1.13073464 -0.8057033   0.19003474 -0.18500494  0.68184733  0.87894059]\n",
      "epoch 151\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018142588898213841 R2: 0.9081615007281192 time: 1703090705.877965\n",
      "batch_idx: 1 loss: 0.0008227491555818121 R2: 0.9081893762092935 time: 1703090708.5956762\n",
      "batch_idx: 2 loss: 0.001573852158662342 R2: 0.9082114203175232 time: 1703090711.175773\n",
      "batch_idx: 3 loss: 0.00076179746929434 R2: 0.9082249066774045 time: 1703090713.845928\n",
      "Training [30%] Loss: 0.0012431644183399696 time: 1703090713.845928\n",
      "weight: [ 1.11457406  1.60899449  1.24439877  0.85304326 -0.34301201  0.20410282\n",
      "  1.1313194  -0.80652603  0.18509268 -0.18499015  0.6819694   0.87943687]\n",
      "epoch 152\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018113674115145233 R2: 0.9082520499286775 time: 1703090716.595827\n",
      "batch_idx: 1 loss: 0.0008228148271441693 R2: 0.9082802059042618 time: 1703090719.242217\n",
      "batch_idx: 2 loss: 0.0015723266216074606 R2: 0.9083024156154474 time: 1703090721.855558\n",
      "batch_idx: 3 loss: 0.000761190492318821 R2: 0.9083158597873077 time: 1703090724.3357868\n",
      "Training [30%] Loss: 0.0012419248381462435 time: 1703090724.3357868\n",
      "weight: [ 1.11846164  1.60776347  1.24383942  0.85069839 -0.34178791  0.20411542\n",
      "  1.13191784 -0.80737007  0.17999459 -0.18497394  0.6820911   0.87992924]\n",
      "epoch 153\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001808438741782369 R2: 0.9083432961824434 time: 1703090727.0138507\n",
      "batch_idx: 1 loss: 0.0008228730884317864 R2: 0.908371731726015 time: 1703090729.5961764\n",
      "batch_idx: 2 loss: 0.0015707990093825515 R2: 0.9083941023088598 time: 1703090732.2958472\n",
      "batch_idx: 3 loss: 0.000760592988515162 R2: 0.9084074953045571 time: 1703090734.8815377\n",
      "Training [31%] Loss: 0.0012406759570279672 time: 1703090734.8815377\n",
      "weight: [ 1.12239011  1.60652537  1.24327639  0.84839556 -0.34056158  0.2041298\n",
      "  1.13253012 -0.80823582  0.17473728 -0.18495627  0.68221219  0.88041551]\n",
      "epoch 154\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018054728654578387 R2: 0.9084352214953523 time: 1703090737.4757557\n",
      "batch_idx: 1 loss: 0.0008229231978218361 R2: 0.9084639353741487 time: 1703090740.0856857\n",
      "batch_idx: 2 loss: 0.0015692702839253223 R2: 0.9084864615700555 time: 1703090742.7507582\n",
      "batch_idx: 3 loss: 0.0007600057192723433 R2: 0.9084997938557059 time: 1703090745.4459016\n",
      "Training [31%] Loss: 0.001239418016619335 time: 1703090745.4459016\n",
      "weight: [ 1.12635841  1.60528106  1.24271004  0.84613483 -0.33933374  0.20414602\n",
      "  1.1331564  -0.80912365  0.16931773 -0.18493712  0.68233244  0.88089332]\n",
      "epoch 155\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0018024698330098496 R2: 0.9085278059389784 time: 1703090748.0487325\n",
      "batch_idx: 1 loss: 0.000822964388086467 R2: 0.9085567965786995 time: 1703090750.8257678\n",
      "batch_idx: 2 loss: 0.001567741456011779 R2: 0.9085794725703144 time: 1703090753.4235642\n",
      "batch_idx: 3 loss: 0.0007594294642239215 R2: 0.9085927340480143 time: 1703090756.060041\n",
      "Training [31%] Loss: 0.0012381512853330042 time: 1703090756.060041\n",
      "weight: [ 1.13036534  1.60403144  1.24214072  0.84391624 -0.33810514  0.20416411\n",
      "  1.1337968  -0.81003391  0.16373318 -0.18491645  0.68245162  0.88136022]\n",
      "epoch 156\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017994297677205867 R2: 0.9086210275334787 time: 1703090758.6759129\n",
      "batch_idx: 1 loss: 0.0008229958685345961 R2: 0.9086502929797019 time: 1703090761.3570967\n",
      "batch_idx: 2 loss: 0.0015662135847458515 R2: 0.9086731123595516 time: 1703090763.9857006\n",
      "batch_idx: 3 loss: 0.0007588650195539244 R2: 0.9086862923507463 time: 1703090766.674897\n",
      "Training [31%] Loss: 0.0012368760601387397 time: 1703090766.674897\n",
      "weight: [ 1.13440957  1.60277744  1.24156881  0.84173981 -0.33687654  0.20418413\n",
      "  1.13445141 -0.81096692  0.1579811  -0.18489423  0.6825695   0.88181367]\n",
      "epoch 157\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017963528731292562 R2: 0.9087148621296931 time: 1703090769.226115\n",
      "batch_idx: 1 loss: 0.0008230168275709644 R2: 0.9087444000061048 time: 1703090771.7958968\n",
      "batch_idx: 2 loss: 0.0015646877766955307 R2: 0.9087673557457239 time: 1703090774.525824\n",
      "batch_idx: 3 loss: 0.0007583131959735461 R2: 0.9087804429765155 time: 1703090777.1959987\n",
      "Training [31%] Loss: 0.0012355926683423244 time: 1703090777.1959987\n",
      "weight: [ 1.13848965  1.60152007  1.24099471  0.83960551 -0.3356487   0.2042061\n",
      "  1.13512029 -0.81192298  0.15205929 -0.18487043  0.68268584  0.8822511 ]\n",
      "epoch 158\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017932394406547255 R2: 0.908809283291737 time: 1703090779.9157257\n",
      "batch_idx: 1 loss: 0.0008230264356792312 R2: 0.9088390907555585 time: 1703090782.5359204\n",
      "batch_idx: 2 loss: 0.0015631651846676898 R2: 0.9088621751755049 time: 1703090785.2409234\n",
      "batch_idx: 3 loss: 0.0007577748163344814 R2: 0.9088751577642616 time: 1703090787.8310812\n",
      "Training [32%] Loss: 0.0012343014693340319 time: 1703090787.8310812\n",
      "weight: [ 1.14260398  1.60026034  1.24041882  0.83751329 -0.33442239  0.20423006\n",
      "  1.13580347 -0.81290234  0.14596587 -0.18484505  0.68280046  0.88266993]\n",
      "epoch 159\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017900898572923711 R2: 0.9089042621817482 time: 1703090790.5342813\n",
      "batch_idx: 1 loss: 0.0008230238488279439 R2: 0.9089343358769844 time: 1703090793.1371458\n",
      "batch_idx: 2 loss: 0.0015616470061188988 R2: 0.9089575406182304 time: 1703090795.7261004\n",
      "batch_idx: 3 loss: 0.0007572507128462186 R2: 0.9089704060658749 time: 1703090798.533422\n",
      "Training [32%] Loss: 0.0012330028562713583 time: 1703090798.533422\n",
      "weight: [ 1.14675079  1.59899932  1.23984157  0.83546303 -0.3331984   0.20425602\n",
      "  1.13650095 -0.81390523  0.13969935 -0.18481807  0.68291313  0.88306763]\n",
      "epoch 160\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001786904613263122 R2: 0.9089997674488173 time: 1703090801.2591558\n",
      "batch_idx: 1 loss: 0.0008230082122902051 R2: 0.9090301034581726 time: 1703090803.8356674\n",
      "batch_idx: 2 loss: 0.0015601344812038018 R2: 0.9090534194554449 time: 1703090806.315716\n",
      "batch_idx: 3 loss: 0.0007567417238671447 R2: 0.9090661546388927 time: 1703090808.9161155\n",
      "Training [32%] Loss: 0.0012316972576560685 time: 1703090808.9161155\n",
      "weight: [ 1.15092818  1.59773811  1.23926339  0.8334546  -0.3319775   0.20428399\n",
      "  1.13721268 -0.81493183  0.13325865 -0.18478948  0.68302369  0.88344175]\n",
      "epoch 161\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017836843094817215 R2: 0.9090957651245917 time: 1703090811.4569478\n",
      "batch_idx: 1 loss: 0.0008229786648566897 R2: 0.9091263589211296 time: 1703090814.0856895\n",
      "batch_idx: 2 loss: 0.0015586288904648337 R2: 0.9091497763788731 time: 1703090816.7311745\n",
      "batch_idx: 3 loss: 0.0007562486902433108 R2: 0.9091623675481488 time: 1703090819.2933805\n",
      "Training [32%] Loss: 0.0012303851387616388 time: 1703090819.2933805\n",
      "weight: [ 1.15513409  1.59647784  1.23868471  0.83148781 -0.33076046  0.20431395\n",
      "  1.13793857 -0.81598229  0.12664314 -0.18475928  0.68313197  0.88379001]\n",
      "epoch 162\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017804296647059028 R2: 0.9091922185285041 time: 1703090821.908266\n",
      "batch_idx: 1 loss: 0.0008229343434092734 R2: 0.9092230649283553 time: 1703090824.4824595\n",
      "batch_idx: 2 loss: 0.0015571315521659321 R2: 0.9092465733001088 time: 1703090827.1058686\n",
      "batch_idx: 3 loss: 0.0007557724511767016 R2: 0.9092590060797706 time: 1703090829.66673\n",
      "Training [32%] Loss: 0.0012290670028644525 time: 1703090829.66673\n",
      "weight: [ 1.15936629  1.59521966  1.23810597  0.82956242 -0.32954805  0.2043459\n",
      "  1.1386785  -0.81705671  0.11985268 -0.1847275   0.68323785  0.88411031]\n",
      "epoch 163\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001777141522227011 R2: 0.9092890881860853 time: 1703090832.2338302\n",
      "batch_idx: 1 loss: 0.0008228743878121506 R2: 0.9093201813036554 time: 1703090834.7778175\n",
      "batch_idx: 2 loss: 0.0015556438192647775 R2: 0.9093437692757631 time: 1703090837.4758987\n",
      "batch_idx: 3 loss: 0.0007553138396182626 R2: 0.9093560286713599 time: 1703090839.984168\n",
      "Training [33%] Loss: 0.0012277433922305504 time: 1703090839.984168\n",
      "weight: [ 1.16362241  1.59396473  1.23752764  0.82767816 -0.32834101  0.2043798\n",
      "  1.13943231 -0.81815513  0.11288766 -0.18469413  0.68334121  0.88440083]\n",
      "epoch 164\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017738208559618458 R2: 0.9093863317643857 time: 1703090842.477468\n",
      "batch_idx: 1 loss: 0.0008227979460705525 R2: 0.9094176649715765 time: 1703090845.121021\n",
      "batch_idx: 2 loss: 0.001554167076004603 R2: 0.9094413204523258 time: 1703090847.6771328\n",
      "batch_idx: 3 loss: 0.000754873677199455 R2: 0.9094533908626611 time: 1703090850.2961686\n",
      "Training [33%] Loss: 0.001226414888809114 time: 1703090850.2961686\n",
      "weight: [ 1.16789988  1.59271425  1.23695016  0.82583468 -0.32714008  0.20441562\n",
      "  1.14019976 -0.81927756  0.10574901 -0.18465922  0.68344199  0.88466004]\n",
      "epoch 165\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017704687758067327 R2: 0.9094839040288759 time: 1703090852.806212\n",
      "batch_idx: 1 loss: 0.0008227041797022368 R2: 0.9095154699198899 time: 1703090855.3655052\n",
      "batch_idx: 2 loss: 0.0015527027340884226 R2: 0.9095391800352657 time: 1703090857.8531597\n",
      "batch_idx: 3 loss: 0.0007544527687384235 R2: 0.9095510452713368 time: 1703090860.4733531\n",
      "Training [33%] Loss: 0.001225082114583954 time: 1703090860.4733531\n",
      "weight: [ 1.17219601  1.59146941  1.23637399  0.82403159 -0.32594597  0.20445331\n",
      "  1.14098062 -0.82042394  0.09843826 -0.18462279  0.68354015  0.88488676]\n",
      "epoch 166\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017670865321161016 R2: 0.9095817568266055 time: 1703090863.0232158\n",
      "batch_idx: 1 loss: 0.000822592269265272 R2: 0.9096135471897779 time: 1703090865.5813704\n",
      "batch_idx: 2 loss: 0.0015512522283776188 R2: 0.9096372982871026 time: 1703090868.2019525\n",
      "batch_idx: 3 loss: 0.0007540518963830366 R2: 0.9096489415986385 time: 1703090870.7281005\n",
      "Training [33%] Loss: 0.0012237457315355073 time: 1703090870.7281005\n",
      "weight: [ 1.17650791  1.59023139  1.23579958  0.82226847 -0.32475937  0.20449279\n",
      "  1.14177455 -0.82159417  0.09095752 -0.18458489  0.68363567  0.8850802 ]\n",
      "epoch 167\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017636755191649505 R2: 0.9096798391004912 time: 1703090873.3645418\n",
      "batch_idx: 1 loss: 0.000822461419989063 R2: 0.9097118448984732 time: 1703090875.8752537\n",
      "batch_idx: 2 loss: 0.0015498170120359968 R2: 0.909735622559339 time: 1703090878.4958732\n",
      "batch_idx: 3 loss: 0.0007536718134820332 R2: 0.9097470266697772 time: 1703090881.1200871\n",
      "Training [33%] Loss: 0.0012224064411680109 time: 1703090881.1200871\n",
      "weight: [ 1.18083257  1.5890014   1.23522738  0.82054481 -0.32358093  0.204534\n",
      "  1.14258121 -0.82278808  0.08330952 -0.18454557  0.68372858  0.88523996]\n",
      "epoch 168\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017602372774475027 R2: 0.9097780969396038 time: 1703090883.719811\n",
      "batch_idx: 1 loss: 0.0008223108674620238 R2: 0.9098103082989674 time: 1703090886.2462327\n",
      "batch_idx: 2 loss: 0.0015483985510243569 R2: 0.909834097362703 time: 1703090888.7623816\n",
      "batch_idx: 3 loss: 0.0007533132383036084 R2: 0.9098452445134851 time: 1703090891.4207878\n",
      "Training [34%] Loss: 0.0012210649835593728 time: 1703090891.4207878\n",
      "weight: [ 1.1851668   1.58778059  1.23465782  0.81886006 -0.32241127  0.20457683\n",
      "  1.14340018 -0.82400546  0.07549763 -0.1845049   0.68381894  0.88536608]\n",
      "epoch 169\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017567734946544564 R2: 0.9098764736698387 time: 1703090893.9636304\n",
      "batch_idx: 1 loss: 0.0008221398833371286 R2: 0.9099088798809527 time: 1703090896.5761683\n",
      "batch_idx: 2 loss: 0.0015469983178446156 R2: 0.9099326644798206 time: 1703090899.0721452\n",
      "batch_idx: 3 loss: 0.0007529768477450563 R2: 0.9099435364847055 time: 1703090901.6496553\n",
      "Training [34%] Loss: 0.0012197221358953142 time: 1703090901.6496553\n",
      "weight: [ 1.18950728  1.58657014  1.23409133  0.81721361 -0.32125097  0.20462119\n",
      "  1.14423101 -0.82524601  0.06752583 -0.18446294  0.68390683  0.88545901]\n",
      "epoch 170\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017532860051620795 R2: 0.9099749099888186 time: 1703090904.179584\n",
      "batch_idx: 1 loss: 0.0008219477810223471 R2: 0.9100074995165052 time: 1703090906.7289941\n",
      "batch_idx: 2 loss: 0.0015456177844414515 R2: 0.9100312631235978 time: 1703090909.2716901\n",
      "batch_idx: 3 loss: 0.0007526632711944304 R2: 0.9100418414335335 time: 1703090911.768222\n",
      "Training [34%] Loss: 0.0012183787104550771 time: 1703090911.768222\n",
      "weight: [ 1.19385057  1.58537115  1.23352832  0.81560478 -0.32010056  0.20466696\n",
      "  1.14507319 -0.8265094   0.05939872 -0.18441977  0.68399237  0.88551958]\n",
      "epoch 171\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017497767878611754 R2: 0.9100733441477665 time: 1703090914.357158\n",
      "batch_idx: 1 loss: 0.0008217339213259717 R2: 0.91010610465302 time: 1703090916.9445388\n",
      "batch_idx: 2 loss: 0.0015442584141946633 R2: 0.9101298301433959 time: 1703090919.6797261\n",
      "batch_idx: 3 loss: 0.0007523730847134758 R2: 0.9101400959222732 time: 1703090922.2623696\n",
      "Training [34%] Loss: 0.0012170355520238216 time: 1703090922.2623696\n",
      "weight: [ 1.19819309  1.58418473  1.23296919  0.81403286 -0.31896053  0.20471401\n",
      "  1.14592616 -0.8277952   0.0511215  -0.18437549  0.68407569  0.88554902]\n",
      "epoch 172\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017462479621575904 R2: 0.9101717121818924 time: 1703090924.879655\n",
      "batch_idx: 1 loss: 0.0008214977180240931 R2: 0.9102046305546532 time: 1703090927.4434667\n",
      "batch_idx: 2 loss: 0.0015429216529787185 R2: 0.9102283002799381 time: 1703090930.077018\n",
      "batch_idx: 3 loss: 0.0007521068057084839 R2: 0.9102382344911982 time: 1703090932.652378\n",
      "Training [34%] Loss: 0.0012156935347172216 time: 1703090932.652378\n",
      "weight: [ 1.20253118  1.5830119   1.23241432  0.81249706 -0.31783132  0.2047622\n",
      "  1.1467893  -0.82910296  0.04269996 -0.18433018  0.68415695  0.8855489 ]\n",
      "epoch 173\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017427017819929263 R2: 0.910269948189311 time: 1703090935.1771255\n",
      "batch_idx: 1 loss: 0.0008212386433088233 R2: 0.9103030105920107 time: 1703090937.7519488\n",
      "batch_idx: 2 loss: 0.001541608919324418 R2: 0.9103266064680907 time: 1703090940.326781\n",
      "batch_idx: 3 loss: 0.0007518648882416259 R2: 0.9103361899718804 time: 1703090942.9310334\n",
      "Training [35%] Loss: 0.0012143535582169484 time: 1703090942.9310334\n",
      "weight: [ 1.20686108  1.58185367  1.23186405  0.81099654 -0.31671328  0.20481137\n",
      "  1.14766195 -0.83043214  0.03414043 -0.18428395  0.68423632  0.88552107]\n",
      "epoch 174\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017391406277676425 R2: 0.91036798465683 time: 1703090945.46172\n",
      "batch_idx: 1 loss: 0.0008209562330617155 R2: 0.9104011765782424 time: 1703090948.1254237\n",
      "batch_idx: 2 loss: 0.001540321593786523 R2: 0.9104246801852158 time: 1703090950.6844847\n",
      "batch_idx: 3 loss: 0.0007516477191111845 R2: 0.910433893845289 time: 1703090953.2875862\n",
      "Training [35%] Loss: 0.0012130165434317665 time: 1703090953.2875862\n",
      "weight: [ 1.21117898  1.58071095  1.23131871  0.80953038 -0.31560675  0.20486136\n",
      "  1.14854342 -0.83178213  0.02544974 -0.1842369   0.68431399  0.88546764]\n",
      "epoch 175\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001735566996099551 R2: 0.9104657528291964 time: 1703090955.7998176\n",
      "batch_idx: 1 loss: 0.0008206500918788993 R2: 0.9104990591478748 time: 1703090958.3854394\n",
      "batch_idx: 2 loss: 0.0015390610076935862 R2: 0.9105224518408338 time: 1703090960.9435515\n",
      "batch_idx: 3 loss: 0.000751455614797368 R2: 0.9105312766401082 time: 1703090963.4584544\n",
      "Training [35%] Loss: 0.0012116834276173513 time: 1703090963.4584544\n",
      "weight: [ 1.21548101  1.57958461  1.2307786   0.80809765 -0.31451196  0.204912\n",
      "  1.14943295 -0.83315228  0.0166352  -0.18418914  0.68439013  0.8853909 ]\n",
      "epoch 176\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017319834874160195 R2: 0.9105631831166919 time: 1703090966.125782\n",
      "batch_idx: 1 loss: 0.0008203198977571538 R2: 0.910596588173083 time: 1703090968.6383579\n",
      "batch_idx: 2 loss: 0.001537828431524165 R2: 0.9106198512018724 time: 1703090971.3247159\n",
      "batch_idx: 3 loss: 0.0007512888193336871 R2: 0.9106282683650212 time: 1703090973.8545766\n",
      "Training [35%] Loss: 0.0012103551590077564 time: 1703090973.8545766\n",
      "weight: [ 1.21976329  1.57847543  1.23024398  0.80669733 -0.31342911  0.2049631\n",
      "  1.15032974 -0.83454187  0.00770452 -0.18414079  0.68446493  0.88529329]\n",
      "epoch 177\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001728392791455815 R2: 0.9106602055343261 time: 1703090976.5388715\n",
      "batch_idx: 1 loss: 0.0008199654063346133 R2: 0.9106936932104676 time: 1703090979.002147\n",
      "batch_idx: 2 loss: 0.0015366250632104614 R2: 0.9107168078460667 time: 1703090981.6060913\n",
      "batch_idx: 3 loss: 0.0007511475031257487 R2: 0.910724798967229 time: 1703090984.132538\n",
      "Training [35%] Loss: 0.0012090326910316595 time: 1703090984.132538\n",
      "weight: [ 1.22402197e+00  1.57738412e+00  1.22971509e+00  8.05328374e-01\n",
      " -3.12358319e-01  2.05014469e-01  1.15123297e+00 -8.35950128e-01\n",
      " -1.33423323e-03 -1.84091947e-01  6.84538596e-01  8.85177315e-01]\n",
      "epoch 178\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017247976708401722 R2: 0.9107567501644939 time: 1703090986.7571507\n",
      "batch_idx: 1 loss: 0.0008195864545705124 R2: 0.9107903039700316 time: 1703090989.3396144\n",
      "batch_idx: 2 loss: 0.0015354520167091897 R2: 0.9108132516349281 time: 1703090991.852677\n",
      "batch_idx: 3 loss: 0.0007510317627027996 R2: 0.9108207988082405 time: 1703090994.4931831\n",
      "Training [36%] Loss: 0.0012077169762056686 time: 1703090994.4931831\n",
      "weight: [ 1.2282532   1.57631132  1.22919212  0.80398968 -0.31129964  0.2050659\n",
      "  1.15214177 -0.83737622 -0.01047271 -0.18404273  0.68461129  0.8850455 ]\n",
      "epoch 179\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00172120094295638 R2: 0.9108527476338553 time: 1703090997.0301619\n",
      "batch_idx: 1 loss: 0.0008191829637461994 R2: 0.9108863507969573 time: 1703090999.66375\n",
      "batch_idx: 2 loss: 0.0015343103111971784 R2: 0.9109091131966428 time: 1703091002.2243433\n",
      "batch_idx: 3 loss: 0.0007509416213551061 R2: 0.9109161991470545 time: 1703091004.734443\n",
      "Training [36%] Loss: 0.0012064089598137159 time: 1703091004.734443\n",
      "weight: [ 1.23245321  1.57525755  1.22867525  0.80268013 -0.31025308  0.2051172\n",
      "  1.15305523 -0.83881928 -0.01970232 -0.18399324  0.6846832   0.88490036]\n",
      "epoch 180\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017176054604744304 R2: 0.910948129594464 time: 1703091007.3510044\n",
      "batch_idx: 1 loss: 0.0008187549416763708 R2: 0.9109817651560819 time: 1703091009.8918216\n",
      "batch_idx: 2 loss: 0.001533200861243641 R2: 0.9110043244087065 time: 1703091012.4444768\n",
      "batch_idx: 3 loss: 0.0007508770305840845 R2: 0.9110109326203796 time: 1703091014.96182\n",
      "Training [36%] Loss: 0.0012051095734946316 time: 1703091014.96182\n",
      "weight: [ 1.23661833  1.57422327  1.2281646   0.80139854 -0.30921856  0.20516814\n",
      "  1.15397244 -0.84027837 -0.02901432 -0.18394359  0.68475447  0.88474433]\n",
      "epoch 181\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017140140908831016 R2: 0.9110428291987537 time: 1703091017.6369302\n",
      "batch_idx: 1 loss: 0.0008183024840341879 R2: 0.9110764801086633 time: 1703091020.1377966\n",
      "batch_idx: 2 loss: 0.0015321244682834473 R2: 0.9110988188699306 time: 1703091022.695176\n",
      "batch_idx: 3 loss: 0.0007508378722728902 R2: 0.9111049337094373 time: 1703091025.2361045\n",
      "Training [36%] Loss: 0.0012038197288684067 time: 1703091025.2361045\n",
      "weight: [ 1.24074499  1.57320885  1.22766028  0.80014373 -0.30819596  0.20521852\n",
      "  1.15489247 -0.84175256 -0.03839986 -0.18389387  0.68482526  0.88457973]\n",
      "epoch 182\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017104296954804285 R2: 0.9111367815581998 time: 1703091027.7014525\n",
      "batch_idx: 1 loss: 0.0008178257747157112 R2: 0.911170430771128 time: 1703091030.308249\n",
      "batch_idx: 2 loss: 0.0015310818136686935 R2: 0.911192532351682 time: 1703091032.850564\n",
      "batch_idx: 3 loss: 0.0007508239614732994 R2: 0.9111981391833218 time: 1703091035.4236474\n",
      "Training [36%] Loss: 0.0012025403113345332 time: 1703091035.4236474\n",
      "weight: [ 1.24482976  1.57221457  1.22716233  0.79891448 -0.30718508  0.2052681\n",
      "  1.15581435 -0.84324084 -0.04785004 -0.18384416  0.6848957   0.88440873]\n",
      "epoch 183\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017068551082830325 R2: 0.9112299241758505 time: 1703091038.0200512\n",
      "batch_idx: 1 loss: 0.0008173250851963016 R2: 0.9112635547460902 time: 1703091040.6942148\n",
      "batch_idx: 2 loss: 0.0015300734535138214 R2: 0.9112854032189039 time: 1703091043.2858846\n",
      "batch_idx: 3 loss: 0.0007508350496997989 R2: 0.9112904885095835 time: 1703091045.7866583\n",
      "Training [37%] Loss: 0.0012012721741732387 time: 1703091045.7866583\n",
      "weight: [ 1.24886939  1.57124062  1.2266708   0.79770959 -0.30618571  0.20531667\n",
      "  1.15673714 -0.8447422  -0.05735601 -0.18379455  0.6849659   0.88423335]\n",
      "epoch 184\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0017032931153262384 R2: 0.9113221973438451 time: 1703091048.2804968\n",
      "batch_idx: 1 loss: 0.0008168007728622072 R2: 0.9113557925168452 time: 1703091050.8501866\n",
      "batch_idx: 2 loss: 0.0015290998154772434 R2: 0.9113773728125037 time: 1703091053.503904\n",
      "batch_idx: 3 loss: 0.0007508708286226305 R2: 0.911381924223902 time: 1703091056.075829\n",
      "Training [37%] Loss: 0.00120001613307208 time: 1703091056.075829\n",
      "weight: [ 1.25286082  1.57028711  1.22618568  0.79652782 -0.30519757  0.20536401\n",
      "  1.15765987 -0.84625562 -0.06690898 -0.18374511  0.68503598  0.88405539]\n",
      "epoch 185\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001699746434813422 R2: 0.9114135444983527 time: 1703091058.5269227\n",
      "batch_idx: 1 loss: 0.0008162532783318443 R2: 0.9114470877978343 time: 1703091061.0518646\n",
      "batch_idx: 2 loss: 0.0015281611975452697 R2: 0.9114683857860276 time: 1703091063.6132705\n",
      "batch_idx: 3 loss: 0.0007509309340575546 R2: 0.91147239225216 time: 1703091066.1680214\n",
      "Training [37%] Loss: 0.0011987729611870228 time: 1703091066.1680214\n",
      "weight: [ 1.25680118  1.56935408  1.22570694  0.79536796 -0.30422033  0.2054099\n",
      "  1.15858161 -0.84778005 -0.07650029 -0.1836959   0.68510601  0.88387647]\n",
      "epoch 186\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016962176985389128 R2: 0.9115039125257166 time: 1703091068.7926602\n",
      "batch_idx: 1 loss: 0.0008156831218123042 R2: 0.9115373878350775 time: 1703091071.320448\n",
      "batch_idx: 2 loss: 0.0015272577688074864 R2: 0.9115583903911592 time: 1703091073.8969324\n",
      "batch_idx: 3 loss: 0.0007510149501592921 R2: 0.9115618421798738 time: 1703091076.4788928\n",
      "Training [37%] Loss: 0.0011975433848294987 time: 1703091076.4788928\n",
      "weight: [ 1.26068785  1.56844149  1.22523453  0.79422879 -0.30325364  0.20545411\n",
      "  1.15950141 -0.84931445 -0.08612148 -0.18364698  0.68517608  0.88369798]\n",
      "epoch 187\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016927094349576603 R2: 0.9115932520154091 time: 1703091079.0354106\n",
      "batch_idx: 1 loss: 0.0008150908985647921 R2: 0.911626643652388 time: 1703091081.6100554\n",
      "batch_idx: 2 loss: 0.0015263895721404207 R2: 0.9116473387082917 time: 1703091084.1870105\n",
      "batch_idx: 3 loss: 0.0007511224137372407 R2: 0.9116502274656902 time: 1703091086.8055391\n",
      "Training [37%] Loss: 0.0011963280798500285 time: 1703091086.8055391\n",
      "weight: [ 1.26451841  1.56754925  1.22476837  0.79310913 -0.30229712  0.20549643\n",
      "  1.16041837 -0.85085776 -0.09576428 -0.18359839  0.68524622  0.8835211 ]\n",
      "epoch 188\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016892240542092693 R2: 0.911681517457097 time: 1703091089.313947\n",
      "batch_idx: 1 loss: 0.0008144772735774536 R2: 0.911714810240832 time: 1703091092.0187583\n",
      "batch_idx: 2 loss: 0.0015255565286527277 R2: 0.9117351868202045 time: 1703091094.4647021\n",
      "batch_idx: 3 loss: 0.0007512528186246039 R2: 0.9117375055975445 time: 1703091097.1822274\n",
      "Training [38%] Loss: 0.0011951276687660135 time: 1703091097.1822274\n",
      "weight: [ 1.26829073  1.56667718  1.22430834  0.79200782 -0.30135038  0.20553665\n",
      "  1.1613316  -0.85240897 -0.10542072 -0.18355015  0.6853165   0.88334679]\n",
      "epoch 189\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001685763835329302 R2: 0.9117686673808562 time: 1703091099.7847795\n",
      "batch_idx: 1 loss: 0.0008138429755638324 R2: 0.9118018466908119 time: 1703091102.6807349\n",
      "batch_idx: 2 loss: 0.0015247584436927585 R2: 0.9118218949286498 time: 1703091105.2303467\n",
      "batch_idx: 3 loss: 0.0007514056200446093 R2: 0.9118236381917628 time: 1703091107.7782707\n",
      "Training [38%] Loss: 0.0011939427186576255 time: 1703091107.7782707\n",
      "weight: [ 1.27200291  1.56582508  1.22385435  0.79092371 -0.30041299  0.20557455\n",
      "  1.16224026 -0.85396704 -0.11508307 -0.1835023   0.68538694  0.88317582]\n",
      "epoch 190\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016823309158005238 R2: 0.9118546644414008 time: 1703091110.3354118\n",
      "batch_idx: 1 loss: 0.0008131887904200645 R2: 0.9118877162677078 time: 1703091112.9422488\n",
      "batch_idx: 2 loss: 0.0015239950141798402 R2: 0.911907427415238 time: 1703091115.5087938\n",
      "batch_idx: 3 loss: 0.0007515802389290746 R2: 0.9119085910369765 time: 1703091118.1470802\n",
      "Training [38%] Loss: 0.0011927737398323758 time: 1703091118.1470802\n",
      "weight: [ 1.27565331  1.56499268  1.22340625  0.7898557  -0.29948453  0.20560994\n",
      "  1.16314352 -0.85553098 -0.12474394 -0.18345486  0.68545755  0.88300876]\n",
      "epoch 191\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016789272835161038 R2: 0.9119394754484725 time: 1703091120.6413498\n",
      "batch_idx: 1 loss: 0.0008125155542828652 R2: 0.9119723864336239 time: 1703091123.183483\n",
      "batch_idx: 2 loss: 0.0015232658369951323 R2: 0.911991752849515 time: 1703091125.771354\n",
      "batch_idx: 3 loss: 0.0007517760661548595 R2: 0.9119923340861915 time: 1703091128.2868145\n",
      "Training [38%] Loss: 0.0011916211852372402 time: 1703091128.2868145\n",
      "weight: [ 1.27924055  1.56417969  1.22296389  0.78880275 -0.29856456  0.2056426\n",
      "  1.16404061 -0.85709981 -0.13439628 -0.18340784  0.68552835  0.882846  ]\n",
      "epoch 192\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016755547711494868 R2: 0.9120230713470848 time: 1703091130.861148\n",
      "batch_idx: 1 loss: 0.0008118241463337993 R2: 0.9120558288189722 time: 1703091133.4500973\n",
      "batch_idx: 2 loss: 0.0015225704181562906 R2: 0.9120748439482265 time: 1703091136.0448418\n",
      "batch_idx: 3 loss: 0.0007519924666719927 R2: 0.9120748414013858 time: 1703091138.680695\n",
      "Training [38%] Loss: 0.0011904854505778923 time: 1703091138.680695\n",
      "weight: [ 1.28276351  1.56338575  1.22252712  0.78776382 -0.29765267  0.20567235\n",
      "  1.16493081 -0.8586726  -0.14403338 -0.18336123  0.68559933  0.8826878 ]\n",
      "epoch 193\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001672215052855976 R2: 0.9121054271521276 time: 1703091141.3022177\n",
      "batch_idx: 1 loss: 0.0008111154814931576 R2: 0.9121380191487122 time: 1703091143.8786032\n",
      "batch_idx: 2 loss: 0.0015219081825013961 R2: 0.9121566774908226 time: 1703091146.487807\n",
      "batch_idx: 3 loss: 0.0007522287835037193 R2: 0.9121560910559763 time: 1703091149.0434332\n",
      "Training [39%] Loss: 0.0011893668750885622 time: 1703091149.0434332\n",
      "weight: [ 1.28622132  1.56261051  1.22209577  0.78673794 -0.29674841  0.20569899\n",
      "  1.16581343 -0.86024843 -0.15364888 -0.18331504  0.6856705   0.88253423]\n",
      "epoch 194\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016689096431703697 R2: 0.9121865218427713 time: 1703091151.6645296\n",
      "batch_idx: 1 loss: 0.0008103905031400244 R2: 0.9122189371287339 time: 1703091154.1282237\n",
      "batch_idx: 2 loss: 0.0015212784836203573 R2: 0.9122372341967665 time: 1703091156.625951\n",
      "batch_idx: 3 loss: 0.0007524843416033807 R2: 0.9122360650009318 time: 1703091159.0721638\n",
      "Training [39%] Loss: 0.0011882657428835329 time: 1703091159.0721638\n",
      "weight: [ 1.28961334  1.56185359  1.22166968  0.78572421 -0.29585139  0.20572235\n",
      "  1.16668784 -0.86182644 -0.16323679 -0.18326927  0.68574184  0.88238529]\n",
      "epoch 195\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001665639897916926 R2: 0.9122663382224514 time: 1703091161.6615365\n",
      "batch_idx: 1 loss: 0.0008096501759835012 R2: 0.9122985662983748 time: 1703091164.1974313\n",
      "batch_idx: 2 loss: 0.0015206806137941678 R2: 0.9123164985707023 time: 1703091166.8250258\n",
      "batch_idx: 3 loss: 0.0007527584515557485 R2: 0.9123147489007405 time: 1703091169.350644\n",
      "Training [39%] Loss: 0.001187182284812586 time: 1703091169.350644\n",
      "weight: [ 1.29293915  1.56111458  1.22124868  0.78472174 -0.29496118  0.20574224\n",
      "  1.16755346 -0.86340578 -0.1727915  -0.18322391  0.68581332  0.88224085]\n",
      "epoch 196\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016624070169119812 R2: 0.9123448627505167 time: 1703091171.9070337\n",
      "batch_idx: 1 loss: 0.000808895479195332 R2: 0.9123768938551772 time: 1703091174.4656694\n",
      "batch_idx: 2 loss: 0.001520113813731555 R2: 0.912394458721565 time: 1703091176.9621706\n",
      "batch_idx: 3 loss: 0.0007530504131124725 R2: 0.9123921319453382 time: 1703091179.5667467\n",
      "Training [39%] Loss: 0.001186116680737835 time: 1703091179.5667467\n",
      "weight: [ 1.29619858  1.56039307  1.22083259  0.78372972 -0.29407741  0.20575849\n",
      "  1.16840976 -0.86498566 -0.18230774 -0.18317894  0.68588494  0.88210073]\n",
      "epoch 197\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001659212048216397 R2: 0.91242208535157 time: 1703091182.2517292\n",
      "batch_idx: 1 loss: 0.0008081273998971631 R2: 0.9124539104580357 time: 1703091184.9046767\n",
      "batch_idx: 2 loss: 0.0015195772819263898 R2: 0.9124711061617038 time: 1703091187.356849\n",
      "batch_idx: 3 loss: 0.0007533595185519003 R2: 0.9124682066440405 time: 1703091190.1671886\n",
      "Training [39%] Loss: 0.0011850690621479625 time: 1703091190.1671886\n",
      "weight: [ 1.29939163  1.55968865  1.22042124  0.78274737 -0.29319971  0.20577093\n",
      "  1.16925628 -0.86656534 -0.19178061 -0.18313436  0.68595666  0.88196466]\n",
      "epoch 198\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00165605589368384 R2: 0.9124979992082698 time: 1703091192.8501875\n",
      "batch_idx: 1 loss: 0.0008073469270768553 R2: 0.9125296100145114 time: 1703091195.543081\n",
      "batch_idx: 2 loss: 0.0015190701834951962 R2: 0.9125464355916458 time: 1703091198.2465746\n",
      "batch_idx: 3 loss: 0.0007536850558541399 R2: 0.91254296860707 time: 1703091200.8454516\n",
      "Training [40%] Loss: 0.001184039515027508 time: 1703091200.8454516\n",
      "weight: [ 1.30251851  1.55900088  1.22001447  0.78177398 -0.29232773  0.20577941\n",
      "  1.17009257 -0.86814411 -0.20120558 -0.18309016  0.68602846  0.88183235]\n",
      "epoch 199\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016529393155506823 R2: 0.9125726005430531 time: 1703091203.4595234\n",
      "batch_idx: 1 loss: 0.0008065550459893792 R2: 0.9126039894578006 time: 1703091206.0301297\n",
      "batch_idx: 2 loss: 0.0015185916583900735 R2: 0.9126204446758648 time: 1703091208.6633203\n",
      "batch_idx: 3 loss: 0.0007540263116824683 R2: 0.9126164163198199 time: 1703091211.225157\n",
      "Training [40%] Loss: 0.0011830280829031507 time: 1703091211.225157\n",
      "weight: [ 1.30557958  1.55832936  1.21961212  0.78080887 -0.29146113  0.20578376\n",
      "  1.17091827 -0.8697213  -0.21057843 -0.18304632  0.68610033  0.88170348]\n",
      "epoch 200\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016498629438217896 R2: 0.9126458883936609 time: 1703091213.656496\n",
      "batch_idx: 1 loss: 0.000805752733079402 R2: 0.912677048518219 time: 1703091216.3679247\n",
      "batch_idx: 2 loss: 0.001518140828916591 R2: 0.9126931338142216 time: 1703091218.8468406\n",
      "batch_idx: 3 loss: 0.0007543825741629097 R2: 0.9126885509144242 time: 1703091221.5012372\n",
      "Training [40%] Loss: 0.001182034769995173 time: 1703091221.5012372\n",
      "weight: [ 1.30857538  1.55767366  1.21921403  0.77985143 -0.29059961  0.20578384\n",
      "  1.17173306 -0.87129629 -0.2198953  -0.18300283  0.68617222  0.88157773]\n",
      "epoch 201\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016468272842221816 R2: 0.9127178643867984 time: 1703091224.020133\n",
      "batch_idx: 1 loss: 0.0008049409514455326 R2: 0.9127487894935488 time: 1703091226.6156878\n",
      "batch_idx: 2 loss: 0.001517716806517108 R2: 0.9127645059132682 time: 1703091229.1276817\n",
      "batch_idx: 3 loss: 0.0007547531354546295 R2: 0.9127593759425473 time: 1703091231.7027411\n",
      "Training [40%] Loss: 0.0011810595444098628 time: 1703091231.7027411\n",
      "weight: [ 1.31150657  1.55703337  1.21882004  0.77890108 -0.28974289  0.20577948\n",
      "  1.17253665 -0.8728685  -0.22915265 -0.18295968  0.68624412  0.88145475]\n",
      "epoch 202\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016438327265056348 R2: 0.9127885325136746 time: 1703091234.2339835\n",
      "batch_idx: 1 loss: 0.0008041206468510439 R2: 0.9128192170218972 time: 1703091236.8198402\n",
      "batch_idx: 2 loss: 0.001517318697806886 R2: 0.9128345661608313 time: 1703091239.3393643\n",
      "batch_idx: 3 loss: 0.0007551372941054057 R2: 0.9128288971526581 time: 1703091241.8361452\n",
      "Training [40%] Loss: 0.0011801023413172424 time: 1703091241.8361452\n",
      "weight: [ 1.31437394  1.55640808  1.21843002  0.77795728 -0.28889069  0.20577055\n",
      "  1.17332882 -0.87443739 -0.23834723 -0.18291686  0.68631601  0.88133425]\n",
      "epoch 203\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016408795529354095 R2: 0.9128578989104789 time: 1703091244.4104738\n",
      "batch_idx: 1 loss: 0.0008032927442729488 R2: 0.9128883378601106 time: 1703091247.1934857\n",
      "batch_idx: 2 loss: 0.0015169456098725119 R2: 0.9129033218068214 time: 1703091249.8074636\n",
      "batch_idx: 3 loss: 0.000755534357188198 R2: 0.9128971222744644 time: 1703091252.3023703\n",
      "Training [41%] Loss: 0.001179163066067267 time: 1703091252.3023703\n",
      "weight: [ 1.31717841  1.5557974   1.21804382  0.77701956 -0.28804279  0.20575691\n",
      "  1.17410937 -0.87600245 -0.2474761  -0.18287436  0.68638785  0.88121591]\n",
      "epoch 204\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001637967946778152 R2: 0.9129259716462789 time: 1703091254.7984324\n",
      "batch_idx: 1 loss: 0.0008024581449708231 R2: 0.91295616067019 time: 1703091257.3306067\n",
      "batch_idx: 2 loss: 0.0015165966548595835 R2: 0.9129707819524748 time: 1703091259.9139163\n",
      "batch_idx: 3 loss: 0.00075594364221722 R2: 0.9129640608125333 time: 1703091262.6260033\n",
      "Training [41%] Loss: 0.0011782415972064447 time: 1703091262.6260033\n",
      "weight: [ 1.31992096  1.55520095  1.21766131  0.77608746 -0.28719894  0.20573842\n",
      "  1.17487816 -0.87756322 -0.2565366  -0.18283218  0.68645964  0.88109947]\n",
      "epoch 205\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016350980006783796 R2: 0.9129927605202729 time: 1703091265.3280885\n",
      "batch_idx: 1 loss: 0.0008016177240486947 R2: 0.9130226958155196 time: 1703091267.8708572\n",
      "batch_idx: 2 loss: 0.001516270953889569 R2: 0.9130369573497825 time: 1703091270.480522\n",
      "batch_idx: 3 loss: 0.0007563644788443987 R2: 0.9130297238506119 time: 1703091273.041367\n",
      "Training [41%] Loss: 0.0011773377893652605 time: 1703091273.041367\n",
      "weight: [ 1.32260267  1.55461834  1.21728238  0.77516056 -0.28635896  0.20571493\n",
      "  1.17563508 -0.87911928 -0.26552632 -0.18279031  0.68653135  0.88098468]\n",
      "epoch 206\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016322697248059366 R2: 0.9130582768697622 time: 1703091275.539539\n",
      "batch_idx: 1 loss: 0.0008007723284776077 R2: 0.9130879551682922 time: 1703091278.182776\n",
      "batch_idx: 2 loss: 0.0015159676403544813 R2: 0.9131018602122593 time: 1703091280.6652377\n",
      "batch_idx: 3 loss: 0.0007567962103397949 R2: 0.9130941238676703 time: 1703091283.1941128\n",
      "Training [41%] Loss: 0.001176451475994455 time: 1703091283.1941128\n",
      "weight: [ 1.32522469  1.55404921  1.2169069   0.7742385  -0.28552266  0.20568632\n",
      "  1.17638006 -0.88067023 -0.27444313 -0.18274874  0.68660297  0.88087132]\n",
      "epoch 207\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016294830546927578 R2: 0.9131225333897943 time: 1703091285.770013\n",
      "batch_idx: 1 loss: 0.0007999227755426453 R2: 0.9131519519289372 time: 1703091288.346264\n",
      "batch_idx: 2 loss: 0.0015156858626432942 R2: 0.9131655040378772 time: 1703091290.9694734\n",
      "batch_idx: 3 loss: 0.0007572381948618826 R2: 0.9131572745662891 time: 1703091293.4731693\n",
      "Training [41%] Loss: 0.0011755824719351447 time: 1703091293.4731693\n",
      "weight: [ 1.3277882   1.55349321  1.21653477  0.77332093 -0.28468987  0.20565246\n",
      "  1.17711304 -0.88221572 -0.28328511 -0.18270747  0.68667447  0.8807592 ]\n",
      "epoch 208\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016267378586963682 R2: 0.9131855439649932 time: 1703091296.0225694\n",
      "batch_idx: 1 loss: 0.000799069851676183 R2: 0.9132147004581002 time: 1703091298.5827334\n",
      "batch_idx: 2 loss: 0.0015154247863564604 R2: 0.913227903444516 time: 1703091301.145653\n",
      "batch_idx: 3 loss: 0.0007576898065260829 R2: 0.9132191907136269 time: 1703091303.7446508\n",
      "Training [42%] Loss: 0.0011747305758137735 time: 1703091303.7446508\n",
      "weight: [ 1.33029446  1.55295     1.21616589  0.77240753 -0.28386044  0.20561321\n",
      "  1.17783404 -0.8837554  -0.29205057 -0.18266651  0.68674585  0.88064818]\n",
      "epoch 209\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016240339450468446 R2: 0.9132473235138294 time: 1703091306.2397144\n",
      "batch_idx: 1 loss: 0.0007982143116385742 R2: 0.9132762161212975 time: 1703091308.7842195\n",
      "batch_idx: 2 loss: 0.0015151835960648034 R2: 0.9132890740180398 time: 1703091311.38453\n",
      "batch_idx: 3 loss: 0.0007581504362817891 R2: 0.9132798879949322 time: 1703091313.8816442\n",
      "Training [42%] Loss: 0.0011738955722580028 time: 1703091313.8816442\n",
      "weight: [ 1.33274474  1.55241924  1.21580016  0.77149803 -0.28303423  0.20556845\n",
      "  1.17854305 -0.88528898 -0.30073804 -0.18262584  0.68681708  0.88053811]\n",
      "epoch 210\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001621371068449707 R2: 0.9133078878452213 time: 1703091316.3773909\n",
      "batch_idx: 1 loss: 0.0007973568780077815 R2: 0.9133365151460996 time: 1703091318.9379165\n",
      "batch_idx: 2 loss: 0.0015149614966676913 R2: 0.9133490321728305 time: 1703091321.5258896\n",
      "batch_idx: 3 loss: 0.000758619492609705 R2: 0.9133393828793986 time: 1703091324.0664012\n",
      "Training [42%] Loss: 0.0011730772339337212 time: 1703091324.0664012\n",
      "weight: [ 1.33514034  1.55190062  1.2154375   0.77059215 -0.28221114  0.20551804\n",
      "  1.17924013 -0.88681619 -0.30934622 -0.18258548  0.68688817  0.8804289 ]\n",
      "epoch 211\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016187489362312541 R2: 0.9133672535272218 time: 1703091326.6568046\n",
      "batch_idx: 1 loss: 0.0007964982409409816 R2: 0.9133956144916328 time: 1703091329.275858\n",
      "batch_idx: 2 loss: 0.0015147577144023095 R2: 0.9134077950244116 time: 1703091331.8640916\n",
      "batch_idx: 3 loss: 0.0007590964020524644 R2: 0.9133976924978514 time: 1703091334.4404721\n",
      "Training [42%] Loss: 0.0011722753234067523 time: 1703091334.4404721\n",
      "weight: [ 1.33748257  1.55139384  1.21507783  0.76968966 -0.28139105  0.20546188\n",
      "  1.17992535 -0.88833678 -0.31787403 -0.18254542  0.68695909  0.88032047]\n",
      "epoch 212\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016161672140237668 R2: 0.9134254377673526 time: 1703091337.0987573\n",
      "batch_idx: 1 loss: 0.0007956390581727805 R2: 0.9134535317297863 time: 1703091339.5974\n",
      "batch_idx: 2 loss: 0.0015145714975524876 R2: 0.9134653802736923 time: 1703091342.3157878\n",
      "batch_idx: 3 loss: 0.0007595806095922224 R2: 0.9134548345317972 time: 1703091344.9375398\n",
      "Training [42%] Loss: 0.0011714895948353144 time: 1703091344.9375398\n",
      "weight: [ 1.33977275  1.55089858  1.21472108  0.76879035 -0.28057387  0.20539982\n",
      "  1.18059878 -0.88985051 -0.32632052 -0.18250566  0.68702983  0.88021274]\n",
      "epoch 213\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001613625530996914 R2: 0.9134824583040361 time: 1703091347.550965\n",
      "batch_idx: 1 loss: 0.0007947799552170499 R2: 0.9135102849376769 time: 1703091350.0846126\n",
      "batch_idx: 2 loss: 0.001514402116901375 R2: 0.9135218061021956 time: 1703091352.7191322\n",
      "batch_idx: 3 loss: 0.0007600715788892759 R2: 0.9135108271131381 time: 1703091355.2779636\n",
      "Training [43%] Loss: 0.0011707197955011539 time: 1703091355.2779636\n",
      "weight: [ 1.34201222  1.55041457  1.21436718  0.76789402 -0.2797595   0.20533175\n",
      "  1.18126055 -0.8913572  -0.33468492 -0.18246622  0.6871004   0.88010567]\n",
      "epoch 214\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016111234846484745 R2: 0.9135383333084865 time: 1703091357.7905357\n",
      "batch_idx: 1 loss: 0.0007939215257419831 R2: 0.9135658926005936 time: 1703091360.3797934\n",
      "batch_idx: 2 loss: 0.0015142488659679117 R2: 0.9135770910776146 time: 1703091362.841855\n",
      "batch_idx: 3 loss: 0.0007605687923956931 R2: 0.913565688733892 time: 1703091365.426838\n",
      "Training [43%] Loss: 0.0011699656671885154 time: 1703091365.426838\n",
      "weight: [ 1.34420228  1.54994153  1.21401607  0.7670005  -0.27894789  0.20525754\n",
      "  1.18191077 -0.89285664 -0.3429666  -0.18242709  0.68717077  0.87999923]\n",
      "epoch 215\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001608660645172602 R2: 0.9135930812963977 time: 1703091367.925276\n",
      "batch_idx: 1 loss: 0.000793064332090362 R2: 0.9136203735248157 time: 1703091370.5112977\n",
      "batch_idx: 2 loss: 0.0015141110610629462 R2: 0.9136312540690218 time: 1703091373.0767643\n",
      "batch_idx: 3 loss: 0.000761071751357767 R2: 0.9136194381651895 time: 1703091375.6776667\n",
      "Training [43%] Loss: 0.0011692269474209195 time: 1703091375.6776667\n",
      "weight: [ 1.34634426  1.54947919  1.21366769  0.76610962 -0.27813895  0.20517707\n",
      "  1.18254958 -0.89434868 -0.35116506 -0.18238827  0.68724093  0.87989339]\n",
      "epoch 216\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016062365594274053 R2: 0.9136467210486943 time: 1703091378.3336918\n",
      "batch_idx: 1 loss: 0.0007922089059198732 R2: 0.9136737467595056 time: 1703091380.9553704\n",
      "batch_idx: 2 loss: 0.0015139880411964525 R2: 0.9136843141709313 time: 1703091383.5362773\n",
      "batch_idx: 3 loss: 0.000761579975720636 R2: 0.913672094384831 time: 1703091386.1612484\n",
      "Training [43%] Loss: 0.0011685033705660917 time: 1703091386.1612484\n",
      "weight: [ 1.34843946  1.54902729  1.213322    0.76522123 -0.27733263  0.20509022\n",
      "  1.18317714 -0.89583318 -0.35927994 -0.18234978  0.68731089  0.87978814]\n",
      "epoch 217\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001603850754525635 R2: 0.9136992715406992 time: 1703091388.8623455\n",
      "batch_idx: 1 loss: 0.0007913557489409226 R2: 0.9137260315270114 time: 1703091391.4642355\n",
      "batch_idx: 2 loss: 0.0015138791678633184 R2: 0.9137362906356256 time: 1703091394.091615\n",
      "batch_idx: 3 loss: 0.0007620930039476416 R2: 0.9137236765127186 time: 1703091396.7551281\n",
      "Training [43%] Loss: 0.0011677946688193796 time: 1703091396.7551281\n",
      "weight: [ 1.35048915  1.54858558  1.21297894  0.7643352  -0.27652888  0.20499687\n",
      "  1.18379361 -0.89730999 -0.36731097 -0.18231161  0.68738063  0.87968346]\n",
      "epoch 218\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0016015027410739 R2: 0.9137507518789455 time: 1703091399.32987\n",
      "batch_idx: 1 loss: 0.0007905053337318784 R2: 0.913777247160845 time: 1703091402.0255933\n",
      "batch_idx: 2 loss: 0.001513783824731549 R2: 0.9137872028129129 time: 1703091404.5647745\n",
      "batch_idx: 3 loss: 0.0007626103927664817 R2: 0.9137742037534353 time: 1703091407.5905027\n",
      "Training [44%] Loss: 0.0011671005730759523 time: 1703091407.5905027\n",
      "weight: [ 1.35249459  1.54815381  1.21263848  0.76345142 -0.27572764  0.2048969\n",
      "  1.18439916 -0.898779   -0.37525801 -0.18227377  0.68745014  0.87957934]\n",
      "epoch 219\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015991920160860185 R2: 0.9138011812450626 time: 1703091410.1652398\n",
      "batch_idx: 1 loss: 0.0007896581046142072 R2: 0.9138274130506628 time: 1703091412.732562\n",
      "batch_idx: 2 loss: 0.0015137014172530148 R2: 0.9138370700967696 time: 1703091415.2336292\n",
      "batch_idx: 3 loss: 0.0007631317168532585 R2: 0.9138236953453583 time: 1703091417.870972\n",
      "Training [44%] Loss: 0.0011664208137016248 time: 1703091417.870972\n",
      "weight: [ 1.35445704  1.54773176  1.21230058  0.76256977 -0.27492889  0.20479018\n",
      "  1.18499397 -0.90024011 -0.383121   -0.18223627  0.68751942  0.87947579]\n",
      "epoch 220\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015969180655958776 R2: 0.9138505788460082 time: 1703091420.3434255\n",
      "batch_idx: 1 loss: 0.0007888144785722816 R2: 0.9138765485936124 time: 1703091422.9560013\n",
      "batch_idx: 2 loss: 0.0015136313722139256 R2: 0.9138859118781314 time: 1703091425.5728703\n",
      "batch_idx: 3 loss: 0.0007636565684647616 R2: 0.9138721705156824 time: 1703091428.0405443\n",
      "Training [44%] Loss: 0.0011657551212117115 time: 1703091428.0405443\n",
      "weight: [ 1.35637769  1.5473192   1.21196521  0.76169014 -0.27413257  0.2046766\n",
      "  1.18557825 -0.90169322 -0.39089998 -0.18219911  0.68758846  0.87937279]\n",
      "epoch 221\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015946803669946593 R2: 0.9138989638701089 time: 1703091430.6178186\n",
      "batch_idx: 1 loss: 0.0007879748462046844 R2: 0.9139246731514292 time: 1703091433.068198\n",
      "batch_idx: 2 loss: 0.001513573137239313 R2: 0.9139337475033356 time: 1703091435.6450489\n",
      "batch_idx: 3 loss: 0.0007641845570284123 R2: 0.9139196484407817 time: 1703091438.209215\n",
      "Training [44%] Loss: 0.0011651032268667674 time: 1703091438.209215\n",
      "weight: [ 1.35825774  1.5469159   1.21163234  0.76081246 -0.27333865  0.20455604\n",
      "  1.18615217 -0.90313827 -0.39859507 -0.1821623   0.68765724  0.87927035]\n",
      "epoch 222\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015924783911162217 R2: 0.9139463554483264 time: 1703091440.8587155\n",
      "batch_idx: 1 loss: 0.0007871395726958228 R2: 0.9139718060127331 time: 1703091443.4396532\n",
      "batch_idx: 2 loss: 0.0015135261802632803 R2: 0.9139805962375851 time: 1703091445.959277\n",
      "batch_idx: 3 loss: 0.0007647153086986267 R2: 0.9139661482113771 time: 1703091448.4580586\n",
      "Training [44%] Loss: 0.0011644648631934879 time: 1703091448.4580586\n",
      "weight: [ 1.36009835  1.54652165  1.21130193  0.75993663 -0.27254709  0.20442838\n",
      "  1.18671595 -0.90457517 -0.40620644 -0.18212583  0.68772577  0.87916846]\n",
      "epoch 223\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015903116040929962 R2: 0.913992772620247 time: 1703091450.949928\n",
      "batch_idx: 1 loss: 0.0007863089987985483 R2: 0.9140179663599797 time: 1703091453.5231473\n",
      "batch_idx: 2 loss: 0.0015134899889747363 R2: 0.9140264772329803 time: 1703091456.0508695\n",
      "batch_idx: 3 loss: 0.0007652484658872058 R2: 0.9140116888020264 time: 1703091458.5976515\n",
      "Training [45%] Loss: 0.0011638397644383716 time: 1703091458.5976515\n",
      "weight: [ 1.36190065  1.54613624  1.21097397  0.75906258 -0.27175788  0.20429351\n",
      "  1.18726979 -0.90600387 -0.41373437 -0.18208972  0.68779404  0.87906713]\n",
      "epoch 224\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015881794690037379 R2: 0.9140382343042809 time: 1703091461.2108274\n",
      "batch_idx: 1 loss: 0.000785483441819701 R2: 0.9140631732406428 time: 1703091463.7867613\n",
      "batch_idx: 2 loss: 0.0015134640702464564 R2: 0.9140714095006137 time: 1703091466.3142605\n",
      "batch_idx: 3 loss: 0.0007657836867749153 R2: 0.9140562890445034 time: 1703091468.8699994\n",
      "Training [45%] Loss: 0.0011632276669612026 time: 1703091468.8699994\n",
      "weight: [ 1.36366575  1.54575947  1.21064844  0.75819024 -0.27097098  0.2041513\n",
      "  1.1878139  -0.90742431 -0.42117917 -0.18205397  0.68786204  0.87896634]\n",
      "epoch 225\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015860814473327178 R2: 0.9140827592716929 time: 1703091471.4429502\n",
      "batch_idx: 1 loss: 0.000784663196602196 R2: 0.914107445542099 time: 1703091473.940181\n",
      "batch_idx: 2 loss: 0.0015134479495538318 R2: 0.9141154118863299 time: 1703091476.4999506\n",
      "batch_idx: 3 loss: 0.0007663206448102571 R2: 0.9140999676046219 time: 1703091479.0169795\n",
      "Training [45%] Loss: 0.0011626283095747508 time: 1703091479.0169795\n",
      "weight: [ 1.36539471  1.54539115  1.21032532  0.75731954 -0.27018636  0.20400165\n",
      "  1.18834849 -0.90883647 -0.42854121 -0.18201858  0.68792977  0.87886611]\n",
      "epoch 226\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001584017000258497 R2: 0.9141263661240151 time: 1703091481.600625\n",
      "batch_idx: 1 loss: 0.0007838485364981271 R2: 0.9141508019699233 time: 1703091484.1451743\n",
      "batch_idx: 2 loss: 0.0015134411703884468 R2: 0.9141585030497543 time: 1703091486.7315547\n",
      "batch_idx: 3 loss: 0.0007668590282009764 R2: 0.9141427429621981 time: 1703091489.2595556\n",
      "Training [45%] Loss: 0.0011620414338365118 time: 1703091489.2595556\n",
      "weight: [ 1.36708858  1.54503108  1.2100046   0.75645043 -0.269404    0.20384444\n",
      "  1.18887377 -0.9102403  -0.43582092 -0.18198356  0.68799721  0.87876643]\n",
      "epoch 227\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015819855897892296 R2: 0.914169073273514 time: 1703091491.851132\n",
      "batch_idx: 1 loss: 0.0007830397143285522 R2: 0.9141932610291607 time: 1703091494.396995\n",
      "batch_idx: 2 loss: 0.0015134432936705863 R2: 0.9142007014462147 time: 1703091496.9469993\n",
      "batch_idx: 3 loss: 0.0007673985394028357 R2: 0.914184633393751 time: 1703091499.5621016\n",
      "Training [45%] Loss: 0.001161466784297801 time: 1703091499.5621016\n",
      "weight: [ 1.36874837  1.54467908  1.20968625  0.75558286 -0.26862388  0.20367956\n",
      "  1.18938996 -0.91163577 -0.44301877 -0.18194891  0.68806437  0.87866729]\n",
      "epoch 228\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015799866797597587 R2: 0.9142108989263766 time: 1703091502.106305\n",
      "batch_idx: 1 loss: 0.0007822369633262145 R2: 0.9142348410082741 time: 1703091504.6993456\n",
      "batch_idx: 2 loss: 0.0015134538971641471 R2: 0.9142420253113009 time: 1703091507.224355\n",
      "batch_idx: 3 loss: 0.0007679388946097107 R2: 0.9142256569577066 time: 1703091509.9113178\n",
      "Training [46%] Loss: 0.001160904108714958 time: 1703091509.9113178\n",
      "weight: [ 1.37037507  1.54433497  1.20937028  0.75471677 -0.26784596  0.20350689\n",
      "  1.18989727 -0.91302286 -0.45013527 -0.18191463  0.68813124  0.87856871]\n",
      "epoch 229\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015780197367045543 R2: 0.9142518610683036 time: 1703091512.4416673\n",
      "batch_idx: 1 loss: 0.0007814404980583673 R2: 0.9142755599654736 time: 1703091515.0018334\n",
      "batch_idx: 2 loss: 0.0015134725748966133 R2: 0.9142824926476957 time: 1703091517.5741723\n",
      "batch_idx: 3 loss: 0.0007684798232482591 R2: 0.9142658314817789 time: 1703091520.0807245\n",
      "Training [46%] Loss: 0.0011603531582269485 time: 1703091520.0807245\n",
      "weight: [ 1.37196962  1.54399857  1.20905666  0.75385212 -0.26707023  0.20332633\n",
      "  1.19039592 -0.91440157 -0.45717097 -0.18188073  0.68819781  0.87847067]\n",
      "epoch 230\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015760842306193432 R2: 0.9142919774522891 time: 1703091522.6595137\n",
      "batch_idx: 1 loss: 0.0007806505153271637 R2: 0.9143154357171724 time: 1703091525.2487383\n",
      "batch_idx: 2 loss: 0.001513498936586542 R2: 0.9143221212141046 time: 1703091527.8299868\n",
      "batch_idx: 3 loss: 0.0007690210674798487 R2: 0.9143051745523236 time: 1703091530.3889985\n",
      "Training [46%] Loss: 0.0011598136875032245 time: 1703091530.3889985\n",
      "weight: [ 1.37353295  1.54366971  1.2087454   0.75298887 -0.26629666  0.20313777\n",
      "  1.19088612 -0.91577187 -0.46412644 -0.18184721  0.68826408  0.87837318]\n",
      "epoch 231\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001574179635623059 R2: 0.9143312655883007 time: 1703091532.978403\n",
      "batch_idx: 1 loss: 0.0007798671950457697 R2: 0.9143544858283279 time: 1703091535.5358512\n",
      "batch_idx: 2 loss: 0.0015135326070804009 R2: 0.9143609285159837 time: 1703091538.0629737\n",
      "batch_idx: 3 loss: 0.0007695623817119326 R2: 0.9143437035054249 time: 1703091540.6817448\n",
      "Training [46%] Loss: 0.0011592854548652905 time: 1703091540.6817448\n",
      "weight: [ 1.37506596  1.54334823  1.20843648  0.75212698 -0.26552522  0.20294111\n",
      "  1.19136808 -0.91713377 -0.47100229 -0.18181407  0.68833005  0.87827624]\n",
      "epoch 232\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015723054305305853 R2: 0.9143697427346696 time: 1703091543.2011876\n",
      "batch_idx: 1 loss: 0.0007790907010885475 R2: 0.9143927276044416 time: 1703091545.77812\n",
      "batch_idx: 2 loss: 0.001513573225800475 R2: 0.9143989317979047 time: 1703091548.356162\n",
      "batch_idx: 3 loss: 0.0007701035321204984 R2: 0.9143814354195653 time: 1703091550.992551\n",
      "Training [46%] Loss: 0.0011587682223850265 time: 1703091550.992551\n",
      "weight: [ 1.37656951  1.54303395  1.20812991  0.75126642 -0.2647559   0.20273624\n",
      "  1.19184203 -0.91848726 -0.47779916 -0.18178131  0.6883957   0.87817985]\n",
      "epoch 233\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00157046109934601 R2: 0.9144074258910282 time: 1703091553.5417392\n",
      "batch_idx: 1 loss: 0.0007783211821141403 R2: 0.9144301780850494 time: 1703091556.124038\n",
      "batch_idx: 2 loss: 0.0015136204462053012 R2: 0.9144361480373687 time: 1703091558.6347938\n",
      "batch_idx: 3 loss: 0.0007706442961847926 R2: 0.9144183871096121 time: 1703091561.2249775\n",
      "Training [47%] Loss: 0.001158261755962561 time: 1703091561.2249775\n",
      "weight: [ 1.37804443  1.54272673  1.20782567  0.75040715 -0.26398866  0.20252307\n",
      "  1.19230815 -0.91983236 -0.48451771 -0.18174894  0.68846105  0.87808401]\n",
      "epoch 234\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015686461316848292 R2: 0.9144443317925603 time: 1703091563.779983\n",
      "batch_idx: 1 loss: 0.0007775587723604292 R2: 0.9144668540385428 time: 1703091566.3284717\n",
      "batch_idx: 2 loss: 0.0015136739352636997 R2: 0.914472593939885 time: 1703091568.9337485\n",
      "batch_idx: 3 loss: 0.0007711844622352631 R2: 0.9144545751220805 time: 1703091571.5063744\n",
      "Training [47%] Loss: 0.0011577658253860553 time: 1703091571.5063744\n",
      "weight: [ 1.37949154  1.54242641  1.20752377  0.74954915 -0.26322349  0.2023015\n",
      "  1.19276668 -0.92116906 -0.49115862 -0.18171696  0.68852608  0.87798872]\n",
      "epoch 235\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015668600231329773 R2: 0.9144804769054675 time: 1703091574.0676405\n",
      "batch_idx: 1 loss: 0.0007768035924108106 R2: 0.9145027719581357 time: 1703091576.6048963\n",
      "batch_idx: 2 loss: 0.0015137333729436009 R2: 0.9145082859351763 time: 1703091579.1880896\n",
      "batch_idx: 3 loss: 0.0007717238290152394 R2: 0.9144900157314607 time: 1703091581.7500124\n",
      "Training [47%] Loss: 0.0011572802043756571 time: 1703091581.7500124\n",
      "weight: [ 1.38091162  1.54213283  1.2072242   0.74869239 -0.26246035  0.20207143\n",
      "  1.1932178  -0.92249738 -0.49772257 -0.18168536  0.6885908   0.87789399]\n",
      "epoch 236\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015651022755496624 R2: 0.914515877423511 time: 1703091584.215856\n",
      "batch_idx: 1 loss: 0.0007760557499312029 R2: 0.9145379480588692 time: 1703091586.8959455\n",
      "batch_idx: 2 loss: 0.001513798451716217 R2: 0.9145432401744152 time: 1703091589.474854\n",
      "batch_idx: 3 loss: 0.0007722622052566452 R2: 0.9145247249374886 time: 1703091592.0395865\n",
      "Training [47%] Loss: 0.0011568046706134317 time: 1703091592.0395865\n",
      "weight: [ 1.38230543  1.54184585  1.20692696  0.74783684 -0.26169922  0.20183278\n",
      "  1.19366173 -0.92381733 -0.50421028 -0.18165416  0.6886552   0.87779981]\n",
      "epoch 237\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015633723973203205 R2: 0.9145505492654624 time: 1703091594.596425\n",
      "batch_idx: 1 loss: 0.000775315340377639 R2: 0.9145723982755303 time: 1703091597.1854138\n",
      "batch_idx: 2 loss: 0.0015138688760764044 R2: 0.9145774725283072 time: 1703091599.721921\n",
      "batch_idx: 3 loss: 0.0007727994092699212 R2: 0.9145587184632987 time: 1703091602.2964568\n",
      "Training [47%] Loss: 0.0011563390057610712 time: 1703091602.2964568\n",
      "weight: [ 1.3836737   1.54156533  1.20663206  0.74698249 -0.26094008  0.20158545\n",
      "  1.19409866 -0.92512894 -0.51062246 -0.18162335  0.68871927  0.87770618]\n",
      "epoch 238\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015616699035652416 R2: 0.9145845080734321 time: 1703091604.817107\n",
      "batch_idx: 1 loss: 0.0007745824476744583 R2: 0.9146061382613849 time: 1703091607.3372946\n",
      "batch_idx: 2 loss: 0.0015139443620794135 R2: 0.9146109985859866 time: 1703091609.9300258\n",
      "batch_idx: 3 loss: 0.0007733352685481681 R2: 0.9145920117543097 time: 1703091612.4489667\n",
      "Training [48%] Loss: 0.0011558829954668205 time: 1703091612.4489667\n",
      "weight: [ 1.38501714  1.54129113  1.20633949  0.74612931 -0.26018288  0.20132937\n",
      "  1.1945288  -0.92643222 -0.51695986 -0.18159293  0.68878302  0.8776131 ]\n",
      "epoch 239\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015599943163089316 R2: 0.9146177692118951 time: 1703091614.9602773\n",
      "batch_idx: 1 loss: 0.0007738571448632581 R2: 0.9146391833876064 time: 1703091617.4837856\n",
      "batch_idx: 2 loss: 0.001514024636894397 R2: 0.9146438336546027 time: 1703091620.1035695\n",
      "batch_idx: 3 loss: 0.0007738696193853114 R2: 0.9146246199777803 time: 1703091622.6164596\n",
      "Training [48%] Loss: 0.0011554364293629743 time: 1703091622.6164596\n",
      "weight: [ 1.38633643  1.5410231   1.20604925  0.74527728 -0.25942761  0.20106445\n",
      "  1.19495233 -0.92772721 -0.52322321 -0.18156291  0.68884645  0.87752058]\n",
      "epoch 240\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015583451646147266 R2: 0.9146503477674 time: 1703091625.2688072\n",
      "batch_idx: 1 loss: 0.0007731394947229086 R2: 0.9146715487433476 time: 1703091627.7469046\n",
      "batch_idx: 2 loss: 0.0015141094383745867 R2: 0.9146759927594902 time: 1703091630.3122828\n",
      "batch_idx: 3 loss: 0.0007744023065081658 R2: 0.9146565580229551 time: 1703091632.8612132\n",
      "Training [48%] Loss: 0.0011549991010550969 time: 1703091632.8612132\n",
      "weight: [ 1.38763224  1.54076113  1.20576134  0.74442639 -0.25867424  0.20079063\n",
      "  1.19536946 -0.92901392 -0.52941327 -0.18153328  0.68890955  0.87742862]\n",
      "epoch 241\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015567219846886276 R2: 0.914682258548846 time: 1703091635.3676546\n",
      "batch_idx: 1 loss: 0.0007724295503612939 R2: 0.9147032491363645 time: 1703091637.9369838\n",
      "batch_idx: 2 loss: 0.0015141985146440906 R2: 0.9147074906449101 time: 1703091640.4741096\n",
      "batch_idx: 3 loss: 0.0007749331827221538 R2: 0.9146878405017421 time: 1703091643.048007\n",
      "Training [48%] Loss: 0.0011545708081040415 time: 1703091643.048007\n",
      "weight: [ 1.38890519  1.54050507  1.20547578  0.74357662 -0.25792272  0.20050783\n",
      "  1.19578036 -0.93029238 -0.53553078 -0.18150404  0.68897232  0.8773372 ]\n",
      "epoch 242\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001555124319955891 R2: 0.91471351608827 time: 1703091645.6833658\n",
      "batch_idx: 1 loss: 0.0007717273557792983 R2: 0.9147342990941152 time: 1703091648.380688\n",
      "batch_idx: 2 loss: 0.0015142916237010405 R2: 0.9147383417752494 time: 1703091650.9395702\n",
      "batch_idx: 3 loss: 0.0007754621085703479 R2: 0.9147184817498297 time: 1703091653.482778\n",
      "Training [48%] Loss: 0.0011541513520016444 time: 1703091653.482778\n",
      "weight: [ 1.39015592  1.5402548   1.20519255  0.74272795 -0.25717305  0.20021598\n",
      "  1.19618523 -0.93156263 -0.5415765  -0.1814752   0.68903476  0.87724634]\n",
      "epoch 243\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015535517211136202 R2: 0.9147441346420827 time: 1703091656.072438\n",
      "batch_idx: 1 loss: 0.000771032946407953 R2: 0.9147647128653122 time: 1703091658.6742523\n",
      "batch_idx: 2 loss: 0.0015143885330366328 R2: 0.9147685603366394 time: 1703091661.2943363\n",
      "batch_idx: 3 loss: 0.0007759889520056491 R2: 0.91474849582822 time: 1703091663.7983778\n",
      "Training [49%] Loss: 0.0011537405381409638 time: 1703091663.7983778\n",
      "weight: [ 1.39138501  1.54001019  1.20491167  0.74188038 -0.25642517  0.19991503\n",
      "  1.19658425 -0.9328247  -0.5475512  -0.18144675  0.68909687  0.87715604]\n",
      "epoch 244\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015520037461620134 R2: 0.9147741281927028 time: 1703091666.4062612\n",
      "batch_idx: 1 loss: 0.0007703463496194525 R2: 0.9147945044218299 time: 1703091669.0017197\n",
      "batch_idx: 2 loss: 0.0015144890192696793 R2: 0.9147981602389249 time: 1703091671.5762012\n",
      "batch_idx: 3 loss: 0.0007765135880756417 R2: 0.9147778965251142 time: 1703091674.210595\n",
      "Training [49%] Loss: 0.0011533381757816968 time: 1703091674.210595\n",
      "weight: [ 1.39259304  1.53977114  1.20463313  0.7410339  -0.25567906  0.19960493\n",
      "  1.19697759 -0.93407862 -0.55345564 -0.18141869  0.68915866  0.87706628]\n",
      "epoch 245\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015504799604169298 R2: 0.9148035104505394 time: 1703091676.6998243\n",
      "batch_idx: 1 loss: 0.0007696675852131025 R2: 0.9148236874609431 time: 1703091679.4035172\n",
      "batch_idx: 2 loss: 0.0015145928677960355 R2: 0.9148271551179901 time: 1703091682.0125172\n",
      "batch_idx: 3 loss: 0.0007770358986199648 R2: 0.914806697358118 time: 1703091684.601354\n",
      "Training [49%] Loss: 0.0011529440780115082 time: 1703091684.601354\n",
      "weight: [ 1.39378056  1.53953751  1.20435694  0.74018848 -0.25493469  0.19928563\n",
      "  1.19736544 -0.93532443 -0.55929059 -0.18139103  0.68922011  0.87697708]\n",
      "epoch 246\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015489799365058475 R2: 0.9148322948562824 time: 1703091687.101342\n",
      "batch_idx: 1 loss: 0.0007689966658771368 R2: 0.9148522754078657 time: 1703091689.6583252\n",
      "batch_idx: 2 loss: 0.001514699872452432 R2: 0.9148555583383183 time: 1703091692.1366026\n",
      "batch_idx: 3 loss: 0.0007775557719797031 R2: 0.9148349115767097 time: 1703091694.7593987\n",
      "Training [49%] Loss: 0.0011525580617037798 time: 1703091694.7593987\n",
      "weight: [ 1.39494812  1.53930919  1.20408309  0.73934413 -0.25419201  0.19895707\n",
      "  1.19774796 -0.93656217 -0.56505681 -0.18136376  0.68928123  0.87688842]\n",
      "epoch 247\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015475032543492747 R2: 0.9148604945834519 time: 1703091697.3467398\n",
      "batch_idx: 1 loss: 0.000768333597627297 R2: 0.9148802814185315 time: 1703091699.8015199\n",
      "batch_idx: 2 loss: 0.0015148098351940224 R2: 0.9148833829958332 time: 1703091702.5266337\n",
      "batch_idx: 3 loss: 0.0007780731027185779 R2: 0.914862552164942 time: 1703091705.107747\n",
      "Training [49%] Loss: 0.001152179947472293 time: 1703091705.107747\n",
      "weight: [ 1.39609624  1.53908607  1.20381161  0.73850084 -0.25345101  0.19861924\n",
      "  1.19812532 -0.93779188 -0.57075506 -0.18133687  0.68934203  0.87680031]\n",
      "epoch 248\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015460495011293345 R2: 0.9148881225411938 time: 1703091707.6845372\n",
      "batch_idx: 1 loss: 0.0007676783802233097 R2: 0.9149077183825922 time: 1703091710.280893\n",
      "batch_idx: 2 loss: 0.0015149225657850834 R2: 0.9149106419209178 time: 1703091712.923608\n",
      "batch_idx: 3 loss: 0.0007785877913555001 R2: 0.9148896318443734 time: 1703091715.5223856\n",
      "Training [50%] Loss: 0.001151809559623307 time: 1703091715.5223856\n",
      "weight: [ 1.3972254   1.53886805  1.20354247  0.7376586  -0.25271163  0.1982721\n",
      "  1.19849768 -0.93901359 -0.5763861  -0.18131038  0.68940249  0.87671275]\n",
      "epoch 249\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015446182712470563 R2: 0.914915191377253 time: 1703091718.1446598\n",
      "batch_idx: 1 loss: 0.0007670310075641085 R2: 0.914934598926607 time: 1703091720.6296978\n",
      "batch_idx: 2 loss: 0.0015150378815023619 R2: 0.9149373476816434 time: 1703091723.112657\n",
      "batch_idx: 3 loss: 0.0007790997441081242 R2: 0.9149161630771528 time: 1703091725.6771846\n",
      "Training [50%] Loss: 0.0011514467261054128 time: 1703091725.6771846\n",
      "weight: [ 1.39833611  1.53865501  1.2032757   0.7368174  -0.25197384  0.19791562\n",
      "  1.19886522 -0.94022736 -0.5819507  -0.18128427  0.68946263  0.87662572]\n",
      "epoch 250\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001543209166269815 R2: 0.9149417134811569 time: 1703091728.2514787\n",
      "batch_idx: 1 loss: 0.0007663914680628499 R2: 0.9149609354173988 time: 1703091730.842588\n",
      "batch_idx: 2 loss: 0.0015151556068504087 R2: 0.914963512587137 time: 1703091733.317092\n",
      "batch_idx: 3 loss: 0.0007796088726470205 R2: 0.9149421580692862 time: 1703091735.900164\n",
      "Training [50%] Loss: 0.0011510912784575235 time: 1703091735.900164\n",
      "weight: [ 1.39942882  1.53844686  1.20301129  0.73597725 -0.25123762  0.19754979\n",
      "  1.19922808 -0.94143322 -0.58744961 -0.18125856  0.68952243  0.87653924]\n",
      "epoch 251\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015418217948702114 R2: 0.9149677009875237 time: 1703091738.3525038\n",
      "batch_idx: 1 loss: 0.0007657597450025372 R2: 0.9149867399655276 time: 1703091741.026247\n",
      "batch_idx: 2 loss: 0.001515275573288472 R2: 0.9149891486910915 time: 1703091743.7133272\n",
      "batch_idx: 3 loss: 0.0007801150938601079 R2: 0.9149676287740073 time: 1703091746.3636544\n",
      "Training [50%] Loss: 0.001150743051755332 time: 1703091746.3636544\n",
      "weight: [ 1.400504    1.53824348  1.20274925  0.73513813 -0.25050291  0.19717461\n",
      "  1.19958642 -0.94263122 -0.59288357 -0.18123322  0.68958191  0.87645329]\n",
      "epoch 252\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001540455772757336 R2: 0.9149931657794983 time: 1703091748.9690516\n",
      "batch_idx: 1 loss: 0.0007651358168732558 R2: 0.9150120244289027 time: 1703091751.5516229\n",
      "batch_idx: 2 loss: 0.0015153976189684463 R2: 0.9150142677953708 time: 1703091754.510334\n",
      "batch_idx: 3 loss: 0.0007806183296268697 R2: 0.9149925868952792 time: 1703091757.1062758\n",
      "Training [50%] Loss: 0.001150401884556477 time: 1703091757.1062758\n",
      "weight: [ 1.40156207  1.53804478  1.20248957  0.73430005 -0.24976969  0.19679006\n",
      "  1.19994039 -0.94382141 -0.59825335 -0.18120827  0.68964106  0.87636788]\n",
      "epoch 253\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015391107226016799 R2: 0.9150181194923158 time: 1703091759.9037359\n",
      "batch_idx: 1 loss: 0.0007645196576917543 R2: 0.9150368004164827 time: 1703091762.5984747\n",
      "batch_idx: 2 loss: 0.0015155215884833637 R2: 0.9150388814537381 time: 1703091765.3153856\n",
      "batch_idx: 3 loss: 0.0007811185066020472 R2: 0.915017043891391 time: 1703091767.9155204\n",
      "Training [51%] Loss: 0.0011500676188447112 time: 1703091767.9155204\n",
      "weight: [ 1.40260346  1.53785067  1.20223227  0.733463   -0.24903791  0.19639617\n",
      "  1.20029015 -0.94500382 -0.60355968 -0.1811837   0.68969989  0.87628301]\n",
      "epoch 254\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015377862739543715 R2: 0.9150425735169361 time: 1703091770.5992754\n",
      "batch_idx: 1 loss: 0.000763911237304279 R2: 0.9150610792920671 time: 1703091773.2853038\n",
      "batch_idx: 2 loss: 0.0015156473326260619 R2: 0.9150630009756305 time: 1703091775.9536295\n",
      "batch_idx: 3 loss: 0.00078161555600836 R2: 0.9150410109786314 time: 1703091778.6095881\n",
      "Training [51%] Loss: 0.0011497400999732682 time: 1703091778.6095881\n",
      "weight: [ 1.40362858  1.53766106  1.20197734  0.73262699 -0.24830753  0.19599294\n",
      "  1.20063582 -0.94617852 -0.6088033  -0.18115951  0.68975839  0.87619866]\n",
      "epoch 255\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015364820631616166 R2: 0.9150665390037742 time: 1703091781.3054414\n",
      "batch_idx: 1 loss: 0.0007633105216734021 R2: 0.9150848721781332 time: 1703091783.9551969\n",
      "batch_idx: 2 loss: 0.0015157747081575568 R2: 0.9150866374300269 time: 1703091786.5954342\n",
      "batch_idx: 3 loss: 0.0007821094134378911 R2: 0.915064499135015 time: 1703091789.381078\n",
      "Training [51%] Loss: 0.0011494191766076166 time: 1703091789.381078\n",
      "weight: [ 1.40463782  1.53747584  1.20172478  0.73179201 -0.24757853  0.19558039\n",
      "  1.20097756 -0.94734554 -0.61398494 -0.18113569  0.68981657  0.87611484]\n",
      "epoch 256\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015351977332751677 R2: 0.9150900268664751 time: 1703091792.1352398\n",
      "batch_idx: 1 loss: 0.0007627174731496124 R2: 0.9151081899597434 time: 1703091794.8454094\n",
      "batch_idx: 2 loss: 0.0015159035775847694 R2: 0.9151098016493305 time: 1703091797.7393427\n",
      "batch_idx: 3 loss: 0.0007826000186617674 R2: 0.9150875191040907 time: 1703091800.3751504\n",
      "Training [51%] Loss: 0.0011491047006678293 time: 1703091800.3751504\n",
      "weight: [ 1.40563157  1.53729493  1.2014746   0.73095807 -0.24685085  0.19515857\n",
      "  1.2013155  -0.94850495 -0.61910533 -0.18111225  0.68987443  0.87603154]\n",
      "epoch 257\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015339329339592604 R2: 0.9151130477857462 time: 1703091803.0005748\n",
      "batch_idx: 1 loss: 0.0007621320507284206 R2: 0.9151310432884839 time: 1703091805.6551423\n",
      "batch_idx: 2 loss: 0.0015160338089471282 R2: 0.9151325042333267 time: 1703091808.4405248\n",
      "batch_idx: 3 loss: 0.0007830873154478131 R2: 0.915110081398743 time: 1703091811.1074994\n",
      "Training [51%] Loss: 0.0011487965272706554 time: 1703091811.1074994\n",
      "weight: [ 1.40661019  1.53711824  1.2012268   0.73012516 -0.24612446  0.1947275\n",
      "  1.20164978 -0.94965677 -0.6241652  -0.18108919  0.68993196  0.87594876]\n",
      "epoch 258\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015326873213947884 R2: 0.9151356122132215 time: 1703091813.8110669\n",
      "batch_idx: 1 loss: 0.0007615542102936383 R2: 0.9151534425864444 time: 1703091816.515542\n",
      "batch_idx: 2 loss: 0.0015161652756117674 R2: 0.915154755553137 time: 1703091819.1291866\n",
      "batch_idx: 3 loss: 0.00078357125138578 R2: 0.9151321963050855 time: 1703091821.8581169\n",
      "Training [52%] Loss: 0.0011484945146714935 time: 1703091821.8581169\n",
      "weight: [ 1.40757405  1.53694569  1.20098138  0.72929329 -0.24539932  0.19428723\n",
      "  1.20198053 -0.95080108 -0.62916524 -0.18106649  0.68998918  0.8758665 ]\n",
      "epoch 259\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015314605581810883 R2: 0.9151577303753694 time: 1703091824.368477\n",
      "batch_idx: 1 loss: 0.000760983904847601 R2: 0.9151753980501954 time: 1703091827.0189898\n",
      "batch_idx: 2 loss: 0.0015162978560768487 R2: 0.9151765657552046 time: 1703091829.6652715\n",
      "batch_idx: 3 loss: 0.0007840517777198923 R2: 0.9151538738863192 time: 1703091832.3543367\n",
      "Training [52%] Loss: 0.0011481985242063576 time: 1703091832.3543367\n",
      "weight: [ 1.40852348  1.5367772   1.20073835  0.72846247 -0.24467539  0.19383782\n",
      "  1.20230787 -0.95193791 -0.63410618 -0.18104416  0.69004609  0.87578475]\n",
      "epoch 260\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015302523132358981 R2: 0.9151794122773825 time: 1703091835.009418\n",
      "batch_idx: 1 loss: 0.0007604210847288811 R2: 0.9151969196547988 time: 1703091837.6394525\n",
      "batch_idx: 2 loss: 0.0015164314337826868 R2: 0.9151979447653013 time: 1703091840.1995707\n",
      "batch_idx: 3 loss: 0.0007845288491883963 R2: 0.9151751239866368 time: 1703091842.7253578\n",
      "Training [52%] Loss: 0.0011479084202339657 time: 1703091842.7253578\n",
      "weight: [ 1.40945883  1.53661269  1.20049769  0.72763269 -0.24395262  0.19337934\n",
      "  1.20263193 -0.95306732 -0.63898872 -0.1810222   0.69010267  0.87570351]\n",
      "epoch 261\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015290622616938164 R2: 0.9152006677071338 time: 1703091845.4265332\n",
      "batch_idx: 1 loss: 0.0007598656978182841 R2: 0.9152180171578042 time: 1703091847.9652317\n",
      "batch_idx: 2 loss: 0.0015165658969303144 R2: 0.915218902292499 time: 1703091850.5693793\n",
      "batch_idx: 3 loss: 0.0007850024238698489 R2: 0.915195956235124 time: 1703091853.1539817\n",
      "Training [52%] Loss: 0.001147624070078066 time: 1703091853.1539817\n",
      "weight: [ 1.41038041  1.53645207  1.20025942  0.72680396 -0.24323099  0.19291187\n",
      "  1.20295283 -0.95418936 -0.64381354 -0.1810006   0.69015895  0.87562277]\n",
      "epoch 262\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015278900848036277 R2: 0.9152215062390716 time: 1703091855.785441\n",
      "batch_idx: 1 loss: 0.000759317689733557 R2: 0.9152387001032591 time: 1703091858.3554583\n",
      "batch_idx: 2 loss: 0.0015167011383071293 R2: 0.9152394478331776 time: 1703091860.9253292\n",
      "batch_idx: 3 loss: 0.0007854724630357895 R2: 0.915216380049657 time: 1703091863.4980628\n",
      "Training [52%] Loss: 0.0011473453439700258 time: 1703091863.4980628\n",
      "weight: [ 1.41128855  1.53629527  1.20002353  0.7259763  -0.24251045  0.19243547\n",
      "  1.20327069 -0.95530409 -0.64858133 -0.18097936  0.69021491  0.87554254]\n",
      "epoch 263\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015267354698249454 R2: 0.9152419372381585 time: 1703091866.0705914\n",
      "batch_idx: 1 loss: 0.0007587770040135541 R2: 0.9152589778256852 time: 1703091868.7755013\n",
      "batch_idx: 2 loss: 0.0015168370551192857 R2: 0.9152595906749939 time: 1703091871.3252056\n",
      "batch_idx: 3 loss: 0.0007859389310097085 R2: 0.9152364046407943 time: 1703091873.9954555\n",
      "Training [53%] Loss: 0.0011470721149918735 time: 1703091873.9954555\n",
      "weight: [ 1.41218353  1.53614222  1.19979003  0.72514969 -0.24179096  0.19195025\n",
      "  1.20358562 -0.95641156 -0.65329278 -0.18095848  0.69027056  0.87546281]\n",
      "epoch 264\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015255981099242145 R2: 0.9152619698637782 time: 1703091876.5497978\n",
      "batch_idx: 1 loss: 0.000758243582292358 R2: 0.9152788594540541 time: 1703091879.2572963\n",
      "batch_idx: 2 loss: 0.0015169735488305247 R2: 0.9152793399008502 time: 1703091881.8203077\n",
      "batch_idx: 3 loss: 0.0007864017950318944 R2: 0.9152560390156582 time: 1703091884.4397497\n",
      "Training [53%] Loss: 0.0011468042590197479 time: 1703091884.4397497\n",
      "weight: [ 1.41306567  1.53599284  1.19955891  0.72432415 -0.24107248  0.1914563\n",
      "  1.20389774 -0.95751182 -0.65794855 -0.18093796  0.69032591  0.87538357]\n",
      "epoch 265\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015244777040705833 R2: 0.915281613073631 time: 1703091887.1062117\n",
      "batch_idx: 1 loss: 0.0007577173644638087 R2: 0.9152983539157497 time: 1703091889.7051642\n",
      "batch_idx: 2 loss: 0.0015171105250071594 R2: 0.9152987043928189 time: 1703091892.3752222\n",
      "batch_idx: 3 loss: 0.0007868610251300147 R2: 0.9152752919817869 time: 1703091894.9354448\n",
      "Training [53%] Loss: 0.0011465416546678916 time: 1703091894.9354448\n",
      "weight: [ 1.41393524  1.53584707  1.19933017  0.72349969 -0.24035496  0.19095374\n",
      "  1.20420716 -0.95860492 -0.66254932 -0.18091778  0.69038095  0.87530483]\n",
      "epoch 266\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015233739569317818 R2: 0.915300875627602 time: 1703091897.5535522\n",
      "batch_idx: 1 loss: 0.0007571982888371236 R2: 0.9153174699404742 time: 1703091900.111672\n",
      "batch_idx: 2 loss: 0.0015172478931688945 R2: 0.9153176928360566 time: 1703091902.8281407\n",
      "batch_idx: 3 loss: 0.0007873165939952615 R2: 0.9152941721509936 time: 1703091905.3287616\n",
      "Training [53%] Loss: 0.0011462841832332654 time: 1703091905.3287616\n",
      "weight: [ 1.41479251  1.53570483  1.19910382  0.72267631 -0.23963838  0.19044268\n",
      "  1.20451399 -0.95969092 -0.66709574 -0.18089796  0.6904357   0.87522657]\n",
      "epoch 267\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001522286578770062 R2: 0.9153197660916133 time: 1703091907.9503055\n",
      "batch_idx: 1 loss: 0.0007566862922838707 R2: 0.9153362160641481 time: 1703091910.4854627\n",
      "batch_idx: 2 loss: 0.0015173855666452561 R2: 0.9153363137226986 time: 1703091913.0889568\n",
      "batch_idx: 3 loss: 0.0007877684768636591 R2: 0.9153126879431616 time: 1703091915.7408268\n",
      "Training [53%] Loss: 0.001146031728640712 time: 1703091915.7408268\n",
      "weight: [ 1.41563776  1.53556606  1.19887984  0.72185402 -0.23892269  0.18992325\n",
      "  1.20481832 -0.96076988 -0.67158845 -0.18087848  0.69049014  0.87514879]\n",
      "epoch 268\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015212152853387071 R2: 0.9153382928414461 time: 1703091918.4353275\n",
      "batch_idx: 1 loss: 0.0007561813103768997 R2: 0.9153546006327813 time: 1703091921.0188026\n",
      "batch_idx: 2 loss: 0.0015175234624373818 R2: 0.9153545753556788 time: 1703091923.6353774\n",
      "batch_idx: 3 loss: 0.0007882166514025386 R2: 0.915330847590029 time: 1703091926.2852306\n",
      "Training [54%] Loss: 0.0011457841773888817 time: 1703091926.2852306\n",
      "weight: [ 1.41647123  1.53543069  1.19865825  0.72103283 -0.23820785  0.18939559\n",
      "  1.20512025 -0.96184185 -0.67602811 -0.18085935  0.69054428  0.8750715 ]\n",
      "epoch 269\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015201597977789537 R2: 0.9153564640665193 time: 1703091928.810288\n",
      "batch_idx: 1 loss: 0.0007556832775215897 R2: 0.9153726318062724 time: 1703091931.355118\n",
      "batch_idx: 2 loss: 0.001517661501084909 R2: 0.9153724858525628 time: 1703091933.9105902\n",
      "batch_idx: 3 loss: 0.0007886610976018425 R2: 0.9153486591389568 time: 1703091936.5685713\n",
      "Training [54%] Loss: 0.0011455414184968237 time: 1703091936.5685713\n",
      "weight: [ 1.4172932   1.53529866  1.19843903  0.72021275 -0.23749382  0.18885984\n",
      "  1.2054199  -0.96290688 -0.68041535 -0.18084055  0.69059812  0.87499468]\n",
      "epoch 270\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015191198425176596 R2: 0.9153742877736389 time: 1703091939.1407826\n",
      "batch_idx: 1 loss: 0.0007551921270798021 R2: 0.9153903175622118 time: 1703091941.7283108\n",
      "batch_idx: 2 loss: 0.001517799606537799 R2: 0.9153900531492901 time: 1703091944.4351737\n",
      "batch_idx: 3 loss: 0.0007891017976700906 R2: 0.9153661304566171 time: 1703091946.9941075\n",
      "Training [54%] Loss: 0.0011453033434513378 time: 1703091946.9941075\n",
      "weight: [ 1.41810389  1.53516991  1.19822218  0.71939378 -0.23678056  0.18831616\n",
      "  1.20571734 -0.96396503 -0.68475079 -0.1808221   0.69065168  0.87491833]\n",
      "epoch 271\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015180951511658224 R2: 0.915391771790714 time: 1703091949.5551772\n",
      "batch_idx: 1 loss: 0.0007547077914869403 R2: 0.9154076656995958 time: 1703091952.1003685\n",
      "batch_idx: 2 loss: 0.0015179377060328366 R2: 0.9154072850039146 time: 1703091954.685505\n",
      "batch_idx: 3 loss: 0.0007895387359348431 R2: 0.9153832692326821 time: 1703091957.1453507\n",
      "Training [54%] Loss: 0.0011450698461551105 time: 1703091957.1453507\n",
      "weight: [ 1.41890354  1.53504438  1.19800771  0.71857594 -0.23606804  0.18776471\n",
      "  1.20601269 -0.96501636 -0.68903506 -0.18080398  0.69070494  0.87484245]\n",
      "epoch 272\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015170854604180134 R2: 0.9154089237704139 time: 1703091959.6959057\n",
      "batch_idx: 1 loss: 0.0007542302023624552 R2: 0.9154246838425454 time: 1703091962.2901638\n",
      "batch_idx: 2 loss: 0.001518075729974656 R2: 0.9154241890002751 time: 1703091964.795121\n",
      "batch_idx: 3 loss: 0.0007899718987474548 R2: 0.9154000829834625 time: 1703091967.3669395\n",
      "Training [54%] Loss: 0.0011448408228756448 time: 1703091967.3669395\n",
      "weight: [ 1.41969238  1.534922    1.19779561  0.71775923 -0.23535622  0.18720566\n",
      "  1.20630602 -0.96606091 -0.69326877 -0.18078619  0.69075791  0.87476704]\n",
      "epoch 273\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015160905119528734 R2: 0.9154257511937989 time: 1703091969.8352623\n",
      "batch_idx: 1 loss: 0.0007537592906141597 R2: 0.9154413794439271 time: 1703091972.3498971\n",
      "batch_idx: 2 loss: 0.0015182136118211105 R2: 0.9154407725516144 time: 1703091974.7453191\n",
      "batch_idx: 3 loss: 0.0007904012743919919 R2: 0.9154165790554888 time: 1703091977.2955732\n",
      "Training [55%] Loss: 0.001144616172195034 time: 1703091977.2955732\n",
      "weight: [ 1.42047063  1.53480272  1.19758588  0.71694367 -0.23464505  0.1866392\n",
      "  1.20659742 -0.96709875 -0.69745253 -0.18076873  0.6908106   0.87469208]\n",
      "epoch 274\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001515110052334728 R2: 0.9154422613738881 time: 1703091979.9051385\n",
      "batch_idx: 1 loss: 0.0007532949865366071 R2: 0.9154577597889502 time: 1703091982.546394\n",
      "batch_idx: 2 loss: 0.0015183512879727553 R2: 0.9154570429041785 time: 1703091985.1054444\n",
      "batch_idx: 3 loss: 0.0007908268529980559 R2: 0.9154327646290599 time: 1703091987.6720724\n",
      "Training [55%] Loss: 0.0011443957949605365 time: 1703091987.6720724\n",
      "weight: [ 1.4212385   1.53468649  1.1973785   0.71612925 -0.2339345   0.18606551\n",
      "  1.20688698 -0.96812994 -0.70158692 -0.18075159  0.69086301  0.87461758]\n",
      "epoch 275\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015141438329164723 R2: 0.9154584614591952 time: 1703091990.2199342\n",
      "batch_idx: 1 loss: 0.0007528372199039424 R2: 0.9154738319987199 time: 1703091992.7201004\n",
      "batch_idx: 2 loss: 0.0015184886976663766 R2: 0.9154730071407237 time: 1703091995.2996557\n",
      "batch_idx: 3 loss: 0.0007912486264574694 R2: 0.9154486467217374 time: 1703091997.920353\n",
      "Training [55%] Loss: 0.0011441795942360652 time: 1703091997.920353\n",
      "weight: [ 1.42199622  1.53457324  1.19717349  0.715316   -0.23322454  0.1854848\n",
      "  1.20717478 -0.96915452 -0.70567256 -0.18073478  0.69091513  0.87454354]\n",
      "epoch 276\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015131916097436966 R2: 0.9154743584371957 time: 1703092000.5236168\n",
      "batch_idx: 1 loss: 0.0007523859200574123 R2: 0.9154896030337152 time: 1703092003.2154765\n",
      "batch_idx: 2 loss: 0.0015186257828723273 R2: 0.9154886721840032 time: 1703092005.8075612\n",
      "batch_idx: 3 loss: 0.0007916665883446015 R2: 0.9154642321918006 time: 1703092008.4451609\n",
      "Training [55%] Loss: 0.0011439674752545094 time: 1703092008.4451609\n",
      "weight: [ 1.42274397  1.53446294  1.19697083  0.71450392 -0.23251512  0.18489726\n",
      "  1.20746091 -0.97017256 -0.70971001 -0.18071829  0.69096697  0.87446994]\n",
      "epoch 277\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015122531434602036 R2: 0.9154899591377644 time: 1703092011.095465\n",
      "batch_idx: 1 loss: 0.0007519410159878644 R2: 0.9155050796972259 time: 1703092013.7738132\n",
      "batch_idx: 2 loss: 0.0015187624881955449 R2: 0.9155040448001868 time: 1703092016.4902177\n",
      "batch_idx: 3 loss: 0.000792080733840185 R2: 0.9154795277416433 time: 1703092019.12044\n",
      "Training [55%] Loss: 0.0011437593453709496 time: 1703092019.12044\n",
      "weight: [ 1.42348195  1.53435552  1.19677051  0.71369303 -0.23180621  0.18430312\n",
      "  1.20774543 -0.9711841  -0.71369986 -0.18070212  0.69101854  0.87439678]\n",
      "epoch 278\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001511328199214902 R2: 0.9155052702365307 time: 1703092022.2851665\n",
      "batch_idx: 1 loss: 0.0007515024364134512 R2: 0.9155202686387302 time: 1703092025.060106\n",
      "batch_idx: 2 loss: 0.0015188987607801525 R2: 0.9155191316022158 time: 1703092027.803265\n",
      "batch_idx: 3 loss: 0.0007924910596585212 R2: 0.9154945399211224 time: 1703092030.668031\n",
      "Training [56%] Loss: 0.0011435551140167568 time: 1703092030.668031\n",
      "weight: [ 1.42421037  1.53425093  1.19657255  0.71288332 -0.23109778  0.18370259\n",
      "  1.20802844 -0.97218921 -0.71764267 -0.18068626  0.69106983  0.87432407]\n",
      "epoch 279\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015104165465701842 R2: 0.9155202982582094 time: 1703092033.6152313\n",
      "batch_idx: 1 loss: 0.0007510701098528494 R2: 0.9155351763572229 time: 1703092036.49215\n",
      "batch_idx: 2 loss: 0.0015190345502174613 R2: 0.9155339390531256 time: 1703092039.51024\n",
      "batch_idx: 3 loss: 0.0007928975639779432 R2: 0.915509275130854 time: 1703092042.1554089\n",
      "Training [56%] Loss: 0.0011433546926546095 time: 1703092042.1554089\n",
      "weight: [ 1.42492939  1.53414913  1.19637692  0.71207482 -0.23038978  0.18309591\n",
      "  1.20830999 -0.97318794 -0.721539   -0.18067071  0.69112086  0.87425179]\n",
      "epoch 280\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015095179594117715 R2: 0.9155350495798587 time: 1703092044.8255687\n",
      "batch_idx: 1 loss: 0.000750643964694136 R2: 0.9155498092044686 time: 1703092047.5728257\n",
      "batch_idx: 2 loss: 0.0015191698084572596 R2: 0.9155484734692878 time: 1703092050.4976058\n",
      "batch_idx: 3 loss: 0.0007933002463743394 R2: 0.9155237396254577 time: 1703092053.055502\n",
      "Training [56%] Loss: 0.0011431579947343766 time: 1703092053.055502\n",
      "weight: [ 1.4256392   1.53405007  1.19618362  0.71126753 -0.22968219  0.18248333\n",
      "  1.20859017 -0.97418034 -0.72538942 -0.18065547  0.69117161  0.87417995]\n",
      "epoch 281\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001508632215860158 R2: 0.9155495304340914 time: 1703092055.670234\n",
      "batch_idx: 1 loss: 0.0007502239292596057 R2: 0.9155641733882207 time: 1703092058.3153338\n",
      "batch_idx: 2 loss: 0.0015193044897223247 R2: 0.9155627410236148 time: 1703092060.8991132\n",
      "batch_idx: 3 loss: 0.0007936991077577282 R2: 0.915537939516747 time: 1703092063.61536\n",
      "Training [56%] Loss: 0.0011429649356499542 time: 1703092063.61536\n",
      "weight: [ 1.42633998  1.53395369  1.19599265  0.71046146 -0.22897497  0.18186508\n",
      "  1.20886904 -0.97516648 -0.72919447 -0.18064054  0.6912221   0.87410854]\n",
      "epoch 282\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015077590981835444 R2: 0.9155637469122129 time: 1703092066.1604345\n",
      "batch_idx: 1 loss: 0.0007498099318667178 R2: 0.9155782749753725 time: 1703092068.7755773\n",
      "batch_idx: 2 loss: 0.0015194385504259354 R2: 0.9155767477486816 time: 1703092071.3753228\n",
      "batch_idx: 3 loss: 0.000794094150311672 R2: 0.9155518807768603 time: 1703092073.9853327\n",
      "Training [56%] Loss: 0.0011427754326969674 time: 1703092073.9853327\n",
      "weight: [ 1.4270319   1.53385996  1.195804    0.70965661 -0.22826808  0.18124143\n",
      "  1.20914667 -0.9761464  -0.73295469 -0.18062591  0.69127232  0.87403755]\n",
      "epoch 283\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015068983927124398 R2: 0.9155777049673327 time: 1703092076.6555824\n",
      "batch_idx: 1 loss: 0.0007494019008853532 R2: 0.9155921198950224 time: 1703092079.1693394\n",
      "batch_idx: 2 loss: 0.0015195719490924016 R2: 0.9155904995398176 time: 1703092081.77516\n",
      "batch_idx: 3 loss: 0.0007944853774354643 R2: 0.9155655692413512 time: 1703092084.3953311\n",
      "Training [57%] Loss: 0.0011425894050314147 time: 1703092084.3953311\n",
      "weight: [ 1.42771512  1.53376883  1.19561767  0.70885301 -0.2275615   0.18061263\n",
      "  1.20942312 -0.97712016 -0.73667061 -0.18061158  0.69132229  0.87396698]\n",
      "epoch 284\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015060498897558803 R2: 0.9155914104173787 time: 1703092087.0902398\n",
      "batch_idx: 1 loss: 0.0007489997647915685 R2: 0.9156057139415326 time: 1703092089.7105548\n",
      "batch_idx: 2 loss: 0.0015197046462804265 R2: 0.9156040021581238 time: 1703092092.2697134\n",
      "batch_idx: 3 loss: 0.0007948727936890078 R2: 0.9155790106122008 time: 1703092094.789679\n",
      "Training [57%] Loss: 0.0011424067736292207 time: 1703092094.789679\n",
      "weight: [ 1.42838981  1.53368026  1.19543364  0.70805066 -0.22685519  0.17997897\n",
      "  1.20969846 -0.97808782 -0.74034277 -0.18059754  0.69137199  0.87389683]\n",
      "epoch 285\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015052133835192886 R2: 0.9156048689480956 time: 1703092097.3551733\n",
      "batch_idx: 1 loss: 0.0007486034522180376 R2: 0.9156190627774949 time: 1703092099.8515546\n",
      "batch_idx: 2 loss: 0.0015198366045092303 R2: 0.9156172612334229 time: 1703092102.3954008\n",
      "batch_idx: 3 loss: 0.0007952564047402488 R2: 0.9155922104608102 time: 1703092105.0852275\n",
      "Training [57%] Loss: 0.0011422274612467012 time: 1703092105.0852275\n",
      "weight: [ 1.42905612  1.53359419  1.1952519   0.70724956 -0.22614911  0.17934072\n",
      "  1.20997275 -0.97904943 -0.74397168 -0.1805838   0.69142144  0.87382709]\n",
      "epoch 286\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001504388672024055 R2: 0.915618086115954 time: 1703092107.8075023\n",
      "batch_idx: 1 loss: 0.0007482128920013352 R2: 0.9156321719366265 time: 1703092110.5085177\n",
      "batch_idx: 2 loss: 0.0015199677881873267 R2: 0.9156302822671816 time: 1703092113.1851666\n",
      "batch_idx: 3 loss: 0.0007956362173151099 R2: 0.9156051742308916 time: 1703092115.777211\n",
      "Training [57%] Loss: 0.0011420513923819566 time: 1703092115.777211\n",
      "weight: [ 1.4297142   1.5335106   1.19507246  0.70644972 -0.22544324  0.17869817\n",
      "  1.21024604 -0.98000504 -0.74755786 -0.18057034  0.69147063  0.87375776]\n",
      "epoch 287\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015035755570287715 R2: 0.9156310673509994 time: 1703092118.3076575\n",
      "batch_idx: 1 loss: 0.0007478280132262208 R2: 0.9156450468266317 time: 1703092120.9254465\n",
      "batch_idx: 2 loss: 0.0015200981635438975 R2: 0.9156430706353265 time: 1703092123.5154803\n",
      "batch_idx: 3 loss: 0.0007960122391498182 R2: 0.9156179072413492 time: 1703092126.1726449\n",
      "Training [57%] Loss: 0.001141878493237177 time: 1703092126.1726449\n",
      "weight: [ 1.43036421  1.53342944  1.1948953   0.70565116 -0.22473755  0.17805162\n",
      "  1.2105184  -0.98095472 -0.75110183 -0.18055718  0.69151958  0.87368884]\n",
      "epoch 288\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015027738439522555 R2: 0.9156438179596812 time: 1703092128.7679598\n",
      "batch_idx: 1 loss: 0.0007474487452670668 R2: 0.9156576927320023 time: 1703092131.4456081\n",
      "batch_idx: 2 loss: 0.0015202276985626134 R2: 0.9156556315910505 time: 1703092134.1557474\n",
      "batch_idx: 3 loss: 0.000796384478945587 R2: 0.9156304146890714 time: 1703092136.7462735\n",
      "Training [58%] Loss: 0.0011417086916818806 time: 1703092136.7462735\n",
      "weight: [ 1.43100629  1.53335067  1.19472042  0.70485388 -0.22403201  0.17740137\n",
      "  1.21078988 -0.98189851 -0.75460407 -0.1805443   0.69156827  0.87362033]\n",
      "epoch 289\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015019833417983081 R2: 0.9156563431275803 time: 1703092139.459001\n",
      "batch_idx: 1 loss: 0.0007470750178265754 R2: 0.9156701148167329 time: 1703092142.1754668\n",
      "batch_idx: 2 loss: 0.0015203563629178668 R2: 0.9156679702675252 time: 1703092144.9106102\n",
      "batch_idx: 3 loss: 0.0007967529463255444 R2: 0.91564270165169 time: 1703092147.6152651\n",
      "Training [58%] Loss: 0.0011415419172170738 time: 1703092147.6152651\n",
      "weight: [ 1.43164057  1.53327425  1.1945478   0.70405789 -0.22332658  0.17674772\n",
      "  1.21106053 -0.98283646 -0.75806508 -0.1805317   0.69161672  0.87355221]\n",
      "epoch 290\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001501203863082224 R2: 0.9156686479220977 time: 1703092150.2955532\n",
      "batch_idx: 1 loss: 0.0007467067609719238 R2: 0.9156823181270017 time: 1703092152.9655442\n",
      "batch_idx: 2 loss: 0.0015204841279133027 R2: 0.9156800916805649 time: 1703092155.5255203\n",
      "batch_idx: 3 loss: 0.0007971176517938682 R2: 0.9156547730902623 time: 1703092158.255637\n",
      "Training [58%] Loss: 0.0011413781009403296 time: 1703092158.255637\n",
      "weight: [ 1.4322672   1.53320014  1.19437743  0.70326319 -0.22262124  0.17609101\n",
      "  1.2113304  -0.98376864 -0.76148536 -0.18051938  0.69166492  0.87348448]\n",
      "epoch 291\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0015004352237591638 R2: 0.915680737295078 time: 1703092160.875606\n",
      "batch_idx: 1 loss: 0.0007463439051684483 R2: 0.9156943075937864 time: 1703092163.6116955\n",
      "batch_idx: 2 loss: 0.0015206109664225678 R2: 0.9156920007312411 time: 1703092166.2752633\n",
      "batch_idx: 3 loss: 0.0007974786066970793 R2: 0.915666633851932 time: 1703092168.9895551\n",
      "Training [58%] Loss: 0.0011412171755118149 time: 1703092168.9895551\n",
      "weight: [ 1.43288632  1.5331283   1.19420931  0.70246979 -0.22191597  0.17543154\n",
      "  1.21159955 -0.98469509 -0.76486539 -0.18050734  0.69171288  0.87341715]\n",
      "epoch 292\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001499677243154286 R2: 0.915692616085394 time: 1703092171.4852457\n",
      "batch_idx: 1 loss: 0.0007459863813109945 R2: 0.915706088035407 time: 1703092174.244203\n",
      "batch_idx: 2 loss: 0.0015207368528322113 R2: 0.9157037022084247 time: 1703092176.965547\n",
      "batch_idx: 3 loss: 0.0007978358231874137 R2: 0.9156782886724908 time: 1703092179.6164188\n",
      "Training [58%] Loss: 0.0011410590751212263 time: 1703092179.6164188\n",
      "weight: [ 1.43349805  1.5330587   1.19404343  0.7016777  -0.22121073  0.17476966\n",
      "  1.21186801 -0.98561586 -0.76820564 -0.18049557  0.6917606   0.87335021]\n",
      "epoch 293\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014989297438947626 R2: 0.9157042890214344 time: 1703092182.3553588\n",
      "batch_idx: 1 loss: 0.0007456341207530578 R2: 0.9157176641600332 time: 1703092184.9652472\n",
      "batch_idx: 2 loss: 0.0015208617629866102 R2: 0.91571520079127 time: 1703092187.6673799\n",
      "batch_idx: 3 loss: 0.000798189314188247 R2: 0.915689742178928 time: 1703092190.3753352\n",
      "Training [59%] Loss: 0.0011409037354556694 time: 1703092190.3753352\n",
      "weight: [ 1.43410251  1.5329913   1.19387977  0.70088692 -0.2205055   0.17410569\n",
      "  1.21213585 -0.98653101 -0.77150659 -0.18048407  0.69180809  0.87328365]\n",
      "epoch 294\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00149819255184367 R2: 0.9157157607235801 time: 1703092193.0753372\n",
      "batch_idx: 1 loss: 0.0007452870553337715 R2: 0.9157290405680969 time: 1703092195.6651485\n",
      "batch_idx: 2 loss: 0.0015209856741348923 R2: 0.915726501051657 time: 1703092198.2656245\n",
      "batch_idx: 3 loss: 0.000798539093361504 R2: 0.9157009988918944 time: 1703092201.0106392\n",
      "Training [59%] Loss: 0.0011407510936684595 time: 1703092201.0106392\n",
      "weight: [ 1.43469985  1.53292607  1.19371832  0.70009746 -0.21980025  0.17343999\n",
      "  1.2124031  -0.98744059 -0.7747687  -0.18047284  0.69185534  0.87321747]\n",
      "epoch 295\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001497465496035727 R2: 0.9157270357065828 time: 1703092203.6802993\n",
      "batch_idx: 1 loss: 0.0007449451174029157 R2: 0.9157402217546936 time: 1703092206.3856757\n",
      "batch_idx: 2 loss: 0.0015211085648797512 R2: 0.9157376074565488 time: 1703092208.9654129\n",
      "batch_idx: 3 loss: 0.000798885175077051 R2: 0.9157120632281289 time: 1703092211.665283\n",
      "Training [59%] Loss: 0.0011406010883488612 time: 1703092211.665283\n",
      "weight: [ 1.43529017  1.53286297  1.19355908  0.69930931 -0.21909497  0.1727729\n",
      "  1.2126698  -0.98834466 -0.77799244 -0.18046187  0.69190236  0.87315167]\n",
      "epoch 296\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014967484086149615 R2: 0.915738118381919 time: 1703092214.2752807\n",
      "batch_idx: 1 loss: 0.0007446082398439579 R2: 0.9157512121118702 time: 1703092216.9055793\n",
      "batch_idx: 2 loss: 0.0015212304151280619 R2: 0.9157485243703152 time: 1703092219.5404027\n",
      "batch_idx: 3 loss: 0.0007992275743839495 R2: 0.9157229395028269 time: 1703092222.2683535\n",
      "Training [59%] Loss: 0.0011404536594927326 time: 1703092222.2683535\n",
      "weight: [ 1.43587359  1.53280196  1.19340204  0.69852249 -0.21838963  0.17210478\n",
      "  1.212936   -0.98924325 -0.78117825 -0.18045117  0.69194914  0.87308625]\n",
      "epoch 297\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014960411247743235 R2: 0.9157490130600493 time: 1703092225.0364032\n",
      "batch_idx: 1 loss: 0.0007442763560952799 R2: 0.9157620159309007 time: 1703092227.6732323\n",
      "batch_idx: 2 loss: 0.001521351206043221 R2: 0.9157592560569927 time: 1703092230.2955077\n",
      "batch_idx: 3 loss: 0.0007995663069836096 R2: 0.915733631931943 time: 1703092232.8353477\n",
      "Training [59%] Loss: 0.0011403087484741085 time: 1703092232.8353477\n",
      "weight: [ 1.43645024  1.53274302  1.19324717  0.69773699 -0.2176842   0.17143598\n",
      "  1.21320174 -0.99013643 -0.78432658 -0.18044073  0.6919957   0.8730212 ]\n",
      "epoch 298\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014953434826971467 R2: 0.9157597239526561 time: 1703092235.525495\n",
      "batch_idx: 1 loss: 0.0007439494001696067 R2: 0.915772637404482 time: 1703092238.221544\n",
      "batch_idx: 2 loss: 0.0015214709199992036 R2: 0.9157698066824714 time: 1703092240.9176452\n",
      "batch_idx: 3 loss: 0.0007999013892047343 R2: 0.9157441446344731 time: 1703092243.5519211\n",
      "Training [60%] Loss: 0.0011401662980176728 time: 1703092243.5519211\n",
      "weight: [ 1.43702023  1.5326861   1.19309447  0.69695282 -0.21697866  0.17076687\n",
      "  1.21346704 -0.99102424 -0.78743788 -0.18043054  0.69204204  0.87295651]\n",
      "epoch 299\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014946553235005967 R2: 0.9157702551748143 time: 1703092246.205408\n",
      "batch_idx: 1 loss: 0.0007436273066717882 R2: 0.9157830806288688 time: 1703092248.9575036\n",
      "batch_idx: 2 loss: 0.0015215895405361044 R2: 0.9157801803166462 time: 1703092251.687637\n",
      "batch_idx: 3 loss: 0.0008002328379800143 R2: 0.9157544816346276 time: 1703092254.4653668\n",
      "Training [60%] Loss: 0.001140026252172126 time: 1703092254.4653668\n",
      "weight: [ 1.43758366  1.53263118  1.19294392  0.69616998 -0.21627301  0.17009782\n",
      "  1.21373196 -0.99190673 -0.79051259 -0.18042061  0.69208815  0.87289219]\n",
      "epoch 300\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014939764911810407 R2: 0.9157806107470858 time: 1703092257.1555424\n",
      "batch_idx: 1 loss: 0.0007433100108148975 R2: 0.9157933496059533 time: 1703092259.8415456\n",
      "batch_idx: 2 loss: 0.0015217070523172913 R2: 0.9157903809355034 time: 1703092262.5452063\n",
      "batch_idx: 3 loss: 0.0008005606708245178 R2: 0.9157646468640113 time: 1703092265.256495\n",
      "Training [60%] Loss: 0.0011398885562844368 time: 1703092265.256495\n",
      "weight: [ 1.43814064  1.53257822  1.19279552  0.69538846 -0.2155672   0.16942918\n",
      "  1.21399652 -0.99278395 -0.79355114 -0.18041093  0.69213404  0.87282822]\n",
      "epoch 301\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014933068325612745 R2: 0.9157907945975838 time: 1703092267.840502\n",
      "batch_idx: 1 loss: 0.0007429974484348372 R2: 0.9158034482453006 time: 1703092270.4305236\n",
      "batch_idx: 2 loss: 0.0015218234410879147 R2: 0.9158004124231379 time: 1703092273.1805458\n",
      "batch_idx: 3 loss: 0.0008008849058156939 R2: 0.9157746441637032 time: 1703092275.786369\n",
      "Training [60%] Loss: 0.00113975315697493 time: 1703092275.786369\n",
      "weight: [ 1.43869129  1.5325272   1.19264925  0.69460828 -0.21486124  0.16876133\n",
      "  1.21426076 -0.99365595 -0.79655395 -0.1804015   0.69217971  0.87276462]\n",
      "epoch 302\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014926461972396671 R2: 0.9158008105639668 time: 1703092278.4782636\n",
      "batch_idx: 1 loss: 0.0007426895560033744 R2: 0.9158133803661175 time: 1703092281.1252542\n",
      "batch_idx: 2 loss: 0.001521938693634844 R2: 0.9158102785737443 time: 1703092283.7753398\n",
      "batch_idx: 3 loss: 0.0008012055615748871 R2: 0.9157844772862948 time: 1703092286.39034\n",
      "Training [60%] Loss: 0.0011396200021131931 time: 1703092286.39034\n",
      "weight: [ 1.4392357   1.53247808  1.1925051   0.69382941 -0.2141551   0.16809464\n",
      "  1.21452471 -0.99452278 -0.79952144 -0.18039232  0.69222517  0.87270137]\n",
      "epoch 303\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001491994437541122 R2: 0.9158106623953884 time: 1703092289.0552127\n",
      "batch_idx: 1 loss: 0.0007423862706397689 R2: 0.9158231496991508 time: 1703092291.6983342\n",
      "batch_idx: 2 loss: 0.0015220527977478737 R2: 0.9158199830935321 time: 1703092294.3206155\n",
      "batch_idx: 3 loss: 0.0008015226572503158 R2: 0.9157941498978973 time: 1703092296.939165\n",
      "Training [61%] Loss: 0.0011394890407947702 time: 1703092296.939165\n",
      "weight: [ 1.43977398  1.53243082  1.19236305  0.69305188 -0.21344876  0.16742948\n",
      "  1.2147884  -0.99538449 -0.80245405 -0.18038338  0.69227041  0.87263847]\n",
      "epoch 304\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014913514084698193 R2: 0.9158203537543758 time: 1703092299.4953494\n",
      "batch_idx: 1 loss: 0.0007420875301209943 R2: 0.9158327598885684 time: 1703092302.1471856\n",
      "batch_idx: 2 loss: 0.0015221657421821935 R2: 0.9158295296025838 time: 1703092304.7530344\n",
      "batch_idx: 3 loss: 0.0008018362125013379 R2: 0.9158036655800512 time: 1703092307.4355524\n",
      "Training [61%] Loss: 0.0011393602233185861 time: 1703092307.4355524\n",
      "weight: [ 1.44030623  1.53238541  1.19222309  0.69227566 -0.21274222  0.1667662\n",
      "  1.21505186 -0.99624111 -0.80535216 -0.18037468  0.69231544  0.87257592]\n",
      "epoch 305\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014907169676636942 R2: 0.9158298882186683 time: 1703092310.0383656\n",
      "batch_idx: 1 loss: 0.0007417932728905609 R2: 0.9158422144937498 time: 1703092312.6819847\n",
      "batch_idx: 2 loss: 0.0015222775166220492 R2: 0.9158389216366821 time: 1703092315.2936785\n",
      "batch_idx: 3 loss: 0.000802146247483875 R2: 0.9158130278316182 time: 1703092317.8756866\n",
      "Training [61%] Loss: 0.0011392335011650447 time: 1703092317.8756866\n",
      "weight: [ 1.44083254  1.5323418   1.1920852   0.69150075 -0.21203546  0.16610518\n",
      "  1.21531511 -0.99709271 -0.8082162  -0.18036622  0.69236026  0.87251371]\n",
      "epoch 306\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001490090975350473 R2: 0.9158392692830123 time: 1703092320.6056702\n",
      "batch_idx: 1 loss: 0.0007415034380660728 R2: 0.915851516991046 time: 1703092323.1902912\n",
      "batch_idx: 2 loss: 0.001522388111645495 R2: 0.9158481626490695 time: 1703092325.8754392\n",
      "batch_idx: 3 loss: 0.0008024527828369243 R2: 0.9158222400706106 time: 1703092328.535297\n",
      "Training [61%] Loss: 0.0011391088269747413 time: 1703092328.535297\n",
      "weight: [ 1.44135301  1.53229998  1.19194938  0.69072716 -0.21132847  0.16544677\n",
      "  1.21557819 -0.99793932 -0.81104656 -0.180358    0.69240487  0.87245184]\n",
      "epoch 307\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014894732943052356 R2: 0.9158485003608801 time: 1703092331.2175086\n",
      "batch_idx: 1 loss: 0.0007412179654454791 R2: 0.9158606707754954 time: 1703092333.8568459\n",
      "batch_idx: 2 loss: 0.0015224975186903399 R2: 0.9158572560121596 time: 1703092336.4965951\n",
      "batch_idx: 3 loss: 0.0008027558396698737 R2: 0.9158313056359463 time: 1703092339.109639\n",
      "Training [61%] Loss: 0.0011389861545277322 time: 1703092339.109639\n",
      "weight: [ 1.44186773  1.5322599   1.1918156   0.68995486 -0.21062123  0.16479131\n",
      "  1.21584112 -0.99878099 -0.81384365 -0.18035001  0.69244927  0.87239031]\n",
      "epoch 308\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014888637898094258 R2: 0.9158575847861586 time: 1703092341.6606026\n",
      "batch_idx: 1 loss: 0.0007409367955120259 R2: 0.9158696791624689 time: 1703092344.3496943\n",
      "batch_idx: 2 loss: 0.0015226057300210612 R2: 0.915866205019215 time: 1703092347.0154104\n",
      "batch_idx: 3 loss: 0.0008030554395505254 R2: 0.915840227789181 time: 1703092349.695581\n",
      "Training [62%] Loss: 0.0011388654387232595 time: 1703092349.695581\n",
      "weight: [ 1.4423768   1.53222155  1.19168385  0.68918387 -0.20991374  0.16413914\n",
      "  1.21610392 -0.99961776 -0.81660784 -0.18034225  0.69249348  0.87232912]\n",
      "epoch 309\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001488262329610952 R2: 0.9158665258147936 time: 1703092352.347416\n",
      "batch_idx: 1 loss: 0.0007406598694381073 R2: 0.9158785453892901 time: 1703092355.0502117\n",
      "batch_idx: 2 loss: 0.001522712738696781 R2: 0.9158750128859715 time: 1703092357.6867616\n",
      "batch_idx: 3 loss: 0.000803351604493557 R2: 0.9158490097161692 time: 1703092360.4356503\n",
      "Training [62%] Loss: 0.0011387466355598493 time: 1703092360.4356503\n",
      "weight: [ 1.44288031  1.53218489  1.19155412  0.68841415 -0.209206    0.16349059\n",
      "  1.21636661 -1.00044969 -0.81933954 -0.18033472  0.69253748  0.87226826]\n",
      "epoch 310\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014876687838854988 R2: 0.915875326626382 time: 1703092363.0438843\n",
      "batch_idx: 1 loss: 0.0007403871290877994 R2: 0.9158872726168144 time: 1703092365.8040445\n",
      "batch_idx: 2 loss: 0.0015228185385402519 R2: 0.9158836827522097 time: 1703092368.475189\n",
      "batch_idx: 3 loss: 0.0008036443569492518 R2: 0.9158576545286842 time: 1703092371.1851852\n",
      "Training [62%] Loss: 0.0011386297021157004 time: 1703092371.1851852\n",
      "weight: [ 1.44337833  1.5321499   1.19142639  0.68764572 -0.20849799  0.16284597\n",
      "  1.21662922 -1.0012768  -0.82203913 -0.18032742  0.69258128  0.87220773]\n",
      "epoch 311\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014870830251986124 R2: 0.9158839903257106 time: 1703092373.81643\n",
      "batch_idx: 1 loss: 0.0007401185170183087 R2: 0.9158958639309562 time: 1703092376.4302783\n",
      "batch_idx: 2 loss: 0.0015229231241078221 R2: 0.9158922176833167 time: 1703092379.1156063\n",
      "batch_idx: 3 loss: 0.0008039337197922375 R2: 0.9158661652659756 time: 1703092381.7152884\n",
      "Training [62%] Loss: 0.0011385145965292452 time: 1703092381.7152884\n",
      "weight: [ 1.44387097  1.53211654  1.19130064  0.68687855 -0.20778972  0.16220558\n",
      "  1.21689176 -1.00209916 -0.82470698 -0.18032034  0.69262488  0.87214752]\n",
      "epoch 312\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014865049284685443 R2: 0.9158925199442886 time: 1703092384.4783025\n",
      "batch_idx: 1 loss: 0.000739853976480287 R2: 0.9159043223441957 time: 1703092387.0856209\n",
      "batch_idx: 2 loss: 0.0015230264906603854 R2: 0.9159006206717903 time: 1703092389.838372\n",
      "batch_idx: 3 loss: 0.0008042197163100242 R2: 0.9158745448962973 time: 1703092392.580239\n",
      "Training [62%] Loss: 0.0011384012779798102 time: 1703092392.580239\n",
      "weight: [ 1.4443583   1.53208479  1.19117686  0.68611264 -0.20708117  0.16156969\n",
      "  1.21715426 -1.00291679 -0.82734347 -0.18031349  0.69266829  0.87208763]\n",
      "epoch 313\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014859343709295628 R2: 0.9159009184418206 time: 1703092395.3237748\n",
      "batch_idx: 1 loss: 0.000739593451417007 R2: 0.9159126507970493 time: 1703092398.0443125\n",
      "batch_idx: 2 loss: 0.0015231286341352928 R2: 0.9159088946387092 time: 1703092400.7055938\n",
      "batch_idx: 3 loss: 0.0008045023701910618 R2: 0.915882796318385 time: 1703092403.4652147\n",
      "Training [63%] Loss: 0.001138289706668231 time: 1703092403.4652147\n",
      "weight: [ 1.44484041  1.53205463  1.19105503  0.68534797 -0.20637235  0.16093856\n",
      "  1.21741673 -1.00372974 -0.82994896 -0.18030685  0.69271151  0.87202807]\n",
      "epoch 314\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014853712320955447 R2: 0.9159091887076445 time: 1703092406.0967436\n",
      "batch_idx: 1 loss: 0.0007393368864624875 R2: 0.9159208521595159 time: 1703092408.7555807\n",
      "batch_idx: 2 loss: 0.0015232295511192332 R2: 0.9159170424352052 time: 1703092411.3511941\n",
      "batch_idx: 3 loss: 0.0008047817055121193 R2: 0.9158909223628818 time: 1703092413.9411626\n",
      "Training [63%] Loss: 0.0011381798437973462 time: 1703092413.9411626\n",
      "weight: [ 1.44531738  1.53202602  1.19093514  0.68458453 -0.20566326  0.16031243\n",
      "  1.21767919 -1.00453806 -0.83252383 -0.18030043  0.69275453  0.87196882]\n",
      "epoch 315\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014848153937236964 R2: 0.9159173335621758 time: 1703092416.5696597\n",
      "batch_idx: 1 loss: 0.0007390842269386084 R2: 0.9159289292324978 time: 1703092419.1553953\n",
      "batch_idx: 2 loss: 0.001523329238822101 R2: 0.9159250668438771 time: 1703092421.8267689\n",
      "batch_idx: 3 loss: 0.0008050577467248052 R2: 0.9158989257937467 time: 1703092424.3905756\n",
      "Training [63%] Loss: 0.0011380716515523028 time: 1703092424.3905756\n",
      "weight: [ 1.44578929  1.53199894  1.19081717  0.6838223  -0.20495389  0.1596915\n",
      "  1.21794165 -1.00534178 -0.83506843 -0.18029422  0.69279737  0.87190988]\n",
      "epoch 316\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014842667397781117 R2: 0.9159253557582806 time: 1703092426.9985976\n",
      "batch_idx: 1 loss: 0.0007388354188511499 R2: 0.9159368847492162 time: 1703092429.62518\n",
      "batch_idx: 2 loss: 0.0015234276950518175 R2: 0.9159329705802103 time: 1703092432.3095355\n",
      "batch_idx: 3 loss: 0.0008053305186409119 R2: 0.9159068093096122 time: 1703092434.8553956\n",
      "Training [63%] Loss: 0.0011379650930804979 time: 1703092434.8553956\n",
      "weight: [ 1.44625621  1.53197336  1.1907011   0.68306127 -0.20424426  0.15907595\n",
      "  1.21820413 -1.00614094 -0.83758313 -0.18028823  0.69284002  0.87185125]\n",
      "epoch 317\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001483725156393115 R2: 0.9159332579826819 time: 1703092437.4938128\n",
      "batch_idx: 1 loss: 0.0007385904088849603 R2: 0.9159447213766059 time: 1703092440.1364505\n",
      "batch_idx: 2 loss: 0.0015235249181901102 R2: 0.9159407562939718 time: 1703092442.6952484\n",
      "batch_idx: 3 loss: 0.0008056000464165778 R2: 0.9159145755451176 time: 1703092445.4056356\n",
      "Training [63%] Loss: 0.0011378601324711908 time: 1703092445.4056356\n",
      "weight: [ 1.44671823  1.53194926  1.19058691  0.68230142 -0.20353437  0.15846594\n",
      "  1.21846665 -1.00693559 -0.84006827 -0.18028245  0.69288248  0.87179293]\n",
      "epoch 318\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014831905318360814 R2: 0.9159410428573171 time: 1703092448.1152716\n",
      "batch_idx: 1 loss: 0.0007383491443981675 R2: 0.9159524417166993 time: 1703092450.8302166\n",
      "batch_idx: 2 loss: 0.0015236209071692638 R2: 0.9159484265705989 time: 1703092453.3854713\n",
      "batch_idx: 3 loss: 0.0008058663555350036 R2: 0.9159222270722293 time: 1703092456.0655158\n",
      "Training [64%] Loss: 0.0011377567347346292 time: 1703092456.0655158\n",
      "weight: [ 1.44717542  1.53192661  1.1904746   0.68154274 -0.20282422  0.15786159\n",
      "  1.21872922 -1.00772576 -0.8425242  -0.18027687  0.69292477  0.87173491]\n",
      "epoch 319\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014826627564697658 R2: 0.915948712940691 time: 1703092458.7706044\n",
      "batch_idx: 1 loss: 0.0007381115734155591 R2: 0.9159600483080214 time: 1703092461.331121\n",
      "batch_idx: 2 loss: 0.0015237156614498273 R2: 0.9159559839325826 time: 1703092464.0353966\n",
      "batch_idx: 3 loss: 0.0008061294717877082 R2: 0.9159297664015126 time: 1703092466.7404819\n",
      "Training [64%] Loss: 0.001137654865780715 time: 1703092466.7404819\n",
      "weight: [ 1.44762785  1.53190539  1.19036414  0.6807852  -0.20211382  0.15726298\n",
      "  1.21899184 -1.0085115  -0.84495127 -0.18027149  0.69296687  0.8716772 ]\n",
      "epoch 320\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001482141722713937 R2: 0.9159562707292533 time: 1703092469.4354763\n",
      "batch_idx: 1 loss: 0.0007378776446211606 R2: 0.9159675436269625 time: 1703092472.0855346\n",
      "batch_idx: 2 loss: 0.0015238091809992162 R2: 0.915963430840853 time: 1703092474.7402244\n",
      "batch_idx: 3 loss: 0.000806389421254262 R2: 0.9159371959834319 time: 1703092477.391818\n",
      "Training [64%] Loss: 0.001137554492397144 time: 1703092477.391818\n",
      "weight: [ 1.4480756   1.53188557  1.19025551  0.68002879 -0.20140319  0.15667018\n",
      "  1.21925453 -1.00929284 -0.84734982 -0.18026632  0.6930088   0.87161978]\n",
      "epoch 321\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014816273250062568 R2: 0.9159637186587256 time: 1703092480.0554166\n",
      "batch_idx: 1 loss: 0.0007376473073501439 R2: 0.9159749300891921 time: 1703092482.6067848\n",
      "batch_idx: 2 loss: 0.001523901466271206 R2: 0.9159707696961507 time: 1703092485.180214\n",
      "batch_idx: 3 loss: 0.0008066462302805524 R2: 0.9159445182095943 time: 1703092487.9115374\n",
      "Training [64%] Loss: 0.00113745558222704 time: 1703092487.9115374\n",
      "weight: [ 1.44851874  1.53186713  1.1901487   0.67927348 -0.20069232  0.15608319\n",
      "  1.21951731 -1.01006981 -0.84972018 -0.18026135  0.69305054  0.87156265]\n",
      "epoch 322\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014811194597624277 R2: 0.9159710591054828 time: 1703092490.6552732\n",
      "batch_idx: 1 loss: 0.0007374205115801033 R2: 0.9159822100510407 time: 1703092493.3254323\n",
      "batch_idx: 2 loss: 0.0015239925181863051 R2: 0.9159780028404244 time: 1703092496.0319483\n",
      "batch_idx: 3 loss: 0.0008068999254555607 R2: 0.9159517354140171 time: 1703092498.7367873\n",
      "Training [64%] Loss: 0.0011373581037460992 time: 1703092498.7367873\n",
      "weight: [ 1.44895734  1.53185004  1.1900437   0.67851926 -0.19998123  0.15550202\n",
      "  1.21978017 -1.01084247 -0.85206268 -0.18025658  0.69309212  0.87150582]\n",
      "epoch 323\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014806180253356207 R2: 0.9159782943878992 time: 1703092501.3176458\n",
      "batch_idx: 1 loss: 0.0007371972079217809 R2: 0.9159893858109017 time: 1703092503.9154742\n",
      "batch_idx: 2 loss: 0.0015240823381129024 R2: 0.9159851325582112 time: 1703092506.4854624\n",
      "batch_idx: 3 loss: 0.0008071505335868898 R2: 0.9159588498743808 time: 1703092509.1352203\n",
      "Training [65%] Loss: 0.0011372620262392985 time: 1703092509.1352203\n",
      "weight: [ 1.44939146  1.53183428  1.18994048  0.67776611 -0.19926994  0.1549266\n",
      "  1.22004314 -1.01161085 -0.85437766 -0.180252    0.69313352  0.87144927]\n",
      "epoch 324\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014801229219752134 R2: 0.9159854267677205 time: 1703092511.850622\n",
      "batch_idx: 1 loss: 0.0007369773476094273 R2: 0.9159964596106546 time: 1703092514.511217\n",
      "batch_idx: 2 loss: 0.0015241709278491574 R2: 0.9159921610780423 time: 1703092517.1690416\n",
      "batch_idx: 3 loss: 0.0008073980816751524 R2: 0.9159658638132837 time: 1703092519.7613153\n",
      "Training [65%] Loss: 0.0011371673197772376 time: 1703092519.7613153\n",
      "weight: [ 1.44982118  1.53181983  1.18983903  0.67701401 -0.19855846  0.15435687\n",
      "  1.22030621 -1.01237497 -0.85666544 -0.18024761  0.69317476  0.87139301]\n",
      "epoch 325\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014796340517849327 R2: 0.9159924584514402 time: 1703092522.42525\n",
      "batch_idx: 1 loss: 0.0007367608824908256 R2: 0.9160034336370885 time: 1703092525.0515\n",
      "batch_idx: 2 loss: 0.0015242582896055977 R2: 0.9159990905738338 time: 1703092527.7553961\n",
      "batch_idx: 3 loss: 0.0008076425968874416 R2: 0.9159727793994958 time: 1703092530.385281\n",
      "Training [65%] Loss: 0.0011370739551921994 time: 1703092530.385281\n",
      "weight: [ 1.45024655  1.53180667  1.18973933  0.67626293 -0.19784679  0.15379271\n",
      "  1.2205694  -1.01313489 -0.85892634 -0.18024341  0.69321582  0.87133703]\n",
      "epoch 326\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001479151318680592 R2: 0.915999391591663 time: 1703092532.9664834\n",
      "batch_idx: 1 loss: 0.0007365477650171217 R2: 0.916010310023316 time: 1703092535.637902\n",
      "batch_idx: 2 loss: 0.001524344425988321 R2: 0.9160059231662961 time: 1703092538.2655833\n",
      "batch_idx: 3 loss: 0.000807884106530158 R2: 0.9159795987492176 time: 1703092540.9406254\n",
      "Training [65%] Loss: 0.0011369819040540482 time: 1703092540.9406254\n",
      "weight: [ 1.45066765  1.53179477  1.18964136  0.67551285 -0.19713497  0.15323397\n",
      "  1.22083271 -1.01389063 -0.86116067 -0.1802394   0.69325673  0.87128133]\n",
      "epoch 327\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014786746283475625 R2: 0.9160062282885095 time: 1703092543.516396\n",
      "batch_idx: 1 loss: 0.0007363379482325846 R2: 0.9160170908502054 time: 1703092546.2552764\n",
      "batch_idx: 2 loss: 0.0015244293399827957 R2: 0.9160126609243436 time: 1703092548.8454118\n",
      "batch_idx: 3 loss: 0.0008081226380215028 R2: 0.9159863239273408 time: 1703092551.4788122\n",
      "Training [65%] Loss: 0.0011368911386461114 time: 1703092551.4788122\n",
      "weight: [ 1.45108454  1.5317841   1.18954512  0.67476376 -0.19642299  0.15268048\n",
      "  1.22109615 -1.01464224 -0.86336875 -0.18023558  0.69329746  0.87122591]\n",
      "epoch 328\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014782038881980826 R2: 0.9160129705909835 time: 1703092554.1953893\n",
      "batch_idx: 1 loss: 0.000736131385764416 R2: 0.9160237781478255 time: 1703092556.845588\n",
      "batch_idx: 2 loss: 0.0015245130349381486 R2: 0.9160193058664798 time: 1703092559.5154963\n",
      "batch_idx: 3 loss: 0.0008083582188639018 R2: 0.9159929569487006 time: 1703092562.0773985\n",
      "Training [66%] Loss: 0.0011368016319411372 time: 1703092562.0773985\n",
      "weight: [ 1.45149727  1.53177466  1.18945058  0.67401562 -0.19571089  0.15213206\n",
      "  1.22135973 -1.01538975 -0.86555089 -0.18023194  0.69333804  0.87117076]\n",
      "epoch 329\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014777390073287954 R2: 0.9160196204983511 time: 1703092564.706759\n",
      "batch_idx: 1 loss: 0.0007359280318127058 R2: 0.9160303738968393 time: 1703092567.3151975\n",
      "batch_idx: 2 loss: 0.001524595514551975 R2: 0.91602585996221 time: 1703092569.991552\n",
      "batch_idx: 3 loss: 0.0008085908766167053 R2: 0.9159994997793588 time: 1703092572.595257\n",
      "Training [66%] Loss: 0.0011367133575775454 time: 1703092572.595257\n",
      "weight: [ 1.45190591  1.53176642  1.18935772  0.67326842 -0.19499867  0.15158847\n",
      "  1.22162345 -1.01613319 -0.86770739 -0.18022847  0.69337846  0.87111588]\n",
      "epoch 330\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014772798964786224 R2: 0.9160261799615197 time: 1703092575.2662916\n",
      "batch_idx: 1 loss: 0.0007357278411406308 R2: 0.91603688002994 time: 1703092577.9602258\n",
      "batch_idx: 2 loss: 0.001524676782855607 R2: 0.91603232513341 time: 1703092580.6413417\n",
      "batch_idx: 3 loss: 0.0008088206388694927 R2: 0.9160059543378182 time: 1703092583.3053079\n",
      "Training [66%] Loss: 0.0011366262898360882 time: 1703092583.3053079\n",
      "weight: [ 1.45231052  1.53175936  1.18926654  0.67252214 -0.19428636  0.15104949\n",
      "  1.22188732 -1.0168726  -0.86983855 -0.18022519  0.69341872  0.87106126]\n",
      "epoch 331\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014768264679871686 R2: 0.9160326508843909 time: 1703092585.9056952\n",
      "batch_idx: 1 loss: 0.0007355307690649725 R2: 0.9160432984332291 time: 1703092588.5338566\n",
      "batch_idx: 2 loss: 0.0015247568441998116 R2: 0.9160387032556925 time: 1703092591.085231\n",
      "batch_idx: 3 loss: 0.0008090475332162295 R2: 0.9160123224963062 time: 1703092593.665588\n",
      "Training [66%] Loss: 0.0011365404036170455 time: 1703092593.665588\n",
      "weight: [ 1.45271116  1.53175345  1.18917701  0.67177676 -0.19357396  0.15051486\n",
      "  1.22215134 -1.01760801 -0.87194468 -0.18022208  0.69345883  0.87100691]\n",
      "epoch 332\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014763786357540648 R2: 0.9160390351252088 time: 1703092596.335376\n",
      "batch_idx: 1 loss: 0.0007353367714470821 R2: 0.9160496309475914 time: 1703092598.985226\n",
      "batch_idx: 2 loss: 0.0015248357032410012 R2: 0.9160449961597392 time: 1703092601.596913\n",
      "batch_idx: 3 loss: 0.0008092715872306244 R2: 0.9160186060819957 time: 1703092604.1303406\n",
      "Training [66%] Loss: 0.0011364556744181931 time: 1703092604.1303406\n",
      "weight: [ 1.45310788  1.53174868  1.18908912  0.67103225 -0.1928615   0.14998431\n",
      "  1.22241551 -1.01833947 -0.87402606 -0.18021914  0.69349878  0.87095282]\n",
      "epoch 333\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001475936315199287 R2: 0.9160453344978524 time: 1703092606.819889\n",
      "batch_idx: 1 loss: 0.0007351458046842562 R2: 0.9160558793700296 time: 1703092609.3290257\n",
      "batch_idx: 2 loss: 0.001524913364927879 R2: 0.9160512056326141 time: 1703092611.9685113\n",
      "batch_idx: 3 loss: 0.000809492828442905 R2: 0.9160248068782109 time: 1703092614.5118074\n",
      "Training [67%] Loss: 0.0011363720783135818 time: 1703092614.5118074\n",
      "weight: [ 1.45350074  1.53174504  1.18900285  0.6702886  -0.192149    0.14945759\n",
      "  1.22267985 -1.019067   -0.87608299 -0.18021638  0.69353859  0.87089898]\n",
      "epoch 334\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014754994232247833 R2: 0.9160515507731477 time: 1703092617.1056495\n",
      "batch_idx: 1 loss: 0.0007349578257016693 R2: 0.916062045454966 time: 1703092619.6427593\n",
      "batch_idx: 2 loss: 0.0015249898344886089 R2: 0.9160573334190414 time: 1703092622.3911033\n",
      "batch_idx: 3 loss: 0.0008097112843182316 R2: 0.9160309266256318 time: 1703092624.931262\n",
      "Training [67%] Loss: 0.0011362895919333233 time: 1703092624.931262\n",
      "weight: [ 1.45388979  1.53174249  1.1889182   0.66954579 -0.19143646  0.14893442\n",
      "  1.22294435 -1.01979064 -0.87811576 -0.18021378  0.69357825  0.8708454 ]\n",
      "epoch 335\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014750678781775852 R2: 0.9160576856800885 time: 1703092627.4964788\n",
      "batch_idx: 1 loss: 0.00073477279194479 R2: 0.9160681309155054 time: 1703092630.063076\n",
      "batch_idx: 2 loss: 0.0015250651174185045 R2: 0.9160633812226078 time: 1703092632.641141\n",
      "batch_idx: 3 loss: 0.0008099269822369432 R2: 0.916036967023467 time: 1703092635.2101526\n",
      "Training [67%] Loss: 0.0011362081924444559 time: 1703092635.2101526\n",
      "weight: [ 1.45427509  1.53174103  1.18883513  0.66880379 -0.19072391  0.14841453\n",
      "  1.22320902 -1.02051042 -0.88012464 -0.18021135  0.69361776  0.87079207]\n",
      "epoch 336\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014746415998144987 R2: 0.9160637409070617 time: 1703092637.7986898\n",
      "batch_idx: 1 loss: 0.000734590661372361 R2: 0.9160741374246347 time: 1703092640.4211364\n",
      "batch_idx: 2 loss: 0.0015251392194682452 R2: 0.9160693507069719 time: 1703092642.8871424\n",
      "batch_idx: 3 loss: 0.0008101399494768133 R2: 0.9160429297305793 time: 1703092645.5249586\n",
      "Training [67%] Loss: 0.0011361278575329795 time: 1703092645.5249586\n",
      "weight: [ 1.45465668  1.53174064  1.18875365  0.66806259 -0.19001136  0.14789765\n",
      "  1.22347386 -1.02122637 -0.88210992 -0.18020908  0.69365712  0.87073899]\n",
      "epoch 337\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014742205092686087 R2: 0.9160697181029839 time: 1703092648.0933874\n",
      "batch_idx: 1 loss: 0.0007344113924498965 R2: 0.9160800666163895 time: 1703092650.6061666\n",
      "batch_idx: 2 loss: 0.001525212146632674 R2: 0.9160752434969895 time: 1703092653.2564554\n",
      "batch_idx: 3 loss: 0.0008103502131973061 R2: 0.9160488163665915 time: 1703092655.8618937\n",
      "Training [67%] Loss: 0.0011360485653871214 time: 1703092655.8618937\n",
      "weight: [ 1.45503463  1.53174129  1.18867373  0.66732217 -0.18929882  0.14738354\n",
      "  1.22373887 -1.02193854 -0.88407187 -0.18020697  0.69369634  0.87068616]\n",
      "epoch 338\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014738045290175984 R2: 0.9160756188784381 time: 1703092658.4530315\n",
      "batch_idx: 1 loss: 0.0007342349441437543 R2: 0.9160859200869661 time: 1703092661.0181322\n",
      "batch_idx: 2 loss: 0.0015252839051400607 R2: 0.916081061179786 time: 1703092663.5979714\n",
      "batch_idx: 3 loss: 0.0008105578004260784 R2: 0.916054628512961 time: 1703092666.0999377\n",
      "Training [68%] Loss: 0.001135970294681873 time: 1703092666.0999377\n",
      "weight: [ 1.45540897  1.53174297  1.18859536  0.66658251 -0.18858632  0.14687194\n",
      "  1.22400406 -1.02264695 -0.88601078 -0.18020502  0.69373543  0.87063357]\n",
      "epoch 339\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001473393582853919 R2: 0.9160814448067164 time: 1703092668.7474158\n",
      "batch_idx: 1 loss: 0.0007340612759156949 R2: 0.9160916993957503 time: 1703092671.307034\n",
      "batch_idx: 2 loss: 0.001525354501441928 R2: 0.9160868053057951 time: 1703092673.8445203\n",
      "batch_idx: 3 loss: 0.0008107627380475286 R2: 0.9160603677139963 time: 1703092676.421453\n",
      "Training [68%] Loss: 0.0011358930245647676 time: 1703092676.421453\n",
      "weight: [ 1.45577977  1.53174567  1.18851853  0.66584361 -0.18787386  0.14636262\n",
      "  1.22426943 -1.02335164 -0.8879269  -0.18020323  0.69377437  0.87058122]\n",
      "epoch 340\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014729875958569931 R2: 0.9160871974248279 time: 1703092678.9267015\n",
      "batch_idx: 1 loss: 0.0007338903477179446 R2: 0.9160974060663281 time: 1703092681.598498\n",
      "batch_idx: 2 loss: 0.0015254239422032507 R2: 0.9160924773897342 time: 1703092684.0937943\n",
      "batch_idx: 3 loss: 0.0008109650527935502 R2: 0.9160660354778539 time: 1703092686.6677632\n",
      "Training [68%] Loss: 0.0011358167346429346 time: 1703092686.6677632\n",
      "weight: [ 1.45614706  1.53174937  1.18844322  0.66510543 -0.18716146  0.14585537\n",
      "  1.22453498 -1.02405264 -0.88982051 -0.18020159  0.69381318  0.87052911]\n",
      "epoch 341\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001472586494367017 R2: 0.9160928782344563 time: 1703092689.1769884\n",
      "batch_idx: 1 loss: 0.0007337221199887995 R2: 0.9161030415874111 time: 1703092691.7823966\n",
      "batch_idx: 2 loss: 0.0015254922342930368 R2: 0.916098078911522 time: 1703092694.3081357\n",
      "batch_idx: 3 loss: 0.0008111647712363033 R2: 0.9160716332774687 time: 1703092696.8379698\n",
      "Training [68%] Loss: 0.0011357414049712894 time: 1703092696.8379698\n",
      "weight: [ 1.45651089  1.53175405  1.18836942  0.66436797 -0.18644913  0.14534999\n",
      "  1.2248007  -1.02474998 -0.89169187 -0.18020011  0.69385186  0.87047723]\n",
      "epoch 342\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00147219020596066 R2: 0.9160984887028766 time: 1703092699.3945854\n",
      "batch_idx: 1 loss: 0.0007335565536486404 R2: 0.9161086074137202 time: 1703092701.9202814\n",
      "batch_idx: 2 loss: 0.0015255593847751654 R2: 0.9161036113171536 time: 1703092704.5411396\n",
      "batch_idx: 3 loss: 0.0008113619197828957 R2: 0.9160771625514871 time: 1703092707.026177\n",
      "Training [68%] Loss: 0.0011356670160418405 time: 1703092707.026177\n",
      "weight: [ 1.45687132  1.5317597   1.18829712  0.66363121 -0.18573688  0.14484631\n",
      "  1.22506662 -1.02544369 -0.89354124 -0.18019877  0.6938904   0.87042558]\n",
      "epoch 343\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001471798659428297 R2: 0.9161040302637969 time: 1703092709.6504064\n",
      "batch_idx: 1 loss: 0.0007333936100964364 R2: 0.9161141049668313 time: 1703092712.1970444\n",
      "batch_idx: 2 loss: 0.0015256254008993537 R2: 0.9161090760195295 time: 1703092714.7877133\n",
      "batch_idx: 3 loss: 0.000811556524671897 R2: 0.9160826247051063 time: 1703092717.346077\n",
      "Training [69%] Loss: 0.001135593548773996 time: 1703092717.346077\n",
      "weight: [ 1.45722838  1.5317663   1.1882263   0.66289515 -0.18502473  0.14434415\n",
      "  1.22533271 -1.02613381 -0.89536888 -0.18019759  0.69392881  0.87037417]\n",
      "epoch 344\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014714117847525548 R2: 0.9161095043181863 time: 1703092719.825577\n",
      "batch_idx: 1 loss: 0.0007332332512066891 R2: 0.9161195356359381 time: 1703092722.4614563\n",
      "batch_idx: 2 loss: 0.001525690290092161 R2: 0.9161144743992449 time: 1703092725.0518625\n",
      "batch_idx: 3 loss: 0.0008117486119713915 R2: 0.916088021110929 time: 1703092727.7658734\n",
      "Training [69%] Loss: 0.001135520984505699 time: 1703092727.7658734\n",
      "weight: [ 1.45758212  1.53177385  1.18815694  0.66215975 -0.18431268  0.14384337\n",
      "  1.225599   -1.02682037 -0.89717504 -0.18019655  0.69396709  0.87032298]\n",
      "epoch 345\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014710295130881121 R2: 0.9161149122350402 time: 1703092730.2459486\n",
      "batch_idx: 1 loss: 0.0007330754393267359 R2: 0.9161249007786255 time: 1703092732.872499\n",
      "batch_idx: 2 loss: 0.0015257540599479767 R2: 0.9161198078053288 time: 1703092735.4731138\n",
      "batch_idx: 3 loss: 0.0008119382075783662 R2: 0.9160933531097488 time: 1703092738.1085405\n",
      "Training [69%] Loss: 0.0011354493049852976 time: 1703092738.1085405\n",
      "weight: [ 1.45793258  1.53178231  1.18808905  0.66142502 -0.18360074  0.14334384\n",
      "  1.22586547 -1.0275034  -0.89895997 -0.18019565  0.69400524  0.87027201]\n",
      "epoch 346\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001470651776742421 R2: 0.9161202553521205 time: 1703092740.7118435\n",
      "batch_idx: 1 loss: 0.0007329201372744168 R2: 0.9161302017215576 time: 1703092743.348671\n",
      "batch_idx: 2 loss: 0.001525816718219832 R2: 0.9161250775559611 time: 1703092745.9074094\n",
      "batch_idx: 3 loss: 0.0008121253372192012 R2: 0.9160986220113138 time: 1703092748.5309486\n",
      "Training [69%] Loss: 0.0011353784923639676 time: 1703092748.5309486\n",
      "weight: [ 1.45827981  1.53179169  1.1880226   0.66069095 -0.18288892  0.14284545\n",
      "  1.22613212 -1.02818293 -0.90072392 -0.1801949   0.69404327  0.87022127]\n",
      "epoch 347\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014702785091570668 R2: 0.9161255349766663 time: 1703092751.1634173\n",
      "batch_idx: 1 loss: 0.0007327673083360683 R2: 0.9161354397611777 time: 1703092753.7380311\n",
      "batch_idx: 2 loss: 0.0015258782728100728 R2: 0.9161302849391717 time: 1703092756.3744516\n",
      "batch_idx: 3 loss: 0.0008123100264509685 R2: 0.9161038290950773 time: 1703092758.901099\n",
      "Training [69%] Loss: 0.0011353085291885441 time: 1703092758.901099\n",
      "weight: [ 1.45862385  1.53180196  1.18795758  0.65995751 -0.18217724  0.14234809\n",
      "  1.22639897 -1.02885899 -0.90246714 -0.18019428  0.69408118  0.87017074]\n",
      "epoch 348\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014699096448896622 R2: 0.9161307523860731 time: 1703092761.5550642\n",
      "batch_idx: 1 loss: 0.0007326169162646986 R2: 0.9161406161643557 time: 1703092764.1565323\n",
      "batch_idx: 2 loss: 0.0015259387317608324 R2: 0.9161354312134888 time: 1703092766.7269342\n",
      "batch_idx: 3 loss: 0.0008124923006632091 R2: 0.9161089756108962 time: 1703092769.3365886\n",
      "Training [70%] Loss: 0.0011352393983946006 time: 1703092769.3365886\n",
      "weight: [ 1.45896473  1.53181312  1.18789398  0.6592247  -0.1814657   0.14185168\n",
      "  1.226666   -1.02953162 -0.90418987 -0.18019381  0.69411896  0.87012043]\n",
      "epoch 349\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014695451195959833 R2: 0.9161359088285523 time: 1703092771.9104023\n",
      "batch_idx: 1 loss: 0.0007324689252783255 R2: 0.9161457321690276 time: 1703092774.4060137\n",
      "batch_idx: 2 loss: 0.0015259981032443603 R2: 0.9161405176085904 time: 1703092776.9653404\n",
      "batch_idx: 3 loss: 0.0008126721850799975 R2: 0.9161140627797326 time: 1703092779.6146092\n",
      "Training [70%] Loss: 0.0011351710832996666 time: 1703092779.6146092\n",
      "weight: [ 1.45930251  1.53182515  1.18783178  0.6584925  -0.18075431  0.14135613\n",
      "  1.22693322 -1.03020084 -0.90589235 -0.18019347  0.69415662  0.87007034]\n",
      "epoch 350\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001469184870012209 R2: 0.9161410055237834 time: 1703092782.1825414\n",
      "batch_idx: 1 loss: 0.0007323233000583627 R2: 0.9161507889848218 time: 1703092784.7541983\n",
      "batch_idx: 2 loss: 0.0015260563955532321 R2: 0.9161455453259479 time: 1703092787.3028386\n",
      "batch_idx: 3 loss: 0.0008128497047619587 R2: 0.9161190917943227 time: 1703092789.8629053\n",
      "Training [70%] Loss: 0.0011351035675964407 time: 1703092789.8629053\n",
      "weight: [ 1.45963721  1.53183803  1.18777098  0.65776092 -0.18004308  0.14086137\n",
      "  1.22720062 -1.03086669 -0.90757481 -0.18019326  0.69419417  0.87002046]\n",
      "epoch 351\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001468828833937067 R2: 0.9161460436635259 time: 1703092792.421958\n",
      "batch_idx: 1 loss: 0.0007321800057480017 R2: 0.9161557877936717 time: 1703092795.0258744\n",
      "batch_idx: 2 loss: 0.0015261136170905782 R2: 0.9161505155394437 time: 1703092797.648922\n",
      "batch_idx: 3 loss: 0.0008130248846080407 R2: 0.9161240638198273 time: 1703092800.314219\n",
      "Training [70%] Loss: 0.0011350368353459218 time: 1703092800.314219\n",
      "weight: [ 1.45996888  1.53185176  1.18771157  0.65702993 -0.17933201  0.14036734\n",
      "  1.22746822 -1.0315292  -0.90923749 -0.18019319  0.69423159  0.86997078]\n",
      "epoch 352\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014684769502139512 R2: 0.9161510244122597 time: 1703092802.9672103\n",
      "batch_idx: 1 loss: 0.0007320390079503492 R2: 0.9161607297504364 time: 1703092805.524972\n",
      "batch_idx: 2 loss: 0.0015261697763604492 R2: 0.9161554293959794 time: 1703092808.099413\n",
      "batch_idx: 3 loss: 0.0008131977493568473 R2: 0.9161289799944823 time: 1703092810.6464489\n",
      "Training [70%] Loss: 0.0011349708709703992 time: 1703092810.6464489\n",
      "weight: [ 1.46029755  1.53186633  1.18765352  0.65629953 -0.17862111  0.13987397\n",
      "  1.22773599 -1.03218839 -0.91088062 -0.18019325  0.69426891  0.86992132]\n",
      "epoch 353\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014681291587128023 R2: 0.9161559489077943 time: 1703092813.260407\n",
      "batch_idx: 1 loss: 0.0007319002727264631 R2: 0.9161656159834818 time: 1703092815.9596283\n",
      "batch_idx: 2 loss: 0.0015262248819583612 R2: 0.9161602880160886 time: 1703092818.5346665\n",
      "batch_idx: 3 loss: 0.000813368323587474 R2: 0.9161338414302233 time: 1703092821.1016886\n",
      "Training [71%] Loss: 0.001134905659246275 time: 1703092821.1016886\n",
      "weight: [ 1.46062326  1.53188171  1.18759684  0.6555697  -0.1779104   0.13938121\n",
      "  1.22800396 -1.03284429 -0.91250443 -0.18019344  0.6943061   0.86987206]\n",
      "epoch 354\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014677854003118042 R2: 0.9161608182618582 time: 1703092823.6145582\n",
      "batch_idx: 1 loss: 0.0007317637665929629 R2: 0.9161704475952929 time: 1703092826.175534\n",
      "batch_idx: 2 loss: 0.0015262789425622542 R2: 0.9161650924945521 time: 1703092828.797133\n",
      "batch_idx: 3 loss: 0.0008135366317195964 R2: 0.9161386492133007 time: 1703092831.4816294\n",
      "Training [71%] Loss: 0.0011348411852966545 time: 1703092831.4816294\n",
      "weight: [ 1.46094606  1.53189791  1.1875415   0.65484045 -0.17719987  0.138889\n",
      "  1.22827211 -1.03349694 -0.91410914 -0.18019375  0.69434319  0.869823  ]\n",
      "epoch 355\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014674456168791536 R2: 0.9161656335607231 time: 1703092834.2004359\n",
      "batch_idx: 1 loss: 0.0007316294565193051 R2: 0.9161752256630734 time: 1703092836.7693892\n",
      "batch_idx: 2 loss: 0.0015263319669239716 R2: 0.9161698439009738 time: 1703092839.3899872\n",
      "batch_idx: 3 loss: 0.000813702698013029 R2: 0.9161434044048974 time: 1703092841.946614\n",
      "Training [71%] Loss: 0.0011347774345838648 time: 1703092841.946614\n",
      "weight: [ 1.46126597  1.5319149   1.18748751  0.65411175 -0.17648953  0.13839729\n",
      "  1.22854044 -1.03414636 -0.91569498 -0.18019419  0.69438016  0.86977414]\n",
      "epoch 356\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014671097512546113 R2: 0.9161703958657765 time: 1703092844.490321\n",
      "batch_idx: 1 loss: 0.0007314973099246409 R2: 0.9161799512393195 time: 1703092847.1156695\n",
      "batch_idx: 2 loss: 0.0015263839638612017 R2: 0.9161745432803909 time: 1703092849.7788546\n",
      "batch_idx: 3 loss: 0.000813866546566594 R2: 0.916148108041712 time: 1703092852.3039048\n",
      "Training [71%] Loss: 0.001134714392901762 time: 1703092852.3039048\n",
      "weight: [ 1.46158303  1.53193268  1.18743483  0.65338361 -0.17577939  0.13790602\n",
      "  1.22880895 -1.03479258 -0.91726217 -0.18019475  0.69441703  0.86972548]\n",
      "epoch 357\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014667777472312166 R2: 0.916175106214126 time: 1703092854.893293\n",
      "batch_idx: 1 loss: 0.000731367294674248 R2: 0.9161846253524206 time: 1703092857.4392884\n",
      "batch_idx: 2 loss: 0.0015264349422501827 R2: 0.9161791916538485 time: 1703092860.008752\n",
      "batch_idx: 3 loss: 0.0008140282013165181 R2: 0.9161527611365633 time: 1703092862.5448854\n",
      "Training [71%] Loss: 0.0011346520463680412 time: 1703092862.5448854\n",
      "weight: [ 1.46189728  1.53195124  1.18738348  0.65265601 -0.17506946  0.13741514\n",
      "  1.22907765 -1.03543564 -0.91881092 -0.18019544  0.69445379  0.86967701]\n",
      "epoch 358\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014664495495372934 R2: 0.916179765619162 time: 1703092865.0299835\n",
      "batch_idx: 1 loss: 0.0007312393790755067 R2: 0.916189249007226 time: 1703092867.610936\n",
      "batch_idx: 2 loss: 0.0015264849110189853 R2: 0.9161837900189782 time: 1703092870.1321638\n",
      "batch_idx: 3 loss: 0.0008141876860343993 R2: 0.9161573646789426 time: 1703092872.7414157\n",
      "Training [72%] Loss: 0.0011345903814165461 time: 1703092872.7414157\n",
      "weight: [ 1.46220874  1.53197056  1.18733343  0.65192895 -0.17435975  0.13692462\n",
      "  1.22934652 -1.03607555 -0.92034145 -0.18019624  0.69449044  0.86962874]\n",
      "epoch 359\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014661251038185783 R2: 0.9161843750711386 time: 1703092875.278721\n",
      "batch_idx: 1 loss: 0.0007311135318735574 R2: 0.9161938231856143 time: 1703092877.9293375\n",
      "batch_idx: 2 loss: 0.0015265338791414645 R2: 0.916188339350563 time: 1703092880.5370739\n",
      "batch_idx: 3 loss: 0.0008143450243249297 R2: 0.9161619196355982 time: 1703092883.235774\n",
      "Training [72%] Loss: 0.0011345293847896325 time: 1703092883.235774\n",
      "weight: [ 1.46251746  1.53199063  1.18728467  0.65120241 -0.17365025  0.13643439\n",
      "  1.22961557 -1.03671235 -0.92185397 -0.18019716  0.69452699  0.86958066]\n",
      "epoch 360\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014658043566208728 R2: 0.9161889355377232 time: 1703092885.8873303\n",
      "batch_idx: 1 loss: 0.0007309897222465828 R2: 0.9161983488470467 time: 1703092888.5974395\n",
      "batch_idx: 2 loss: 0.001526581855631824 R2: 0.9161928406010762 time: 1703092891.1646414\n",
      "batch_idx: 3 loss: 0.0008145002396234778 R2: 0.9161664269510712 time: 1703092893.7152276\n",
      "Training [72%] Loss: 0.0011344690435306894 time: 1703092893.7152276\n",
      "weight: [ 1.46282347  1.53201145  1.18723719  0.6504764  -0.17294097  0.13594442\n",
      "  1.2298848  -1.03734607 -0.92334869 -0.1801982   0.69456343  0.86953277]\n",
      "epoch 361\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014654872553731084 R2: 0.9161934479645449 time: 1703092896.2875829\n",
      "batch_idx: 1 loss: 0.0007308679198008495 R2: 0.9162028269291087 time: 1703092899.1128447\n",
      "batch_idx: 2 loss: 0.0015266288495396805 R2: 0.9161972947012428 time: 1703092901.7061155\n",
      "batch_idx: 3 loss: 0.0008146533551937303 R2: 0.9161708875482478 time: 1703092904.2103221\n",
      "Training [72%] Loss: 0.0011344093449768423 time: 1703092904.2103221\n",
      "weight: [ 1.4631268   1.532033    1.18719099  0.64975089 -0.17223192  0.13545466\n",
      "  1.2301542  -1.03797673 -0.92482582 -0.18019936  0.69459977  0.86948507]\n",
      "epoch 362\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014651737483708886 R2: 0.916197913275718 time: 1703092906.8032846\n",
      "batch_idx: 1 loss: 0.000730748094565644 R2: 0.9162072583480393 time: 1703092909.395529\n",
      "batch_idx: 2 loss: 0.0015266748699455479 R2: 0.9162017025605419 time: 1703092911.9808667\n",
      "batch_idx: 3 loss: 0.0008148043941254982 R2: 0.9161753023288671 time: 1703092914.4823244\n",
      "Training [72%] Loss: 0.0011343502767518947 time: 1703092914.4823244\n",
      "weight: [ 1.46342747  1.53205527  1.18714606  0.64902589 -0.17152311  0.13496507\n",
      "  1.23042377 -1.03860435 -0.92628557 -0.18020063  0.69463601  0.86943755]\n",
      "epoch 363\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001464863784760509 R2: 0.9162023323743684 time: 1703092917.0126836\n",
      "batch_idx: 1 loss: 0.0007306302169880688 R2: 0.9162116439992414 time: 1703092919.5770206\n",
      "batch_idx: 2 loss: 0.0015267199259566336 R2: 0.9162060650677246 time: 1703092922.0865448\n",
      "batch_idx: 3 loss: 0.0008149533793326953 R2: 0.9161796721740402 time: 1703092924.6822093\n",
      "Training [73%] Loss: 0.0011342918267594768 time: 1703092924.6822093\n",
      "weight: [ 1.46372553  1.53207826  1.18710237  0.64830139 -0.17081454  0.13447562\n",
      "  1.23069351 -1.03922898 -0.92772814 -0.18020201  0.69467215  0.86939021]\n",
      "epoch 364\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014645573145235613 R2: 0.9162067061431275 time: 1703092927.2504869\n",
      "batch_idx: 1 loss: 0.0007305142579278759 R2: 0.9162159847577701 time: 1703092929.8438628\n",
      "batch_idx: 2 loss: 0.0015267640267028378 R2: 0.9162103830913061 time: 1703092932.3509479\n",
      "batch_idx: 3 loss: 0.0008151003335517025 R2: 0.9161839979447436 time: 1703092934.9018474\n",
      "Training [73%] Loss: 0.0011342339831764943 time: 1703092934.9018474\n",
      "weight: [ 1.46402101  1.53210195  1.18705993  0.64757738 -0.17010622  0.13398627\n",
      "  1.23096341 -1.03985063 -0.92915372 -0.1802035   0.6947082   0.86934306]\n",
      "epoch 365\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014642542884618194 R2: 0.9162110354446172 time: 1703092937.5336118\n",
      "batch_idx: 1 loss: 0.0007304001886523895 R2: 0.9162202814788346 time: 1703092939.9926953\n",
      "batch_idx: 2 loss: 0.001526807181332845 R2: 0.9162146574800543 time: 1703092942.6215465\n",
      "batch_idx: 3 loss: 0.0008152452793400237 R2: 0.9161882804823025 time: 1703092945.1933658\n",
      "Training [73%] Loss: 0.0011341767344467694 time: 1703092945.1933658\n",
      "weight: [ 1.46431392  1.53212634  1.18701872  0.64685386 -0.16939814  0.13349699\n",
      "  1.23123348 -1.04046933 -0.93056252 -0.1802051   0.69474415  0.86929608]\n",
      "epoch 366\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014639546581825913 R2: 0.9162153211219298 time: 1703092947.7455685\n",
      "batch_idx: 1 loss: 0.0007302879808315254 R2: 0.9162245349982439 time: 1703092950.2885284\n",
      "batch_idx: 2 loss: 0.0015268493990102448 R2: 0.9162188890634425 time: 1703092952.8233461\n",
      "batch_idx: 3 loss: 0.0008153882390752444 R2: 0.916192520608855 time: 1703092955.4090588\n",
      "Training [73%] Loss: 0.0011341200692749015 time: 1703092955.4090588\n",
      "weight: [ 1.46460432  1.53215141  1.18697873  0.64613081 -0.16869032  0.13300775\n",
      "  1.23150372 -1.0410851  -0.93195472 -0.1802068   0.69478     0.86924928]\n",
      "epoch 367\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001463658376084367 R2: 0.9162195639990843 time: 1703092957.943435\n",
      "batch_idx: 1 loss: 0.0007301776065329952 R2: 0.9162287461328734 time: 1703092960.5195055\n",
      "batch_idx: 2 loss: 0.0015268906889096328 R2: 0.916223078652109 time: 1703092963.1247752\n",
      "batch_idx: 3 loss: 0.000815529234954302 R2: 0.9161967191278173 time: 1703092965.6845665\n",
      "Training [73%] Loss: 0.0011340639766203244 time: 1703092965.6845665\n",
      "weight: [ 1.46489221  1.53217716  1.18693995  0.64540824 -0.16798276  0.13251851\n",
      "  1.23177411 -1.04169798 -0.93333054 -0.18020861  0.69481576  0.86920266]\n",
      "epoch 368\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001463365395342698 R2: 0.9162237648814738 time: 1703092968.2558777\n",
      "batch_idx: 1 loss: 0.000730069038217649 R2: 0.9162329156811151 time: 1703092970.861512\n",
      "batch_idx: 2 loss: 0.0015269310602126875 R2: 0.9162272270383054 time: 1703092973.453423\n",
      "batch_idx: 3 loss: 0.0008156682889929944 R2: 0.9162008768243209 time: 1703092976.0399265\n",
      "Training [74%] Loss: 0.0011340084456915073 time: 1703092976.0399265\n",
      "weight: [ 1.46517764  1.53220357  1.18690238  0.64468613 -0.16727547  0.13202926\n",
      "  1.23204466 -1.04230799 -0.93469015 -0.18021053  0.69485143  0.86915621]\n",
      "epoch 369\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014630756698962755 R2: 0.9162279245563051 time: 1703092978.6344426\n",
      "batch_idx: 1 loss: 0.0007299622487349942 R2: 0.9162370444232918 time: 1703092981.220452\n",
      "batch_idx: 2 loss: 0.0015269705221042005 R2: 0.9162313349963253 time: 1703092983.8385444\n",
      "batch_idx: 3 loss: 0.0008158054230255958 R2: 0.9162049944656528 time: 1703092986.3510923\n",
      "Training [74%] Loss: 0.0011339534659402664 time: 1703092986.3510923\n",
      "weight: [ 1.46546063  1.53223064  1.186866    0.64396448 -0.16656844  0.13153997\n",
      "  1.23231536 -1.04291515 -0.93603374 -0.18021255  0.694887    0.86910993]\n",
      "epoch 370\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014627891544332344 R2: 0.9162320437930223 time: 1703092989.0450807\n",
      "batch_idx: 1 loss: 0.0007298572113188015 R2: 0.9162411331220996 time: 1703092991.7582128\n",
      "batch_idx: 2 loss: 0.001527009083768147 R2: 0.9162354032829241 time: 1703092994.4963124\n",
      "batch_idx: 3 loss: 0.0008159406587046654 R2: 0.9162090728016731 time: 1703092997.1215491\n",
      "Training [74%] Loss: 0.0011338990270562121 time: 1703092997.1215491\n",
      "weight: [ 1.46574121  1.53225836  1.18683081  0.64324328 -0.16586169  0.13105062\n",
      "  1.23258622 -1.04351949 -0.9373615  -0.18021467  0.69492249  0.86906382]\n",
      "epoch 371\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001462505804377532 R2: 0.9162361233437284 time: 1703092999.690439\n",
      "batch_idx: 1 loss: 0.0007297538995828329 R2: 0.9162451825230133 time: 1703093002.222438\n",
      "batch_idx: 2 loss: 0.0015270467543837883 R2: 0.9162394326377324 time: 1703093004.772189\n",
      "batch_idx: 3 loss: 0.0008160740175008433 R2: 0.9162131125652367 time: 1703093007.4587996\n",
      "Training [74%] Loss: 0.0011338451189612491 time: 1703093007.4587996\n",
      "weight: [ 1.4660194   1.53228673  1.18679679  0.64252254 -0.16515521  0.13056118\n",
      "  1.23285722 -1.04412104 -0.93867362 -0.18021689  0.69495789  0.86901787]\n",
      "epoch 372\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014622255758755937 R2: 0.9162401639435901 time: 1703093010.037153\n",
      "batch_idx: 1 loss: 0.0007296522875165695 R2: 0.9162491933546887 time: 1703093012.5906384\n",
      "batch_idx: 2 loss: 0.001527083543121947 R2: 0.9162434237836742 time: 1703093015.1809916\n",
      "batch_idx: 3 loss: 0.0008162055207026732 R2: 0.9162171144725922 time: 1703093017.735457\n",
      "Training [74%] Loss: 0.001133791731804196 time: 1703093017.735457\n",
      "weight: [ 1.46629524  1.53231572  1.18676394  0.64180224 -0.16444901  0.13007163\n",
      "  1.23312837 -1.04471981 -0.93997028 -0.1802192   0.6949932   0.86897209]\n",
      "epoch 373\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014619484257830946 R2: 0.9162441663112387 time: 1703093020.1995187\n",
      "batch_idx: 1 loss: 0.0007295523494809513 R2: 0.9162531663293741 time: 1703093022.8296757\n",
      "batch_idx: 2 loss: 0.001527119459141398 R2: 0.916247377427341 time: 1703093025.379936\n",
      "batch_idx: 3 loss: 0.0008163351894164405 R2: 0.9162210792237794 time: 1703093027.942463\n",
      "Training [75%] Loss: 0.001133738855955471 time: 1703093027.942463\n",
      "weight: [ 1.46656875  1.53234534  1.18673225  0.64108237 -0.1637431   0.12958196\n",
      "  1.23339966 -1.04531584 -0.94125165 -0.18022162  0.69502842  0.86892648]\n",
      "epoch 374\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014616743116519656 R2: 0.9162481311491619 time: 1703093030.4501517\n",
      "batch_idx: 1 loss: 0.0007294540602040955 R2: 0.9162571021432816 time: 1703093032.9879706\n",
      "batch_idx: 2 loss: 0.0015271545115855558 R2: 0.9162512942594013 time: 1703093035.6876516\n",
      "batch_idx: 3 loss: 0.0008164630445659746 R2: 0.9162250075030173 time: 1703093038.1971185\n",
      "Training [75%] Loss: 0.0011336864820018979 time: 1703093038.1971185\n",
      "weight: [ 1.46683996  1.53237558  1.18670171  0.64036294 -0.16303747  0.12909213\n",
      "  1.23367109 -1.04590915 -0.94251792 -0.18022413  0.69506356  0.86888102]\n",
      "epoch 375\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014614031917177166 R2: 0.91625205914409 time: 1703093040.7527983\n",
      "batch_idx: 1 loss: 0.0007293573947769134 R2: 0.9162610014769779 time: 1703093043.2850356\n",
      "batch_idx: 2 loss: 0.0015271887095793016 R2: 0.9162551749549556 time: 1703093045.7474055\n",
      "batch_idx: 3 loss: 0.0008165891068924495 R2: 0.9162288999790841 time: 1703093048.3455222\n",
      "Training [75%] Loss: 0.0011336346007415953 time: 1703093048.3455222\n",
      "weight: [ 1.46710889  1.53240642  1.1866723   0.63964394 -0.16233214  0.12860215\n",
      "  1.23394266 -1.04649976 -0.94376926 -0.18022673  0.69509862  0.86883573]\n",
      "epoch 376\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014611350248869494 R2: 0.9162559509673545 time: 1703093050.8562875\n",
      "batch_idx: 1 loss: 0.0007292623286487404 R2: 0.9162648649957547 time: 1703093053.4692626\n",
      "batch_idx: 2 loss: 0.0015272220622261634 R2: 0.9162590201739308 time: 1703093056.042361\n",
      "batch_idx: 3 loss: 0.0008167133969542141 R2: 0.916232757305677 time: 1703093058.6784897\n",
      "Training [75%] Loss: 0.0011335832031790169 time: 1703093058.6784897\n",
      "weight: [ 1.46737557  1.53243786  1.18664403  0.63892536 -0.1616271   0.12811199\n",
      "  1.23421436 -1.04708769 -0.94500584 -0.18022943  0.69513359  0.86879059]\n",
      "epoch 377\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014608697707252025 R2: 0.9162598072752687 time: 1703093061.2681873\n",
      "batch_idx: 1 loss: 0.0007291688376228478 R2: 0.9162686933499901 time: 1703093063.982692\n",
      "batch_idx: 2 loss: 0.0015272545786055925 R2: 0.9162628305614172 time: 1703093066.7453592\n",
      "batch_idx: 3 loss: 0.0008168359351266403 R2: 0.916236580121771 time: 1703093069.3157156\n",
      "Training [75%] Loss: 0.0011335322805200707 time: 1703093069.3157156\n",
      "weight: [ 1.46764002  1.5324699   1.18661688  0.6382072  -0.16092236  0.12762163\n",
      "  1.23448619 -1.04767298 -0.94622784 -0.18023221  0.69516848  0.86874561]\n",
      "epoch 378\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014606073894451131 R2: 0.9162636287094788 time: 1703093071.9693046\n",
      "batch_idx: 1 loss: 0.0007290768978519852 R2: 0.9162724871754901 time: 1703093074.50089\n",
      "batch_idx: 2 loss: 0.0015272862677705675 R2: 0.9162666067480384 time: 1703093077.0606377\n",
      "batch_idx: 3 loss: 0.0008169567416020585 R2: 0.9162403690519895 time: 1703093079.612296\n",
      "Training [76%] Loss: 0.0011334818241674311 time: 1703093079.612296\n",
      "weight: [ 1.46790228  1.53250253  1.18659084  0.63748945 -0.16021792  0.12713106\n",
      "  1.23475815 -1.04825563 -0.94743543 -0.18023509  0.6952033   0.86870078]\n",
      "epoch 379\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001460347841894761 R2: 0.9162674158973007 time: 1703093082.1809742\n",
      "batch_idx: 1 loss: 0.0007289864858338706 R2: 0.9162762470938522 time: 1703093084.7611084\n",
      "batch_idx: 2 loss: 0.0015273171387452165 R2: 0.9162703493502761 time: 1703093087.411461\n",
      "batch_idx: 3 loss: 0.000817075836389732 R2: 0.9162441247069152 time: 1703093090.0008788\n",
      "Training [76%] Loss: 0.001133431825715895 time: 1703093090.0008788\n",
      "weight: [ 1.46816235  1.53253573  1.18656591  0.63677212 -0.15951379  0.12664026\n",
      "  1.23503023 -1.04883569 -0.94862877 -0.18023806  0.69523803  0.86865611]\n",
      "epoch 380\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014600910895463536 R2: 0.9162711694520678 time: 1703093092.5587957\n",
      "batch_idx: 1 loss: 0.0007288975784067648 R2: 0.9162799737127839 time: 1703093095.1478717\n",
      "batch_idx: 2 loss: 0.0015273472005226225 R2: 0.9162740589708214 time: 1703093097.710722\n",
      "batch_idx: 3 loss: 0.0008171932393159665 R2: 0.9162478476834496 time: 1703093100.2871299\n",
      "Training [76%] Loss: 0.0011333822769479269 time: 1703093100.2871299\n",
      "weight: [ 1.46842028  1.5325695   1.18654208  0.63605518 -0.15880996  0.12614923\n",
      "  1.23530242 -1.04941316 -0.94980803 -0.18024111  0.69527268  0.86861159]\n",
      "epoch 381\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014598370944850804 R2: 0.9162748899734557 time: 1703093102.809969\n",
      "batch_idx: 1 loss: 0.0007288101527450684 R2: 0.9162836676264398 time: 1703093105.396335\n",
      "batch_idx: 2 loss: 0.0015273764620626926 R2: 0.916277736198887 time: 1703093107.9706042\n",
      "batch_idx: 3 loss: 0.000817308970024263 R2: 0.916251538565119 time: 1703093110.4809985\n",
      "Training [76%] Loss: 0.0011333331698292761 time: 1703093110.4809985\n",
      "weight: [ 1.46867607  1.53260383  1.18651934  0.63533865 -0.15810644  0.12565795\n",
      "  1.23557474 -1.04998808 -0.95097337 -0.18024425  0.69530726  0.86856721]\n",
      "epoch 382\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014595858193982086 R2: 0.9162785780478073 time: 1703093113.068209\n",
      "batch_idx: 1 loss: 0.0007287241863549552 R2: 0.9162873294157329 time: 1703093115.6236086\n",
      "batch_idx: 2 loss: 0.0015274049322900611 R2: 0.916281381610531 time: 1703093118.231179\n",
      "batch_idx: 3 loss: 0.0008174230479755844 R2: 0.9162551979224013 time: 1703093120.868314\n",
      "Training [76%] Loss: 0.0011332844965047024 time: 1703093120.868314\n",
      "weight: [ 1.46892976  1.53263872  1.18649767  0.63462252 -0.15740324  0.12516641\n",
      "  1.23584717 -1.05056046 -0.95212496 -0.18024748  0.69534177  0.86852299]\n",
      "epoch 383\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014593372275642938 R2: 0.9162822342484359 time: 1703093123.4902122\n",
      "batch_idx: 1 loss: 0.0007286396570701434 R2: 0.9162909596486501 time: 1703093126.0317855\n",
      "batch_idx: 2 loss: 0.001527432620092073 R2: 0.9162849957689666 time: 1703093128.6405005\n",
      "batch_idx: 3 loss: 0.0008175354924486964 R2: 0.9162588263130352 time: 1703093131.2542074\n",
      "Training [77%] Loss: 0.0011332362492938017 time: 1703093131.2542074\n",
      "weight: [ 1.46918137  1.53267417  1.18647708  0.63390678 -0.15670035  0.1246746\n",
      "  1.23611971 -1.05113033 -0.95326295 -0.18025079  0.69537619  0.86847891]\n",
      "epoch 384\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014590912828426734 R2: 0.9162858591359522 time: 1703093133.8171668\n",
      "batch_idx: 1 loss: 0.0007285565430476969 R2: 0.9162945588805643 time: 1703093136.3415396\n",
      "batch_idx: 2 loss: 0.0015274595343168125 R2: 0.9162885792248673 time: 1703093138.9425159\n",
      "batch_idx: 3 loss: 0.0008176463225405435 R2: 0.9162624242823181 time: 1703093141.5219648\n",
      "Training [77%] Loss: 0.0011331884206869315 time: 1703093141.5219648\n",
      "weight: [ 1.46943092  1.53271015  1.18645756  0.63319143 -0.15599778  0.12418251\n",
      "  1.23639235 -1.05169771 -0.95438751 -0.18025418  0.69541055  0.86843497]\n",
      "epoch 385\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014588479496630423 R2: 0.9162894532585366 time: 1703093144.0945456\n",
      "batch_idx: 1 loss: 0.0007284748227638484 R2: 0.916298127654508 time: 1703093146.9746118\n",
      "batch_idx: 2 loss: 0.0015274856837711656 R2: 0.9162921325166533 time: 1703093149.824697\n",
      "batch_idx: 3 loss: 0.0008177555571667281 R2: 0.9162659923634051 time: 1703093152.978142\n",
      "Training [77%] Loss: 0.0011331410033411963 time: 1703093152.978142\n",
      "weight: [ 1.46967843  1.53274667  1.1864391   0.63247646 -0.15529554  0.12369013\n",
      "  1.2366651  -1.05226262 -0.95549879 -0.18025765  0.69544483  0.86839118]\n",
      "epoch 386\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014586071930152418 R2: 0.9162930171522546 time: 1703093156.1151013\n",
      "batch_idx: 1 loss: 0.0007283944750099602 R2: 0.9163016665014918 time: 1703093159.112153\n",
      "batch_idx: 2 loss: 0.0015275110772190448 R2: 0.9162956561707964 time: 1703093161.9689448\n",
      "batch_idx: 3 loss: 0.0008178632150619751 R2: 0.9162695310775838 time: 1703093164.8552265\n",
      "Training [77%] Loss: 0.0011330939900765556 time: 1703093164.8552265\n",
      "weight: [ 1.46992392  1.53278372  1.18642168  0.63176188 -0.15459361  0.12319746\n",
      "  1.23693795 -1.05282508 -0.95659694 -0.18026121  0.69547904  0.86834753]\n",
      "epoch 387\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014583689784392901 R2: 0.9162965513413266 time: 1703093167.7748187\n",
      "batch_idx: 1 loss: 0.0007283154788884123 R2: 0.9163051759407731 time: 1703093170.5058048\n",
      "batch_idx: 2 loss: 0.0015275357233796377 R2: 0.9162991507020875 time: 1703093173.3297725\n",
      "batch_idx: 3 loss: 0.000817969314780677 R2: 0.9162730409345791 time: 1703093176.10755\n",
      "Training [77%] Loss: 0.0011330473738720044 time: 1703093176.10755\n",
      "weight: [ 1.47016742  1.53282129  1.18640531  0.63104767 -0.15389201  0.12270447\n",
      "  1.23721089 -1.05338511 -0.95768212 -0.18026484  0.69551318  0.86830402]\n",
      "epoch 388\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014581332720155168 R2: 0.9163000563384148 time: 1703093178.9102657\n",
      "batch_idx: 1 loss: 0.0007282378138085699 R2: 0.916308656480132 time: 1703093181.7270052\n",
      "batch_idx: 2 loss: 0.001527559630925795 R2: 0.9163026166139192 time: 1703093184.581311\n",
      "batch_idx: 3 loss: 0.0008180738746974565 R2: 0.9162765224328048 time: 1703093187.3745685\n",
      "Training [78%] Loss: 0.0011330011478618346 time: 1703093187.3745685\n",
      "weight: [ 1.47040895  1.53285938  1.18638997  0.63033384 -0.15319074  0.12221118\n",
      "  1.23748393 -1.05394275 -0.95875447 -0.18026855  0.69554725  0.86826065]\n",
      "epoch 389\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014579000403549672 R2: 0.9163035326448942 time: 1703093190.1209927\n",
      "batch_idx: 1 loss: 0.0007281614594827794 R2: 0.9163121086161444 time: 1703093193.0333517\n",
      "batch_idx: 2 loss: 0.001527582808482548 R2: 0.9163060543985548 time: 1703093195.6085184\n",
      "batch_idx: 3 loss: 0.0008181769130077603 R2: 0.9162799760596412 time: 1703093198.3206625\n",
      "Training [78%] Loss: 0.0011329553053320137 time: 1703093198.3206625\n",
      "weight: [ 1.47064853  1.53289798  1.18637566  0.62962038 -0.1524898   0.12171756\n",
      "  1.23775705 -1.05449799 -0.95981415 -0.18027233  0.69558126  0.86821741]\n",
      "epoch 390\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014576692505899975 R2: 0.9163069807511081 time: 1703093200.9638827\n",
      "batch_idx: 1 loss: 0.0007280863959223325 R2: 0.9163155328344457 time: 1703093203.613757\n",
      "batch_idx: 2 loss: 0.0015276052646256758 R2: 0.9163094645373834 time: 1703093206.3452983\n",
      "batch_idx: 3 loss: 0.0008182784477285137 R2: 0.916283402291692 time: 1703093209.1034758\n",
      "Training [78%] Loss: 0.0011329098397166299 time: 1703093209.1034758\n",
      "weight: [ 1.47088618  1.53293708  1.18636236  0.62890729 -0.1517892   0.12122362\n",
      "  1.23803026 -1.05505088 -0.96086131 -0.1802762   0.69561519  0.86817431]\n",
      "epoch 391\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014574408703650148 R2: 0.9163104011366411 time: 1703093211.7668467\n",
      "batch_idx: 1 loss: 0.0007280126034335068 R2: 0.9163189296099862 time: 1703093214.3928943\n",
      "batch_idx: 2 loss: 0.0015276270078804102 R2: 0.9163128475011885 time: 1703093216.988928\n",
      "batch_idx: 3 loss: 0.0008183784966987647 R2: 0.9162868015950437 time: 1703093219.5939808\n",
      "Training [78%] Loss: 0.001132864744594424 time: 1703093219.5939808\n",
      "weight: [ 1.47112192  1.53297668  1.18635009  0.62819456 -0.15108892  0.12072935\n",
      "  1.23830355 -1.05560142 -0.96189608 -0.18028013  0.69564906  0.86813134]\n",
      "epoch 392\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014572148678274777 R2: 0.9163137942705581 time: 1703093222.2316167\n",
      "batch_idx: 1 loss: 0.0007279400626136177 R2: 0.9163222994072852 time: 1703093224.8048944\n",
      "batch_idx: 2 loss: 0.0015276480467201852 R2: 0.9163162037503788 time: 1703093227.513912\n",
      "batch_idx: 3 loss: 0.000818477077580408 R2: 0.9162901744255073 time: 1703093230.1245754\n",
      "Training [78%] Loss: 0.0011328200136854222 time: 1703093230.1245754\n",
      "weight: [ 1.47135577  1.53301678  1.18633881  0.62748219 -0.15038899  0.12023474\n",
      "  1.23857692 -1.05614964 -0.96291862 -0.18028414  0.69568287  0.8680885 ]\n",
      "epoch 393\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014569912116189885 R2: 0.9163171606116606 time: 1703093232.7250273\n",
      "batch_idx: 1 loss: 0.0007278687543471154 R2: 0.9163256426806704 time: 1703093235.2677033\n",
      "batch_idx: 2 loss: 0.00152766838956547 R2: 0.9163195337352537 time: 1703093237.8398707\n",
      "batch_idx: 3 loss: 0.0008185742078589417 R2: 0.9162935212288656 time: 1703093240.4240808\n",
      "Training [79%] Loss: 0.0011327756408476288 time: 1703093240.4240808\n",
      "weight: [ 1.47158775  1.53305736  1.18632854  0.62677018 -0.14968939  0.11973979\n",
      "  1.23885036 -1.05669556 -0.96392906 -0.18028822  0.6957166   0.8680458 ]\n",
      "epoch 394\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001456769870866605 R2: 0.9163205006087208 time: 1703093242.9233284\n",
      "batch_idx: 1 loss: 0.000727798659801708 R2: 0.9163289598745192 time: 1703093245.5624626\n",
      "batch_idx: 2 loss: 0.0015276880447826768 R2: 0.9163228378962238 time: 1703093248.212319\n",
      "batch_idx: 3 loss: 0.0008186699048442325 R2: 0.9162968424411007 time: 1703093250.8551052\n",
      "Training [79%] Loss: 0.0011327316200738056 time: 1703093250.8551052\n",
      "weight: [ 1.47181788  1.53309841  1.18631925  0.62605853 -0.14899013  0.1192445\n",
      "  1.23912388 -1.0572392  -0.96492755 -0.18029238  0.69575028  0.86800322]\n",
      "epoch 395\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014565508151742862 R2: 0.9163238147007234 time: 1703093253.3529935\n",
      "batch_idx: 1 loss: 0.0007277297604245531 R2: 0.9163322514234918 time: 1703093256.0132678\n",
      "batch_idx: 2 loss: 0.0015277070206830958 R2: 0.9163261166640518 time: 1703093258.5144258\n",
      "batch_idx: 3 loss: 0.0008187641856713353 R2: 0.9163001384886431 time: 1703093261.0805347\n",
      "Training [79%] Loss: 0.0011326879454883177 time: 1703093261.0805347\n",
      "weight: [ 1.47204619  1.53313995  1.18631095  0.62534722 -0.14829122  0.11874885\n",
      "  1.23939746 -1.05778057 -0.96591423 -0.1802966   0.69578389  0.86796077]\n",
      "epoch 396\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014563340146145065 R2: 0.9163271033170812 time: 1703093263.640993\n",
      "batch_idx: 1 loss: 0.0007276620379384967 R2: 0.9163355177527613 time: 1703093266.2344315\n",
      "batch_idx: 2 loss: 0.001527725325521909 R2: 0.9163293704600701 time: 1703093268.7944057\n",
      "batch_idx: 3 loss: 0.0008188570673013458 R2: 0.9163034097885744 time: 1703093271.3401477\n",
      "Training [79%] Loss: 0.0011326446113440645 time: 1703093271.3401477\n",
      "weight: [ 1.47227268  1.53318195  1.18630363  0.62463627 -0.14759265  0.11825284\n",
      "  1.2396711  -1.05831971 -0.96688922 -0.18030089  0.69581744  0.86791845]\n",
      "epoch 397\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.00145611943972004 R2: 0.9163303668778726 time: 1703093273.907501\n",
      "batch_idx: 1 loss: 0.0007275954743383176 R2: 0.9163387592782325 time: 1703093276.448992\n",
      "batch_idx: 2 loss: 0.0015277429674972777 R2: 0.9163325996964172 time: 1703093279.128432\n",
      "batch_idx: 3 loss: 0.0008189485665222927 R2: 0.9163066567488587 time: 1703093281.6565325\n",
      "Training [79%] Loss: 0.001132601612019482 time: 1703093281.6565325\n",
      "weight: [ 1.47249738  1.53322441  1.18629728  0.62392566 -0.14689442  0.11775648\n",
      "  1.2399448  -1.05885662 -0.96785268 -0.18030525  0.69585093  0.86787626]\n",
      "epoch 398\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014559070614758541 R2: 0.9163336057940528 time: 1703093284.2678306\n",
      "batch_idx: 1 loss: 0.0007275300518870463 R2: 0.9163419764067557 time: 1703093286.8640285\n",
      "batch_idx: 2 loss: 0.001527759954749464 R2: 0.9163358047762371 time: 1703093289.4824815\n",
      "batch_idx: 3 loss: 0.0008190386999500197 R2: 0.9163098797685574 time: 1703093292.0538294\n",
      "Training [80%] Loss: 0.001132558942015596 time: 1703093292.0538294\n",
      "weight: [ 1.4727203   1.53326733  1.18629189  0.6232154  -0.14619654  0.11725976\n",
      "  1.24021856 -1.05939132 -0.96880472 -0.18030968  0.69588436  0.86783418]\n",
      "epoch 399\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014556968513112435 R2: 0.9163368204676725 time: 1703093294.6806645\n",
      "batch_idx: 1 loss: 0.0007274657531123066 R2: 0.9163451695363513 time: 1703093297.2645068\n",
      "batch_idx: 2 loss: 0.0015277762953600272 R2: 0.9163389860938989 time: 1703093299.8322947\n",
      "batch_idx: 3 loss: 0.0008191274840291462 R2: 0.9163130792380372 time: 1703093302.465548\n",
      "Training [80%] Loss: 0.0011325165959531808 time: 1703093302.465548\n",
      "weight: [ 1.47294148  1.53331071  1.18628746  0.62250547 -0.14549901  0.11676267\n",
      "  1.24049238 -1.05992384 -0.96974549 -0.18031417  0.69591773  0.86779223]\n",
      "epoch 400\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014554887810920188 R2: 0.9163400112920733 time: 1703093305.0194464\n",
      "batch_idx: 1 loss: 0.0007274025608026904 R2: 0.9163483390563986 time: 1703093307.5935054\n",
      "batch_idx: 2 loss: 0.0015277919973510786 R2: 0.9163421440352029 time: 1703093310.251805\n",
      "batch_idx: 3 loss: 0.0008192149350340171 R2: 0.9163162555391675 time: 1703093312.8500464\n",
      "Training [80%] Loss: 0.0011324745685699512 time: 1703093312.8500464\n",
      "weight: [ 1.47316091  1.53335453  1.18628398  0.62179589 -0.14480183  0.11626522\n",
      "  1.24076624 -1.0604542  -0.97067512 -0.18031873  0.69595104  0.8677504 ]\n",
      "epoch 401\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014552828231129181 R2: 0.9163431786521047 time: 1703093315.5113428\n",
      "batch_idx: 1 loss: 0.0007273404580041638 R2: 0.916351485347852 time: 1703093318.06445\n",
      "batch_idx: 2 loss: 0.0015278070686845966 R2: 0.9163452789775736 time: 1703093320.6920059\n",
      "batch_idx: 3 loss: 0.0008193010690696909 R2: 0.9163194090455324 time: 1703093323.2507787\n",
      "Training [80%] Loss: 0.0011324328547178423 time: 1703093323.2507787\n",
      "weight: [ 1.47337863  1.53339879  1.18628145  0.62108664 -0.144105    0.1157674\n",
      "  1.24104015 -1.06098241 -0.97159373 -0.18032335  0.6959843   0.86770869]\n",
      "epoch 402\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014550789500901514 R2: 0.9163463229243121 time: 1703093325.9147422\n",
      "batch_idx: 1 loss: 0.0007272794280165584 R2: 0.9163546087834302 time: 1703093328.495438\n",
      "batch_idx: 2 loss: 0.001527821517261785 R2: 0.9163483912902691 time: 1703093331.1691868\n",
      "batch_idx: 3 loss: 0.0008193859020729445 R2: 0.9163225401226074 time: 1703093333.832647\n",
      "Training [80%] Loss: 0.0011323914493603599 time: 1703093333.832647\n",
      "weight: [ 1.47359465  1.53344349  1.18627985  0.62037772 -0.14340853  0.11526921\n",
      "  1.2413141  -1.06150849 -0.97250145 -0.18032804  0.6960175   0.8676671 ]\n",
      "epoch 403\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014548771351540618 R2: 0.9163494444771357 time: 1703093336.3660114\n",
      "batch_idx: 1 loss: 0.0007272194543900169 R2: 0.9163577097278054 time: 1703093338.9629626\n",
      "batch_idx: 2 loss: 0.001527835350922491 R2: 0.9163514813345459 time: 1703093341.4665956\n",
      "batch_idx: 3 loss: 0.0008194694498133131 R2: 0.9163256491279693 time: 1703093344.1809063\n",
      "Training [81%] Loss: 0.0011323503475699707 time: 1703093344.1809063\n",
      "weight: [ 1.47380898  1.53348862  1.18627919  0.61966913 -0.1427124   0.11477064\n",
      "  1.24158808 -1.06203246 -0.97339841 -0.18033278  0.69605064  0.86762562]\n",
      "epoch 404\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014546773518419186 R2: 0.9163525436711003 time: 1703093346.7303667\n",
      "batch_idx: 1 loss: 0.0007271605209215701 R2: 0.9163607885378017 time: 1703093349.3752365\n",
      "batch_idx: 2 loss: 0.00152784857744465 R2: 0.9163545494638846 time: 1703093351.8884017\n",
      "batch_idx: 3 loss: 0.000819551727894109 R2: 0.9163287364114595 time: 1703093354.3451087\n",
      "Training [81%] Loss: 0.001132309544525562 time: 1703093354.3451087\n",
      "weight: [ 1.47402165  1.53353417  1.18627944  0.61896087 -0.14201664  0.11427171\n",
      "  1.24186211 -1.06255433 -0.97428473 -0.18033759  0.69608373  0.86758426]\n",
      "epoch 405\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014544795740909042 R2: 0.9163556208589879 time: 1703093356.8933287\n",
      "batch_idx: 1 loss: 0.0007271026116516795 R2: 0.9163638455625703 time: 1703093359.4792912\n",
      "batch_idx: 2 loss: 0.001527861204543799 R2: 0.9163575960241325 time: 1703093362.089522\n",
      "batch_idx: 3 loss: 0.0008196327517535218 R2: 0.9163318023153891 time: 1703093364.63073\n",
      "Training [81%] Loss: 0.0011322690355099762 time: 1703093364.63073\n",
      "weight: [ 1.47423267  1.53358015  1.18628062  0.61825294 -0.14132123  0.11377239\n",
      "  1.24213616 -1.06307414 -0.97516055 -0.18034246  0.69611676  0.86754302]\n",
      "epoch 406\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014542837762311796 R2: 0.9163586763860334 time: 1703093367.1691\n",
      "batch_idx: 1 loss: 0.000727045710860862 R2: 0.9163668811437601 time: 1703093369.7663496\n",
      "batch_idx: 2 loss: 0.001527873239872655 R2: 0.9163606213537034 time: 1703093372.4070015\n",
      "batch_idx: 3 loss: 0.000819712536665689 R2: 0.9163348471746865 time: 1703093374.998659\n",
      "Training [81%] Loss: 0.0011322288159075964 time: 1703093374.998659\n",
      "weight: [ 1.47444206  1.53362654  1.18628271  0.61754533 -0.14062618  0.1132727\n",
      "  1.24241024 -1.06359188 -0.97602597 -0.18034739  0.69614974  0.86750188]\n",
      "epoch 407\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001454089932979082 R2: 0.9163617105900871 time: 1703093377.5137365\n",
      "batch_idx: 1 loss: 0.0007269898030663413 R2: 0.916369895615715 time: 1703093380.1279867\n",
      "batch_idx: 2 loss: 0.0015278846910206556 R2: 0.9163636257837469 time: 1703093382.6467235\n",
      "batch_idx: 3 loss: 0.0008197910977417969 R2: 0.9163378713170957 time: 1703093385.3059576\n",
      "Training [81%] Loss: 0.001132188881201969 time: 1703093385.3059576\n",
      "weight: [ 1.47464983  1.53367334  1.18628571  0.61683803 -0.13993148  0.11277263\n",
      "  1.24268435 -1.06410759 -0.97688112 -0.18035238  0.69618266  0.86746086]\n",
      "epoch 408\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014538980194304986 R2: 0.9163647238017919 time: 1703093387.8575506\n",
      "batch_idx: 1 loss: 0.0007269348730187362 R2: 0.9163728893056156 time: 1703093390.5869613\n",
      "batch_idx: 2 loss: 0.0015278955655136615 R2: 0.9163666096383182 time: 1703093393.2015984\n",
      "batch_idx: 3 loss: 0.0008198684499311854 R2: 0.916340875063322 time: 1703093395.9224703\n",
      "Training [82%] Loss: 0.0011321492269735205 time: 1703093395.9224703\n",
      "weight: [ 1.474856    1.53372055  1.1862896   0.61613106 -0.13923715  0.11227219\n",
      "  1.24295847 -1.06462127 -0.97772612 -0.18035742  0.69621554  0.86741995]\n",
      "epoch 409\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014537080110543217 R2: 0.9163677163447519 time: 1703093398.439936\n",
      "batch_idx: 1 loss: 0.000726880905698756 R2: 0.9163758625336701 time: 1703093400.9978516\n",
      "batch_idx: 2 loss: 0.0015279058708135948 R2: 0.9163695732345379 time: 1703093403.646926\n",
      "batch_idx: 3 loss: 0.0008199446080225123 R2: 0.9163438587272171 time: 1703093406.1894467\n",
      "Training [82%] Loss: 0.0011321098488972963 time: 1703093406.1894467\n",
      "weight: [ 1.4750606   1.53376816  1.18629439  0.6154244  -0.13854318  0.11177137\n",
      "  1.24323262 -1.06513295 -0.97856108 -0.18036252  0.69624836  0.86737915]\n",
      "epoch 410\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014535198836860492 R2: 0.9163706885356883 time: 1703093408.759926\n",
      "batch_idx: 1 loss: 0.0007268278863140222 R2: 0.9163788156132584 time: 1703093411.3712707\n",
      "batch_idx: 2 loss: 0.0015279156143181544 R2: 0.9163725168827538 time: 1703093414.0055838\n",
      "batch_idx: 3 loss: 0.0008200195866448802 R2: 0.9163468226159213 time: 1703093416.536014\n",
      "Training [82%] Loss: 0.0011320707427407766 time: 1703093416.536014\n",
      "weight: [ 1.47526362  1.53381617  1.18630007  0.61471806 -0.13784957  0.11127017\n",
      "  1.24350678 -1.06564264 -0.97938613 -0.18036768  0.69628114  0.86733846]\n",
      "epoch 411\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014533336135214843 R2: 0.9163736406846053 time: 1703093419.1374629\n",
      "batch_idx: 1 loss: 0.0007267758002958135 R2: 0.9163817488511027 time: 1703093421.699318\n",
      "batch_idx: 2 loss: 0.0015279248033606102 R2: 0.9163754408867048 time: 1703093424.3038826\n",
      "batch_idx: 3 loss: 0.0008200934002689866 R2: 0.9163497670300261 time: 1703093426.8941448\n",
      "Training [82%] Loss: 0.0011320319043617237 time: 1703093426.8941448\n",
      "weight: [ 1.4754651   1.53386457  1.18630663  0.61401202 -0.13715633  0.11076858\n",
      "  1.24378094 -1.06615036 -0.98020138 -0.18037289  0.69631386  0.86729788]\n",
      "epoch 412\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014531491771106173 R2: 0.9163765730949379 time: 1703093429.461957\n",
      "batch_idx: 1 loss: 0.0007267246332959262 R2: 0.916384662547409 time: 1703093432.1003525\n",
      "batch_idx: 2 loss: 0.0015279334452095524 R2: 0.9163783455436688 time: 1703093434.6191924\n",
      "batch_idx: 3 loss: 0.0008201660632083134 R2: 0.9163526922637228 time: 1703093437.189315\n",
      "Training [82%] Loss: 0.0011319933297061022 time: 1703093437.189315\n",
      "weight: [ 1.47566504  1.53391335  1.18631407  0.6133063  -0.13646344  0.11026662\n",
      "  1.24405512 -1.06665612 -0.98100694 -0.18037816  0.69634653  0.8672574 ]\n",
      "epoch 413\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014529665513514996 R2: 0.916379486063718 time: 1703093439.7996993\n",
      "batch_idx: 1 loss: 0.0007266743711835857 R2: 0.916387556996028 time: 1703093442.4352982\n",
      "batch_idx: 2 loss: 0.0015279415470687222 R2: 0.9163812311446125 time: 1703093444.9879282\n",
      "batch_idx: 3 loss: 0.0008202375896203042 R2: 0.9163555986049602 time: 1703093447.4666848\n",
      "Training [83%] Loss: 0.001131955014806028 time: 1703093447.4666848\n",
      "weight: [ 1.47586346  1.53396252  1.18632238  0.61260088 -0.13577093  0.10976429\n",
      "  1.2443293  -1.06715995 -0.98180292 -0.18038348  0.69637916  0.86721702]\n",
      "epoch 414\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014527857134843866 R2: 0.9163823798817013 time: 1703093450.094432\n",
      "batch_idx: 1 loss: 0.0007266250000422824 R2: 0.9163904324845996 time: 1703093452.574227\n",
      "batch_idx: 2 loss: 0.001527949116076904 R2: 0.9163840979743394 time: 1703093455.2549777\n",
      "batch_idx: 3 loss: 0.0008203079935075392 R2: 0.916358486335581 time: 1703093457.8796628\n",
      "Training [83%] Loss: 0.001131916955777778 time: 1703093457.8796628\n",
      "weight: [ 1.47606037  1.53401207  1.18633156  0.61189577 -0.13507878  0.10926157\n",
      "  1.24460347 -1.06766185 -0.98258944 -0.18038885  0.69641174  0.86717675]\n",
      "epoch 415\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014526066410858718 R2: 0.9163852548335288 time: 1703093460.569953\n",
      "batch_idx: 1 loss: 0.0007265765061668137 R2: 0.9163932892946971 time: 1703093463.0999084\n",
      "batch_idx: 2 loss: 0.0015279561593077606 R2: 0.9163869463116328 time: 1703093465.7109342\n",
      "batch_idx: 3 loss: 0.0008203772887189814 R2: 0.9163613557314594 time: 1703093468.2725682\n",
      "Training [83%] Loss: 0.001131879148819857 time: 1703093468.2725682\n",
      "weight: [ 1.4762558   1.53406199  1.18634159  0.61119096 -0.13438699  0.10875847\n",
      "  1.24487765 -1.06816185 -0.9833666  -0.18039427  0.69644427  0.86713659]\n",
      "epoch 416\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014524293120631534 R2: 0.9163881111978626 time: 1703093470.8908405\n",
      "batch_idx: 1 loss: 0.0007265288760602158 R2: 0.9163961277019583 time: 1703093473.4815514\n",
      "batch_idx: 2 loss: 0.0015279626837698013 R2: 0.9163897764293892 time: 1703093476.0700336\n",
      "batch_idx: 3 loss: 0.0008204454889511202 R2: 0.9163642070626562 time: 1703093478.7094197\n",
      "Training [83%] Loss: 0.0011318415902110727 time: 1703093478.7094197\n",
      "weight: [ 1.47644975  1.53411228  1.18635248  0.61048645 -0.13369557  0.108255\n",
      "  1.24515182 -1.06865996 -0.98413452 -0.18039975  0.69647676  0.86709652]\n",
      "epoch 417\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001452253704648508 R2: 0.9163909492475202 time: 1703093481.2753444\n",
      "batch_idx: 1 loss: 0.0007264820964307967 R2: 0.9163989479762383 time: 1703093483.8814435\n",
      "batch_idx: 2 loss: 0.0015279686964063024 R2: 0.9163925885947608 time: 1703093486.455062\n",
      "batch_idx: 3 loss: 0.0008205126077492468 R2: 0.9163670405935281 time: 1703093489.1099796\n",
      "Training [83%] Loss: 0.0011318042763087135 time: 1703093489.1099796\n",
      "weight: [ 1.47664225  1.53416294  1.18636421  0.60978224 -0.13300452  0.10775115\n",
      "  1.24542597 -1.06915619 -0.9848933  -0.18040527  0.6965092   0.86705656]\n",
      "epoch 418\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014520797973937038 R2: 0.9163937692496095 time: 1703093491.6625333\n",
      "batch_idx: 1 loss: 0.0007264361541892209 R2: 0.9164017503817249 time: 1703093494.2952476\n",
      "batch_idx: 2 loss: 0.00152797420409531 R2: 0.9163953830692874 time: 1703093496.876595\n",
      "batch_idx: 3 loss: 0.0008205786585086548 R2: 0.9163698565828848 time: 1703093499.4489274\n",
      "Training [84%] Loss: 0.0011317672035467223 time: 1703093499.4489274\n",
      "weight: [ 1.47683329  1.53421396  1.18637679  0.60907832 -0.13231384  0.10724693\n",
      "  1.24570012 -1.06965057 -0.98564304 -0.18041084  0.6965416   0.86701669]\n",
      "epoch 419\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014519075691646539 R2: 0.9163965714656669 time: 1703093502.042859\n",
      "batch_idx: 1 loss: 0.0007263910364455987 R2: 0.9164045351770878 time: 1703093504.6139438\n",
      "batch_idx: 2 loss: 0.0015279792136495924 R2: 0.9163981601090244 time: 1703093507.2484019\n",
      "batch_idx: 3 loss: 0.0008206436544758828 R2: 0.9163726552840987 time: 1703093509.7905774\n",
      "Training [84%] Loss: 0.0011317303684339319 time: 1703093509.7905774\n",
      "weight: [ 1.47702291  1.53426533  1.18639021  0.6083747  -0.13162353  0.10674232\n",
      "  1.24597424 -1.0701431  -0.98638385 -0.18041647  0.69657395  0.86697692]\n",
      "epoch 420\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014517369991361019 R2: 0.9163993561517702 time: 1703093512.4578683\n",
      "batch_idx: 1 loss: 0.0007263467305065655 R2: 0.9164073026155822 time: 1703093515.0044174\n",
      "batch_idx: 2 loss: 0.0015279837318167904 R2: 0.91640091996466 time: 1703093517.5271082\n",
      "batch_idx: 3 loss: 0.000820707608749881 R2: 0.9163754369452389 time: 1703093520.1670523\n",
      "Training [84%] Loss: 0.0011316937675523346 time: 1703093520.1670523\n",
      "weight: [ 1.47721111  1.53431706  1.18640446  0.60767137 -0.13093359  0.10623735\n",
      "  1.24624835 -1.07063381 -0.98711584 -0.18042214  0.69660626  0.86693725]\n",
      "epoch 421\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014515680667864443 R2: 0.9164021235586818 time: 1703093522.7069268\n",
      "batch_idx: 1 loss: 0.0007263032238726379 R2: 0.9164100529452007 time: 1703093525.319007\n",
      "batch_idx: 2 loss: 0.0015279877652791933 R2: 0.916403662881663 time: 1703093527.8648498\n",
      "batch_idx: 3 loss: 0.0008207705342834889 R2: 0.916378201809189 time: 1703093530.6452043\n",
      "Training [84%] Loss: 0.0011316573975554411 time: 1703093530.6452043\n",
      "weight: [ 1.47739791  1.53436914  1.18641954  0.60696833 -0.13024402  0.105732\n",
      "  1.24652243 -1.0711227  -0.98783911 -0.18042786  0.69663852  0.86689768]\n",
      "epoch 422\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014514007518925778 R2: 0.9164048739319572 time: 1703093533.688643\n",
      "batch_idx: 1 loss: 0.0007262605042350002 R2: 0.9164127864087657 time: 1703093536.2931695\n",
      "batch_idx: 2 loss: 0.0015279913206544863 R2: 0.9164063891003688 time: 1703093538.8829973\n",
      "batch_idx: 3 loss: 0.0008208324438840824 R2: 0.9163809501137713 time: 1703093541.410523\n",
      "Training [84%] Loss: 0.0011316212551665367 time: 1703093541.410523\n",
      "weight: [ 1.47758332  1.53442156  1.18643543  0.60626558 -0.12955482  0.10522627\n",
      "  1.24679649 -1.0716098  -0.98855375 -0.18043362  0.69667074  0.8668582 ]\n",
      "epoch 423\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014512350345250282 R2: 0.9164076075120692 time: 1703093543.9835744\n",
      "batch_idx: 1 loss: 0.0007262185594737208 R2: 0.9164155032440725 time: 1703093546.5412414\n",
      "batch_idx: 2 loss: 0.0015279944044942091 R2: 0.9164090988561309 time: 1703093549.115849\n",
      "batch_idx: 3 loss: 0.0008208933502162556 R2: 0.9163836820918474 time: 1703093551.626497\n",
      "Training [85%] Loss: 0.0011315853371773035 time: 1703093551.626497\n",
      "weight: [ 1.47776736  1.53447432  1.18645215  0.60556312 -0.12886599  0.10472018\n",
      "  1.24707052 -1.07209511 -0.98925987 -0.18043943  0.69670293  0.86681881]\n",
      "epoch 424\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014510708950427513 R2: 0.9164103245345198 time: 1703093554.154666\n",
      "batch_idx: 1 loss: 0.0007261773776524821 R2: 0.9164182036839874 time: 1703093556.693718\n",
      "batch_idx: 2 loss: 0.0015279970232880986 R2: 0.916411792379407 time: 1703093559.3142881\n",
      "batch_idx: 3 loss: 0.0008209532657994448 R2: 0.9163863979714885 time: 1703093561.9207182\n",
      "Training [85%] Loss: 0.0011315496404456942 time: 1703093561.9207182\n",
      "weight: [ 1.47795004  1.53452742  1.18646967  0.60486094 -0.12817753  0.10421371\n",
      "  1.24734451 -1.07257866 -0.98995757 -0.18044529  0.69673507  0.86677952]\n",
      "epoch 425\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014509083140889975 R2: 0.9164130252299654 time: 1703093564.5418909\n",
      "batch_idx: 1 loss: 0.0007261369470229962 R2: 0.9164208879565624 time: 1703093567.1665256\n",
      "batch_idx: 2 loss: 0.0015279991834528622 R2: 0.9164144698959028 time: 1703093569.7833605\n",
      "batch_idx: 3 loss: 0.0008210122030189714 R2: 0.9163890979759092 time: 1703093572.4747875\n",
      "Training [85%] Loss: 0.0011315141618959568 time: 1703093572.4747875\n",
      "weight: [ 1.47813137  1.53458085  1.186488    0.60415904 -0.12748945  0.10370688\n",
      "  1.24761847 -1.07306045 -0.99064694 -0.18045119  0.69676717  0.86674032]\n",
      "epoch 426\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014507472725846975 R2: 0.9164157098243054 time: 1703093575.0335326\n",
      "batch_idx: 1 loss: 0.0007260972560018323 R2: 0.9164235562851625 time: 1703093577.670469\n",
      "batch_idx: 2 loss: 0.0015280008913642275 R2: 0.9164171316266148 time: 1703093580.2341444\n",
      "batch_idx: 3 loss: 0.0008210701740997324 R2: 0.9163917823240963 time: 1703093582.8912387\n",
      "Training [85%] Loss: 0.0011314788985126224 time: 1703093582.8912387\n",
      "weight: [ 1.47831136  1.53463461  1.18650713  0.60345742 -0.12680174  0.10319968\n",
      "  1.24789239 -1.0735405  -0.99132809 -0.18045713  0.69679923  0.8667012 ]\n",
      "epoch 427\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014505877517293933 R2: 0.9164183785388216 time: 1703093585.4597452\n",
      "batch_idx: 1 loss: 0.0007260582932289462 R2: 0.9164262088885395 time: 1703093588.1473916\n",
      "batch_idx: 2 loss: 0.001528002153264658 R2: 0.9164197777881073 time: 1703093590.9589825\n",
      "batch_idx: 3 loss: 0.0008211271911875753 R2: 0.9163944512293888 time: 1703093593.6041136\n",
      "Training [85%] Loss: 0.0011314438473526431 time: 1703093593.6041136\n",
      "weight: [ 1.47849003  1.53468869  1.18652706  0.60275609 -0.1261144   0.10269211\n",
      "  1.24816626 -1.07401883 -0.99200109 -0.18046311  0.69683125  0.86666221]\n",
      "epoch 428\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014504297329799107 R2: 0.9164210315902179 time: 1703093596.3495593\n",
      "batch_idx: 1 loss: 0.0007260200473771033 R2: 0.9164288459809932 time: 1703093599.1938086\n",
      "batch_idx: 2 loss: 0.0015280029755404035 R2: 0.9164224085921264 time: 1703093601.9211385\n",
      "batch_idx: 3 loss: 0.0008211832661104961 R2: 0.9163971049041203 time: 1703093604.4802465\n",
      "Training [86%] Loss: 0.0011314090055019783 time: 1703093604.4802465\n",
      "weight: [ 1.4786674   1.5347431   1.18654778  0.60205502 -0.12542744  0.10218417\n",
      "  1.24844009 -1.07449545 -0.99266606 -0.18046914  0.69686323  0.8666232 ]\n",
      "epoch 429\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014502731980971725 R2: 0.9164236691909279 time: 1703093607.1228719\n",
      "batch_idx: 1 loss: 0.000725982507745217 R2: 0.9164314677723399 time: 1703093609.7375295\n",
      "batch_idx: 2 loss: 0.001528003363866278 R2: 0.9164250242472128 time: 1703093612.3416624\n",
      "batch_idx: 3 loss: 0.0008212384111216815 R2: 0.9163997435457876 time: 1703093614.9454467\n",
      "Training [86%] Loss: 0.0011313743702075871 time: 1703093614.9454467\n",
      "weight: [ 1.47884346  1.53479782  1.18656929  0.60135424 -0.12474085  0.10167587\n",
      "  1.24871387 -1.07497037 -0.99332308 -0.18047521  0.69689518  0.86658461]\n",
      "epoch 430\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014501181289811884 R2: 0.9164262915485384 time: 1703093617.597302\n",
      "batch_idx: 1 loss: 0.0007259456623092507 R2: 0.9164340744683981 time: 1703093620.2665932\n",
      "batch_idx: 2 loss: 0.0015280033259323683 R2: 0.9164276249540247 time: 1703093622.8529384\n",
      "batch_idx: 3 loss: 0.0008212926365365669 R2: 0.9164023673813801 time: 1703093625.5280461\n",
      "Training [86%] Loss: 0.0011313399384398435 time: 1703093625.5280461\n",
      "weight: [ 1.47901825  1.53485286  1.18659157  0.60065372 -0.12405463  0.10116721\n",
      "  1.2489876  -1.07544361 -0.99397225 -0.18048132  0.69692708  0.86654503]\n",
      "epoch 431\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001449964508183091 R2: 0.9164288988681195 time: 1703093628.129028\n",
      "batch_idx: 1 loss: 0.0007259095042687442 R2: 0.9164366662698453 time: 1703093630.8022668\n",
      "batch_idx: 2 loss: 0.0015280028624867783 R2: 0.9164302109208793 time: 1703093633.3748438\n",
      "batch_idx: 3 loss: 0.0008213459584924682 R2: 0.9164049765223238 time: 1703093635.9683046\n",
      "Training [86%] Loss: 0.0011313057083577704 time: 1703093635.9683046\n",
      "weight: [ 1.47919177  1.5349082   1.18661464  0.59995348 -0.12336879  0.10065819\n",
      "  1.24926128 -1.07591518 -0.99461365 -0.18048747  0.69695897  0.8665092 ]\n",
      "epoch 432\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001449812317189793 R2: 0.9164314913448252 time: 1703093638.6445546\n",
      "batch_idx: 1 loss: 0.0007258740093553138 R2: 0.91643924337653 time: 1703093641.1866748\n",
      "batch_idx: 2 loss: 0.00152800199766236 R2: 0.9164327823125056 time: 1703093643.899266\n",
      "batch_idx: 3 loss: 0.0008213983726250409 R2: 0.9164075714541994 time: 1703093646.556093\n",
      "Training [86%] Loss: 0.001131271674208127 time: 1703093646.556093\n",
      "weight: [ 1.47936402  1.53496386  1.18663847  0.59925351 -0.12268333  0.10014881\n",
      "  1.24953489 -1.07638509 -0.99524738 -0.18049366  0.69699074  0.86646064]\n",
      "epoch 433\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014496615421683797 R2: 0.9164340691894729 time: 1703093649.1595457\n",
      "batch_idx: 1 loss: 0.0007258392166272654 R2: 0.9164418059726798 time: 1703093651.6948407\n",
      "batch_idx: 2 loss: 0.0015280006733300012 R2: 0.9164353394271954 time: 1703093654.3040369\n",
      "batch_idx: 3 loss: 0.0008214499447221603 R2: 0.9164101513132767 time: 1703093656.8755393\n",
      "Training [87%] Loss: 0.0011312378442119516 time: 1703093656.8755393\n",
      "weight: [ 1.47953504  1.53501981  1.18666307  0.5985538  -0.12199823  0.09963908\n",
      "  1.24980845 -1.07685336 -0.99587352 -0.1804999   0.69702279  0.86645821]\n",
      "epoch 434\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001449512153158862 R2: 0.91643663253565 time: 1703093659.4976206\n",
      "batch_idx: 1 loss: 0.0007258049311335939 R2: 0.9164443542798099 time: 1703093662.1022506\n",
      "batch_idx: 2 loss: 0.0015279991291092965 R2: 0.9164378820839485 time: 1703093664.7316766\n",
      "batch_idx: 3 loss: 0.0008215004709508598 R2: 0.916412719829291 time: 1703093667.38987\n",
      "Training [87%] Loss: 0.001131204171088153 time: 1703093667.38987\n",
      "weight: [ 1.47970481  1.53507607  1.18668844  0.59785436 -0.12131352  0.09912898\n",
      "  1.25008194 -1.07732    -0.99649216 -0.18050615  0.69705363  0.86628592]\n",
      "epoch 435\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014493641674620601 R2: 0.9164391817317604 time: 1703093670.000513\n",
      "batch_idx: 1 loss: 0.0007257718268898238 R2: 0.9164468883467972 time: 1703093672.6688588\n",
      "batch_idx: 2 loss: 0.0015279965140411944 R2: 0.9164404120511401 time: 1703093675.2837882\n",
      "batch_idx: 3 loss: 0.0008215505074739999 R2: 0.9164152596986325 time: 1703093677.9454386\n",
      "Training [87%] Loss: 0.0011311707539667696 time: 1703093677.9454386\n",
      "weight: [ 1.47987337  1.53513261  1.18671455  0.59715518 -0.12062918  0.09861853\n",
      "  1.25035536 -1.07778502 -0.9971034  -0.18051251  0.69708886  0.86676008]\n",
      "epoch 436\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014492172562963433 R2: 0.9164417156002711 time: 1703093680.464654\n",
      "batch_idx: 1 loss: 0.0007257369151269737 R2: 0.9164494086406453 time: 1703093683.0357864\n",
      "batch_idx: 2 loss: 0.0015279963706843352 R2: 0.916442926918171 time: 1703093685.7499835\n",
      "batch_idx: 3 loss: 0.000821594093708832 R2: 0.9164177744162314 time: 1703093688.264307\n",
      "Training [87%] Loss: 0.001131136158954121 time: 1703093688.264307\n",
      "weight: [ 1.4800406   1.53518957  1.18674154  0.59645636 -0.11994532  0.09810779\n",
      "  1.25062882 -1.07824855 -0.99770722 -0.18051862  0.69710709  0.86474396]\n",
      "epoch 437\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001449069552964253 R2: 0.9164442273495382 time: 1703093690.8979106\n",
      "batch_idx: 1 loss: 0.0007257066771985334 R2: 0.9164519104777169 time: 1703093693.4854636\n",
      "batch_idx: 2 loss: 0.0015279888812672036 R2: 0.9164454907226085 time: 1703093696.19591\n",
      "batch_idx: 3 loss: 0.0008215985012123561 R2: 0.9164193263905253 time: 1703093698.7766857\n",
      "Training [87%] Loss: 0.0011310909031605864 time: 1703093698.7766857\n",
      "weight: [ 1.48020581  1.5352476   1.18677003  0.59575848 -0.1192626   0.09759721\n",
      "  1.25090293 -1.07871119 -0.99830315 -0.18052524  0.69719245  0.87231663]\n",
      "epoch 438\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001448899170744768 R2: 0.9164466170309582 time: 1703093701.3505483\n",
      "batch_idx: 1 loss: 0.0007257037827316182 R2: 0.9164543866133952 time: 1703093703.9556067\n",
      "batch_idx: 2 loss: 0.0015279995672962665 R2: 0.916447763544498 time: 1703093706.6856647\n",
      "batch_idx: 3 loss: 0.0008216087857450437 R2: 0.9164218538360498 time: 1703093709.2756746\n",
      "Training [88%] Loss: 0.001131052826629424 time: 1703093709.2756746\n",
      "weight: [ 1.48036556  1.53531005  1.18680333  0.59506437 -0.11858419  0.09708816\n",
      "  1.25118075 -1.079176   -0.9988888  -0.18052772  0.69708644  0.85884633]\n",
      "epoch 439\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001448746519834361 R2: 0.9164490412624581 time: 1703093711.8915665\n",
      "batch_idx: 1 loss: 0.0007256832037875889 R2: 0.9164568525546176 time: 1703093714.5268512\n",
      "batch_idx: 2 loss: 0.001527965221805813 R2: 0.9164500304678723 time: 1703093717.1825845\n",
      "batch_idx: 3 loss: 0.0008217763294467789 R2: 0.916425857246376 time: 1703093719.8480034\n",
      "Training [88%] Loss: 0.0011310428187186355 time: 1703093719.8480034\n",
      "weight: [ 1.48053083  1.53536643  1.18683121  0.5943649  -0.11790001  0.09657607\n",
      "  1.25145258 -1.07963352 -0.9994728  -0.18053528  0.69721033  0.8659909 ]\n",
      "epoch 440\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014486359598821442 R2: 0.9164516880558103 time: 1703093722.486798\n",
      "batch_idx: 1 loss: 0.000725590795862805 R2: 0.916459356294714 time: 1703093725.138457\n",
      "batch_idx: 2 loss: 0.0015279899819314001 R2: 0.9164532116645316 time: 1703093727.7842653\n",
      "batch_idx: 3 loss: 0.0008217163824464357 R2: 0.9164263725255019 time: 1703093730.3991199\n",
      "Training [88%] Loss: 0.0011309832800306962 time: 1703093730.3991199\n",
      "weight: [ 1.48070355  1.53541479  1.18685173  0.59365862 -0.11720832  0.09605958\n",
      "  1.2517167  -1.08008203 -1.00005667 -0.18054713  0.69731443  0.87197201]\n",
      "epoch 441\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001448558857781641 R2: 0.9164543846482192 time: 1703093733.0612173\n",
      "batch_idx: 1 loss: 0.0007256044832280868 R2: 0.9164617855292031 time: 1703093735.7051587\n",
      "batch_idx: 2 loss: 0.001527947339000781 R2: 0.91645499955539 time: 1703093738.353856\n",
      "batch_idx: 3 loss: 0.0008218957447946408 R2: 0.9164311129055053 time: 1703093740.9132695\n",
      "Training [88%] Loss: 0.0011310016062012875 time: 1703093740.9132695\n",
      "weight: [ 1.48085038  1.53548712  1.18689603  0.59297306 -0.11653977  0.09555266\n",
      "  1.25200266 -1.08055031 -1.00061358 -0.18054692  0.6973019   0.86857535]\n",
      "epoch 442\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014482668669105918 R2: 0.9164562386666406 time: 1703093743.5040205\n",
      "batch_idx: 1 loss: 0.0007255950095071334 R2: 0.916464223150298 time: 1703093746.0590992\n",
      "batch_idx: 2 loss: 0.001527979874202687 R2: 0.9164576696257202 time: 1703093748.7272806\n",
      "batch_idx: 3 loss: 0.000821840451409694 R2: 0.916432441387727 time: 1703093751.3473477\n",
      "Training [88%] Loss: 0.0011309205505075266 time: 1703093751.3473477\n",
      "weight: [ 1.48102142  1.53553543  1.18691743  0.59226687 -0.11584831  0.09503584\n",
      "  1.25226603 -1.08099524 -1.00118441 -0.18055891  0.6972661   0.86457055]\n",
      "epoch 443\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014483018035734638 R2: 0.9164593537475143 time: 1703093754.1567376\n",
      "batch_idx: 1 loss: 0.0007254566155457135 R2: 0.9164666893887506 time: 1703093756.9032335\n",
      "batch_idx: 2 loss: 0.0015280027845269984 R2: 0.9164604265020702 time: 1703093759.567553\n",
      "batch_idx: 3 loss: 0.0008218842430745405 R2: 0.9164348818209762 time: 1703093762.1656992\n",
      "Training [89%] Loss: 0.0011309113616801791 time: 1703093762.1656992\n",
      "weight: [ 1.48118092  1.53559396  1.1869492   0.59156949 -0.11516678  0.09452241\n",
      "  1.25253858 -1.08144756 -1.0017396  -0.18056543  0.69729978  0.86467911]\n",
      "epoch 444\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014480921510206086 R2: 0.9164615010672608 time: 1703093764.7821243\n",
      "batch_idx: 1 loss: 0.0007255172270696259 R2: 0.9164690758501937 time: 1703093767.4685133\n",
      "batch_idx: 2 loss: 0.0015279488166310578 R2: 0.9164623422460776 time: 1703093770.1804736\n",
      "batch_idx: 3 loss: 0.0008219972947861368 R2: 0.91643813059522 time: 1703093772.9101958\n",
      "Training [89%] Loss: 0.0011308888723768572 time: 1703093772.9101958\n",
      "weight: [ 1.48133203  1.53565969  1.18698845  0.59087836 -0.11449228  0.09401152\n",
      "  1.25281747 -1.08190459 -1.00228208 -0.18056823  0.69737678  0.8674422 ]\n",
      "epoch 445\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001447916537413702 R2: 0.9164637628854277 time: 1703093775.5023293\n",
      "batch_idx: 1 loss: 0.000725483534660579 R2: 0.9164714811781008 time: 1703093778.164816\n",
      "batch_idx: 2 loss: 0.001527955036867017 R2: 0.9164650186445444 time: 1703093780.8659978\n",
      "batch_idx: 3 loss: 0.0008219870843257912 R2: 0.9164397133104532 time: 1703093783.5647802\n",
      "Training [89%] Loss: 0.0011308355483167722 time: 1703093783.5647802\n",
      "weight: [ 1.4814962   1.53571212  1.18701521  0.59017582 -0.11380515  0.09349493\n",
      "  1.2530837  -1.08234795 -1.00282959 -0.18057798  0.6974209   0.8684815 ]\n",
      "epoch 446\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014478625323185398 R2: 0.9164664821326497 time: 1703093786.295611\n",
      "batch_idx: 1 loss: 0.0007254241620428955 R2: 0.9164738847886106 time: 1703093788.9482968\n",
      "batch_idx: 2 loss: 0.0015279538496361512 R2: 0.9164674248867474 time: 1703093791.835393\n",
      "batch_idx: 3 loss: 0.00082204642208186 R2: 0.9164424842326955 time: 1703093794.4571168\n",
      "Training [89%] Loss: 0.0011308217415198617 time: 1703093794.4571168\n",
      "weight: [ 1.48164975  1.53577393  1.18705154  0.58948137 -0.11312715  0.09298145\n",
      "  1.25335828 -1.08279802 -1.0033628  -0.18058325  0.69743328  0.86712695]\n",
      "epoch 447\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014476758972508227 R2: 0.9164686617467057 time: 1703093797.1107922\n",
      "batch_idx: 1 loss: 0.0007254307639653028 R2: 0.9164762499169317 time: 1703093799.7302349\n",
      "batch_idx: 2 loss: 0.001527940306548523 R2: 0.9164696238688691 time: 1703093802.209238\n",
      "batch_idx: 3 loss: 0.0008220938099819939 R2: 0.9164450684953079 time: 1703093804.7494566\n",
      "Training [89%] Loss: 0.0011307851944366606 time: 1703093804.7494566\n",
      "weight: [ 1.4818029   1.53583532  1.18708793  0.58878661 -0.1124489   0.09246756\n",
      "  1.25363213 -1.08324603 -1.00389015 -0.18058896  0.69744609  0.8658213 ]\n",
      "epoch 448\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001447551863478019 R2: 0.9164710686459661 time: 1703093807.2029421\n",
      "batch_idx: 1 loss: 0.0007253834312264509 R2: 0.9164786244158167 time: 1703093809.8388853\n",
      "batch_idx: 2 loss: 0.0015279450790322917 R2: 0.9164721498562802 time: 1703093812.4406223\n",
      "batch_idx: 3 loss: 0.0008221112625408196 R2: 0.9164471146371286 time: 1703093815.0619833\n",
      "Training [90%] Loss: 0.0011307479090693954 time: 1703093815.0619833\n",
      "weight: [ 1.48195996  1.53589219  1.18712036  0.58808798 -0.11176643  0.09195154\n",
      "  1.25390146 -1.08368827 -1.00441516 -0.18059714  0.69748005  0.86607089]\n",
      "epoch 449\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014474490916951573 R2: 0.9164735459640194 time: 1703093817.5044289\n",
      "batch_idx: 1 loss: 0.0007253548611808488 R2: 0.9164809802545951 time: 1703093820.1456494\n",
      "batch_idx: 2 loss: 0.0015279308162072561 R2: 0.9164744631510903 time: 1703093822.6556432\n",
      "batch_idx: 3 loss: 0.0008221678950886488 R2: 0.9164496740687722 time: 1703093825.1987467\n",
      "Training [90%] Loss: 0.0011307256660429777 time: 1703093825.1987467\n",
      "weight: [ 1.48211076  1.53595427  1.18715833  0.58739384 -0.1110891   0.09143686\n",
      "  1.25417529 -1.08413353 -1.00492958 -0.18060286  0.69752656  0.86701098]\n",
      "epoch 450\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014472886650071654 R2: 0.9164757799585944 time: 1703093827.71866\n",
      "batch_idx: 1 loss: 0.0007253517203839844 R2: 0.9164833133792614 time: 1703093830.283833\n",
      "batch_idx: 2 loss: 0.001527915874003192 R2: 0.9164767239513909 time: 1703093832.9115975\n",
      "batch_idx: 3 loss: 0.0008222098960365971 R2: 0.9164520797512081 time: 1703093835.375528\n",
      "Training [90%] Loss: 0.0011306915388577348 time: 1703093835.375528\n",
      "weight: [ 1.48226189  1.53601528  1.1871957   0.58669881 -0.11041087  0.09092156\n",
      "  1.25444778 -1.08457617 -1.00543896 -0.18060936  0.6975604   0.86714667]\n",
      "epoch 451\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014471682802463311 R2: 0.91647815359279 time: 1703093837.9891865\n",
      "batch_idx: 1 loss: 0.0007253143305819455 R2: 0.9164856493009665 time: 1703093840.490885\n",
      "batch_idx: 2 loss: 0.0015279166229083187 R2: 0.9164791391390693 time: 1703093843.0994496\n",
      "batch_idx: 3 loss: 0.0008222336992784148 R2: 0.9164542789177844 time: 1703093845.709403\n",
      "Training [90%] Loss: 0.0011306582332537526 time: 1703093845.709403\n",
      "weight: [ 1.48241408  1.53607451  1.18723179  0.58600229 -0.10973109  0.09040523\n",
      "  1.25471829 -1.08501557 -1.00594393 -0.18061698  0.69758213  0.86653212]\n",
      "epoch 452\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014470550058347793 R2: 0.9164805381542903 time: 1703093848.3175113\n",
      "batch_idx: 1 loss: 0.0007252857434290794 R2: 0.9164879699430143 time: 1703093850.997918\n",
      "batch_idx: 2 loss: 0.0015279087466727602 R2: 0.9164814311982351 time: 1703093853.4774263\n",
      "batch_idx: 3 loss: 0.0008222768441540244 R2: 0.9164567355540983 time: 1703093856.1278052\n",
      "Training [90%] Loss: 0.0011306315850226607 time: 1703093856.1278052\n",
      "weight: [ 1.48256251  1.53613659  1.18727111  0.58530823 -0.10905418  0.0898893\n",
      "  1.2549911  -1.0854559  -1.00644058 -0.18062333  0.69760883  0.8661633 ]\n",
      "epoch 453\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014469137271196967 R2: 0.9164827972531728 time: 1703093858.6905727\n",
      "batch_idx: 1 loss: 0.0007252713080621459 R2: 0.9164902737792827 time: 1703093861.3701277\n",
      "batch_idx: 2 loss: 0.0015278974443596158 R2: 0.9164837031662124 time: 1703093863.9913905\n",
      "batch_idx: 3 loss: 0.0008223142824023193 R2: 0.9164590691247698 time: 1703093866.6488867\n",
      "Training [91%] Loss: 0.0011305991904859444 time: 1703093866.6488867\n",
      "weight: [ 1.48271092  1.53619794  1.18731017  0.58461357 -0.10837672  0.08937288\n",
      "  1.2552629  -1.08589396 -1.00693204 -0.1806302   0.69764362  0.86639188]\n",
      "epoch 454\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001446794557865695 R2: 0.9164851284496022 time: 1703093869.2486825\n",
      "batch_idx: 1 loss: 0.0007252426509649852 R2: 0.9164925725051759 time: 1703093871.915243\n",
      "batch_idx: 2 loss: 0.0015278908804410136 R2: 0.9164860417727565 time: 1703093874.6145513\n",
      "batch_idx: 3 loss: 0.0008223449139976921 R2: 0.9164613016459334 time: 1703093877.1793\n",
      "Training [91%] Loss: 0.0011305682508173465 time: 1703093877.1793\n",
      "weight: [ 1.48285913  1.53625875  1.18734914  0.58391847 -0.10769888  0.0888559\n",
      "  1.25553387 -1.08632993 -1.00741821 -0.18063748  0.69767835  0.86664958]\n",
      "epoch 455\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014466753373947832 R2: 0.9164874437100098 time: 1703093879.8819642\n",
      "batch_idx: 1 loss: 0.0007252211425977267 R2: 0.9164948573218001 time: 1703093882.5120544\n",
      "batch_idx: 2 loss: 0.0015278803528518967 R2: 0.9164883001405139 time: 1703093885.2164626\n",
      "batch_idx: 3 loss: 0.0008223843620213354 R2: 0.9164636852300557 time: 1703093887.8917828\n",
      "Training [91%] Loss: 0.0011305402987164355 time: 1703093887.8917828\n",
      "weight: [ 1.4830049   1.53632116  1.18739013  0.58322477 -0.10702274  0.08833891\n",
      "  1.25580599 -1.08676576 -1.00789734 -0.18064408  0.69770815  0.86650873]\n",
      "epoch 456\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014465444656114853 R2: 0.9164896975421455 time: 1703093890.6372337\n",
      "batch_idx: 1 loss: 0.0007252022535308632 R2: 0.9164971302888981 time: 1703093893.258485\n",
      "batch_idx: 2 loss: 0.0015278714684836933 R2: 0.9164905637553081 time: 1703093895.9094641\n",
      "batch_idx: 3 loss: 0.0008224163628575882 R2: 0.916465968669925 time: 1703093898.609838\n",
      "Training [91%] Loss: 0.0011305086376209076 time: 1703093898.609838\n",
      "weight: [ 1.48315053  1.53638298  1.18743098  0.58253058 -0.10634618  0.08782145\n",
      "  1.25607722 -1.08719947 -1.00837139 -0.18065111  0.69773579  0.86624365]\n",
      "epoch 457\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014464284537264813 R2: 0.9164919944957635 time: 1703093901.2302296\n",
      "batch_idx: 1 loss: 0.0007251755884223919 R2: 0.9164993957421353 time: 1703093904.0156264\n",
      "batch_idx: 2 loss: 0.0015278639655973824 R2: 0.9164928497365186 time: 1703093906.6741161\n",
      "batch_idx: 3 loss: 0.000822447312319921 R2: 0.9164682199274099 time: 1703093909.3698328\n",
      "Training [91%] Loss: 0.001130478830016544 time: 1703093909.3698328\n",
      "weight: [ 1.48329535  1.53644486  1.18747235  0.58183648 -0.10566983  0.0873036\n",
      "  1.25634817 -1.08763168 -1.00883983 -0.18065825  0.69776662  0.86621276]\n",
      "epoch 458\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001446308895491254 R2: 0.9164942629831441 time: 1703093911.9809248\n",
      "batch_idx: 1 loss: 0.000725156266466662 R2: 0.9165016477623172 time: 1703093914.690174\n",
      "batch_idx: 2 loss: 0.0015278523131703387 R2: 0.916495082102186 time: 1703093917.3097792\n",
      "batch_idx: 3 loss: 0.0008224835858862363 R2: 0.9164705365803483 time: 1703093919.933761\n",
      "Training [92%] Loss: 0.0011304502652536227 time: 1703093919.933761\n",
      "weight: [ 1.48343843  1.53650768  1.18751507  0.5811432  -0.10499455  0.08678558\n",
      "  1.25661967 -1.08806318 -1.00930197 -0.18066503  0.69779968  0.86631987]\n",
      "epoch 459\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014461848876887915 R2: 0.9164964993851562 time: 1703093922.5873759\n",
      "batch_idx: 1 loss: 0.0007251377086282485 R2: 0.9165038890306174 time: 1703093925.1994593\n",
      "batch_idx: 2 loss: 0.0015278418886466158 R2: 0.9164973202560136 time: 1703093927.8618777\n",
      "batch_idx: 3 loss: 0.0008225146125585255 R2: 0.9164727851995165 time: 1703093930.5496674\n",
      "Training [92%] Loss: 0.0011304197743805453 time: 1703093930.5496674\n",
      "weight: [ 1.48358112  1.53657017  1.18755792  0.58044967 -0.10431911  0.08626721\n",
      "  1.25689053 -1.08849286 -1.00975898 -0.18067211  0.69783065  0.86629588]\n",
      "epoch 460\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014460698477501853 R2: 0.9164987561014751 time: 1703093933.3034248\n",
      "batch_idx: 1 loss: 0.0007251147606372365 R2: 0.9165061217153309 time: 1703093935.9854882\n",
      "batch_idx: 2 loss: 0.001527832689398148 R2: 0.9164995616132835 time: 1703093938.659365\n",
      "batch_idx: 3 loss: 0.0008225448429420446 R2: 0.9164750282201195 time: 1703093941.1685386\n",
      "Training [92%] Loss: 0.0011303905351819036 time: 1703093941.1685386\n",
      "weight: [ 1.48372284  1.5366329   1.18760144  0.57975637 -0.10364407  0.08574845\n",
      "  1.25716127 -1.08892122 -1.01021045 -0.18067921  0.69786007  0.86615676]\n",
      "epoch 461\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014459525032267384 R2: 0.9165009892355507 time: 1703093943.7023551\n",
      "batch_idx: 1 loss: 0.0007250956963296901 R2: 0.9165083426124184 time: 1703093946.2901387\n",
      "batch_idx: 2 loss: 0.0015278214697544868 R2: 0.9165017707504232 time: 1703093948.8343437\n",
      "batch_idx: 3 loss: 0.0008225771773708741 R2: 0.916477295235334 time: 1703093951.517217\n",
      "Training [92%] Loss: 0.0011303617116704473 time: 1703093951.517217\n",
      "weight: [ 1.48386326  1.53669617  1.18764593  0.57906357 -0.10296971  0.08522944\n",
      "  1.25743218 -1.08934855 -1.01065615 -0.18068617  0.69789061  0.86608946]\n",
      "epoch 462\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014458341610392002 R2: 0.9165032042701581 time: 1703093954.158298\n",
      "batch_idx: 1 loss: 0.0007250769717526415 R2: 0.9165105532750234 time: 1703093956.7580462\n",
      "batch_idx: 2 loss: 0.001527810458023749 R2: 0.9165039807768427 time: 1703093959.303619\n",
      "batch_idx: 3 loss: 0.0008226068033363777 R2: 0.9164795170044757 time: 1703093961.9493892\n",
      "Training [92%] Loss: 0.0011303320985379922 time: 1703093961.9493892\n",
      "weight: [ 1.48400306  1.53675935  1.18769077  0.57837071 -0.10229543  0.08471017\n",
      "  1.25770267 -1.08977431 -1.0110967  -0.18069331  0.69792211  0.86610877]\n",
      "epoch 463\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014457205966737214 R2: 0.9165054239035738 time: 1703093964.6911473\n",
      "batch_idx: 1 loss: 0.0007250569551042431 R2: 0.9165127544372261 time: 1703093967.476995\n",
      "batch_idx: 2 loss: 0.0015277995124045192 R2: 0.9165061840776699 time: 1703093970.2441654\n",
      "batch_idx: 3 loss: 0.0008226362920059005 R2: 0.9164817379691923 time: 1703093972.8673556\n",
      "Training [93%] Loss: 0.001130303339047096 time: 1703093972.8673556\n",
      "weight: [ 1.48414184  1.53682282  1.18773633  0.57767812 -0.10162159  0.08419051\n",
      "  1.2579731  -1.09019883 -1.01153183 -0.18070043  0.69795308  0.86608677]\n",
      "epoch 464\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014456057273248499 R2: 0.9165076243573701 time: 1703093975.6336775\n",
      "batch_idx: 1 loss: 0.0007250390662432001 R2: 0.9165149448245616 time: 1703093978.1880727\n",
      "batch_idx: 2 loss: 0.001527787788217299 R2: 0.9165083670176616 time: 1703093980.7994397\n",
      "batch_idx: 3 loss: 0.0008226659819715876 R2: 0.9164839640303912 time: 1703093983.4292445\n",
      "Training [93%] Loss: 0.001130274640939234 time: 1703093983.4292445\n",
      "weight: [ 1.48427957  1.53688661  1.18778265  0.57698585 -0.10094825  0.08367058\n",
      "  1.2582435  -1.09062218 -1.01196156 -0.18070752  0.69798331  0.86600433]\n",
      "epoch 465\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014454916148880388 R2: 0.9165098138530319 time: 1703093986.137269\n",
      "batch_idx: 1 loss: 0.0007250207936453936 R2: 0.9165171255443172 time: 1703093988.7341282\n",
      "batch_idx: 2 loss: 0.0015277763696535812 R2: 0.9165105480652386 time: 1703093991.3981307\n",
      "batch_idx: 3 loss: 0.0008226938147314884 R2: 0.9164861606760214 time: 1703093994.111094\n",
      "Training [93%] Loss: 0.0011302456482296254 time: 1703093994.111094\n",
      "weight: [ 1.48441657  1.53695044  1.18782944  0.57629363 -0.10027512  0.0831504\n",
      "  1.2585136  -1.09104409 -1.01238622 -0.18071472  0.69801377  0.8659484 ]\n",
      "epoch 466\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001445380266832223 R2: 0.9165120004713712 time: 1703093996.7238202\n",
      "batch_idx: 1 loss: 0.000725002427047975 R2: 0.9165192965917865 time: 1703093999.4298384\n",
      "batch_idx: 2 loss: 0.0015277645250897647 R2: 0.9165127187858874 time: 1703094002.0762835\n",
      "batch_idx: 3 loss: 0.0008227218079756062 R2: 0.9164883557519529 time: 1703094004.7864833\n",
      "Training [93%] Loss: 0.0011302172567363921 time: 1703094004.7864833\n",
      "weight: [ 1.48455257  1.53701455  1.18787695  0.57560168 -0.09960244  0.08262983\n",
      "  1.25878362 -1.09146481 -1.01280564 -0.18072191  0.69804478  0.86593318]\n",
      "epoch 467\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014452682521666287 R2: 0.9165141709596215 time: 1703094007.423783\n",
      "batch_idx: 1 loss: 0.0007249856028530843 R2: 0.9165214574132168 time: 1703094010.0751798\n",
      "batch_idx: 2 loss: 0.0015277520942142571 R2: 0.9165148747108829 time: 1703094012.7455442\n",
      "batch_idx: 3 loss: 0.0008227495159617671 R2: 0.9164905463858316 time: 1703094015.6618652\n",
      "Training [93%] Loss: 0.0011301888662989343 time: 1703094015.6618652\n",
      "weight: [ 1.48468763  1.53707891  1.18792512  0.57490997 -0.09893016  0.08210902\n",
      "  1.25905355 -1.0918843  -1.01321991 -0.1807291   0.69807554  0.86589893]\n",
      "epoch 468\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014451574338056519 R2: 0.9165163326653444 time: 1703094018.5972555\n",
      "batch_idx: 1 loss: 0.0007249684616140694 R2: 0.9165236088309714 time: 1703094021.4528992\n",
      "batch_idx: 2 loss: 0.0015277398929055565 R2: 0.9165170261469481 time: 1703094024.183697\n",
      "batch_idx: 3 loss: 0.0008227758512374804 R2: 0.9164927174912177 time: 1703094026.9763696\n",
      "Training [94%] Loss: 0.0011301604098906896 time: 1703094026.9763696\n",
      "weight: [ 1.48482191  1.53714336  1.18797383  0.57421838 -0.09825817  0.08158794\n",
      "  1.25932323 -1.09230245 -1.01362922 -0.18073636  0.69810592  0.8658387 ]\n",
      "epoch 469\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014450484393071388 R2: 0.9165184881827091 time: 1703094029.8978434\n",
      "batch_idx: 1 loss: 0.0007249514684813319 R2: 0.9165257507588281 time: 1703094032.7052262\n",
      "batch_idx: 2 loss: 0.001527727351022828 R2: 0.9165191670089051 time: 1703094035.5147538\n",
      "batch_idx: 3 loss: 0.0008228021127413549 R2: 0.9164948850959999 time: 1703094038.31904\n",
      "Training [94%] Loss: 0.0011301323428881634 time: 1703094038.31904\n",
      "weight: [ 1.48495524  1.53720806  1.18802322  0.57352703 -0.0975866   0.08106648\n",
      "  1.25959281 -1.09271942 -1.01403348 -0.18074361  0.6981365   0.86579391]\n",
      "epoch 470\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014449394006207888 R2: 0.916520630409933 time: 1703094041.0327024\n",
      "batch_idx: 1 loss: 0.0007249355094936713 R2: 0.9165278829474286 time: 1703094043.7208674\n",
      "batch_idx: 2 loss: 0.0015277143441560605 R2: 0.9165212960886888 time: 1703094046.3725052\n",
      "batch_idx: 3 loss: 0.0008228279669454514 R2: 0.9164970444530965 time: 1703094048.9937937\n",
      "Training [94%] Loss: 0.001130104305303993 time: 1703094048.9937937\n",
      "weight: [ 1.48508769  1.53727297  1.18807324  0.57283588 -0.09691542  0.08054481\n",
      "  1.25986226 -1.09313516 -1.01443281 -0.18075087  0.69816726  0.86576489]\n",
      "epoch 471\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014448315226214521 R2: 0.9165227641649996 time: 1703094051.583841\n",
      "batch_idx: 1 loss: 0.000724919541926316 R2: 0.9165300058912382 time: 1703094054.2980857\n",
      "batch_idx: 2 loss: 0.0015277013372908322 R2: 0.9165234186185479 time: 1703094056.9136605\n",
      "batch_idx: 3 loss: 0.0008228528838514638 R2: 0.9164991896348609 time: 1703094059.5850556\n",
      "Training [94%] Loss: 0.001130076321422516 time: 1703094059.5850556\n",
      "weight: [ 1.48521932  1.53733801  1.18812383  0.57214487 -0.09624456  0.08002284\n",
      "  1.2601315  -1.09354963 -1.01482729 -0.18075819  0.69819783  0.86572307]\n",
      "epoch 472\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001444724929073096 R2: 0.9165248900340529 time: 1703094062.3469045\n",
      "batch_idx: 1 loss: 0.0007249038538321331 R2: 0.9165321195623207 time: 1703094064.9213822\n",
      "batch_idx: 2 loss: 0.0015276880702578943 R2: 0.9165255310029753 time: 1703094067.4817467\n",
      "batch_idx: 3 loss: 0.0008228775109820569 R2: 0.9165013295225461 time: 1703094070.111215\n",
      "Training [94%] Loss: 0.001130048591036295 time: 1703094070.111215\n",
      "weight: [ 1.48535006  1.53740328  1.18817506  0.57145409 -0.0955741   0.07950051\n",
      "  1.26040061 -1.09396291 -1.01521693 -0.1807655   0.6982283   0.86567328]\n",
      "epoch 473\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014446187320945598 R2: 0.9165270047018483 time: 1703094072.7586172\n",
      "batch_idx: 1 loss: 0.0007248888043594038 R2: 0.9165342239111484 time: 1703094075.3105571\n",
      "batch_idx: 2 loss: 0.0015276744942537518 R2: 0.9165276333918738 time: 1703094078.0891812\n",
      "batch_idx: 3 loss: 0.0008229016328608122 R2: 0.91650346004259 time: 1703094080.8344395\n",
      "Training [95%] Loss: 0.001130020915892132 time: 1703094080.8344395\n",
      "weight: [ 1.48547996  1.53746872  1.18822691  0.57076349 -0.09490401  0.07897799\n",
      "  1.26066956 -1.09437499 -1.0156018  -0.18077283  0.69825888  0.86563417]\n",
      "epoch 474\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014445136134730314 R2: 0.9165291109612925 time: 1703094083.6271608\n",
      "batch_idx: 1 loss: 0.0007248739147233385 R2: 0.916536319209371 time: 1703094086.2764823\n",
      "batch_idx: 2 loss: 0.0015276607870595594 R2: 0.9165297280955114 time: 1703094089.024115\n",
      "batch_idx: 3 loss: 0.0008229250859420086 R2: 0.9165055793106089 time: 1703094091.663808\n",
      "Training [95%] Loss: 0.0011299933502994844 time: 1703094091.663808\n",
      "weight: [ 1.48560904  1.53753433  1.18827934  0.57007306 -0.09423426  0.07845512\n",
      "  1.26093834 -1.09478585 -1.01598198 -0.1807802   0.69828947  0.86559779]\n",
      "epoch 475\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014444094812717787 R2: 0.9165312085671562 time: 1703094094.3173933\n",
      "batch_idx: 1 loss: 0.0007248593912570587 R2: 0.9165384054574875 time: 1703094096.9916708\n",
      "batch_idx: 2 loss: 0.0015276468343705823 R2: 0.9165318131104969 time: 1703094099.634453\n",
      "batch_idx: 3 loss: 0.0008229481593271613 R2: 0.9165076919665202 time: 1703094102.398035\n",
      "Training [95%] Loss: 0.0011299659665566452 time: 1703094102.398035\n",
      "weight: [ 1.48573727  1.53760013  1.18833239  0.56938282 -0.09356491  0.07793197\n",
      "  1.26120696 -1.09519554 -1.01635748 -0.18078757  0.69831996  0.86555357]\n",
      "epoch 476\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001444305971753699 R2: 0.9165332962220475 time: 1703094105.000259\n",
      "batch_idx: 1 loss: 0.0007248453050587006 R2: 0.9165404827104165 time: 1703094107.763413\n",
      "batch_idx: 2 loss: 0.0015276326628716522 R2: 0.9165338890723593 time: 1703094110.4342277\n",
      "batch_idx: 3 loss: 0.000822970687434175 R2: 0.9165097951888928 time: 1703094113.1212616\n",
      "Training [95%] Loss: 0.0011299386567795568 time: 1703094113.1212616\n",
      "weight: [ 1.48586468  1.5376661   1.18838603  0.56869276 -0.09289592  0.07740859\n",
      "  1.26147542 -1.09560404 -1.01672839 -0.18079497  0.69835044  0.86551035]\n",
      "epoch 477\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014442034640649594 R2: 0.9165353755277007 time: 1703094115.8127527\n",
      "batch_idx: 1 loss: 0.0007248314413143273 R2: 0.9165425511324946 time: 1703094118.3560803\n",
      "batch_idx: 2 loss: 0.0015276183212506796 R2: 0.9165359568984772 time: 1703094121.0172122\n",
      "batch_idx: 3 loss: 0.0008229926689140646 R2: 0.9165118887370969 time: 1703094123.6137938\n",
      "Training [95%] Loss: 0.0011299114738860076 time: 1703094123.6137938\n",
      "weight: [ 1.48599128  1.53773224  1.18844027  0.56800286 -0.09222728  0.07688486\n",
      "  1.2617437  -1.09601136 -1.01709475 -0.18080239  0.69838096  0.86547224]\n",
      "epoch 478\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014441018056993548 R2: 0.9165374460110497 time: 1703094126.2530775\n",
      "batch_idx: 1 loss: 0.0007248179608617097 R2: 0.9165446107404401 time: 1703094128.8539486\n",
      "batch_idx: 2 loss: 0.0015276037439900896 R2: 0.9165380154844358 time: 1703094131.4711897\n",
      "batch_idx: 3 loss: 0.0008230142388340333 R2: 0.9165139749025369 time: 1703094134.0312965\n",
      "Training [96%] Loss: 0.001129884437346297 time: 1703094134.0312965\n",
      "weight: [ 1.48611707  1.53779856  1.18849511  0.56731315 -0.09155903  0.07636091\n",
      "  1.26201182 -1.09641752 -1.01745661 -0.18080982  0.69841145  0.86543155]\n",
      "epoch 479\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014440008646705302 R2: 0.9165395072705567 time: 1703094136.5433311\n",
      "batch_idx: 1 loss: 0.0007248048349544447 R2: 0.9165466616223149 time: 1703094139.1790147\n",
      "batch_idx: 2 loss: 0.0015275889802280327 R2: 0.9165400654864003 time: 1703094141.7848969\n",
      "batch_idx: 3 loss: 0.0008230352755762033 R2: 0.9165160519251915 time: 1703094144.453029\n",
      "Training [96%] Loss: 0.0011298574888573027 time: 1703094144.453029\n",
      "weight: [ 1.48624206  1.53786504  1.18855053  0.56662361 -0.09089113  0.07583665\n",
      "  1.26227976 -1.09682252 -1.01781403 -0.18081728  0.69844189  0.86538878]\n",
      "epoch 480\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001443900850674271 R2: 0.9165415602356941 time: 1703094147.1836684\n",
      "batch_idx: 1 loss: 0.000724791960018084 R2: 0.9165487038945199 time: 1703094149.8668802\n",
      "batch_idx: 2 loss: 0.0015275740397043068 R2: 0.9165421072485886 time: 1703094152.5131702\n",
      "batch_idx: 3 loss: 0.0008230558199028386 R2: 0.916518120112135 time: 1703094155.234113\n",
      "Training [96%] Loss: 0.0011298306675748752 time: 1703094155.234113\n",
      "weight: [ 1.48636626  1.53793168  1.18860654  0.56593423 -0.0902236   0.07531211\n",
      "  1.26254753 -1.09722637 -1.01816706 -0.18082475  0.69847234  0.86534896]\n",
      "epoch 481\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014438016285427933 R2: 0.9165436044988271 time: 1703094157.9169216\n",
      "batch_idx: 1 loss: 0.0007247794475924907 R2: 0.9165507375899496 time: 1703094160.5235763\n",
      "batch_idx: 2 loss: 0.0015275588814843738 R2: 0.916544140186782 time: 1703094163.1896567\n",
      "batch_idx: 3 loss: 0.0008230759398670854 R2: 0.9165201805526617 time: 1703094165.8574305\n",
      "Training [96%] Loss: 0.0011298039743716857 time: 1703094165.8574305\n",
      "weight: [ 1.48648967  1.53799849  1.18866314  0.56524503 -0.08955645  0.07478733\n",
      "  1.26281513 -1.09762908 -1.01851573 -0.18083224  0.69850279  0.86530919]\n",
      "epoch 482\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014437031560096591 R2: 0.9165456400043868 time: 1703094168.4793322\n",
      "batch_idx: 1 loss: 0.0007247672533164501 R2: 0.9165527627985183 time: 1703094171.0681846\n",
      "batch_idx: 2 loss: 0.0015275435470580114 R2: 0.916546164810258 time: 1703094173.7035306\n",
      "batch_idx: 3 loss: 0.0008230955577563316 R2: 0.916522232226176 time: 1703094176.3281512\n",
      "Training [96%] Loss: 0.001129777378535113 time: 1703094176.3281512\n",
      "weight: [ 1.4866123   1.53806546  1.18872032  0.56455598 -0.08888965  0.07426224\n",
      "  1.26308254 -1.09803066 -1.01886012 -0.18083974  0.6985332   0.86526762]\n",
      "epoch 483\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014436055441347218 R2: 0.9165476672909078 time: 1703094179.0228975\n",
      "batch_idx: 1 loss: 0.0007247553252808433 R2: 0.9165547796124448 time: 1703094181.613901\n",
      "batch_idx: 2 loss: 0.0015275280371830284 R2: 0.9165481812475479 time: 1703094184.2652733\n",
      "batch_idx: 3 loss: 0.0008231147136163212 R2: 0.9165242755305341 time: 1703094186.9758162\n",
      "Training [97%] Loss: 0.0011297509050537287 time: 1703094186.9758162\n",
      "weight: [ 1.48673417  1.53813258  1.18877807  0.5638671  -0.08822321  0.07373691\n",
      "  1.26334978 -1.09843111 -1.01920027 -0.18084727  0.69856361  0.86522731]\n",
      "epoch 484\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001443508695989906 R2: 0.9165496860930865 time: 1703094189.6889033\n",
      "batch_idx: 1 loss: 0.0007247437308421912 R2: 0.9165567880777117 time: 1703094192.4731512\n",
      "batch_idx: 2 loss: 0.0015275123289466893 R2: 0.916550189218319 time: 1703094195.2031488\n",
      "batch_idx: 3 loss: 0.0008231334424128166 R2: 0.9165263109742577 time: 1703094197.8826952\n",
      "Training [97%] Loss: 0.0011297245495479008 time: 1703094197.8826952\n",
      "weight: [ 1.48685527  1.53819987  1.1888364   0.56317838 -0.08755715  0.07321128\n",
      "  1.26361683 -1.09883045 -1.01953621 -0.18085481  0.69859401  0.86518761]\n",
      "epoch 485\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014434126009044352 R2: 0.9165516964742061 time: 1703094200.496033\n",
      "batch_idx: 1 loss: 0.0007247324334601263 R2: 0.9165587882776839 time: 1703094203.2129261\n",
      "batch_idx: 2 loss: 0.001527496450619182 R2: 0.916552189075617 time: 1703094205.9214568\n",
      "batch_idx: 3 loss: 0.000823151700541133 R2: 0.9165283380079773 time: 1703094208.4828763\n",
      "Training [97%] Loss: 0.0011296982963812192 time: 1703094208.4828763\n",
      "weight: [ 1.48697562  1.5382673   1.1888953   0.56248981 -0.08689144  0.07268542\n",
      "  1.2638837  -1.09922867 -1.01986801 -0.18086236  0.69862439  0.86514684]\n",
      "epoch 486\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014433173129435783 R2: 0.9165536987465461 time: 1703094211.1429644\n",
      "batch_idx: 1 loss: 0.0007247214075289897 R2: 0.9165607802904757 time: 1703094213.8308847\n",
      "batch_idx: 2 loss: 0.001527480401331543 R2: 0.9165541808736938 time: 1703094216.5295782\n",
      "batch_idx: 3 loss: 0.0008231695185704236 R2: 0.916530356967262 time: 1703094219.166613\n",
      "Training [97%] Loss: 0.0011296721600936336 time: 1703094219.166613\n",
      "weight: [ 1.48709522  1.53833489  1.18895477  0.5618014  -0.0862261   0.07215924\n",
      "  1.26415039 -1.09962579 -1.02019572 -0.18086994  0.69865476  0.86510666]\n",
      "epoch 487\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014432227687258732 R2: 0.9165556927684408 time: 1703094221.8962126\n",
      "batch_idx: 1 loss: 0.000724710689373637 R2: 0.9165627641703222 time: 1703094224.533057\n",
      "batch_idx: 2 loss: 0.0015274641703827356 R2: 0.9165561645030149 time: 1703094227.1842947\n",
      "batch_idx: 3 loss: 0.0008231869143776764 R2: 0.9165323680937488 time: 1703094229.8224847\n",
      "Training [97%] Loss: 0.0011296461357149805 time: 1703094229.8224847\n",
      "weight: [ 1.48721408  1.53840262  1.18901481  0.56111314 -0.08556112  0.07163288\n",
      "  1.26441689 -1.10002182 -1.02051937 -0.18087752  0.69868512  0.86506696]\n",
      "epoch 488\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014431289669280378 R2: 0.9165576786353059 time: 1703094232.4982893\n",
      "batch_idx: 1 loss: 0.0007247002528196639 R2: 0.9165647399928026 time: 1703094235.1872842\n",
      "batch_idx: 2 loss: 0.0015274477757731219 R2: 0.9165581401986602 time: 1703094237.9059937\n",
      "batch_idx: 3 loss: 0.0008232038665405754 R2: 0.9165343711177532 time: 1703094240.7442396\n",
      "Training [98%] Loss: 0.0011296202155153497 time: 1703094240.7442396\n",
      "weight: [ 1.48733221  1.5384705   1.18907541  0.56042502 -0.08489651  0.07110612\n",
      "  1.2646832  -1.10041676 -1.02083902 -0.18088513  0.69871546  0.86502669]\n",
      "epoch 489\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014430359303702078 R2: 0.9165596565332865 time: 1703094243.5690558\n",
      "batch_idx: 1 loss: 0.0007246900853891566 R2: 0.9165667078280915 time: 1703094246.2842257\n",
      "batch_idx: 2 loss: 0.0015274312167145234 R2: 0.9165601079974183 time: 1703094248.934972\n",
      "batch_idx: 3 loss: 0.000823220396764869 R2: 0.9165363662865265 time: 1703094251.6966991\n",
      "Training [98%] Loss: 0.001129594407309689 time: 1703094251.6966991\n",
      "weight: [ 1.48744961  1.53853853  1.18913657  0.55973705 -0.08423225  0.07057932\n",
      "  1.26494932 -1.10081062 -1.0211547  -0.18089275  0.6987458   0.86498681]\n",
      "epoch 490\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014429436187684704 R2: 0.9165616264056181 time: 1703094254.337964\n",
      "batch_idx: 1 loss: 0.0007246802048213668 R2: 0.9165686677329189 time: 1703094256.9074664\n",
      "batch_idx: 2 loss: 0.0015274144896173032 R2: 0.9165620678745808 time: 1703094259.6297822\n",
      "batch_idx: 3 loss: 0.0008232365150733992 R2: 0.9165383537273174 time: 1703094262.3209825\n",
      "Training [98%] Loss: 0.001129568707070135 time: 1703094262.3209825\n",
      "weight: [ 1.48756629  1.5386067   1.18919829  0.55904923 -0.08356836  0.07005188\n",
      "  1.26521525 -1.1012034  -1.02146648 -0.18090038  0.69877612  0.86494717]\n",
      "epoch 491\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014428520320472218 R2: 0.9165635883466765 time: 1703094265.0523283\n",
      "batch_idx: 1 loss: 0.0007246705928246127 R2: 0.9165706197783837 time: 1703094267.6060941\n",
      "batch_idx: 2 loss: 0.001527397605899196 R2: 0.9165640199963152 time: 1703094270.2023253\n",
      "batch_idx: 3 loss: 0.0008232522120872 R2: 0.9165403333229986 time: 1703094272.8350127\n",
      "Training [98%] Loss: 0.0011295431107145577 time: 1703094272.8350127\n",
      "weight: [ 1.48768225  1.538675    1.18926056  0.55836154 -0.08290482  0.06952488\n",
      "  1.26548098 -1.10159512 -1.02177439 -0.18090803  0.69880643  0.86490726]\n",
      "epoch 492\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014427611770594477 R2: 0.9165655424786591 time: 1703094275.5830922\n",
      "batch_idx: 1 loss: 0.0007246612433887093 R2: 0.916572564025431 time: 1703094278.2019992\n",
      "batch_idx: 2 loss: 0.001527380565298993 R2: 0.9165659643870173 time: 1703094281.0286136\n",
      "batch_idx: 3 loss: 0.0008232675045974315 R2: 0.9165423052522076 time: 1703094283.850919\n",
      "Training [98%] Loss: 0.0011295176225861454 time: 1703094283.850919\n",
      "weight: [ 1.48779751  1.53874345  1.18932339  0.55767399 -0.08224165  0.06899626\n",
      "  1.26574652 -1.10198578 -1.02207847 -0.18091569  0.69883673  0.86486769]\n",
      "epoch 493\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014426710276472178 R2: 0.9165674887911021 time: 1703094286.5207093\n",
      "batch_idx: 1 loss: 0.0007246521633325332 R2: 0.9165745005387766 time: 1703094289.189916\n",
      "batch_idx: 2 loss: 0.0015273633679981809 R2: 0.916567901086012 time: 1703094291.8391733\n",
      "batch_idx: 3 loss: 0.0008232823966010076 R2: 0.9165442695931046 time: 1703094294.42918\n",
      "Training [99%] Loss: 0.001129492238894735 time: 1703094294.42918\n",
      "weight: [ 1.48791208  1.53881203  1.18938676  0.55698658 -0.08157883  0.06847018\n",
      "  1.26601186 -1.10237539 -1.02237877 -0.18092337  0.69886701  0.86482817]\n",
      "epoch 494\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001442581582637816 R2: 0.9165694273761084 time: 1703094297.016514\n",
      "batch_idx: 1 loss: 0.0007246433410057668 R2: 0.9165764293686051 time: 1703094299.6583507\n",
      "batch_idx: 2 loss: 0.001527346021371782 R2: 0.9165698301713121 time: 1703094302.2539136\n",
      "batch_idx: 3 loss: 0.0008232968902567207 R2: 0.9165462263094769 time: 1703094304.813006\n",
      "Training [99%] Loss: 0.0011294669588180215 time: 1703094304.813006\n",
      "weight: [ 1.48802594  1.53888074  1.18945069  0.5562993  -0.08091638  0.06793785\n",
      "  1.266277   -1.10276396 -1.02267534 -0.18093106  0.69889729  0.8647886 ]\n",
      "epoch 495\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014424928413363756 R2: 0.916571358310539 time: 1703094307.5007713\n",
      "batch_idx: 1 loss: 0.0007246347706355939 R2: 0.9165783506065045 time: 1703094310.1211371\n",
      "batch_idx: 2 loss: 0.0015273285258412313 R2: 0.9165717517620197 time: 1703094312.8407671\n",
      "batch_idx: 3 loss: 0.000823310988550676 R2: 0.916548175532952 time: 1703094315.4744637\n",
      "Training [99%] Loss: 0.0011294417815909692 time: 1703094315.4744637\n",
      "weight: [ 1.48813913  1.53894958  1.18951515  0.55561216 -0.08025426  0.06741863\n",
      "  1.26654195 -1.10315148 -1.02296822 -0.18093876  0.69892755  0.86474928]\n",
      "epoch 496\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001442404785012953 R2: 0.9165732816320388 time: 1703094318.213386\n",
      "batch_idx: 1 loss: 0.0007246264588320857 R2: 0.9165802642363954 time: 1703094320.8703792\n",
      "batch_idx: 2 loss: 0.0015273108836346486 R2: 0.9165736657124814 time: 1703094323.6175616\n",
      "batch_idx: 3 loss: 0.0008233247150561229 R2: 0.916550117314736 time: 1703094326.3324938\n",
      "Training [99%] Loss: 0.0011294167106339526 time: 1703094326.3324938\n",
      "weight: [ 1.48825163  1.53901855  1.18958016  0.55492511 -0.07959258  0.06686815\n",
      "  1.26680668 -1.10353798 -1.02325745 -0.18094648  0.6989578   0.86470993]\n",
      "epoch 497\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014423174133902884 R2: 0.9165751973830684 time: 1703094328.9841833\n",
      "batch_idx: 1 loss: 0.000724618385507636 R2: 0.9165821704943526 time: 1703094330.5688274\n",
      "batch_idx: 2 loss: 0.0015272930987336275 R2: 0.9165755725495769 time: 1703094333.239094\n",
      "batch_idx: 3 loss: 0.0008233380258222093 R2: 0.9165520516615399 time: 1703094335.9100797\n",
      "Training [99%] Loss: 0.0011293917308634403 time: 1703094335.9100797\n",
      "weight: [ 1.48836346  1.53908765  1.1896457   0.55423826 -0.07893104  0.06639221\n",
      "  1.26707122 -1.10392345 -1.02354307 -0.18095421  0.69898805  0.86467068]\n",
      "epoch 498\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001442230714746321 R2: 0.9165771056976185 time: 1703094338.5563054\n",
      "batch_idx: 1 loss: 0.0007246105746484076 R2: 0.9165840689968417 time: 1703094341.2724156\n",
      "batch_idx: 2 loss: 0.0015272751756214655 R2: 0.916577471254674 time: 1703094343.9723024\n",
      "batch_idx: 3 loss: 0.0008233510310056749 R2: 0.9165539784733656 time: 1703094346.6978905\n",
      "Training [100%] Loss: 0.0011293668740054673 time: 1703094346.6978905\n",
      "weight: [ 1.48847463  1.53915687  1.18971178  0.55355135 -0.07827041  0.0657287\n",
      "  1.26733555 -1.1043079  -1.02382512 -0.18096195  0.69901828  0.86463156]\n",
      "epoch 499\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.001442144687543135 R2: 0.9165790064490494 time: 1703094349.3805556\n",
      "batch_idx: 1 loss: 0.0007246029608299377 R2: 0.9165859609316047 time: 1703094351.9260807\n",
      "batch_idx: 2 loss: 0.0015272571081791238 R2: 0.9165793645979555 time: 1703094354.563716\n",
      "batch_idx: 3 loss: 0.00082336341555848 R2: 0.916555897189738 time: 1703094357.1533604\n",
      "Training [100%] Loss: 0.001129342043027669 time: 1703094357.1533604\n",
      "weight: [ 1.48858514  1.53922621  1.1897784   0.55286503 -0.07760869  0.06555043\n",
      "  1.26759967 -1.10469134 -1.02410365 -0.18096971  0.6990485   0.86459244]\n",
      "epoch 500\n",
      "-------------------------------\n",
      "batch_idx: 0 loss: 0.0014420592378452542 R2: 0.9165808998204884 time: 1703094359.7581685\n",
      "batch_idx: 1 loss: 0.0007245957068164605 R2: 0.9165878432866302 time: 1703094362.328091\n",
      "batch_idx: 2 loss: 0.0015272389374753005 R2: 0.9165812459721978 time: 1703094364.9519606\n",
      "batch_idx: 3 loss: 0.0008233755023437609 R2: 0.9165577999493392 time: 1703094367.58695\n",
      "Training [100%] Loss: 0.001129317346120194 time: 1703094367.58695\n",
      "weight: [ 1.48869497  1.53929569  1.18984556  0.55217757 -0.07695122  0.06406488\n",
      "  1.2678636  -1.1050738  -1.02437867 -0.18097746  0.69907872  0.86455345]\n",
      "train_MSE: 0.0011323706662730768\n",
      "train_RMSE: 0.03365071568738289\n",
      "train_MAE: 0.02753208651272298\n",
      "train_MAPE: 0.06024905580646352\n",
      "train_R2: 0.9165577999493392\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "weights =[0.68756473 , 1.2864305 ,  0.5411694 , -0.01524038 , 0.5852044 ,  0.6762012,\n",
    "  0.35593897 , 0.22628789,  0.38244092,  0.35140917,  0.86482936 , 0.8531242,\n",
    "  0.09241156 , 0.6720707  , 0.38071635,  0.95416117 , 0.63409   ,  0.40179932,\n",
    "  0.7345088  , 0.6243114  , 0.3178202 , -0.2618623  , 0.18122938,  1.0447433,\n",
    "  0.48699683 , 0.7739934  , 0.38703147 , 0.48046085,  0.5525667 ,  0.52838504,\n",
    "  0.28538367 , 0.30099392,  0.74503726 , 0.67772216,  0.3839896 ,  0.417687]\n",
    "weights = npp.array(weights, requires_grad=True)\n",
    "'''\n",
    "weights = params\n",
    "loss_list=[]\n",
    "r2_list=[]\n",
    "\n",
    "n_epochs=500\n",
    "\n",
    "start_time=time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss  = []\n",
    "    total_r2  = []\n",
    "    print(f\"epoch {epoch+1}\\n-------------------------------\")\n",
    "    for it, batch_index in enumerate (chain(*[X_batches])):\n",
    "        # Update the weights by one optimizer step\n",
    "        \n",
    "        X_batch = X[batch_index]\n",
    "        Y_batch = Y[batch_index]\n",
    "        weights, _, _ = opt.step(cost, weights, X_batch, Y_batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        predictions = [QNN(weights, x) for x in X]\n",
    "        r2 = R2(Y, predictions)\n",
    "        cost_t=cost(weights,X_batch,Y_batch)\n",
    "        total_loss.append(cost_t)\n",
    "        total_r2.append(r2)\n",
    "        end_timet=time.time()\n",
    "        print(\"batch_idx:\",it,\"loss:\",cost_t,\"R2:\",r2,\"time:\",end_timet)\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    r2_list.append(sum(total_r2)/len(total_r2))\n",
    "    print('Training [{:.0f}%]'.format(100. * (epoch + 1) / n_epochs),\"Loss:\", loss_list[-1], \"time:\",end_timet)\n",
    "    print(\"weight:\",weights)\n",
    "    \n",
    "    \n",
    "predictions = [QNN(weights, x) for x in X]\n",
    "\n",
    "train_R2 = R2(Y, predictions)\n",
    "train_MSE=metrics.mean_squared_error(Y,predictions)\n",
    "train_RMSE=train_MSE**(1/2)\n",
    "train_MAE=metrics.mean_absolute_error(Y,predictions)\n",
    "train_MAPE=metrics.mean_absolute_percentage_error(Y,predictions)\n",
    "\n",
    "print(\"train_MSE:\",train_MSE)\n",
    "print(\"train_RMSE:\",train_RMSE)\n",
    "print(\"train_MAE:\",train_MAE)\n",
    "print(\"train_MAPE:\",train_MAPE)\n",
    "print(\"train_R2:\",train_R2)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "plt.title(\"MSE value against epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.plot(range(len(loss_list)), np.log(loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf38ce2-431b-47e0-825d-5b3fe912706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=xtv_test_log\n",
    "Y_test=ytv_test_log\n",
    "test_predictions = [QNN(weights, x) for x in X_test]\n",
    "\n",
    "test_R2 = R2(Y_test, test_predictions)\n",
    "test_MSE=metrics.mean_squared_error(Y_test,test_predictions)\n",
    "test_RMSE=test_MSE**(1/2)\n",
    "test_MAE=metrics.mean_absolute_error(Y_test,test_predictions)\n",
    "test_MAPE=metrics.mean_absolute_percentage_error(Y_test,test_predictions)\n",
    "\n",
    "print(\"test_MSE:\",test_MSE)\n",
    "print(\"test_RMSE:\",test_RMSE)\n",
    "print(\"test_MAE:\",test_MAE)\n",
    "print(\"test_MAPE:\",test_MAPE)\n",
    "print(\"test_R2:\",test_R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
